{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/images/my/1.png","path":"images/my/1.png","modified":0,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/uploads/alipay.png","path":"uploads/alipay.png","modified":0,"renderable":1},{"_id":"themes/next/source/uploads/avatar.png","path":"uploads/avatar.png","modified":0,"renderable":1},{"_id":"themes/next/source/uploads/weichatpay.png","path":"uploads/weichatpay.png","modified":0,"renderable":1},{"_id":"source/images/my/2.png","path":"images/my/2.png","modified":0,"renderable":0},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"themes/next/debug.log","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1663213603378},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1663213603378},{"_id":"themes/next/README.en.md","hash":"4ece25ee5f64447cd522e54cb0fffd9a375f0bd4","modified":1663213603378},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1663213603378},{"_id":"themes/next/bower.json","hash":"be0a430362cb73a7e3cf9ecf51a67edf8214b637","modified":1663213603378},{"_id":"themes/next/_config.yml","hash":"84af073dbab8c9e2116f9956e4cbe48fd1ab053d","modified":1663213603378},{"_id":"themes/next/README.md","hash":"500b5606eb6a09c979d16128f8b00f4bf9bc95ac","modified":1663213603378},{"_id":"themes/next/package.json","hash":"7e87b2621104b39a30488654c2a8a0c6a563574b","modified":1663213603383},{"_id":"source/about/index.md","hash":"1ec5af9aace8947e5b85491ef9992abff6a103b3","modified":1663213603369},{"_id":"source/categories/index.md","hash":"f5140a91e5d63149267bc971761a8b9fa2bc8af7","modified":1663213603369},{"_id":"source/tags/index.md","hash":"a41b6d2bd39231f3e05a6d508a6561036a581403","modified":1663213603370},{"_id":"themes/next/languages/de.yml","hash":"306db8c865630f32c6b6260ade9d3209fbec8011","modified":1663213603378},{"_id":"themes/next/languages/default.yml","hash":"4cc6aeb1ac09a58330e494c8771773758ab354af","modified":1663213603378},{"_id":"themes/next/languages/en.yml","hash":"e7def07a709ef55684490b700a06998c67f35f39","modified":1663213603379},{"_id":"themes/next/languages/fr-FR.yml","hash":"24180322c83587a153cea110e74e96eacc3355ad","modified":1663213603379},{"_id":"themes/next/languages/id.yml","hash":"2835ea80dadf093fcf47edd957680973f1fb6b85","modified":1663213603379},{"_id":"themes/next/languages/ja.yml","hash":"1c3a05ab80a6f8be63268b66da6f19da7aa2c638","modified":1663213603379},{"_id":"themes/next/languages/ko.yml","hash":"be150543379150f78329815af427bf152c0e9431","modified":1663213603379},{"_id":"themes/next/languages/pt-BR.yml","hash":"958e49571818a34fdf4af3232a07a024050f8f4e","modified":1663213603379},{"_id":"themes/next/languages/pt.yml","hash":"36c8f60dacbe5d27d84d0e0d6974d7679f928da0","modified":1663213603379},{"_id":"themes/next/languages/ru.yml","hash":"1549a7c2fe23caa7cbedcd0aa2b77c46e57caf27","modified":1663213603379},{"_id":"themes/next/languages/zh-Hans.yml","hash":"3c0c7dfd0256457ee24df9e9879226c58cb084b5","modified":1663213603379},{"_id":"themes/next/languages/zh-hk.yml","hash":"1c917997413bf566cb79e0975789f3c9c9128ccd","modified":1663213603379},{"_id":"themes/next/languages/zh-tw.yml","hash":"0b2c18aa76570364003c8d1cd429fa158ae89022","modified":1663213603379},{"_id":"themes/next/layout/category.swig","hash":"82e7bc278559b4335ad974659104eaaf04863032","modified":1663213603383},{"_id":"themes/next/layout/archive.swig","hash":"5de4dca06b05d99e4f6bad617a4b8f4f3592fb01","modified":1663213603383},{"_id":"themes/next/layout/index.swig","hash":"03e8a2cda03bad42ac0cb827025eb81f95d496a2","modified":1663213603383},{"_id":"themes/next/layout/post.swig","hash":"2d5f8d7f0a96b611e2d5a5e4d111fc17726a990f","modified":1663213603383},{"_id":"themes/next/layout/page.swig","hash":"baa667bc801349d5c4984c0f172973d3780400df","modified":1663213603383},{"_id":"themes/next/layout/schedule.swig","hash":"f93c53f6fd5c712584f6efba6f770c30fa8a3e80","modified":1663213603383},{"_id":"themes/next/layout/tag.swig","hash":"2e73ee478e981092ea9a5d10dd472a9461db395b","modified":1663213603383},{"_id":"themes/next/layout/_layout.swig","hash":"98910163f4bb2856692fdbb55d6e82233fb0c24e","modified":1663213603379},{"_id":"themes/next/scripts/merge-configs.js","hash":"13c8b3a2d9fce06c2488820d9248d190c8100e0a","modified":1663213603383},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1663213603383},{"_id":"themes/next/scripts/openfile.js","hash":"eec41e9ff5dda592a567210cfbc2c369cfbde87d","modified":1663213603383},{"_id":"themes/next/source/.DS_Store","hash":"4017d53f5015aad12744b8c46d60e463741b3ad3","modified":1663213603384},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1663213603402},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1663213603402},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1663213603402},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1663213603389},{"_id":"source/_posts/ML框架/Cuda、Tensorflow、Pytorch版本匹配.md","hash":"5aba1dc5788d26c6cd9ebafacae1cfe801488a76","modified":1663213603358},{"_id":"source/_posts/ML框架/Tensorflow和Pytorch的比较.md","hash":"03a298ee90b412e7ab1a199cb37c2833abb1696a","modified":1663213603359},{"_id":"source/_posts/ML框架/Tf 2.0的几个变动.md","hash":"65b6111362c8c25eba68a6c3e5a6ab10d5438460","modified":1663213603359},{"_id":"source/_posts/ML框架/Tf中有关Graph和Session的几个问题.md","hash":"6b0b540a7c12e1aafd506a1333da2ef3b6e4d3ab","modified":1663213603359},{"_id":"source/_posts/ML框架/Tf一些常用方法记录.md","hash":"149cf1d16318d1468d5ba24ff579420eedf45f6f","modified":1663213603359},{"_id":"source/_posts/ML框架/Tf中的变量作用域和名称作用域.md","hash":"560507cb5125c2dd1c53ed45cc1d5dc4d8df99f5","modified":1663213603359},{"_id":"source/_posts/前端开发/前端学习流程.md","hash":"6965c6ba0d4f8dbc31e79663ee4ec352e9a64838","modified":1663213603359},{"_id":"source/_posts/信息安全/RSA加密算法.markdown","hash":"dcfc08f1430ddffb30ac08a9e080ff76207d6689","modified":1663213603359},{"_id":"source/_posts/前端开发/前端开发环境配置.md","hash":"2d44a89247e06908634176e27385c8a548712a82","modified":1663213603359},{"_id":"source/_posts/搜推广/Online Learning中的优化器.md","hash":"60721f75d0d64444f379881185e4fb1ec59dd9ff","modified":1663213603360},{"_id":"source/_posts/搜推广/推荐系统实战.md","hash":"ae890650455cf5a520954c742c5fc33cedf7a5a1","modified":1663213603360},{"_id":"source/_posts/搜推广/浅谈FM和FFM.md","hash":"582ab2c13b8042adec5bf7c3eaa01cb39104c7d6","modified":1663213603360},{"_id":"source/_posts/搜推广/计算广告基础概念.md","hash":"fc33c290ea89d2cd548eb9bcd4f4d943f775166c","modified":1663213603360},{"_id":"source/_posts/搜推广/理解召回和LTR.md","hash":"2d1d912aa87f9ed60c2d1da56a96539ad376e316","modified":1663213603360},{"_id":"source/_posts/数学/伪多项式时间复杂度.md","hash":"26b54dcc6cf4ad811e9f4e6a500e54928416586f","modified":1663213603361},{"_id":"source/_posts/数学/关于凸、P和NP.md","hash":"f25003cf50c94e54ed748e5a18c46cc8fd074ce7","modified":1663213603361},{"_id":"source/_posts/数学/内积、叉积和外积.md","hash":"24e912140dce8e46072a3509445fbef847244005","modified":1663213603361},{"_id":"source/_posts/数学/可导和可微.md","hash":"2fd42bd3605a85b03f3ecf281cf5acf43172c845","modified":1663213603361},{"_id":"source/_posts/搜推广/uplift model理解.md","hash":"2e392887236ad0f5fb6f276e97defefc935a172b","modified":1666692068533},{"_id":"source/_posts/数学/拉格朗日对偶.md","hash":"c7cb01a54e5892c6bd69c2aa7d8922d12cb8ed61","modified":1663213603361},{"_id":"source/_posts/数学/整数规划中的分支定界和分支切割.md","hash":"071b7e661e72f12ce6f3de09eb4843093308425a","modified":1663213603361},{"_id":"source/_posts/数学/计算复杂度公式.md","hash":"3db824bd579fdc0422d8faa064d0d7fe96ddc8a5","modified":1663213603361},{"_id":"source/_posts/机器学习/CART与普通决策树的区别.md","hash":"59343e13c01f5b60f5c473d4bb14f2c4b1ef0bd4","modified":1663213603361},{"_id":"source/_posts/机器学习/Xgboost和LightGBM调参.md","hash":"ceec014af776f5321856f5e31ccc95ef42e969c1","modified":1663213603361},{"_id":"source/_posts/数学/时间序列中随机过程.md","hash":"e5f5ddadf98d9aecab21c468c60beb3e5684c750","modified":1663213603361},{"_id":"source/_posts/机器学习/xgboost调参.md","hash":"c8e88c046c3713438b014695a1cd6c42c30a4fef","modified":1663213603361},{"_id":"source/_posts/机器学习/关于PCA和SVD分解.md","hash":"75d0e6b73633e2ba41270472f2f97f8a0acb56cb","modified":1663213603361},{"_id":"source/_posts/机器学习/关于模型选型.md","hash":"1aea504332457f93f924106e3ec0a90560eca991","modified":1663213603361},{"_id":"source/_posts/机器学习/关于特征值分布不均匀的问题.md","hash":"889b305d7b9725c8bfc5e967e30e44baa2044f0b","modified":1663213603361},{"_id":"source/_posts/机器学习/关于特征工程.md","hash":"2da031276def5fed56aa2bd9f02e9c95ea25f289","modified":1663213603361},{"_id":"source/_posts/机器学习/关于特征归一化的一些理解.md","hash":"0d286b010d068f0d99b449fb8807f2ea899e9c4b","modified":1663213603361},{"_id":"source/_posts/机器学习/损失函数之交叉熵和MSE.md","hash":"662501e71f35099c3fe44cdcbf5e74d73bc5db70","modified":1663213603361},{"_id":"source/_posts/机器学习/支持向量机.markdown","hash":"d8089241dd29647d52ccc193a9a8265bdebd61d6","modified":1663213603361},{"_id":"source/_posts/机器学习/最大熵与最大似然估计.md","hash":"a4316d839fe02da2649b8bd09015ce8c109aa5fe","modified":1663213603362},{"_id":"source/_posts/机器学习/特征是否越多越好.md","hash":"273a6bbaa02482937e8729b4fc60ba9ffa03558b","modified":1663213603362},{"_id":"source/_posts/机器学习/生成模型和判别模型的直观解释.md","hash":"3900311508b85e630f48ef7c7f96e0e8af56de94","modified":1663213603362},{"_id":"source/_posts/机器学习/类别不均衡问题的调参.md","hash":"de272d67d83a167bdbd99eadf8d35d088a8c2295","modified":1663213603362},{"_id":"source/_posts/深度学习/Dead ReLu问题.md","hash":"34482fd1bea748d33fcfc6b5a93d4ac731641fc2","modified":1663213603362},{"_id":"source/_posts/深度学习/ML2020笔记-ELMO、BERT和GPT.md","hash":"761b7c14dd569ad2f776740499abd42c91f2031b","modified":1663213603362},{"_id":"source/_posts/深度学习/ML2020笔记-基于RNN的生成模型和Attention.md","hash":"4a75218d415eb9ace78210ec9fe8c0424727c25c","modified":1663213603362},{"_id":"source/_posts/深度学习/RNN的BPTT.md","hash":"261900ed3699c0d10b9855c53d7d00d2270e89e9","modified":1663213603362},{"_id":"source/_posts/深度学习/NAS系列文章解读.md","hash":"b798d1a91b05c191c8d645db57d13bcc2e3d82b4","modified":1663213603362},{"_id":"source/_posts/深度学习/关于policy network.md","hash":"f36d68de87808bf4fa54b63d258a634a8ad1a9d5","modified":1663213603362},{"_id":"source/_posts/编程开发/Github代理加速.md","hash":"c08be2347fd8fc6836098bf0c41138d42795b277","modified":1663213603362},{"_id":"source/_posts/深度学习/Attention和Transformer.md","hash":"50fc0880ace6c2a57eb467727030fa6f573f4583","modified":1666079611165},{"_id":"source/_posts/编程开发/各语言对象和变量的关系.md","hash":"e2a696f490593fc07110f63ee7ec4cb28977bde3","modified":1663213603368},{"_id":"source/_posts/编程开发/后端技术栈.md","hash":"9324b531775dff6298e600f2bdca0c4588fd8a77","modified":1663213603368},{"_id":"source/_posts/自然语言处理/word2vec详解.md","hash":"47efa28a02729739d06656904769b6e8743d6db2","modified":1663213603368},{"_id":"source/_posts/自然语言处理/《自然语言处理入门》笔记.md","hash":"bcf48d75b10512b75ed62175cf8751687bf90c31","modified":1663213603368},{"_id":"source/_posts/自然语言处理/理解LSI、PLSI、LDA和LFM.md","hash":"e5ec0e4b4c2a8441006b3b74695870c6f3e51a6a","modified":1663213603368},{"_id":"source/images/my/1.png","hash":"7d2b9aeddb64e5fe03ea7c41068bb5c31f658b27","modified":1663213603369},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1663213603379},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1663213603379},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1663213603379},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"b16fcbf0efd20c018d7545257a8533c497ea7647","modified":1663213603379},{"_id":"themes/next/layout/_macro/post.swig","hash":"9481f43ed356e00df7b519e92ad0becebc9e1505","modified":1663213603379},{"_id":"themes/next/layout/_macro/reward.swig","hash":"37e5b7c42ec17b9b6b786c5512bcc481a21c974e","modified":1663213603379},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"1034191ecd87e783ae0475854dc77a076bb420a6","modified":1663213603380},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"14e785adeb0e671ba0ff9a553e6f0d8def6c670c","modified":1663213603380},{"_id":"themes/next/layout/_partials/comments.swig","hash":"1c7d3c975e499b9aa3119d6724b030b7b00fc87e","modified":1663213603380},{"_id":"themes/next/layout/_partials/footer.swig","hash":"7172c6053118b7c291a56a7860128a652ae66b83","modified":1663213603380},{"_id":"themes/next/layout/_partials/head.swig","hash":"6a7eb93d8aa7d4baa472890bd666b921f449d8af","modified":1663213603380},{"_id":"themes/next/layout/_partials/header.swig","hash":"a1ffbb691dfad3eaf2832a11766e58a179003b8b","modified":1663213603380},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1663213603380},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1663213603380},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1663213603380},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1663213603381},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1663213603381},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"9baf90f7c40b3b10f288e9268c3191e895890cea","modified":1663213603381},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1663213603382},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1663213603382},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1663213603382},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1663213603382},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1663213603382},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1663213603382},{"_id":"themes/next/scripts/tags/button.js","hash":"62e6dbeb53d07627a048132c79630b45d9a8f2cc","modified":1663213603383},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1663213603383},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1663213603383},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1663213603383},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1663213603383},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1663213603383},{"_id":"themes/next/scripts/tags/note.js","hash":"21b102db8a01c7b15ae2c0ea3ef3d4cf807ec6ed","modified":1663213603384},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1663213603389},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1663213603389},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1663213603389},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1663213603389},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1663213603389},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1663213603389},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1663213603389},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1663213603389},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1663213603389},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1663213603390},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1663213603390},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1663213603390},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1663213603390},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1663213603390},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1663213603390},{"_id":"themes/next/source/uploads/alipay.png","hash":"4c4c4cf01bbdaa2f5e8280ab79f00529f9069d9c","modified":1663213603401},{"_id":"themes/next/source/uploads/avatar.png","hash":"23c03d14b32d6fed422fa2a21f4f4e437b510341","modified":1663213603401},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1663213603381},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1663213603381},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1663213603387},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1663213603387},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1663213603388},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1663213603389},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1663213603389},{"_id":"themes/next/source/uploads/weichatpay.png","hash":"72cd85497ee9a0c9a8d18cdac47caf5a6fdff78b","modified":1663213603402},{"_id":"source/_posts/大数据/Databus/Databus学习笔记.md","hash":"f0168f7331f500493fb62cb457cea88d50d8a4b3","modified":1663213603359},{"_id":"source/_posts/大数据/Flink/Flink学习笔记.md","hash":"bb39910010ac9ccb1fa4a47a11fc7abd1f030f7a","modified":1663213603359},{"_id":"source/_posts/大数据/Hive/hdfs文件理解.md","hash":"8c10dc0fac3cad83cab9e3c49e0ff581ad180ffd","modified":1663213603359},{"_id":"source/_posts/大数据/Hive/hive建表时的format.md","hash":"b655195d230a7e8b24a645fe9e2b0916d4bb5829","modified":1663213603359},{"_id":"source/_posts/大数据/Kafka/Kafka学习笔记.md","hash":"5925e4df701fc850d375f6a6d9210103b36becea","modified":1663213603359},{"_id":"source/_posts/大数据/Spark/Spark中的UDF.md","hash":"b6f9ca3ac3e8d69dd725aa071ae3606cc866f7f8","modified":1663213603359},{"_id":"source/_posts/大数据/Spark/Spark名词相关理解.md","hash":"ed2b8923d5accbaaaeec462facef372a4a047586","modified":1663213603359},{"_id":"source/_posts/大数据/Spark/Spark性能调优.md","hash":"0c08a8fca6586c54f0b65543cf345e7800560a61","modified":1663213603360},{"_id":"source/_posts/大数据/Spark/Spark笔记.md","hash":"c33ef174a9335101dfc67ff74bcd5547e0884e0d","modified":1663213603360},{"_id":"source/_posts/大数据/Spark/关于线程进程的理解.md","hash":"dc844a91e8568e0cce88b9466a75804aeac770a6","modified":1663213603360},{"_id":"source/_posts/大数据/Spark/多进程，多线程以及spark的executor等概念.md","hash":"2efb6e857f14000b06555d08a914f1ddbd571c7e","modified":1663213603360},{"_id":"source/_posts/操作系统/Linux/Ubuntu与Windows之间的远程连接.md","hash":"ce68116602de33bcc6c2693c6185dff8f3552159","modified":1663213603360},{"_id":"source/_posts/操作系统/Linux/开始使用Ubuntu.markdown","hash":"0e1e78a75f09f5de49281fd630794e1953bc6741","modified":1663213603360},{"_id":"source/_posts/操作系统/Linux/系统管理工具systemd.md","hash":"ad80c8552c62bab042d14e592277f0e22351eb1e","modified":1663213603360},{"_id":"source/_posts/操作系统/Linux/重装Ubuntu16.04.md","hash":"ee833f7518d21a07038710b1dfc04e5b0ee46813","modified":1663213603360},{"_id":"source/_posts/操作系统/Mac/从零搭建Mac开发环境.md","hash":"240f05ecb6e99c4b64335304919b2299ad0ce9e7","modified":1663213603360},{"_id":"source/_posts/编程开发/C++/C++虚函数和Java类比.md","hash":"66c4d4e972ec0b4d952cd845dff03135b8b9cf8f","modified":1663213603362},{"_id":"source/_posts/编程开发/C++/C语言中的指针详解.md","hash":"aff5bae22c27abd4eb68dcd52d2932f7bc9fc191","modified":1663213603362},{"_id":"source/_posts/编程开发/C++/关于Include.md","hash":"ac79d09ddd871bc4e4e4348d75e7c33ad8a7460b","modified":1663213603362},{"_id":"source/_posts/编程开发/C++/理解blade.md","hash":"c6651c248624efa26caee0e595876d67f40031b2","modified":1663213603362},{"_id":"source/_posts/编程开发/Java/Java泛型.md","hash":"db3daef2dfec15e5c4ec4ecdbeba20dc992400e1","modified":1663213603362},{"_id":"source/_posts/编程开发/Java/POJO、JavaBean和SpringBean.md","hash":"246a8d35e65514bc585cb7dc5439f3c025e4be71","modified":1663213603363},{"_id":"source/_posts/编程开发/Java/hash数据结构原理.md","hash":"fd5e00a72ffc87b8e3308d7790ae3fbfa17330fc","modified":1663213603363},{"_id":"source/_posts/编程开发/Java/java IO.md","hash":"1d82375ab4da019d6a628847062d16e29f62e28f","modified":1663213603363},{"_id":"source/_posts/编程开发/Java/java和python的字符字节数问题.md","hash":"52f248acfa6f26ab2f99ab116654f4214900e322","modified":1663213603363},{"_id":"source/_posts/编程开发/Java/关于==和equals.md","hash":"a5429fc89a8e8e87bd9d692413d45c60ec941b3d","modified":1663213603363},{"_id":"source/_posts/编程开发/Java/关于阻塞非阻塞，同步异步的最好解释.md","hash":"3913c08d7ab6cda22b1e5437eebd96ea7307e737","modified":1663213603363},{"_id":"source/_posts/编程开发/Java/堆和栈内存.md","hash":"786bb157b1c65ddfefa0dd7ebee84dbdfeec9940","modified":1663213603363},{"_id":"source/_posts/编程开发/Java/序列化与反序列化.md","hash":"975d79215eda326be94b009ed29208ee5c80a43e","modified":1663213603363},{"_id":"source/_posts/编程开发/Java/异常处理.md","hash":"7719bbd8490dfe1b3374b6ab55d4e1e6c77c7e07","modified":1663213603363},{"_id":"source/_posts/编程开发/Java/输入输出流相关类.md","hash":"6d45bacd5bf63c74b67b9769d8f360b14b45ca5a","modified":1663213603363},{"_id":"source/_posts/编程开发/Latex/some-questions-about-ctex-and-texlive.md","hash":"2c1274d46ce690e1d559fd54c00da3f1929f4804","modified":1663213603363},{"_id":"source/_posts/编程开发/Python/import及__init__.py.md","hash":"5665bd6e1a24d63c11733beb2851a43289b78377","modified":1663213603363},{"_id":"source/_posts/编程开发/Python/python2和3切换注意事项.md","hash":"2404ee6345868426b60e29652443e96ad33964e2","modified":1663213603363},{"_id":"source/_posts/编程开发/Python/下划线用法.md","hash":"be4845970eb13f002d66cb024c7a6867cd8f5b55","modified":1663213603363},{"_id":"source/_posts/编程开发/Python/关于python2的编码问题.md","hash":"58e96e3586d8e15432dad9ead8ce1674903c9175","modified":1663213603363},{"_id":"source/_posts/编程开发/Python/切片操作.md","hash":"6f437531e7add6399f0306223e08986850076dbd","modified":1663213603363},{"_id":"source/_posts/编程开发/Python/引用, 浅拷贝和深拷贝.md","hash":"16a66b97875c7747e927acbb1ea548c50b45feff","modified":1663213603364},{"_id":"source/_posts/编程开发/Python/类变量和实例变量.md","hash":"1f5cb43b3d91a84109b2a91b997bece7e36b0661","modified":1663213603364},{"_id":"source/_posts/编程开发/Shell/Shell多进程并发以及并发数控制.md","hash":"53dc0114d3574852f933445c9c8bbdfe057307ea","modified":1663213603364},{"_id":"source/_posts/编程开发/Shell/shell $1,$#等.md","hash":"cba1b56f71c605dfb87626d582daeaa88a7c2506","modified":1663213603364},{"_id":"source/_posts/编程开发/Shell/shell交互式及登录式.md","hash":"82f502c8e18417ad0854ec285260d0e6ca4b1a43","modified":1663213603364},{"_id":"source/_posts/编程开发/Shell/shell变量中的反斜杠.md","hash":"71f4a7ab55dff1f7cd9ce3c8256ad0f37b92cfdc","modified":1663213603364},{"_id":"source/_posts/编程开发/Shell/shell的变量.md","hash":"baa1219b3c5a4b8b9e278a38fdfe36dd0bc0f631","modified":1663213603364},{"_id":"source/_posts/编程开发/Shell/sudo与su.md","hash":"5cf37e4d3300eab3bc0ccbeeee46c0d1cf9d00cf","modified":1663213603364},{"_id":"source/_posts/编程开发/Shell/关于nuhup与&.md","hash":"6adfeaf8a4365cead575e1f54302cb8c2a04597c","modified":1663213603364},{"_id":"source/_posts/编程开发/Shell/关于sh,source,exec.md","hash":"06c90e631f2c4eec7212bfde4f43b06f1c8def9b","modified":1663213603364},{"_id":"source/_posts/编程开发/Shell/父子shell和父子进程.md","hash":"8ce53a0727e2560e77fefd8be98d417af6ad3bc0","modified":1663213603364},{"_id":"source/_posts/编程开发/Vim/Vim自动补全神器.md","hash":"770d8afb233d57dfbb931894acce3d34c4be1bd9","modified":1663213603364},{"_id":"source/images/my/2.png","hash":"84000b4ca881203f242c1f928fad78660bc432a8","modified":1663213603369},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1663213603380},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1663213603380},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1663213603380},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1663213603380},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1663213603380},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1663213603380},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1663213603380},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1663213603380},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"63315fcf210799f894208c9f512737096df84962","modified":1663213603380},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1663213603381},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1663213603381},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1663213603381},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1663213603381},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1663213603381},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1663213603381},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"394d008e5e94575280407ad8a1607a028026cbc3","modified":1663213603381},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1663213603381},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"3358d11b9a26185a2d36c96049e4340e701646e4","modified":1663213603381},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"92dc60821307fc9769bea9b2d60adaeb798342af","modified":1663213603381},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1663213603381},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1663213603381},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1663213603381},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1663213603381},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1663213603381},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1663213603382},{"_id":"themes/next/layout/_third-party/comments/gentie.swig","hash":"03592d1d731592103a41ebb87437fe4b0a4c78ca","modified":1663213603382},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1663213603382},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"abb92620197a16ed2c0775edf18a0f044a82256e","modified":1663213603382},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"1d0d01aaeb7bcde3671263d736718f8837c20182","modified":1663213603382},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"af9dd8a4aed7d06cf47b363eebff48850888566c","modified":1663213603382},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1663213603382},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"1f349aa30dd1f7022f7d07a1f085eea5ace3f26d","modified":1663213603382},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1663213603382},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1663213603382},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1663213603387},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"715d5b40dc52f319fe4bff0325beb874774d9bd9","modified":1663213603387},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"78a83c38f69a8747bb74e420e6c9eeef1ea76525","modified":1663213603388},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1663213603389},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"06f432f328a5b8a9ef0dbd5301b002aba600b4ce","modified":1663213603389},{"_id":"themes/next/source/css/_variables/base.styl","hash":"d6a793bcada68d4b6c58392546bc48a482e4a7d3","modified":1663213603389},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1663213603390},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1663213603390},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"aab7be0a6e2724b3faa9338db93c19556c559625","modified":1663213603390},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1663213603390},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1663213603390},{"_id":"themes/next/source/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1663213603390},{"_id":"themes/next/source/js/src/post-details.js","hash":"af7a417dd1cb02465a7b98211653e7c6192e6d55","modified":1663213603390},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1663213603390},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1663213603390},{"_id":"themes/next/source/js/src/utils.js","hash":"b2ea56de27fddc6d9118051da384f781cd93951d","modified":1663213603391},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1663213603392},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1663213603393},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"3587602ad777b031628bb5944864d1a4fcfea4ac","modified":1663213603393},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1663213603393},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1663213603393},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1663213603394},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1663213603394},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1663213603394},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1663213603394},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1663213603394},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1663213603394},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1663213603395},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1663213603395},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1663213603395},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1663213603397},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1663213603397},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1663213603397},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1663213603397},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1663213603397},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1663213603397},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1663213603397},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1663213603397},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1663213603390},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1663213603397},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1663213603397},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1663213603398},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1663213603398},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1663213603398},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1663213603398},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1663213603398},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1663213603398},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1663213603398},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1663213603398},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1663213603398},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1663213603398},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1663213603398},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1663213603398},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1663213603398},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1663213603398},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1663213603400},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1663213603400},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1663213603401},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1663213603401},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1663213603401},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1663213603397},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1663213603382},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1663213603382},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"59ad08bcc6fe9793594869ac2b4c525021453e78","modified":1663213603384},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"ef089a407c90e58eca10c49bc47ec978f96e03ba","modified":1663213603384},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1663213603384},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1663213603384},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1663213603384},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1663213603386},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1663213603387},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"7804e31c44717c9a9ddf0f8482b9b9c1a0f74538","modified":1663213603387},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1663213603387},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1663213603387},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"013619c472c7e4b08311c464fcbe9fcf5edde603","modified":1663213603387},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1663213603387},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1663213603388},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1663213603388},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1663213603388},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1663213603388},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"fda14bc35be2e1b332809b55b3d07155a833dbf4","modified":1663213603388},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1663213603388},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1663213603388},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1663213603388},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1663213603388},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"82bbaa6322764779a1ac2e2c8390ce901c7972e2","modified":1663213603388},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1663213603388},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1663213603388},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1663213603388},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"feed6b09dd32626211e79ca7c0f4f798942e54f1","modified":1663213603388},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1663213603389},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1663213603389},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"e3e23751d4ad24e8714b425d768cf68e37de7ded","modified":1663213603389},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1663213603389},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1663213603390},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1663213603392},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1663213603393},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"d9c0b3dc9158e717fde36f554709e6c3a22b5f85","modified":1663213603392},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1663213603393},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1663213603393},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1663213603393},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1663213603393},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1663213603393},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1663213603394},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1663213603394},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1663213603394},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1663213603394},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1663213603394},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1663213603395},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1663213603395},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1663213603395},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1663213603400},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1663213603400},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"38e48f275ad00daa9dcdcb8d9b44e576acda4707","modified":1663213603391},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1663213603391},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1663213603396},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1663213603397},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1663213603400},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1663213603384},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1663213603384},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1663213603384},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1663213603384},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1663213603384},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1663213603384},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1663213603384},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"740d37f428b8f4574a76fc95cc25e50e0565f45e","modified":1663213603384},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1663213603384},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"7778920dd105fa4de3a7ab206eeba30b1a7bac45","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"beccb53dcd658136fb91a0c5678dea8f37d6e0b6","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"88c7d75646b66b168213190ee4cd874609afd5e3","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"ed88c8b51d0517759c777e71a6bfbe2907bcd994","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"e792c8dc41561c96d128e9b421187f1c3dc978a0","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"08a500b2984f109b751f3697ca33172d1340591a","modified":1663213603385},{"_id":"themes/next/source/css/_common/components/post/post-wordcount.styl","hash":"4fda5d38c6c8d910e3bf5c74a48a8d4a3f3dc73d","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"468bc734f47209096588ef1a8e55e60a3b12aa63","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"2e7ec9aaa3293941106b1bdd09055246aa3c3dc6","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"5f6ea57aabfa30a437059bf8352f1ad829dbd4ff","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"77c92a449ce84d558d26d052681f2e0dd77c70c9","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"a2ec22ef4a6817bbb2abe8660fcd99fe4ca0cc5e","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"234facd038f144bd0fe09a31ed1357c5d74c517f","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"dfc86d37f5b580977d82af6ef835082d09a0c499","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"dd310c2d999185e881db007360176ee2f811df10","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1663213603386},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1663213603387},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1663213603387},{"_id":"themes/next/source/css/_common/components/third-party/gentie.styl","hash":"586a3ec0f1015e7207cd6a2474362e068c341744","modified":1663213603387},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1663213603387},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1663213603387},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1663213603387},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"bb3be8374c31c372ed0995bd8030d2b920d581de","modified":1663213603387},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1663213603388},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1663213603388},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1663213603388},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1663213603391},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1663213603391},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1663213603391},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1663213603391},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1663213603394},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1663213603394},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1663213603394},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1663213603394},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1663213603394},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1663213603394},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1663213603396},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1663213603395},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1663213603396},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1663213603393},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1663213603400},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1663213603396},{"_id":"public/search.xml","hash":"6670601d09f360e97d056fc227937928fcb8cbfc","modified":1666698314497},{"_id":"public/categories/index.html","hash":"65a185f641fb763a8ded5e37bf66ad99ae936d7f","modified":1666698314640},{"_id":"public/about/index.html","hash":"e33abdd186a57634d7bef729bc10bdea10cf2ee2","modified":1666698314640},{"_id":"public/tags/index.html","hash":"5523390d5d4d44bf8ef31abc9a07f868dc7f2c57","modified":1666698314640},{"_id":"public/2022/08/10/搜推广/Online Learning中的优化器/index.html","hash":"dc24db02a9610cb04b96f688a94d274941046a86","modified":1666698314641},{"_id":"public/2022/08/10/搜推广/浅谈FM和FFM/index.html","hash":"457146a620914981fd01e5541613747cd679a171","modified":1666698314641},{"_id":"public/2022/08/10/搜推广/计算广告基础概念/index.html","hash":"af0377911119c915dbbfb8d40a2e1e93191ee521","modified":1666698314641},{"_id":"public/2022/08/10/搜推广/理解召回和LTR/index.html","hash":"3b68fb6f9dbb8c795b1942713d6f21aba294c725","modified":1666698314641},{"_id":"public/2022/08/10/深度学习/Attention和Transformer/index.html","hash":"d7bf9b6d1ca8d98b9c10d1e91f6f2a03d1ef5743","modified":1666698314641},{"_id":"public/2021/06/25/编程开发/Python/类变量和实例变量/index.html","hash":"305b313453ff10562f4eeb6dd23a4658130a97a4","modified":1666698314641},{"_id":"public/2021/05/31/编程开发/C++/C++虚函数和Java类比/index.html","hash":"674e579e10956e65553f24cceb8d9b5e75a6e1ab","modified":1666698314641},{"_id":"public/2021/02/03/编程开发/C++/理解blade/index.html","hash":"1bff1ee66792735bd9f7f810439c54a4cff850b0","modified":1666698314641},{"_id":"public/2021/01/20/操作系统/Linux/系统管理工具systemd/index.html","hash":"fb80132d0eda6d8d2d23baf174b05dd9b775aeba","modified":1666698314641},{"_id":"public/2021/01/08/数学/内积、叉积和外积/index.html","hash":"bc0c0481cb8c990dd3639d89b93650f54dab9ea3","modified":1666698314641},{"_id":"public/2021/01/08/深度学习/RNN的BPTT/index.html","hash":"be35ca869a98e2f8bb234d18ef22ed02dad98996","modified":1666698314641},{"_id":"public/2020/12/16/大数据/Spark/关于线程进程的理解/index.html","hash":"97e408cf45229d7e9ee132282a9536d8491f8878","modified":1666698314641},{"_id":"public/2020/11/10/编程开发/后端技术栈/index.html","hash":"05914dac076a8131bfa111090d755f8acfde2d5b","modified":1666698314641},{"_id":"public/2020/11/10/大数据/Databus/Databus学习笔记/index.html","hash":"653682710668219ceeb720d339df4f336279c098","modified":1666698314641},{"_id":"public/2020/11/10/大数据/Hive/hdfs文件理解/index.html","hash":"ef6755b74f79fcf280ad29c0fe6a211726ff96ce","modified":1666698314641},{"_id":"public/2020/11/10/大数据/Flink/Flink学习笔记/index.html","hash":"7356c066f21b0eb2886bbdac373340066c75a3b1","modified":1666698314641},{"_id":"public/2020/11/10/大数据/Kafka/Kafka学习笔记/index.html","hash":"0d9fb5082d1dc490a22e9c7d29a212e5a25cecd7","modified":1666698314641},{"_id":"public/2020/11/02/深度学习/NAS系列文章解读/index.html","hash":"7b05be8327591994ad236dce428a99ca0eae21d6","modified":1666698314641},{"_id":"public/2020/10/30/深度学习/关于policy network/index.html","hash":"1bbed4132927baa5823ce0ee80a35434892198ce","modified":1666698314641},{"_id":"public/2020/10/28/ML框架/Tf一些常用方法记录/index.html","hash":"04935f1aee1260618d7c0af54d7b2114bd5fa71f","modified":1666698314641},{"_id":"public/2020/10/22/编程开发/Python/关于python2的编码问题/index.html","hash":"c7fee917861b6022f2aef8dd8c53c615b5e2ed64","modified":1666698314641},{"_id":"public/2020/10/09/编程开发/Python/下划线用法/index.html","hash":"ebb8db96fef94c31e4d66d1d1e8b75abb4889a37","modified":1666698314641},{"_id":"public/2020/08/13/大数据/Spark/Spark中的UDF/index.html","hash":"44a511851d426eeea64176a13837f34e5324f805","modified":1666698314641},{"_id":"public/2020/07/29/ML框架/Tensorflow和Pytorch的比较/index.html","hash":"89b29de2951431aed79cd67484f494fd9abc6492","modified":1666698314641},{"_id":"public/2020/07/22/搜推广/推荐系统实战/index.html","hash":"194f16c02527816e194f23a997eafad7054af7e7","modified":1666698314641},{"_id":"public/2020/07/20/数学/伪多项式时间复杂度/index.html","hash":"540a8d9da3db3df57c9c89b4fd49c9b98243d2fe","modified":1666698314641},{"_id":"public/2020/07/20/数学/时间序列中随机过程/index.html","hash":"15ec2930fe133d6f1d93f49ba9bb730c522c8c5a","modified":1666698314641},{"_id":"public/2020/06/22/数学/计算复杂度公式/index.html","hash":"566a4320f44077a8a829b49802e16ba55a9463e9","modified":1666698314641},{"_id":"public/2020/06/20/前端开发/前端开发环境配置/index.html","hash":"e9b9149e161b70782e2961cb96fada0988e6e39e","modified":1666698314641},{"_id":"public/2020/06/20/操作系统/Mac/从零搭建Mac开发环境/index.html","hash":"8f3256f72c10c14c6b2a962b2d93c2ca22a5ac28","modified":1666698314641},{"_id":"public/2020/06/05/编程开发/Github代理加速/index.html","hash":"8d1cc85e3cdfc54b0b468c67aa932336513c314a","modified":1666698314641},{"_id":"public/2020/05/24/机器学习/最大熵与最大似然估计/index.html","hash":"e787786b4026184f0445955ec88762e07ae5d603","modified":1666698314641},{"_id":"public/2020/05/09/编程开发/Java/POJO、JavaBean和SpringBean/index.html","hash":"fb896aa01b4bdd9f20a4bdb578c98a71a548b579","modified":1666698314641},{"_id":"public/2020/05/09/编程开发/Java/关于==和equals/index.html","hash":"1f8332bb8bd5eb63e588f57346a4ce7966fb778e","modified":1666698314641},{"_id":"public/2020/05/08/编程开发/Java/异常处理/index.html","hash":"ea0b68e3fcf43b548ba79b56f2e80aac4d64f2f0","modified":1666698314641},{"_id":"public/2020/04/25/机器学习/关于PCA和SVD分解/index.html","hash":"642837b5f089d358790f3ba648f40f5074d98842","modified":1666698314641},{"_id":"public/2020/04/25/自然语言处理/理解LSI、PLSI、LDA和LFM/index.html","hash":"e356f3e1fcc2ac70d4ee18e5ee7461e9acfa33af","modified":1666698314641},{"_id":"public/2020/04/03/深度学习/ML2020笔记-基于RNN的生成模型和Attention/index.html","hash":"8b5a1083ed05634a6ffef5e404f4be2963ba5796","modified":1666698314641},{"_id":"public/2020/04/02/深度学习/ML2020笔记-ELMO、BERT和GPT/index.html","hash":"7e3cdebbb8cbf9752fd7f6b4465dd0a3dc860796","modified":1666698314641},{"_id":"public/2020/03/20/自然语言处理/《自然语言处理入门》笔记/index.html","hash":"46755ad85e64434b14b37b76e185f8165b770160","modified":1666698314641},{"_id":"public/2020/03/14/编程开发/Java/输入输出流相关类/index.html","hash":"37065b717e58401ebab6500b07d2defb2a78c7c3","modified":1666698314641},{"_id":"public/2020/03/08/编程开发/Java/hash数据结构原理/index.html","hash":"6e618a065ceab2fe5c7b860ba7c99ee3e0b103ad","modified":1666698314641},{"_id":"public/2020/03/07/编程开发/Java/序列化与反序列化/index.html","hash":"51816fbeda2e8fec8e0cc4fb08617aaa0471c07b","modified":1666698314641},{"_id":"public/2020/03/05/大数据/Spark/Spark名词相关理解/index.html","hash":"7145b661e419bc5ce62c0b38fc12162fa6342572","modified":1666698314641},{"_id":"public/2020/02/10/ML框架/Cuda、Tensorflow、Pytorch版本匹配/index.html","hash":"8e4cac74f155b9480f0f5d1fc13b656facf735cf","modified":1666698314641},{"_id":"public/2020/01/19/编程开发/C++/关于Include/index.html","hash":"03de94408ff53d0737709190381e062fe9a2592b","modified":1666698314641},{"_id":"public/2020/01/07/编程开发/各语言对象和变量的关系/index.html","hash":"789549e1d4bbdd41ec0fddd15808c354830b0b92","modified":1666698314641},{"_id":"public/2020/01/07/编程开发/Java/堆和栈内存/index.html","hash":"60187e87fae804b9b104d8b234de92fa00ed5d9b","modified":1666698314641},{"_id":"public/2019/11/18/ML框架/Tf 2.0的几个变动/index.html","hash":"e32e1590d391bbc283e8ff7abdfd95a05b453827","modified":1666698314641},{"_id":"public/2019/11/18/机器学习/损失函数之交叉熵和MSE/index.html","hash":"d267855f5271800e32219b48d3619a4964954bad","modified":1666698314641},{"_id":"public/2019/11/04/自然语言处理/word2vec详解/index.html","hash":"8862cdc68144b305fcc5418ae914aa6c9cb1cfde","modified":1666698314641},{"_id":"public/2019/11/01/机器学习/生成模型和判别模型的直观解释/index.html","hash":"14695eb5399af107c1ae29d5578a1ba38eded1fd","modified":1666698314641},{"_id":"public/2019/10/17/编程开发/Java/关于阻塞非阻塞，同步异步的最好解释/index.html","hash":"78cf2e1db1109214a028d4189fc0cbb589f7ea1a","modified":1666698314641},{"_id":"public/2019/08/28/数学/整数规划中的分支定界和分支切割/index.html","hash":"cbeffd8b10ffa55169966f3b5bbf2f774ab56204","modified":1666698314641},{"_id":"public/2019/08/27/数学/关于凸、P和NP/index.html","hash":"192f38d4c8b78a2a13006e3166f09c8658cab018","modified":1666698314641},{"_id":"public/2019/08/26/数学/可导和可微/index.html","hash":"eb63d288e70b52b3e3cb84b27e552ec831b39291","modified":1666698314641},{"_id":"public/2019/08/26/数学/拉格朗日对偶/index.html","hash":"08f6cda9bf60d203384296acfad4d5a84cf965c7","modified":1666698314642},{"_id":"public/2019/08/10/前端开发/前端学习流程/index.html","hash":"192b65139765e9596b5e62e519ceda5a2a3424fe","modified":1666698314642},{"_id":"public/2019/07/02/编程开发/Shell/shell的变量/index.html","hash":"ab11973f176ac7a7de6b676bd586e8a50a8e42c9","modified":1666698314642},{"_id":"public/2019/06/11/编程开发/Java/java IO/index.html","hash":"d6d63aec9286236c6bf43fd453750d9929785399","modified":1666698314642},{"_id":"public/2019/06/11/编程开发/Java/java和python的字符字节数问题/index.html","hash":"84d506b97088e3be26adb68d4d686dcaad797376","modified":1666698314642},{"_id":"public/2019/05/16/机器学习/关于模型选型/index.html","hash":"7cf066232dc465a1a970f39336057709f371b538","modified":1666698314642},{"_id":"public/2019/05/16/深度学习/Dead ReLu问题/index.html","hash":"3ff02078ea17a3a06a0a4200eb5a3c4db1b0af5b","modified":1666698314642},{"_id":"public/2019/05/06/编程开发/Python/引用, 浅拷贝和深拷贝/index.html","hash":"cb91605100207e81f3d936b23868edce15dc6b0c","modified":1666698314642},{"_id":"public/2019/04/29/机器学习/CART与普通决策树的区别/index.html","hash":"96ac00929d8c775689a2045a6e99679b35e9154b","modified":1666698314642},{"_id":"public/2019/04/24/机器学习/类别不均衡问题的调参/index.html","hash":"594680d0b5d8053dfda75b0191f0630f2ba0e2a6","modified":1666698314642},{"_id":"public/2019/03/07/编程开发/Python/import及__init__.py/index.html","hash":"4ab4adf191ea17fbf41fe91d15fbf05336529ea0","modified":1666698314642},{"_id":"public/2019/02/15/编程开发/Shell/shell交互式及登录式/index.html","hash":"559421f3710be554681fe7fdefd41eb1f8e7fa33","modified":1666698314642},{"_id":"public/2019/02/15/编程开发/Shell/sudo与su/index.html","hash":"b62315f299ded9a570d8dea3443b0b5651f64d87","modified":1666698314642},{"_id":"public/2019/02/15/编程开发/Shell/父子shell和父子进程/index.html","hash":"d85cadc4ee30d3004357c70a115bff830a248fd3","modified":1666698314642},{"_id":"public/2019/02/02/编程开发/Python/python2和3切换注意事项/index.html","hash":"8066db2914527fa67d8b79f943a44a01a40a05b0","modified":1666698314642},{"_id":"public/2018/12/06/机器学习/关于特征值分布不均匀的问题/index.html","hash":"78137de58a29725e3d9132df9b2760d388b759f5","modified":1666698314642},{"_id":"public/2018/12/06/机器学习/关于特征工程/index.html","hash":"29ce652438c633db251eebb2183d7a568419d752","modified":1666698314642},{"_id":"public/2018/12/06/机器学习/特征是否越多越好/index.html","hash":"f036f4e99eef6c42d5525c10c1e5240215d39dfd","modified":1666698314642},{"_id":"public/2018/12/05/机器学习/Xgboost和LightGBM调参/index.html","hash":"18c1c32aa9400ac43a93cdb77b66aa4e4ecbc8ba","modified":1666698314642},{"_id":"public/2018/11/28/大数据/Spark/Spark性能调优/index.html","hash":"2261e2ec568040bfd2cc0e5baa8b052b2103d59a","modified":1666698314642},{"_id":"public/2018/11/21/机器学习/关于特征归一化的一些理解/index.html","hash":"a4f57b64c0bbf4a5d54a4d3405252c9a21f8ff29","modified":1666698314642},{"_id":"public/2018/11/19/编程开发/Java/Java泛型/index.html","hash":"36cb8261bd0e27dd30cc1526881cd8745a94ba75","modified":1666698314642},{"_id":"public/2018/11/11/编程开发/Shell/shell $1,$#等/index.html","hash":"516f86e8f54f0cbd233f2c150b86bf0dd01e3976","modified":1666698314642},{"_id":"public/2018/11/07/大数据/Spark/多进程，多线程以及spark的executor等概念/index.html","hash":"1d4ce5b635db06f338d8d805e15edfd292e029d4","modified":1666698314642},{"_id":"public/2018/11/05/编程开发/Shell/Shell多进程并发以及并发数控制/index.html","hash":"dee76cf36d5fabc92a8f886d7fd06cfc1d89289e","modified":1666698314642},{"_id":"public/2018/11/02/编程开发/Shell/关于nuhup与&/index.html","hash":"ddd28b4f2a26e4734379f0b69924bbecffa62fc7","modified":1666698314642},{"_id":"public/2018/11/02/编程开发/Shell/关于sh,source,exec/index.html","hash":"782f3e8d769d74fd654caef4c2e2c99fbb38a8eb","modified":1666698314642},{"_id":"public/2018/10/18/大数据/Spark/Spark笔记/index.html","hash":"9234bee2c0378da61cb7389e9a42ae218cd82aff","modified":1666698314642},{"_id":"public/2018/06/20/机器学习/xgboost调参/index.html","hash":"85d70f90979f4a134ff8e64be928c0745d9bf868","modified":1666698314642},{"_id":"public/2018/06/03/编程开发/Python/切片操作/index.html","hash":"ba5a8062bddfafd5eb8448a3d3565d1c4791e405","modified":1666698314642},{"_id":"public/2018/05/30/大数据/Hive/hive建表时的format/index.html","hash":"ea2f8e3934b843e61e0bf058421348358161f6ba","modified":1666698314642},{"_id":"public/2018/05/22/编程开发/Shell/shell变量中的反斜杠/index.html","hash":"4bd28c1bed817d1d8040542ab740363d69f9d4aa","modified":1666698314642},{"_id":"public/2017/07/18/ML框架/Tf中的变量作用域和名称作用域/index.html","hash":"1309347a22e87ba3dd705b8855a0bf9503d799ac","modified":1666698314642},{"_id":"public/2017/07/15/ML框架/Tf中有关Graph和Session的几个问题/index.html","hash":"0bac057199e487d1df3ea8c8f23a27f2521b8e43","modified":1666698314642},{"_id":"public/2017/07/07/编程开发/Latex/some-questions-about-ctex-and-texlive/index.html","hash":"4c0c36294ecd6cf07e0d0d0acf86357e73240e47","modified":1666698314642},{"_id":"public/2017/06/28/编程开发/C++/C语言中的指针详解/index.html","hash":"9fe9a6fb602956fedbbc7136b2d2b780d73a61f0","modified":1666698314642},{"_id":"public/2017/06/13/操作系统/Linux/Ubuntu与Windows之间的远程连接/index.html","hash":"968e8bf763b484753ca676ee9e4fc7a560f87709","modified":1666698314642},{"_id":"public/2017/06/12/编程开发/Vim/Vim自动补全神器/index.html","hash":"e586d94d08ab964dd5824215b04d77b58a714ed4","modified":1666698314642},{"_id":"public/2017/06/12/操作系统/Linux/重装Ubuntu16.04/index.html","hash":"3817f1ecd0ef526ad76757b716f3616bcbaed826","modified":1666698314642},{"_id":"public/2016/05/10/机器学习/支持向量机/index.html","hash":"b5f393324835e2705fca16be2a1dec7d36a0cb56","modified":1666698314642},{"_id":"public/2016/04/21/信息安全/RSA加密算法/index.html","hash":"7229731aa807d612b72a5e18081b1561ef080cde","modified":1666698314642},{"_id":"public/2016/04/19/操作系统/Linux/开始使用Ubuntu/index.html","hash":"54dc0d1b4a753b6d1d7221f54be11335a6de60c7","modified":1666698314642},{"_id":"public/categories/ML框架/index.html","hash":"fd7b848340593646e119be6eddf6043e8ac85737","modified":1666698314642},{"_id":"public/categories/Web开发/index.html","hash":"bb334dc5c36d5e4928cc4705a757a8b59ec1b848","modified":1666698314642},{"_id":"public/categories/信息安全/index.html","hash":"f90ad9cdd3e7a38857b4a538a4eb54a71272c0cf","modified":1666698314642},{"_id":"public/categories/搜推广/index.html","hash":"48bff701e5c71aac820a5813014094cb9b1fa820","modified":1666698314642},{"_id":"public/categories/数学/index.html","hash":"7a7adbc6ce240f76b0dd35c64a8de924ec6371b8","modified":1666698314642},{"_id":"public/categories/机器学习/index.html","hash":"a290855f78d5b6c65141058cb6cf2a4e81dd1c50","modified":1666698314642},{"_id":"public/categories/机器学习/page/2/index.html","hash":"7eb6dd7f997c24c180f6d0e85daf721c1dd07400","modified":1666698314642},{"_id":"public/categories/深度学习/index.html","hash":"7954dca677d1924d26006659200ddef8f6118ade","modified":1666698314642},{"_id":"public/categories/编程开发/index.html","hash":"9ce40055fb37d65c81d712b521d631c18bf47242","modified":1666698314642},{"_id":"public/categories/编程开发/page/2/index.html","hash":"bda17c1ce36a83152da16cbc6014a4c582084e74","modified":1666698314642},{"_id":"public/categories/编程开发/page/3/index.html","hash":"9750d72c87f45693a8fe417086885c7a2f366ca0","modified":1666698314642},{"_id":"public/categories/编程开发/page/4/index.html","hash":"7d76c2950009a2b37795441edd13ceede35ac085","modified":1666698314642},{"_id":"public/categories/自然语言处理/index.html","hash":"d167758a60f0f10104ffd672f827ca19c063fc50","modified":1666698314642},{"_id":"public/categories/深度学习/AutoML/index.html","hash":"ccaa047c988ca0c00b0284af84a6c30d30250898","modified":1666698314642},{"_id":"public/categories/深度学习/强化学习/index.html","hash":"702cf0121e8ff87ca09784b172d8d2df1da616c2","modified":1666698314642},{"_id":"public/categories/大数据/index.html","hash":"51b2d75f7987d9d0bb0902c3d9b8c6f9f7580af7","modified":1666698314642},{"_id":"public/categories/大数据/page/2/index.html","hash":"6bd98e04eebbe870f04a99105e3b1a49b7bf16a7","modified":1666698314642},{"_id":"public/categories/大数据/Flink/index.html","hash":"cbeea50a2825fcff8a730838a6bd466d8170ce6f","modified":1666698314642},{"_id":"public/categories/大数据/Databus/index.html","hash":"0ada49514a92fb106cfe7436c4e4fb3a46de7928","modified":1666698314642},{"_id":"public/categories/大数据/Kafka/index.html","hash":"6e3571ebe3441b345f55d3c399a273be13012694","modified":1666698314642},{"_id":"public/categories/大数据/Spark/index.html","hash":"3b595a170eaf096cf8ab6bd614edb853a619f5a9","modified":1666698314642},{"_id":"public/categories/大数据/Hive/index.html","hash":"a8fa17104ee97ad4cecfa23da36d622326452bea","modified":1666698314642},{"_id":"public/categories/操作系统/index.html","hash":"b1d633f165918cc2692aa03d862f624ea03b1f05","modified":1666698314642},{"_id":"public/categories/编程开发/C/index.html","hash":"11fc5c1624ad7e7f936950ec867e2592201c9196","modified":1666698314642},{"_id":"public/categories/编程开发/Java/index.html","hash":"3622a044f133c3e0367dde2292d097204c0a6f3b","modified":1666698314642},{"_id":"public/categories/编程开发/Latex/index.html","hash":"227447b48aa941b42a23279983aadd7ba11ea595","modified":1666698314642},{"_id":"public/categories/编程开发/Python/index.html","hash":"4e82f257481ac6c56726b0dfb36f682adcfa4fb5","modified":1666698314642},{"_id":"public/categories/操作系统/Linux/index.html","hash":"bcb095cfedd697ee2858e343b9b5e32ac0fd5495","modified":1666698314642},{"_id":"public/categories/操作系统/Mac/index.html","hash":"a3d89b5cc78e92097bc2f0d82d1b8d95ae057905","modified":1666698314642},{"_id":"public/categories/编程开发/Java/page/2/index.html","hash":"7c27ba4a96bb99e65c65b03e3c4d294e05ce3eb5","modified":1666698314642},{"_id":"public/categories/编程开发/Shell/index.html","hash":"39ce1fbae0126045cc2fa04f6593e133fb7ef96c","modified":1666698314642},{"_id":"public/archives/index.html","hash":"c0ee6369f6d79672280fa34db9cba953ef009505","modified":1666698314642},{"_id":"public/categories/编程开发/Vim/index.html","hash":"353a100be1f183482b4847a83731e98da3da6da2","modified":1666698314642},{"_id":"public/archives/page/2/index.html","hash":"13fcbf9fbd51ccddf2d9dfd71e8fa77e0713b924","modified":1666698314642},{"_id":"public/archives/page/3/index.html","hash":"d731937a3e1f9d9156cf49ca7e11dc5cf54d5bec","modified":1666698314642},{"_id":"public/archives/page/4/index.html","hash":"a792d447938af7102e7ec946b6d09189fba6f95d","modified":1666698314642},{"_id":"public/archives/page/5/index.html","hash":"a6538f539da2d80f1ab45bfda68868bac499876c","modified":1666698314642},{"_id":"public/archives/page/7/index.html","hash":"beab91f0a40ed8ca12672693eab697271d1fc35a","modified":1666698314643},{"_id":"public/archives/page/8/index.html","hash":"a6332f985953bc67bf752d20d2bf1a62f45a7d75","modified":1666698314643},{"_id":"public/archives/page/9/index.html","hash":"bcaa2c8373896d1e3b5eb52edccccd75b93c0328","modified":1666698314643},{"_id":"public/archives/2016/index.html","hash":"9f4445e23a81460005794c17e045ff6cf32ae7fd","modified":1666698314643},{"_id":"public/archives/2016/04/index.html","hash":"16906743a50f9a76618357c27712d94030569b69","modified":1666698314643},{"_id":"public/archives/2016/05/index.html","hash":"f74d9fd09486dc418ef06b2419c96a61d64ce55c","modified":1666698314643},{"_id":"public/archives/2017/index.html","hash":"8c9eae5b8f4f5053e346f09bed863da65aa2d484","modified":1666698314643},{"_id":"public/archives/page/6/index.html","hash":"67e55417d40e9d1ad6e40c5af40f92d210835a35","modified":1666698314643},{"_id":"public/archives/2017/06/index.html","hash":"a19e00db8a39fbcf4880751a9da16c5255d007c7","modified":1666698314643},{"_id":"public/archives/2017/07/index.html","hash":"68663509757533d5898d8991fd71700251b3da7f","modified":1666698314643},{"_id":"public/archives/2018/index.html","hash":"55212e2c3c34964593fb01633abf652887a70618","modified":1666698314643},{"_id":"public/archives/2018/page/2/index.html","hash":"10a60ba7c88599af81407fe7345f332628555b5d","modified":1666698314643},{"_id":"public/archives/2018/05/index.html","hash":"479cbe16b37eb9fb7b2a2cac90db780be79b78cc","modified":1666698314643},{"_id":"public/archives/page/10/index.html","hash":"a6559ae26b1501f35a324de0a2b0d4b6e152eb0a","modified":1666698314643},{"_id":"public/archives/2018/06/index.html","hash":"7d6adb4e14f5e49d5dfa1af64183465583de88dc","modified":1666698314643},{"_id":"public/archives/2018/10/index.html","hash":"9f4dac74a410943d0de26ddae7dfac3c5857afe3","modified":1666698314643},{"_id":"public/archives/2018/12/index.html","hash":"cad26b4aa4d1dbe564fe9794b275d2d8a01c1bea","modified":1666698314643},{"_id":"public/archives/2019/index.html","hash":"fdc088ef427e6b3fdac9d4837a88ba823f7c7fae","modified":1666698314643},{"_id":"public/archives/2018/11/index.html","hash":"16547b918ef1d081ba8d94e62e22e968ef92bd09","modified":1666698314643},{"_id":"public/archives/2019/page/3/index.html","hash":"7b2a44ebdfe1c8faca9c2deedd654f7d7fce8c5d","modified":1666698314643},{"_id":"public/archives/2019/page/2/index.html","hash":"5eb66a11b1ffcabb480ae913fad367f2a46b2d12","modified":1666698314643},{"_id":"public/archives/2019/02/index.html","hash":"5a4988228b94364820964207d5b27ef0c34a953c","modified":1666698314643},{"_id":"public/archives/2019/03/index.html","hash":"ed4fe50cc378e45f5d382db6720f596aa3bcd299","modified":1666698314643},{"_id":"public/archives/2019/04/index.html","hash":"a99b70142f50506b5f067c58d692f994f3b4146a","modified":1666698314643},{"_id":"public/archives/2019/05/index.html","hash":"f730092f23ee88825522a87a77341cffb4b39110","modified":1666698314643},{"_id":"public/archives/2019/06/index.html","hash":"f101523076643bc41fd282b34950a85076d33dd7","modified":1666698314643},{"_id":"public/archives/2019/07/index.html","hash":"e1f147d3e508f0e19760a0df44f6afe13babc8cd","modified":1666698314643},{"_id":"public/archives/2019/08/index.html","hash":"b1afc7fd893d05963f251e75c24914e7a1e7e18b","modified":1666698314643},{"_id":"public/archives/2019/10/index.html","hash":"c9ee04ab34e037fbd0470efe1a6e3d13eaf2132e","modified":1666698314643},{"_id":"public/archives/2019/11/index.html","hash":"1078136f4a172faae1545871953c44364d3eeea9","modified":1666698314643},{"_id":"public/archives/2020/index.html","hash":"942a8916d3e6fdc85ea2d6e6ea6a8f06b4466d8a","modified":1666698314643},{"_id":"public/archives/2020/page/2/index.html","hash":"9cd96873fa3620a42748fc80153ea6b908ccf6fe","modified":1666698314643},{"_id":"public/archives/2020/page/3/index.html","hash":"10b8e69b75f8962d1595b1fc4f47ad9a43d29397","modified":1666698314643},{"_id":"public/archives/2020/page/4/index.html","hash":"d25b59f5cbd9d9a6aa01f659b2d53faf5093e987","modified":1666698314643},{"_id":"public/archives/2020/01/index.html","hash":"fc443444e153a06f0a75a53397979e1faf10a0cc","modified":1666698314643},{"_id":"public/archives/2020/02/index.html","hash":"b6bf171e4e6b87368d48929ef4f354eb036c748d","modified":1666698314643},{"_id":"public/archives/2020/03/index.html","hash":"402a41142f35e01d10f436cf3694c9f3ca0b1fde","modified":1666698314643},{"_id":"public/archives/2020/04/index.html","hash":"88ce4c4688c5faf8c66ebb3a75eb5c6c5cf9dd82","modified":1666698314643},{"_id":"public/archives/2020/05/index.html","hash":"c459cff78865425a015f2a0b9a27371141397591","modified":1666698314643},{"_id":"public/archives/2020/06/index.html","hash":"88093f7f0328348628ba1b1c0c83a073abb2eca3","modified":1666698314643},{"_id":"public/archives/2020/07/index.html","hash":"5c6610b5ec8d146c466963aa2721e36808a5023a","modified":1666698314643},{"_id":"public/archives/2020/08/index.html","hash":"2d4f0864ccf085d6e4e75eef43fdb72db9976244","modified":1666698314643},{"_id":"public/archives/2020/10/index.html","hash":"bbd2b960a44094499527c9616f4463517064dfa7","modified":1666698314643},{"_id":"public/archives/2020/11/index.html","hash":"6c94ce3beaaf372bd25be1c0aab5a9745de22207","modified":1666698314643},{"_id":"public/archives/2020/12/index.html","hash":"ca0fa6ff6672b62aaf20af98978b3e24eba851cd","modified":1666698314643},{"_id":"public/archives/2021/index.html","hash":"34f70d944be4d20d283500d848e55fd9bd7cd88c","modified":1666698314643},{"_id":"public/archives/2021/01/index.html","hash":"8963a4ff50b8f8b52ca67080b885cff2556499b6","modified":1666698314643},{"_id":"public/archives/2021/02/index.html","hash":"d38dd82cfa01b7b4ba8b42ab84b12575252cac96","modified":1666698314643},{"_id":"public/archives/2021/05/index.html","hash":"0919dbfc2773efa49348f48c479276abd2080c0a","modified":1666698314643},{"_id":"public/archives/2021/06/index.html","hash":"6936109444456ba9a9d5d91911ded3279d6370aa","modified":1666698314643},{"_id":"public/archives/2022/index.html","hash":"82096c6f4176e7576029a47911a5ea3d0ee2b6e0","modified":1666698314643},{"_id":"public/archives/2022/08/index.html","hash":"c8560bf82c783513f5e551304541cf03e4aaad06","modified":1666698314643},{"_id":"public/tags/Tensorflow/index.html","hash":"24aaa67626c428fcd68c42375d936fa29ad88b2b","modified":1666698314643},{"_id":"public/tags/Pytorch/index.html","hash":"06b099ad91be284be5777d9f8f6ba7cd4e1ccd22","modified":1666698314643},{"_id":"public/tags/前端/index.html","hash":"d8441d48ca46d1479dbf027ac274db6e43c417e5","modified":1666698314643},{"_id":"public/tags/《推荐系统实战》/index.html","hash":"1de2638ac81ac77d71d0adc51731ebe475933b00","modified":1666698314643},{"_id":"public/tags/CART/index.html","hash":"0febe63e6104629edce6d1a93b35277d56d3ca2f","modified":1666698314643},{"_id":"public/tags/XGBoost/index.html","hash":"4f0cc3e83b0e78fcde82a9e512454042503a2295","modified":1666698314643},{"_id":"public/tags/时间序列/index.html","hash":"5bd8b966c77902ef0541ab08c0e677d4f4efa450","modified":1666698314643},{"_id":"public/tags/特征工程/index.html","hash":"ca534d5b0f750c73a08b1bb5463a5cea8ac41ca7","modified":1666698314643},{"_id":"public/tags/SVM/index.html","hash":"64b4653f6e72e4ff9769a429cb1a0c7c43b089a6","modified":1666698314643},{"_id":"public/tags/李宏毅-ML2020/index.html","hash":"4272ea5d19b0a215352612e072e7db0ff65b1968","modified":1666698314643},{"_id":"public/tags/word2vec/index.html","hash":"833873b9f12e4c5475476271c40feaf00ba049a8","modified":1666698314643},{"_id":"public/tags/《自然语言处理入门》/index.html","hash":"fbaa224324d08b6db3e7534e0cf494d4de50c22f","modified":1666698314643},{"_id":"public/tags/模型上线/index.html","hash":"9ded40485f153e413ce4def26521eb92a92fc481","modified":1666698314643},{"_id":"public/tags/并发/index.html","hash":"89011226ee1985dc740cb645d715a0051af81d79","modified":1666698314643},{"_id":"public/index.html","hash":"0694e0e66b8390aaab4f0c3d603c9e76cf4d023c","modified":1666698314643},{"_id":"public/page/2/index.html","hash":"089d687225bab3a507f37b55449cb54f184f5688","modified":1666698314643},{"_id":"public/page/3/index.html","hash":"f2281b01fc2415299874e12db4c117a4301dd6b6","modified":1666698314643},{"_id":"public/page/4/index.html","hash":"aafc4c6a129bad1ffb14ac70b108684aee01fcc5","modified":1666698314643},{"_id":"public/page/5/index.html","hash":"861fb605fc5a1fbb515a99522bcb995a5a9056a9","modified":1666698314643},{"_id":"public/page/6/index.html","hash":"e7561922ce3eea93ac9e657228ee8eeb0b94d595","modified":1666698314643},{"_id":"public/page/7/index.html","hash":"c23df6b8988f184f191145903bbadf9699c248c0","modified":1666698314643},{"_id":"public/page/8/index.html","hash":"651ceaff0d124d75d058573c22ace64b340b84a7","modified":1666698314643},{"_id":"public/page/9/index.html","hash":"55528b53ab32348b9c67a603ebb02cce75661ce9","modified":1666698314643},{"_id":"public/page/10/index.html","hash":"d4c908494a329803624d450cd0a17d50fc593063","modified":1666698314643},{"_id":"public/2022/10/25/搜推广/uplift model理解/index.html","hash":"ac0843940c2b0e4a24e0169f816c7fa65c72c07f","modified":1666698314650},{"_id":"public/archives/2022/10/index.html","hash":"78565d34cd0f0636a1d9eda4e6de1d491c4d3c3b","modified":1666698314650},{"_id":"public/images/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1666698314654},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1666698314654},{"_id":"public/images/my/1.png","hash":"7d2b9aeddb64e5fe03ea7c41068bb5c31f658b27","modified":1666698314654},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1666698314654},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1666698314654},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1666698314654},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1666698314654},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1666698314654},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1666698314654},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1666698314654},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1666698314654},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1666698314654},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1666698314654},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1666698314654},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1666698314654},{"_id":"public/uploads/alipay.png","hash":"4c4c4cf01bbdaa2f5e8280ab79f00529f9069d9c","modified":1666698314654},{"_id":"public/uploads/avatar.png","hash":"23c03d14b32d6fed422fa2a21f4f4e437b510341","modified":1666698314654},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1666698314654},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1666698314654},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1666698314654},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1666698314654},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1666698314654},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1666698314654},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1666698314655},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1666698314655},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1666698314655},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1666698314655},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1666698314655},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1666698314655},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1666698314655},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1666698314655},{"_id":"public/assets/css/APlayer.min.css","hash":"07372a2ba507388d0fed166d761b1c2c2a659dce","modified":1666698314655},{"_id":"public/assets/js/APlayer.min.js","hash":"22caa28ff6b41a16ff40f15d38f1739e22359478","modified":1666698314655},{"_id":"public/assets/js/Meting.min.js","hash":"a0585220b918d78649a7893279e1ec4fb5abe835","modified":1666698314655},{"_id":"public/uploads/weichatpay.png","hash":"72cd85497ee9a0c9a8d18cdac47caf5a6fdff78b","modified":1666698314982},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1666698314987},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1666698314992},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1666698315000},{"_id":"public/js/src/bootstrap.js","hash":"aab7be0a6e2724b3faa9338db93c19556c559625","modified":1666698315000},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1666698315000},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1666698315000},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1666698315000},{"_id":"public/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1666698315000},{"_id":"public/js/src/post-details.js","hash":"af7a417dd1cb02465a7b98211653e7c6192e6d55","modified":1666698315000},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1666698315000},{"_id":"public/js/src/utils.js","hash":"b2ea56de27fddc6d9118051da384f781cd93951d","modified":1666698315000},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1666698315000},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1666698315000},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"3587602ad777b031628bb5944864d1a4fcfea4ac","modified":1666698315000},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1666698315000},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1666698315000},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1666698315000},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1666698315000},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1666698315000},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1666698315000},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1666698315000},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1666698315000},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1666698315000},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1666698315000},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1666698315000},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1666698315000},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1666698315000},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1666698315000},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1666698315001},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1666698315001},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1666698315001},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1666698315001},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1666698315001},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1666698315001},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1666698315001},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1666698315001},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1666698315001},{"_id":"public/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1666698315001},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1666698315001},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1666698315001},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1666698315001},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1666698315001},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1666698315001},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1666698315001},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1666698315001},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1666698315001},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1666698315001},{"_id":"public/lib/fastclick/README.html","hash":"c07b353b4efa132290ec4479102a55d80ac6d300","modified":1666698315001},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"06811ca2f722dead021493457f27cdc264ef928d","modified":1666698315001},{"_id":"public/lib/jquery_lazyload/README.html","hash":"a08fccd381c8fdb70ba8974b208254c5ba23a95f","modified":1666698315001},{"_id":"public/css/main.css","hash":"769874209833f6a0019abdfded5080885199b29f","modified":1666698315001},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1666698315001},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1666698315001},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1666698315001},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1666698315001},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1666698315001},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1666698315001},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1666698315001},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1666698315001},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1666698315001},{"_id":"public/lib/Han/dist/han.min.css","hash":"d9c0b3dc9158e717fde36f554709e6c3a22b5f85","modified":1666698315001},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1666698315001},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1666698315001},{"_id":"public/lib/Han/dist/han.css","hash":"38e48f275ad00daa9dcdcb8d9b44e576acda4707","modified":1666698315001},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1666698315001},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1666698315001},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1666698315001},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1666698315001},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1666698315001},{"_id":"public/images/my/2.png","hash":"84000b4ca881203f242c1f928fad78660bc432a8","modified":1666698315001},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1666698315001},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1666698315001},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1666698315001},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1666698315007}],"Category":[{"name":"ML框架","_id":"cl9o551nx0005jqrrvmm6b0y6"},{"name":"Web开发","_id":"cl9o551o8000pjqrr7o73lh1d"},{"name":"信息安全","_id":"cl9o551o9000wjqrrkcbssxp6"},{"name":"搜推广","_id":"cl9o551ob0019jqrrys7svt6v"},{"name":"数学","_id":"cl9o551oj0020jqrriemy1k6g"},{"name":"机器学习","_id":"cl9o551ox0038jqrrs9fght1t"},{"name":"深度学习","_id":"cl9o551pa004ojqrrpso5l46z"},{"name":"编程开发","_id":"cl9o551pb0050jqrr3sx3to5c"},{"name":"自然语言处理","_id":"cl9o551pc0056jqrr37o0dh24"},{"name":"AutoML","parent":"cl9o551pa004ojqrrpso5l46z","_id":"cl9o551pc005cjqrrhjx4rjtm"},{"name":"强化学习","parent":"cl9o551pa004ojqrrpso5l46z","_id":"cl9o551pd005fjqrrv2s8wu0z"},{"name":"大数据","_id":"cl9o551qd005mjqrrmi7z3orm"},{"name":"Flink","parent":"cl9o551qd005mjqrrmi7z3orm","_id":"cl9o551qh005xjqrr2mwcjraj"},{"name":"Databus","parent":"cl9o551qd005mjqrrmi7z3orm","_id":"cl9o551qi0061jqrrmz3xr6zb"},{"name":"Kafka","parent":"cl9o551qd005mjqrrmi7z3orm","_id":"cl9o551qk0066jqrr8otwtl7f"},{"name":"Spark","parent":"cl9o551qd005mjqrrmi7z3orm","_id":"cl9o551qp006djqrrulq178d6"},{"name":"Hive","parent":"cl9o551qd005mjqrrmi7z3orm","_id":"cl9o551qq006kjqrrq4qcwhx7"},{"name":"操作系统","_id":"cl9o551r5007jjqrru6ypn7l8"},{"name":"C++","parent":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551rf007zjqrr480trm4s"},{"name":"Java","parent":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551rp0085jqrr7jh70lq3"},{"name":"Latex","parent":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s0009ejqrr8ps7o9qo"},{"name":"Python","parent":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s0009ijqrr7dh6lcdo"},{"name":"Linux","parent":"cl9o551r5007jjqrru6ypn7l8","_id":"cl9o551s1009ljqrrp4nbnhtd"},{"name":"Mac","parent":"cl9o551r5007jjqrru6ypn7l8","_id":"cl9o551s300abjqrr4j3p1dmh"},{"name":"Shell","parent":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s300afjqrrbsk9dkb3"},{"name":"Vim","parent":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s500b5jqrrdx55s50t"}],"Data":[],"Page":[{"title":"分类","date":"2020-06-04T12:25:11.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle: 分类\ndate: 2020-06-04 20:25:11\ntype: \"categories\"\ncomments: false\n---\n","updated":"2022-09-15T03:46:43.369Z","path":"categories/index.html","layout":"page","_id":"cl9o551lq0000jqrr3djc6boi","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script>","site":{"data":{}},"excerpt":"","more":""},{"title":"关于我","date":"2020-06-04T13:04:18.000Z","type":"about","_content":"\n一个很菜的、需要不断学习的、主攻算法的伪全栈工程师。\n\n{% aplayer \"火车驶向云外,梦安魂于九霄\" \"刺猬乐队\" \"https://link.hhtjim.com/163/528272281.mp3\" \"https://pic2.zhimg.com/v2-803be54f1f05f2fdce4735d43809c0d3_1200x500.jpg\" \"autoplay\" %}\n\n\n\n","source":"about/index.md","raw":"---\ntitle: 关于我\ndate: 2020-06-04 21:04:18\ntype: \"about\"\n---\n\n一个很菜的、需要不断学习的、主攻算法的伪全栈工程师。\n\n{% aplayer \"火车驶向云外,梦安魂于九霄\" \"刺猬乐队\" \"https://link.hhtjim.com/163/528272281.mp3\" \"https://pic2.zhimg.com/v2-803be54f1f05f2fdce4735d43809c0d3_1200x500.jpg\" \"autoplay\" %}\n\n\n\n","updated":"2022-09-15T03:46:43.369Z","path":"about/index.html","comments":1,"layout":"page","_id":"cl9o551ls0001jqrrv7jmvkh9","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>一个很菜的、需要不断学习的、主攻算法的伪全栈工程师。</p>\n\n        <div id=\"aplayer-SMLnNrZd\" class=\"aplayer aplayer-tag-marker\" style=\"margin-bottom: 20px;\">\n            <pre class=\"aplayer-lrc-content\"></pre>\n        </div>\n        <script>\n          var ap = new APlayer({\n            element: document.getElementById(\"aplayer-SMLnNrZd\"),\n            narrow: false,\n            autoplay: true,\n            showlrc: false,\n            music: {\n              title: \"火车驶向云外,梦安魂于九霄\",\n              author: \"刺猬乐队\",\n              url: \"https://link.hhtjim.com/163/528272281.mp3\",\n              pic: \"https://pic2.zhimg.com/v2-803be54f1f05f2fdce4735d43809c0d3_1200x500.jpg\",\n              lrc: \"\"\n            }\n          });\n          window.aplayers || (window.aplayers = []);\n          window.aplayers.push(ap);\n        </script>\n","site":{"data":{}},"excerpt":"","more":"<p>一个很菜的、需要不断学习的、主攻算法的伪全栈工程师。</p>\n\n        <div id=\"aplayer-SMLnNrZd\" class=\"aplayer aplayer-tag-marker\" style=\"margin-bottom: 20px;\">\n            <pre class=\"aplayer-lrc-content\"></pre>\n        </div>\n        <script>\n          var ap = new APlayer({\n            element: document.getElementById(\"aplayer-SMLnNrZd\"),\n            narrow: false,\n            autoplay: true,\n            showlrc: false,\n            music: {\n              title: \"火车驶向云外,梦安魂于九霄\",\n              author: \"刺猬乐队\",\n              url: \"https://link.hhtjim.com/163/528272281.mp3\",\n              pic: \"https://pic2.zhimg.com/v2-803be54f1f05f2fdce4735d43809c0d3_1200x500.jpg\",\n              lrc: \"\"\n            }\n          });\n          window.aplayers || (window.aplayers = []);\n          window.aplayers.push(ap);\n        </script>\n"},{"title":"tags","date":"2019-11-13T03:21:44.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-11-13 11:21:44\ntype: \"tags\"\ncomments: false\n---\n","updated":"2022-09-15T03:46:43.370Z","path":"tags/index.html","layout":"page","_id":"cl9o551lt0002jqrrqueie8q3","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script>","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Cuda、Tensorflow、Pytorch版本匹配","date":"2020-02-09T16:00:00.000Z","_content":"\n\n\n#### Tensorflow和Cuda、Cudnn版本对应关系\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh6yeb38cmj315y0u0h0c.jpg\" alt=\"image-20200728202135462\" style=\"zoom:50%;\" />\n\n所以Cuda 10.0以上版本，就需要tensorflow 1.13.1以上\n\n\n\n#### Pytorch和Cuda版本对应关系\n\nhttps://pytorch.org/get-started/previous-versions/\n\n一般就Cuda 10.0的话，pytorch得是1.0.0以上","source":"_posts/ML框架/Cuda、Tensorflow、Pytorch版本匹配.md","raw":"---\ntitle: Cuda、Tensorflow、Pytorch版本匹配\ndate: 2020-02-10\ntags: [Tensorflow,Pytorch]\ncategories: ML框架\n---\n\n\n\n#### Tensorflow和Cuda、Cudnn版本对应关系\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh6yeb38cmj315y0u0h0c.jpg\" alt=\"image-20200728202135462\" style=\"zoom:50%;\" />\n\n所以Cuda 10.0以上版本，就需要tensorflow 1.13.1以上\n\n\n\n#### Pytorch和Cuda版本对应关系\n\nhttps://pytorch.org/get-started/previous-versions/\n\n一般就Cuda 10.0的话，pytorch得是1.0.0以上","slug":"ML框架/Cuda、Tensorflow、Pytorch版本匹配","published":1,"updated":"2022-09-15T03:46:43.358Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551ns0003jqrrsy54fx4t","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h4 id=\"Tensorflow和Cuda、Cudnn版本对应关系\"><a href=\"#Tensorflow和Cuda、Cudnn版本对应关系\" class=\"headerlink\" title=\"Tensorflow和Cuda、Cudnn版本对应关系\"></a>Tensorflow和Cuda、Cudnn版本对应关系</h4><p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh6yeb38cmj315y0u0h0c.jpg\" alt=\"image-20200728202135462\" style=\"zoom:50%;\"></p>\n<p>所以Cuda 10.0以上版本，就需要tensorflow 1.13.1以上</p>\n<h4 id=\"Pytorch和Cuda版本对应关系\"><a href=\"#Pytorch和Cuda版本对应关系\" class=\"headerlink\" title=\"Pytorch和Cuda版本对应关系\"></a>Pytorch和Cuda版本对应关系</h4><p><a href=\"https://pytorch.org/get-started/previous-versions/\" target=\"_blank\" rel=\"noopener\">https://pytorch.org/get-started/previous-versions/</a></p>\n<p>一般就Cuda 10.0的话，pytorch得是1.0.0以上</p>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"Tensorflow和Cuda、Cudnn版本对应关系\"><a href=\"#Tensorflow和Cuda、Cudnn版本对应关系\" class=\"headerlink\" title=\"Tensorflow和Cuda、Cudnn版本对应关系\"></a>Tensorflow和Cuda、Cudnn版本对应关系</h4><p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh6yeb38cmj315y0u0h0c.jpg\" alt=\"image-20200728202135462\" style=\"zoom:50%;\"></p>\n<p>所以Cuda 10.0以上版本，就需要tensorflow 1.13.1以上</p>\n<h4 id=\"Pytorch和Cuda版本对应关系\"><a href=\"#Pytorch和Cuda版本对应关系\" class=\"headerlink\" title=\"Pytorch和Cuda版本对应关系\"></a>Pytorch和Cuda版本对应关系</h4><p><a href=\"https://pytorch.org/get-started/previous-versions/\" target=\"_blank\" rel=\"noopener\">https://pytorch.org/get-started/previous-versions/</a></p>\n<p>一般就Cuda 10.0的话，pytorch得是1.0.0以上</p>\n"},{"title":"Tensorflow和Pytorch的比较","date":"2020-07-28T16:00:00.000Z","_content":"\n\n\n### 比较\n\n来自：https://zhuanlan.zhihu.com/p/110177607\n\nTensorflow 在工业界有着更广泛的应用，Pytorch在学术界有着更广泛的应用。\n\nTensorFlow强在在线部署，多语言支持和较好的线上系统稳定性，我觉得这个是TensorFlow在业界被广泛应用的最主要原因。在业界，无论算法性能有多好，总归还是要上线的，不然都是白扯，不上线就算不到kpi中去。而方便部署到线上，支持多语言，并且有较好的系统稳定性以及有非常多线上应用实例是TensorFlow称霸业界的主要原因。\n\n比较好一点的公司会在线上部署TensorFlow Serving，这样算法科学家们只需要提供相应的Tensorflow model即可将模型上线。但是据我所知，在国内某电商巨头公司内部，只有某院才能够使用TensorFlow Serving, 其他业务部门(包括很多小公司)想将TensorFlow modle上到线上，一律通过TensorFlow api来加载模型，做线上serve。这时候TensorFlow 支持多语言的特性就发挥了巨大的作用，它不仅支持c++， python，还支持如java等语言；很多公司目前的infrastructure 还没有针对AI做更新换代，也不提供相应的TensorFlow serving 能力，所以这些公司基本都用C++或者java来做TensorFlow 模型的线上serve。再者，TensorFlow基于静态图的这种方式非常适合线上应用，一次build好graph，多次在这个图上面做inference，工程效率很高。\n\n但是在线下，TensorFlow体验很差，用过的人都觉得体验很不好。1. 在TensorFlow1.x时期，基于静态图的模式，无法在变量定义和使用的时候查看tensor的值，只有在session run的时候才能查看tensor的值，使得debug起来异常困难。2. TensorFlow API混乱，使用体验比较差。\n\n而Pytorch 在API和文档方面都做得更好，并且pytorch是基于动态图的模式，可以很方便的查看tensor的值，可以像debug Python程序一样debug pytorch模型。因此，pytorch在只关心算法性能而不用太关心部署的学术界，非常受欢迎。\n\n虽然TensorFlow2.x默认是eager execution模式，可以像pytorch一样直接查看tensor的值，但是个人感觉出来的还是有点晚，短时间内可能不太会是主流的线下框架了。一方面，已经习惯TensorFlow1.x的人还要重新学习tensorflow2.x，并且在TensorFlow1.x中静态图习惯的一些写法，在TensorFlow2.x可能不怎么支持，还要重新再踩很多坑，才能比较好的掌握；另一方面，习惯使用pytorch的那波人不太会去在学习TensorFlow2.x。\n\n虽然Pytorch在新版本中也出了新的特性，更好的支持线上部署，但毕竟是才出来不久，没有经过线上的长时间检验，实际线上应用案例和分享也比较少。而TensorFlow自15年release以来，已经在线上经历了五年多的考验，撑过了多次双十一高流量的检测，性能稳定。Pytorch想更广泛应用在线上，短时间内也不太现实，替换成本还是很高，TensorFlow在这方面已经占尽了先机。\n\n总的来说，Tensorflow在业界线上部署占尽了先机，而Pytorch在线下占尽了先机，短时间内谁都不能很快的取代谁。\n\n\n\n### 现在较好的部署手段\n\n##### 使用Tensorflow\n\n- TF-serving\n- Tensorflow java/C++/python api，自定义服务上线\n- 转成uff模型，tensorRT上线 \n\n##### 使用Pytorch\n\n- Pytorch python等api，自定义服务上线\n- 转成tensorflow模型，然后参考tensorflow上线方式\n- 转成onnx模型，tensorRT上线\n\n\n\nTensorRT：https://zhuanlan.zhihu.com/p/88318324","source":"_posts/ML框架/Tensorflow和Pytorch的比较.md","raw":"---\ntitle: Tensorflow和Pytorch的比较\ndate: 2020-07-29\ntags: [Tensorflow,Pytorch]\ncategories: ML框架\n---\n\n\n\n### 比较\n\n来自：https://zhuanlan.zhihu.com/p/110177607\n\nTensorflow 在工业界有着更广泛的应用，Pytorch在学术界有着更广泛的应用。\n\nTensorFlow强在在线部署，多语言支持和较好的线上系统稳定性，我觉得这个是TensorFlow在业界被广泛应用的最主要原因。在业界，无论算法性能有多好，总归还是要上线的，不然都是白扯，不上线就算不到kpi中去。而方便部署到线上，支持多语言，并且有较好的系统稳定性以及有非常多线上应用实例是TensorFlow称霸业界的主要原因。\n\n比较好一点的公司会在线上部署TensorFlow Serving，这样算法科学家们只需要提供相应的Tensorflow model即可将模型上线。但是据我所知，在国内某电商巨头公司内部，只有某院才能够使用TensorFlow Serving, 其他业务部门(包括很多小公司)想将TensorFlow modle上到线上，一律通过TensorFlow api来加载模型，做线上serve。这时候TensorFlow 支持多语言的特性就发挥了巨大的作用，它不仅支持c++， python，还支持如java等语言；很多公司目前的infrastructure 还没有针对AI做更新换代，也不提供相应的TensorFlow serving 能力，所以这些公司基本都用C++或者java来做TensorFlow 模型的线上serve。再者，TensorFlow基于静态图的这种方式非常适合线上应用，一次build好graph，多次在这个图上面做inference，工程效率很高。\n\n但是在线下，TensorFlow体验很差，用过的人都觉得体验很不好。1. 在TensorFlow1.x时期，基于静态图的模式，无法在变量定义和使用的时候查看tensor的值，只有在session run的时候才能查看tensor的值，使得debug起来异常困难。2. TensorFlow API混乱，使用体验比较差。\n\n而Pytorch 在API和文档方面都做得更好，并且pytorch是基于动态图的模式，可以很方便的查看tensor的值，可以像debug Python程序一样debug pytorch模型。因此，pytorch在只关心算法性能而不用太关心部署的学术界，非常受欢迎。\n\n虽然TensorFlow2.x默认是eager execution模式，可以像pytorch一样直接查看tensor的值，但是个人感觉出来的还是有点晚，短时间内可能不太会是主流的线下框架了。一方面，已经习惯TensorFlow1.x的人还要重新学习tensorflow2.x，并且在TensorFlow1.x中静态图习惯的一些写法，在TensorFlow2.x可能不怎么支持，还要重新再踩很多坑，才能比较好的掌握；另一方面，习惯使用pytorch的那波人不太会去在学习TensorFlow2.x。\n\n虽然Pytorch在新版本中也出了新的特性，更好的支持线上部署，但毕竟是才出来不久，没有经过线上的长时间检验，实际线上应用案例和分享也比较少。而TensorFlow自15年release以来，已经在线上经历了五年多的考验，撑过了多次双十一高流量的检测，性能稳定。Pytorch想更广泛应用在线上，短时间内也不太现实，替换成本还是很高，TensorFlow在这方面已经占尽了先机。\n\n总的来说，Tensorflow在业界线上部署占尽了先机，而Pytorch在线下占尽了先机，短时间内谁都不能很快的取代谁。\n\n\n\n### 现在较好的部署手段\n\n##### 使用Tensorflow\n\n- TF-serving\n- Tensorflow java/C++/python api，自定义服务上线\n- 转成uff模型，tensorRT上线 \n\n##### 使用Pytorch\n\n- Pytorch python等api，自定义服务上线\n- 转成tensorflow模型，然后参考tensorflow上线方式\n- 转成onnx模型，tensorRT上线\n\n\n\nTensorRT：https://zhuanlan.zhihu.com/p/88318324","slug":"ML框架/Tensorflow和Pytorch的比较","published":1,"updated":"2022-09-15T03:46:43.359Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551nv0004jqrrm844gqrs","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"比较\"><a href=\"#比较\" class=\"headerlink\" title=\"比较\"></a>比较</h3><p>来自：<a href=\"https://zhuanlan.zhihu.com/p/110177607\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/110177607</a></p>\n<p>Tensorflow 在工业界有着更广泛的应用，Pytorch在学术界有着更广泛的应用。</p>\n<p>TensorFlow强在在线部署，多语言支持和较好的线上系统稳定性，我觉得这个是TensorFlow在业界被广泛应用的最主要原因。在业界，无论算法性能有多好，总归还是要上线的，不然都是白扯，不上线就算不到kpi中去。而方便部署到线上，支持多语言，并且有较好的系统稳定性以及有非常多线上应用实例是TensorFlow称霸业界的主要原因。</p>\n<p>比较好一点的公司会在线上部署TensorFlow Serving，这样算法科学家们只需要提供相应的Tensorflow model即可将模型上线。但是据我所知，在国内某电商巨头公司内部，只有某院才能够使用TensorFlow Serving, 其他业务部门(包括很多小公司)想将TensorFlow modle上到线上，一律通过TensorFlow api来加载模型，做线上serve。这时候TensorFlow 支持多语言的特性就发挥了巨大的作用，它不仅支持c++， python，还支持如java等语言；很多公司目前的infrastructure 还没有针对AI做更新换代，也不提供相应的TensorFlow serving 能力，所以这些公司基本都用C++或者java来做TensorFlow 模型的线上serve。再者，TensorFlow基于静态图的这种方式非常适合线上应用，一次build好graph，多次在这个图上面做inference，工程效率很高。</p>\n<p>但是在线下，TensorFlow体验很差，用过的人都觉得体验很不好。1. 在TensorFlow1.x时期，基于静态图的模式，无法在变量定义和使用的时候查看tensor的值，只有在session run的时候才能查看tensor的值，使得debug起来异常困难。2. TensorFlow API混乱，使用体验比较差。</p>\n<p>而Pytorch 在API和文档方面都做得更好，并且pytorch是基于动态图的模式，可以很方便的查看tensor的值，可以像debug Python程序一样debug pytorch模型。因此，pytorch在只关心算法性能而不用太关心部署的学术界，非常受欢迎。</p>\n<p>虽然TensorFlow2.x默认是eager execution模式，可以像pytorch一样直接查看tensor的值，但是个人感觉出来的还是有点晚，短时间内可能不太会是主流的线下框架了。一方面，已经习惯TensorFlow1.x的人还要重新学习tensorflow2.x，并且在TensorFlow1.x中静态图习惯的一些写法，在TensorFlow2.x可能不怎么支持，还要重新再踩很多坑，才能比较好的掌握；另一方面，习惯使用pytorch的那波人不太会去在学习TensorFlow2.x。</p>\n<p>虽然Pytorch在新版本中也出了新的特性，更好的支持线上部署，但毕竟是才出来不久，没有经过线上的长时间检验，实际线上应用案例和分享也比较少。而TensorFlow自15年release以来，已经在线上经历了五年多的考验，撑过了多次双十一高流量的检测，性能稳定。Pytorch想更广泛应用在线上，短时间内也不太现实，替换成本还是很高，TensorFlow在这方面已经占尽了先机。</p>\n<p>总的来说，Tensorflow在业界线上部署占尽了先机，而Pytorch在线下占尽了先机，短时间内谁都不能很快的取代谁。</p>\n<h3 id=\"现在较好的部署手段\"><a href=\"#现在较好的部署手段\" class=\"headerlink\" title=\"现在较好的部署手段\"></a>现在较好的部署手段</h3><h5 id=\"使用Tensorflow\"><a href=\"#使用Tensorflow\" class=\"headerlink\" title=\"使用Tensorflow\"></a>使用Tensorflow</h5><ul>\n<li>TF-serving</li>\n<li>Tensorflow java/C++/python api，自定义服务上线</li>\n<li>转成uff模型，tensorRT上线 </li>\n</ul>\n<h5 id=\"使用Pytorch\"><a href=\"#使用Pytorch\" class=\"headerlink\" title=\"使用Pytorch\"></a>使用Pytorch</h5><ul>\n<li>Pytorch python等api，自定义服务上线</li>\n<li>转成tensorflow模型，然后参考tensorflow上线方式</li>\n<li>转成onnx模型，tensorRT上线</li>\n</ul>\n<p>TensorRT：<a href=\"https://zhuanlan.zhihu.com/p/88318324\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/88318324</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"比较\"><a href=\"#比较\" class=\"headerlink\" title=\"比较\"></a>比较</h3><p>来自：<a href=\"https://zhuanlan.zhihu.com/p/110177607\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/110177607</a></p>\n<p>Tensorflow 在工业界有着更广泛的应用，Pytorch在学术界有着更广泛的应用。</p>\n<p>TensorFlow强在在线部署，多语言支持和较好的线上系统稳定性，我觉得这个是TensorFlow在业界被广泛应用的最主要原因。在业界，无论算法性能有多好，总归还是要上线的，不然都是白扯，不上线就算不到kpi中去。而方便部署到线上，支持多语言，并且有较好的系统稳定性以及有非常多线上应用实例是TensorFlow称霸业界的主要原因。</p>\n<p>比较好一点的公司会在线上部署TensorFlow Serving，这样算法科学家们只需要提供相应的Tensorflow model即可将模型上线。但是据我所知，在国内某电商巨头公司内部，只有某院才能够使用TensorFlow Serving, 其他业务部门(包括很多小公司)想将TensorFlow modle上到线上，一律通过TensorFlow api来加载模型，做线上serve。这时候TensorFlow 支持多语言的特性就发挥了巨大的作用，它不仅支持c++， python，还支持如java等语言；很多公司目前的infrastructure 还没有针对AI做更新换代，也不提供相应的TensorFlow serving 能力，所以这些公司基本都用C++或者java来做TensorFlow 模型的线上serve。再者，TensorFlow基于静态图的这种方式非常适合线上应用，一次build好graph，多次在这个图上面做inference，工程效率很高。</p>\n<p>但是在线下，TensorFlow体验很差，用过的人都觉得体验很不好。1. 在TensorFlow1.x时期，基于静态图的模式，无法在变量定义和使用的时候查看tensor的值，只有在session run的时候才能查看tensor的值，使得debug起来异常困难。2. TensorFlow API混乱，使用体验比较差。</p>\n<p>而Pytorch 在API和文档方面都做得更好，并且pytorch是基于动态图的模式，可以很方便的查看tensor的值，可以像debug Python程序一样debug pytorch模型。因此，pytorch在只关心算法性能而不用太关心部署的学术界，非常受欢迎。</p>\n<p>虽然TensorFlow2.x默认是eager execution模式，可以像pytorch一样直接查看tensor的值，但是个人感觉出来的还是有点晚，短时间内可能不太会是主流的线下框架了。一方面，已经习惯TensorFlow1.x的人还要重新学习tensorflow2.x，并且在TensorFlow1.x中静态图习惯的一些写法，在TensorFlow2.x可能不怎么支持，还要重新再踩很多坑，才能比较好的掌握；另一方面，习惯使用pytorch的那波人不太会去在学习TensorFlow2.x。</p>\n<p>虽然Pytorch在新版本中也出了新的特性，更好的支持线上部署，但毕竟是才出来不久，没有经过线上的长时间检验，实际线上应用案例和分享也比较少。而TensorFlow自15年release以来，已经在线上经历了五年多的考验，撑过了多次双十一高流量的检测，性能稳定。Pytorch想更广泛应用在线上，短时间内也不太现实，替换成本还是很高，TensorFlow在这方面已经占尽了先机。</p>\n<p>总的来说，Tensorflow在业界线上部署占尽了先机，而Pytorch在线下占尽了先机，短时间内谁都不能很快的取代谁。</p>\n<h3 id=\"现在较好的部署手段\"><a href=\"#现在较好的部署手段\" class=\"headerlink\" title=\"现在较好的部署手段\"></a>现在较好的部署手段</h3><h5 id=\"使用Tensorflow\"><a href=\"#使用Tensorflow\" class=\"headerlink\" title=\"使用Tensorflow\"></a>使用Tensorflow</h5><ul>\n<li>TF-serving</li>\n<li>Tensorflow java/C++/python api，自定义服务上线</li>\n<li>转成uff模型，tensorRT上线 </li>\n</ul>\n<h5 id=\"使用Pytorch\"><a href=\"#使用Pytorch\" class=\"headerlink\" title=\"使用Pytorch\"></a>使用Pytorch</h5><ul>\n<li>Pytorch python等api，自定义服务上线</li>\n<li>转成tensorflow模型，然后参考tensorflow上线方式</li>\n<li>转成onnx模型，tensorRT上线</li>\n</ul>\n<p>TensorRT：<a href=\"https://zhuanlan.zhihu.com/p/88318324\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/88318324</a></p>\n"},{"title":"Tensorflow2.0的几个变动","date":"2019-11-18T14:06:02.000Z","_content":"\n\n\n## 1. 原来API的变动\n\n原先v1.0的诸多API都是发生了变动或者删除：\n\n- 删除了tf.variable_scope, tf.get_variable\n\n- tf.layer弃用，高层api统一用tf.keras\n\n- 原先一些api也都不要用了，目前可以用tf.compat.v1.*来代替，但是只维护一年。\n\n  \n## 2. 动态图机制\n\n- Eager execution作为默认工作模式\n    - Eager Execution（动态图机制）是TensorFlow的一个命令式编程环境，它无需构建计算图，可以直接评估你的操作：直接返回具体值，而不是构建完计算图后再返回。\n    - 有了Eager Execution，我们不再需要事先定义计算图，然后再在session里评估它。它允许用python语句控制模型的结构。\n- AutoGraph\n    - 在 TensorFlow 1.x 版本中，要开发基于张量控制流的程序，必须使用 tf.conf、tf. while_loop 之类的专用函数。这增加了开发的复杂度。\n    - 在 TensorFlow 2.x 版本中，可以通过自动图（AutoGraph）功能，将普通的 Python 控制流语句转成基于张量的运算图，大大简化了开发工作。\n\n总体来看，动态图的机制和pytorch极像。目前为了稳妥起见，打算先不升级到2.0，用tf.13就行，高层api统一切换到tf.keras\n\n","source":"_posts/ML框架/Tf 2.0的几个变动.md","raw":"---\ntitle: Tensorflow2.0的几个变动\ndate: 2019-11-18 22:06:02\ntags: Tensorflow\ncategories: ML框架\n---\n\n\n\n## 1. 原来API的变动\n\n原先v1.0的诸多API都是发生了变动或者删除：\n\n- 删除了tf.variable_scope, tf.get_variable\n\n- tf.layer弃用，高层api统一用tf.keras\n\n- 原先一些api也都不要用了，目前可以用tf.compat.v1.*来代替，但是只维护一年。\n\n  \n## 2. 动态图机制\n\n- Eager execution作为默认工作模式\n    - Eager Execution（动态图机制）是TensorFlow的一个命令式编程环境，它无需构建计算图，可以直接评估你的操作：直接返回具体值，而不是构建完计算图后再返回。\n    - 有了Eager Execution，我们不再需要事先定义计算图，然后再在session里评估它。它允许用python语句控制模型的结构。\n- AutoGraph\n    - 在 TensorFlow 1.x 版本中，要开发基于张量控制流的程序，必须使用 tf.conf、tf. while_loop 之类的专用函数。这增加了开发的复杂度。\n    - 在 TensorFlow 2.x 版本中，可以通过自动图（AutoGraph）功能，将普通的 Python 控制流语句转成基于张量的运算图，大大简化了开发工作。\n\n总体来看，动态图的机制和pytorch极像。目前为了稳妥起见，打算先不升级到2.0，用tf.13就行，高层api统一切换到tf.keras\n\n","slug":"ML框架/Tf 2.0的几个变动","published":1,"updated":"2022-09-15T03:46:43.359Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551ny0007jqrri69yfdh8","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"1-原来API的变动\"><a href=\"#1-原来API的变动\" class=\"headerlink\" title=\"1. 原来API的变动\"></a>1. 原来API的变动</h2><p>原先v1.0的诸多API都是发生了变动或者删除：</p>\n<ul>\n<li><p>删除了tf.variable_scope, tf.get_variable</p>\n</li>\n<li><p>tf.layer弃用，高层api统一用tf.keras</p>\n</li>\n<li><p>原先一些api也都不要用了，目前可以用tf.compat.v1.*来代替，但是只维护一年。</p>\n</li>\n</ul>\n<h2 id=\"2-动态图机制\"><a href=\"#2-动态图机制\" class=\"headerlink\" title=\"2. 动态图机制\"></a>2. 动态图机制</h2><ul>\n<li>Eager execution作为默认工作模式<ul>\n<li>Eager Execution（动态图机制）是TensorFlow的一个命令式编程环境，它无需构建计算图，可以直接评估你的操作：直接返回具体值，而不是构建完计算图后再返回。</li>\n<li>有了Eager Execution，我们不再需要事先定义计算图，然后再在session里评估它。它允许用python语句控制模型的结构。</li>\n</ul>\n</li>\n<li>AutoGraph<ul>\n<li>在 TensorFlow 1.x 版本中，要开发基于张量控制流的程序，必须使用 tf.conf、tf. while_loop 之类的专用函数。这增加了开发的复杂度。</li>\n<li>在 TensorFlow 2.x 版本中，可以通过自动图（AutoGraph）功能，将普通的 Python 控制流语句转成基于张量的运算图，大大简化了开发工作。</li>\n</ul>\n</li>\n</ul>\n<p>总体来看，动态图的机制和pytorch极像。目前为了稳妥起见，打算先不升级到2.0，用tf.13就行，高层api统一切换到tf.keras</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"1-原来API的变动\"><a href=\"#1-原来API的变动\" class=\"headerlink\" title=\"1. 原来API的变动\"></a>1. 原来API的变动</h2><p>原先v1.0的诸多API都是发生了变动或者删除：</p>\n<ul>\n<li><p>删除了tf.variable_scope, tf.get_variable</p>\n</li>\n<li><p>tf.layer弃用，高层api统一用tf.keras</p>\n</li>\n<li><p>原先一些api也都不要用了，目前可以用tf.compat.v1.*来代替，但是只维护一年。</p>\n</li>\n</ul>\n<h2 id=\"2-动态图机制\"><a href=\"#2-动态图机制\" class=\"headerlink\" title=\"2. 动态图机制\"></a>2. 动态图机制</h2><ul>\n<li>Eager execution作为默认工作模式<ul>\n<li>Eager Execution（动态图机制）是TensorFlow的一个命令式编程环境，它无需构建计算图，可以直接评估你的操作：直接返回具体值，而不是构建完计算图后再返回。</li>\n<li>有了Eager Execution，我们不再需要事先定义计算图，然后再在session里评估它。它允许用python语句控制模型的结构。</li>\n</ul>\n</li>\n<li>AutoGraph<ul>\n<li>在 TensorFlow 1.x 版本中，要开发基于张量控制流的程序，必须使用 tf.conf、tf. while_loop 之类的专用函数。这增加了开发的复杂度。</li>\n<li>在 TensorFlow 2.x 版本中，可以通过自动图（AutoGraph）功能，将普通的 Python 控制流语句转成基于张量的运算图，大大简化了开发工作。</li>\n</ul>\n</li>\n</ul>\n<p>总体来看，动态图的机制和pytorch极像。目前为了稳妥起见，打算先不升级到2.0，用tf.13就行，高层api统一切换到tf.keras</p>\n"},{"title":"Tensorflow中有关Graph和Session的几个问题","date":"2017-07-15T14:48:55.000Z","_content":"\n晚上在写一个简单的cnn时遇到了一个编译错误，代码检查了半天没找到问题。。最后鬼使神差地把全局变量初始化语句改了一下，竟然编译通过了。。研究了一下原因，应该是默认graph的问题。于是，再加上之前的默认session，我把tensorflow中默认graph和默认session几个注意点总结一下。\n\n# 默认Session问题\n\n- session创建后，如果没有指定graph，则该session会调用默认的graph。\n- 调用默认graph的话，session创建语句可以在文件任意位置。因为即使session放在前文，后文里若是定义了新的graph节点，这些节点也会加到默认graph中，接下来调用该session时，调用的也是新的默认graph。\n- 如果以`sess = tf.Session()`创建session，则该session不会作为下文的默认session，需要以`with`语句开头调用该session后，才作为下文的默认session。如果以`sess = tf.InteractiveSession()`创建session, 则该session即是下文的默认session。**默认session的好处是可以直接使用`operation.run()`或`tensor.eval()`, 无需指定session来run**。\n- `with`语句有个好处是，该代码块结束后，session会自动`close`。\n\n# 默认Graph问题\n\n- 如果不指定graph，创建的新节点都会加入到默认graph中。注意，该graph是一个**全局默认graph**,也就说如果你定义了一个函数，这个函数里增加了一些节点，那么，每次调用这个函数，都会在默认graph中增加新节点！因此，如果想要定义类来实现算法，那么以防这种情况，建议将所有的节点操作放在类的初始化`__init__`方法中，这样对于每个实例，初始化也只会执行一次而已。\n- 有个要特别注意的节点操作`tf.global_variables_intializer()`。该项操作读取的是**当前默认graph中**的variable，如果在前文中定义就会出现问题！举个例子，我在前文中定义`init_var = tf.global_variables_intializer()`，然后中间加入新的variable, 最后再执行`init_var.run()`，这样就会出现编译错误信息`Attempting to use uninitialized value beta1_power`！也就是我今天遇到的编译问题！我们只能重新执行`tf.global_variables_intializer().run()`才行！\n\n\n# 总结\n\n其实上面说了那么多问题，其实只要规范好代码就可以避免上述问题。所谓的规范就是，session创建和variable初始化这两个步骤，都在graph定义完成后再执行！\n","source":"_posts/ML框架/Tf中有关Graph和Session的几个问题.md","raw":"---\ntitle: Tensorflow中有关Graph和Session的几个问题\ndate: 2017-07-15 22:48:55\ntags: Tensorflow\ncategories: ML框架\n---\n\n晚上在写一个简单的cnn时遇到了一个编译错误，代码检查了半天没找到问题。。最后鬼使神差地把全局变量初始化语句改了一下，竟然编译通过了。。研究了一下原因，应该是默认graph的问题。于是，再加上之前的默认session，我把tensorflow中默认graph和默认session几个注意点总结一下。\n\n# 默认Session问题\n\n- session创建后，如果没有指定graph，则该session会调用默认的graph。\n- 调用默认graph的话，session创建语句可以在文件任意位置。因为即使session放在前文，后文里若是定义了新的graph节点，这些节点也会加到默认graph中，接下来调用该session时，调用的也是新的默认graph。\n- 如果以`sess = tf.Session()`创建session，则该session不会作为下文的默认session，需要以`with`语句开头调用该session后，才作为下文的默认session。如果以`sess = tf.InteractiveSession()`创建session, 则该session即是下文的默认session。**默认session的好处是可以直接使用`operation.run()`或`tensor.eval()`, 无需指定session来run**。\n- `with`语句有个好处是，该代码块结束后，session会自动`close`。\n\n# 默认Graph问题\n\n- 如果不指定graph，创建的新节点都会加入到默认graph中。注意，该graph是一个**全局默认graph**,也就说如果你定义了一个函数，这个函数里增加了一些节点，那么，每次调用这个函数，都会在默认graph中增加新节点！因此，如果想要定义类来实现算法，那么以防这种情况，建议将所有的节点操作放在类的初始化`__init__`方法中，这样对于每个实例，初始化也只会执行一次而已。\n- 有个要特别注意的节点操作`tf.global_variables_intializer()`。该项操作读取的是**当前默认graph中**的variable，如果在前文中定义就会出现问题！举个例子，我在前文中定义`init_var = tf.global_variables_intializer()`，然后中间加入新的variable, 最后再执行`init_var.run()`，这样就会出现编译错误信息`Attempting to use uninitialized value beta1_power`！也就是我今天遇到的编译问题！我们只能重新执行`tf.global_variables_intializer().run()`才行！\n\n\n# 总结\n\n其实上面说了那么多问题，其实只要规范好代码就可以避免上述问题。所谓的规范就是，session创建和variable初始化这两个步骤，都在graph定义完成后再执行！\n","slug":"ML框架/Tf中有关Graph和Session的几个问题","published":1,"updated":"2022-09-15T03:46:43.359Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551nz0008jqrrdgiulxo3","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>晚上在写一个简单的cnn时遇到了一个编译错误，代码检查了半天没找到问题。。最后鬼使神差地把全局变量初始化语句改了一下，竟然编译通过了。。研究了一下原因，应该是默认graph的问题。于是，再加上之前的默认session，我把tensorflow中默认graph和默认session几个注意点总结一下。</p>\n<h1 id=\"默认Session问题\"><a href=\"#默认Session问题\" class=\"headerlink\" title=\"默认Session问题\"></a>默认Session问题</h1><ul>\n<li>session创建后，如果没有指定graph，则该session会调用默认的graph。</li>\n<li>调用默认graph的话，session创建语句可以在文件任意位置。因为即使session放在前文，后文里若是定义了新的graph节点，这些节点也会加到默认graph中，接下来调用该session时，调用的也是新的默认graph。</li>\n<li>如果以<code>sess = tf.Session()</code>创建session，则该session不会作为下文的默认session，需要以<code>with</code>语句开头调用该session后，才作为下文的默认session。如果以<code>sess = tf.InteractiveSession()</code>创建session, 则该session即是下文的默认session。<strong>默认session的好处是可以直接使用<code>operation.run()</code>或<code>tensor.eval()</code>, 无需指定session来run</strong>。</li>\n<li><code>with</code>语句有个好处是，该代码块结束后，session会自动<code>close</code>。</li>\n</ul>\n<h1 id=\"默认Graph问题\"><a href=\"#默认Graph问题\" class=\"headerlink\" title=\"默认Graph问题\"></a>默认Graph问题</h1><ul>\n<li>如果不指定graph，创建的新节点都会加入到默认graph中。注意，该graph是一个<strong>全局默认graph</strong>,也就说如果你定义了一个函数，这个函数里增加了一些节点，那么，每次调用这个函数，都会在默认graph中增加新节点！因此，如果想要定义类来实现算法，那么以防这种情况，建议将所有的节点操作放在类的初始化<code>__init__</code>方法中，这样对于每个实例，初始化也只会执行一次而已。</li>\n<li>有个要特别注意的节点操作<code>tf.global_variables_intializer()</code>。该项操作读取的是<strong>当前默认graph中</strong>的variable，如果在前文中定义就会出现问题！举个例子，我在前文中定义<code>init_var = tf.global_variables_intializer()</code>，然后中间加入新的variable, 最后再执行<code>init_var.run()</code>，这样就会出现编译错误信息<code>Attempting to use uninitialized value beta1_power</code>！也就是我今天遇到的编译问题！我们只能重新执行<code>tf.global_variables_intializer().run()</code>才行！</li>\n</ul>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>其实上面说了那么多问题，其实只要规范好代码就可以避免上述问题。所谓的规范就是，session创建和variable初始化这两个步骤，都在graph定义完成后再执行！</p>\n","site":{"data":{}},"excerpt":"","more":"<p>晚上在写一个简单的cnn时遇到了一个编译错误，代码检查了半天没找到问题。。最后鬼使神差地把全局变量初始化语句改了一下，竟然编译通过了。。研究了一下原因，应该是默认graph的问题。于是，再加上之前的默认session，我把tensorflow中默认graph和默认session几个注意点总结一下。</p>\n<h1 id=\"默认Session问题\"><a href=\"#默认Session问题\" class=\"headerlink\" title=\"默认Session问题\"></a>默认Session问题</h1><ul>\n<li>session创建后，如果没有指定graph，则该session会调用默认的graph。</li>\n<li>调用默认graph的话，session创建语句可以在文件任意位置。因为即使session放在前文，后文里若是定义了新的graph节点，这些节点也会加到默认graph中，接下来调用该session时，调用的也是新的默认graph。</li>\n<li>如果以<code>sess = tf.Session()</code>创建session，则该session不会作为下文的默认session，需要以<code>with</code>语句开头调用该session后，才作为下文的默认session。如果以<code>sess = tf.InteractiveSession()</code>创建session, 则该session即是下文的默认session。<strong>默认session的好处是可以直接使用<code>operation.run()</code>或<code>tensor.eval()</code>, 无需指定session来run</strong>。</li>\n<li><code>with</code>语句有个好处是，该代码块结束后，session会自动<code>close</code>。</li>\n</ul>\n<h1 id=\"默认Graph问题\"><a href=\"#默认Graph问题\" class=\"headerlink\" title=\"默认Graph问题\"></a>默认Graph问题</h1><ul>\n<li>如果不指定graph，创建的新节点都会加入到默认graph中。注意，该graph是一个<strong>全局默认graph</strong>,也就说如果你定义了一个函数，这个函数里增加了一些节点，那么，每次调用这个函数，都会在默认graph中增加新节点！因此，如果想要定义类来实现算法，那么以防这种情况，建议将所有的节点操作放在类的初始化<code>__init__</code>方法中，这样对于每个实例，初始化也只会执行一次而已。</li>\n<li>有个要特别注意的节点操作<code>tf.global_variables_intializer()</code>。该项操作读取的是<strong>当前默认graph中</strong>的variable，如果在前文中定义就会出现问题！举个例子，我在前文中定义<code>init_var = tf.global_variables_intializer()</code>，然后中间加入新的variable, 最后再执行<code>init_var.run()</code>，这样就会出现编译错误信息<code>Attempting to use uninitialized value beta1_power</code>！也就是我今天遇到的编译问题！我们只能重新执行<code>tf.global_variables_intializer().run()</code>才行！</li>\n</ul>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>其实上面说了那么多问题，其实只要规范好代码就可以避免上述问题。所谓的规范就是，session创建和variable初始化这两个步骤，都在graph定义完成后再执行！</p>\n"},{"title":"Tensorflow一些常用方法记录","date":"2020-10-27T16:00:00.000Z","_content":"\n\n\n### tf.stack\n\ntf.stack(values, axis=0, name=\"stack\"):\n\n```python\n  x = tf.constant([1, 4])\n  y = tf.constant([2, 5])\n  z = tf.constant([3, 6])\n  tf.stack([x, y, z])  # [[1, 4], [2, 5], [3, 6]] (Pack along first dim.)\n  tf.stack([x, y, z], axis=1)  # [[1, 2, 3], [4, 5, 6]]\n```\n\n本质是把一个长度为N的list，list里的元素有自己的shape：\n\n- axis = 0，则变为（N，shape[0], shape[1], ...）\n- axis = 1，则变为（shape[0], N, shape[1], ...）\n\n常见用法有：\n\n如果元素为长度为M的list\n\n- Axis =0,  其实就相当于横着concate\n- Axis =1，相当于把元素看为列向量，然后竖着concate\n\n\n\n### tf.gather和tf.gather_nd\n\ntf.gather(params, indices, validate_indices=None, name=None, axis=0):\n\n对于params,就是你的输入，axis就是你进行操作的维度，默认为0(对于tf.gather,只能对于给定的axis操作),indices就是你想获取的axis维度上的值，来看一个例子，可以更佳清楚的了解函数是如何使用的：\n\n```python\ntemp = tf.range(0,10)*10 + tf.constant(1,shape=[10])\n\ntemp2 = tf.gather(temp,[1,5,9])\n\nwith tf.Session() as sess:\n\nprint sess.run(temp)\n\nprint sess.run(temp2)\n\n输出\n\n[ 1 11 21 31 41 51 61 71 81 91]\n\n[11 51 91]\n```\n\ntf.gather只能对低维度进行操作，gather_nd可以进行高维度的操作。和gather相比，没有了axis参数，如果indices的维度和params的维度等价，他是直接获取一个具体值(之后组合成向量)。\n\n\n\n### tf.expand_dims和tf.squeeze\n\n- tf.expand_dims(input, axis=None)，就是在对应的axis上加个1的维度，这样可以让tensorflow的元素乘和元素加运算可以用上broadcast机制。\n- broadcast机制：满足下面两个条件即可进行元素复制。\n  - 从后往前维度相同\n  - 遇到不同的话，必须有一个维度为1.\n  - 举例：\n    - a.shape = (4,1,3,3), b.shape(1,3), a+b = (4,1,3,3)\n    - a.shape = (4,1,1,3), b.shape(3,1), a+b = (4,1,3,3)\n\n- tf.squeeze则相反，去掉维度为1的维度。\n\n\n\n### tf.split()\n\n将矩阵的某一维度切分为一个list。\n\n- 'value' is a tensor with shape [5, 30]\n- split0, split1, split2 = tf.split(value, [4, 15, 11], 1)\n- tf.shape(split0)  # [5, 4]\n- tf.shape(split1)  # [5, 15]\n- tf.shape(split2)  # [5, 11]\n\n\n\n### tf.add_n()\n\n将input list里的tensor按元素相加，和普通相加没什么区别，只是可以加个operation name","source":"_posts/ML框架/Tf一些常用方法记录.md","raw":"---\ntitle: Tensorflow一些常用方法记录\ndate: 2020-10-28\ntags: Tensorflow\ncategories: ML框架\n---\n\n\n\n### tf.stack\n\ntf.stack(values, axis=0, name=\"stack\"):\n\n```python\n  x = tf.constant([1, 4])\n  y = tf.constant([2, 5])\n  z = tf.constant([3, 6])\n  tf.stack([x, y, z])  # [[1, 4], [2, 5], [3, 6]] (Pack along first dim.)\n  tf.stack([x, y, z], axis=1)  # [[1, 2, 3], [4, 5, 6]]\n```\n\n本质是把一个长度为N的list，list里的元素有自己的shape：\n\n- axis = 0，则变为（N，shape[0], shape[1], ...）\n- axis = 1，则变为（shape[0], N, shape[1], ...）\n\n常见用法有：\n\n如果元素为长度为M的list\n\n- Axis =0,  其实就相当于横着concate\n- Axis =1，相当于把元素看为列向量，然后竖着concate\n\n\n\n### tf.gather和tf.gather_nd\n\ntf.gather(params, indices, validate_indices=None, name=None, axis=0):\n\n对于params,就是你的输入，axis就是你进行操作的维度，默认为0(对于tf.gather,只能对于给定的axis操作),indices就是你想获取的axis维度上的值，来看一个例子，可以更佳清楚的了解函数是如何使用的：\n\n```python\ntemp = tf.range(0,10)*10 + tf.constant(1,shape=[10])\n\ntemp2 = tf.gather(temp,[1,5,9])\n\nwith tf.Session() as sess:\n\nprint sess.run(temp)\n\nprint sess.run(temp2)\n\n输出\n\n[ 1 11 21 31 41 51 61 71 81 91]\n\n[11 51 91]\n```\n\ntf.gather只能对低维度进行操作，gather_nd可以进行高维度的操作。和gather相比，没有了axis参数，如果indices的维度和params的维度等价，他是直接获取一个具体值(之后组合成向量)。\n\n\n\n### tf.expand_dims和tf.squeeze\n\n- tf.expand_dims(input, axis=None)，就是在对应的axis上加个1的维度，这样可以让tensorflow的元素乘和元素加运算可以用上broadcast机制。\n- broadcast机制：满足下面两个条件即可进行元素复制。\n  - 从后往前维度相同\n  - 遇到不同的话，必须有一个维度为1.\n  - 举例：\n    - a.shape = (4,1,3,3), b.shape(1,3), a+b = (4,1,3,3)\n    - a.shape = (4,1,1,3), b.shape(3,1), a+b = (4,1,3,3)\n\n- tf.squeeze则相反，去掉维度为1的维度。\n\n\n\n### tf.split()\n\n将矩阵的某一维度切分为一个list。\n\n- 'value' is a tensor with shape [5, 30]\n- split0, split1, split2 = tf.split(value, [4, 15, 11], 1)\n- tf.shape(split0)  # [5, 4]\n- tf.shape(split1)  # [5, 15]\n- tf.shape(split2)  # [5, 11]\n\n\n\n### tf.add_n()\n\n将input list里的tensor按元素相加，和普通相加没什么区别，只是可以加个operation name","slug":"ML框架/Tf一些常用方法记录","published":1,"updated":"2022-09-15T03:46:43.359Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551o00009jqrr09luyjkz","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"tf-stack\"><a href=\"#tf-stack\" class=\"headerlink\" title=\"tf.stack\"></a>tf.stack</h3><p>tf.stack(values, axis=0, name=”stack”):</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = tf.constant([<span class=\"number\">1</span>, <span class=\"number\">4</span>])</span><br><span class=\"line\">y = tf.constant([<span class=\"number\">2</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">z = tf.constant([<span class=\"number\">3</span>, <span class=\"number\">6</span>])</span><br><span class=\"line\">tf.stack([x, y, z])  <span class=\"comment\"># [[1, 4], [2, 5], [3, 6]] (Pack along first dim.)</span></span><br><span class=\"line\">tf.stack([x, y, z], axis=<span class=\"number\">1</span>)  <span class=\"comment\"># [[1, 2, 3], [4, 5, 6]]</span></span><br></pre></td></tr></table></figure>\n<p>本质是把一个长度为N的list，list里的元素有自己的shape：</p>\n<ul>\n<li>axis = 0，则变为（N，shape[0], shape[1], …）</li>\n<li>axis = 1，则变为（shape[0], N, shape[1], …）</li>\n</ul>\n<p>常见用法有：</p>\n<p>如果元素为长度为M的list</p>\n<ul>\n<li>Axis =0,  其实就相当于横着concate</li>\n<li>Axis =1，相当于把元素看为列向量，然后竖着concate</li>\n</ul>\n<h3 id=\"tf-gather和tf-gather-nd\"><a href=\"#tf-gather和tf-gather-nd\" class=\"headerlink\" title=\"tf.gather和tf.gather_nd\"></a>tf.gather和tf.gather_nd</h3><p>tf.gather(params, indices, validate_indices=None, name=None, axis=0):</p>\n<p>对于params,就是你的输入，axis就是你进行操作的维度，默认为0(对于tf.gather,只能对于给定的axis操作),indices就是你想获取的axis维度上的值，来看一个例子，可以更佳清楚的了解函数是如何使用的：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">temp = tf.range(<span class=\"number\">0</span>,<span class=\"number\">10</span>)*<span class=\"number\">10</span> + tf.constant(<span class=\"number\">1</span>,shape=[<span class=\"number\">10</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">temp2 = tf.gather(temp,[<span class=\"number\">1</span>,<span class=\"number\">5</span>,<span class=\"number\">9</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> sess.run(temp)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> sess.run(temp2)</span><br><span class=\"line\"></span><br><span class=\"line\">输出</span><br><span class=\"line\"></span><br><span class=\"line\">[ <span class=\"number\">1</span> <span class=\"number\">11</span> <span class=\"number\">21</span> <span class=\"number\">31</span> <span class=\"number\">41</span> <span class=\"number\">51</span> <span class=\"number\">61</span> <span class=\"number\">71</span> <span class=\"number\">81</span> <span class=\"number\">91</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">[<span class=\"number\">11</span> <span class=\"number\">51</span> <span class=\"number\">91</span>]</span><br></pre></td></tr></table></figure>\n<p>tf.gather只能对低维度进行操作，gather_nd可以进行高维度的操作。和gather相比，没有了axis参数，如果indices的维度和params的维度等价，他是直接获取一个具体值(之后组合成向量)。</p>\n<h3 id=\"tf-expand-dims和tf-squeeze\"><a href=\"#tf-expand-dims和tf-squeeze\" class=\"headerlink\" title=\"tf.expand_dims和tf.squeeze\"></a>tf.expand_dims和tf.squeeze</h3><ul>\n<li>tf.expand_dims(input, axis=None)，就是在对应的axis上加个1的维度，这样可以让tensorflow的元素乘和元素加运算可以用上broadcast机制。</li>\n<li><p>broadcast机制：满足下面两个条件即可进行元素复制。</p>\n<ul>\n<li>从后往前维度相同</li>\n<li>遇到不同的话，必须有一个维度为1.</li>\n<li>举例：<ul>\n<li>a.shape = (4,1,3,3), b.shape(1,3), a+b = (4,1,3,3)</li>\n<li>a.shape = (4,1,1,3), b.shape(3,1), a+b = (4,1,3,3)</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>tf.squeeze则相反，去掉维度为1的维度。</p>\n</li>\n</ul>\n<h3 id=\"tf-split\"><a href=\"#tf-split\" class=\"headerlink\" title=\"tf.split()\"></a>tf.split()</h3><p>将矩阵的某一维度切分为一个list。</p>\n<ul>\n<li>‘value’ is a tensor with shape [5, 30]</li>\n<li>split0, split1, split2 = tf.split(value, [4, 15, 11], 1)</li>\n<li>tf.shape(split0)  # [5, 4]</li>\n<li>tf.shape(split1)  # [5, 15]</li>\n<li>tf.shape(split2)  # [5, 11]</li>\n</ul>\n<h3 id=\"tf-add-n\"><a href=\"#tf-add-n\" class=\"headerlink\" title=\"tf.add_n()\"></a>tf.add_n()</h3><p>将input list里的tensor按元素相加，和普通相加没什么区别，只是可以加个operation name</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"tf-stack\"><a href=\"#tf-stack\" class=\"headerlink\" title=\"tf.stack\"></a>tf.stack</h3><p>tf.stack(values, axis=0, name=”stack”):</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = tf.constant([<span class=\"number\">1</span>, <span class=\"number\">4</span>])</span><br><span class=\"line\">y = tf.constant([<span class=\"number\">2</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">z = tf.constant([<span class=\"number\">3</span>, <span class=\"number\">6</span>])</span><br><span class=\"line\">tf.stack([x, y, z])  <span class=\"comment\"># [[1, 4], [2, 5], [3, 6]] (Pack along first dim.)</span></span><br><span class=\"line\">tf.stack([x, y, z], axis=<span class=\"number\">1</span>)  <span class=\"comment\"># [[1, 2, 3], [4, 5, 6]]</span></span><br></pre></td></tr></table></figure>\n<p>本质是把一个长度为N的list，list里的元素有自己的shape：</p>\n<ul>\n<li>axis = 0，则变为（N，shape[0], shape[1], …）</li>\n<li>axis = 1，则变为（shape[0], N, shape[1], …）</li>\n</ul>\n<p>常见用法有：</p>\n<p>如果元素为长度为M的list</p>\n<ul>\n<li>Axis =0,  其实就相当于横着concate</li>\n<li>Axis =1，相当于把元素看为列向量，然后竖着concate</li>\n</ul>\n<h3 id=\"tf-gather和tf-gather-nd\"><a href=\"#tf-gather和tf-gather-nd\" class=\"headerlink\" title=\"tf.gather和tf.gather_nd\"></a>tf.gather和tf.gather_nd</h3><p>tf.gather(params, indices, validate_indices=None, name=None, axis=0):</p>\n<p>对于params,就是你的输入，axis就是你进行操作的维度，默认为0(对于tf.gather,只能对于给定的axis操作),indices就是你想获取的axis维度上的值，来看一个例子，可以更佳清楚的了解函数是如何使用的：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">temp = tf.range(<span class=\"number\">0</span>,<span class=\"number\">10</span>)*<span class=\"number\">10</span> + tf.constant(<span class=\"number\">1</span>,shape=[<span class=\"number\">10</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">temp2 = tf.gather(temp,[<span class=\"number\">1</span>,<span class=\"number\">5</span>,<span class=\"number\">9</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> sess.run(temp)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> sess.run(temp2)</span><br><span class=\"line\"></span><br><span class=\"line\">输出</span><br><span class=\"line\"></span><br><span class=\"line\">[ <span class=\"number\">1</span> <span class=\"number\">11</span> <span class=\"number\">21</span> <span class=\"number\">31</span> <span class=\"number\">41</span> <span class=\"number\">51</span> <span class=\"number\">61</span> <span class=\"number\">71</span> <span class=\"number\">81</span> <span class=\"number\">91</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">[<span class=\"number\">11</span> <span class=\"number\">51</span> <span class=\"number\">91</span>]</span><br></pre></td></tr></table></figure>\n<p>tf.gather只能对低维度进行操作，gather_nd可以进行高维度的操作。和gather相比，没有了axis参数，如果indices的维度和params的维度等价，他是直接获取一个具体值(之后组合成向量)。</p>\n<h3 id=\"tf-expand-dims和tf-squeeze\"><a href=\"#tf-expand-dims和tf-squeeze\" class=\"headerlink\" title=\"tf.expand_dims和tf.squeeze\"></a>tf.expand_dims和tf.squeeze</h3><ul>\n<li>tf.expand_dims(input, axis=None)，就是在对应的axis上加个1的维度，这样可以让tensorflow的元素乘和元素加运算可以用上broadcast机制。</li>\n<li><p>broadcast机制：满足下面两个条件即可进行元素复制。</p>\n<ul>\n<li>从后往前维度相同</li>\n<li>遇到不同的话，必须有一个维度为1.</li>\n<li>举例：<ul>\n<li>a.shape = (4,1,3,3), b.shape(1,3), a+b = (4,1,3,3)</li>\n<li>a.shape = (4,1,1,3), b.shape(3,1), a+b = (4,1,3,3)</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>tf.squeeze则相反，去掉维度为1的维度。</p>\n</li>\n</ul>\n<h3 id=\"tf-split\"><a href=\"#tf-split\" class=\"headerlink\" title=\"tf.split()\"></a>tf.split()</h3><p>将矩阵的某一维度切分为一个list。</p>\n<ul>\n<li>‘value’ is a tensor with shape [5, 30]</li>\n<li>split0, split1, split2 = tf.split(value, [4, 15, 11], 1)</li>\n<li>tf.shape(split0)  # [5, 4]</li>\n<li>tf.shape(split1)  # [5, 15]</li>\n<li>tf.shape(split2)  # [5, 11]</li>\n</ul>\n<h3 id=\"tf-add-n\"><a href=\"#tf-add-n\" class=\"headerlink\" title=\"tf.add_n()\"></a>tf.add_n()</h3><p>将input list里的tensor按元素相加，和普通相加没什么区别，只是可以加个operation name</p>\n"},{"title":"Tensorflow中的变量作用域和名称作用域","date":"2017-07-18T14:06:02.000Z","_content":"\n在定义复杂网络时，为了让变量和操作更加清晰，我们需要用作用域scope来为变量或者操作加前缀。在Tensorflow中，总共有以下几个定义域操作：\n\n```python\ntf.name_scope()\ntf.op_scope()\ntf.variable_scope()\ntf.variable_op_scope()\n```\n主要可以分为两类：变量作用域和名称作用域。其中`tf.name_scope`和`tf.op_scope`都属于名称作用域，这两者的唯一区别就是values的参数位置不同：\n\n\n```python\ntf.name_scope(name, default_name=None, values=None)\ntf.op_scope(values, name, default_name=None)\n```\n\n`tf.variable_scope`和`tf.variable_op_scope`都属于变量作用域，两者区别跟上面是类似的。\n\n那么，变量作用域和名称作用域又有什么区别呢？\n\n对于名称作用域，顾名思义，就是一旦定义了该作用域，该代码块中的**变量和操作**，全部会加上该作用域前缀，若作用域名称相同，则名称后缀自动加一。但是，也有一个例外就是`tf.get_variable()`这个操作。\n\n`tf.get_variable()`有以下的性质：\n- `tf.get_variable('name', ...)` 中的name是无视名称作用域的，也就是说，即使该操作在某名称作用域中，name也不会加上相应前缀。\n- 不同于`tf.Variable()`通过直接获取值来初始化，`tf.get_variable()`则是通过变量名以及定义初始化分布来进行初始化，若变量名已经存在，那么程序就会报错，相反，如果对于`tf.Variable()`，我们定义了相同的变量名，则程序会在变量名后缀上自动加一。\n\n\n从某种意义上说，变量作用域`tf.variable_scope`就是为了`tf.get_variable`而设计的。\n\n- `tf.get_variable('name', ...)`中的name会自动加上变量作用域的后缀。\n- 变量作用域可以设定`reuse = True`，从而定义相同名字的变量为共享变量，若名字不同，则会报错。个人认为，定义变量作用域以及该操作都是为了实现共享变量的功能。\n- 变量作用域还可以为`tf.get_variable('name', ...)`设置默认的初始化分布！\n- 最重要的一点是，**变量作用域`tf.variable_scope('name')`一旦开启，也就相当于间接开启了一个名称作用域`tf.name_scope('name')`！**\n\n总结来说，这些设计的目的大概这样的：\n\n- 为了区分变量和操作，定义了名称作用域。\n- 名称作用域和普通的变量创建操作有重复名称自动后缀加一的特性，因此无法实现变量共享，于是定义了`tf.get_variable`操作。\n- `tf.get_variable`操作也需要加前缀，于是定义了变量作用域。变量作用域相当于加强版的名称作用域！\n\n最后，给个测试代码：\n\n```python\nwith tf.variable_scope(\"foo\"):\n    v = tf.get_variable(\"v\", [1])\n    x = 1.0 + v\nassert v.name == \"foo/v:0\"\nassert x.op.name == \"foo/add\"\nassert x.name == \"foo/add:0\"\n\nwith tf.variable_scope(\"foo\", reuse = True):\n    with tf.name_scope(\"bar\"):\n        v = tf.get_variable(\"v\", [1])\n        x = 1.0 + v\n        y = 1.0 + x\nassert v.name == \"foo/v:0\"  # 共享变量\nassert x.op.name == \"foo_1/bar/add\"  # foo此时为名称作用域，重复定义，需要加一\nassert x.name == \"foo_1/bar/add:0\"\nassert y.op.name == \"foo_1/bar/add_1\" # add操作重复定义，自动加一\n\n\n# 还有一个关于名称作用域和变量作用域嵌套的问题，若使用对象而非字符串开启作用域，则该作用域不嵌套\n\nwith tf.name_scope('t1') as scope:\n    with tf.name_scope('t2'):\n        with tf.name_scope(scope):\n            x = tf.Variable(1)\nassert x.op.name == 't1/Variable'\n\nwith tf.name_scope('t1') as scope:\n    with tf.name_scope('t2'):\n        with tf.name_scope('t3'):\n            x = tf.Variable(1, name = scope) # 这样也不嵌套\nassert x.op.name == 't1_1'\n```\n\n关于`tf.variable_scope()`和`tf.get_variable()`的更多操作，可以看[共享变量-极客学院Wiki](http://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/variable_scope.html)\n\n\n","source":"_posts/ML框架/Tf中的变量作用域和名称作用域.md","raw":"---\ntitle: 'Tensorflow中的变量作用域和名称作用域'\ndate: 2017-07-18 22:06:02\ntags: Tensorflow\ncategories: ML框架\n---\n\n在定义复杂网络时，为了让变量和操作更加清晰，我们需要用作用域scope来为变量或者操作加前缀。在Tensorflow中，总共有以下几个定义域操作：\n\n```python\ntf.name_scope()\ntf.op_scope()\ntf.variable_scope()\ntf.variable_op_scope()\n```\n主要可以分为两类：变量作用域和名称作用域。其中`tf.name_scope`和`tf.op_scope`都属于名称作用域，这两者的唯一区别就是values的参数位置不同：\n\n\n```python\ntf.name_scope(name, default_name=None, values=None)\ntf.op_scope(values, name, default_name=None)\n```\n\n`tf.variable_scope`和`tf.variable_op_scope`都属于变量作用域，两者区别跟上面是类似的。\n\n那么，变量作用域和名称作用域又有什么区别呢？\n\n对于名称作用域，顾名思义，就是一旦定义了该作用域，该代码块中的**变量和操作**，全部会加上该作用域前缀，若作用域名称相同，则名称后缀自动加一。但是，也有一个例外就是`tf.get_variable()`这个操作。\n\n`tf.get_variable()`有以下的性质：\n- `tf.get_variable('name', ...)` 中的name是无视名称作用域的，也就是说，即使该操作在某名称作用域中，name也不会加上相应前缀。\n- 不同于`tf.Variable()`通过直接获取值来初始化，`tf.get_variable()`则是通过变量名以及定义初始化分布来进行初始化，若变量名已经存在，那么程序就会报错，相反，如果对于`tf.Variable()`，我们定义了相同的变量名，则程序会在变量名后缀上自动加一。\n\n\n从某种意义上说，变量作用域`tf.variable_scope`就是为了`tf.get_variable`而设计的。\n\n- `tf.get_variable('name', ...)`中的name会自动加上变量作用域的后缀。\n- 变量作用域可以设定`reuse = True`，从而定义相同名字的变量为共享变量，若名字不同，则会报错。个人认为，定义变量作用域以及该操作都是为了实现共享变量的功能。\n- 变量作用域还可以为`tf.get_variable('name', ...)`设置默认的初始化分布！\n- 最重要的一点是，**变量作用域`tf.variable_scope('name')`一旦开启，也就相当于间接开启了一个名称作用域`tf.name_scope('name')`！**\n\n总结来说，这些设计的目的大概这样的：\n\n- 为了区分变量和操作，定义了名称作用域。\n- 名称作用域和普通的变量创建操作有重复名称自动后缀加一的特性，因此无法实现变量共享，于是定义了`tf.get_variable`操作。\n- `tf.get_variable`操作也需要加前缀，于是定义了变量作用域。变量作用域相当于加强版的名称作用域！\n\n最后，给个测试代码：\n\n```python\nwith tf.variable_scope(\"foo\"):\n    v = tf.get_variable(\"v\", [1])\n    x = 1.0 + v\nassert v.name == \"foo/v:0\"\nassert x.op.name == \"foo/add\"\nassert x.name == \"foo/add:0\"\n\nwith tf.variable_scope(\"foo\", reuse = True):\n    with tf.name_scope(\"bar\"):\n        v = tf.get_variable(\"v\", [1])\n        x = 1.0 + v\n        y = 1.0 + x\nassert v.name == \"foo/v:0\"  # 共享变量\nassert x.op.name == \"foo_1/bar/add\"  # foo此时为名称作用域，重复定义，需要加一\nassert x.name == \"foo_1/bar/add:0\"\nassert y.op.name == \"foo_1/bar/add_1\" # add操作重复定义，自动加一\n\n\n# 还有一个关于名称作用域和变量作用域嵌套的问题，若使用对象而非字符串开启作用域，则该作用域不嵌套\n\nwith tf.name_scope('t1') as scope:\n    with tf.name_scope('t2'):\n        with tf.name_scope(scope):\n            x = tf.Variable(1)\nassert x.op.name == 't1/Variable'\n\nwith tf.name_scope('t1') as scope:\n    with tf.name_scope('t2'):\n        with tf.name_scope('t3'):\n            x = tf.Variable(1, name = scope) # 这样也不嵌套\nassert x.op.name == 't1_1'\n```\n\n关于`tf.variable_scope()`和`tf.get_variable()`的更多操作，可以看[共享变量-极客学院Wiki](http://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/variable_scope.html)\n\n\n","slug":"ML框架/Tf中的变量作用域和名称作用域","published":1,"updated":"2022-09-15T03:46:43.359Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551o4000djqrriljwauk8","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>在定义复杂网络时，为了让变量和操作更加清晰，我们需要用作用域scope来为变量或者操作加前缀。在Tensorflow中，总共有以下几个定义域操作：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tf.name_scope()</span><br><span class=\"line\">tf.op_scope()</span><br><span class=\"line\">tf.variable_scope()</span><br><span class=\"line\">tf.variable_op_scope()</span><br></pre></td></tr></table></figure>\n<p>主要可以分为两类：变量作用域和名称作用域。其中<code>tf.name_scope</code>和<code>tf.op_scope</code>都属于名称作用域，这两者的唯一区别就是values的参数位置不同：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tf.name_scope(name, default_name=<span class=\"literal\">None</span>, values=<span class=\"literal\">None</span>)</span><br><span class=\"line\">tf.op_scope(values, name, default_name=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n<p><code>tf.variable_scope</code>和<code>tf.variable_op_scope</code>都属于变量作用域，两者区别跟上面是类似的。</p>\n<p>那么，变量作用域和名称作用域又有什么区别呢？</p>\n<p>对于名称作用域，顾名思义，就是一旦定义了该作用域，该代码块中的<strong>变量和操作</strong>，全部会加上该作用域前缀，若作用域名称相同，则名称后缀自动加一。但是，也有一个例外就是<code>tf.get_variable()</code>这个操作。</p>\n<p><code>tf.get_variable()</code>有以下的性质：</p>\n<ul>\n<li><code>tf.get_variable(&#39;name&#39;, ...)</code> 中的name是无视名称作用域的，也就是说，即使该操作在某名称作用域中，name也不会加上相应前缀。</li>\n<li>不同于<code>tf.Variable()</code>通过直接获取值来初始化，<code>tf.get_variable()</code>则是通过变量名以及定义初始化分布来进行初始化，若变量名已经存在，那么程序就会报错，相反，如果对于<code>tf.Variable()</code>，我们定义了相同的变量名，则程序会在变量名后缀上自动加一。</li>\n</ul>\n<p>从某种意义上说，变量作用域<code>tf.variable_scope</code>就是为了<code>tf.get_variable</code>而设计的。</p>\n<ul>\n<li><code>tf.get_variable(&#39;name&#39;, ...)</code>中的name会自动加上变量作用域的后缀。</li>\n<li>变量作用域可以设定<code>reuse = True</code>，从而定义相同名字的变量为共享变量，若名字不同，则会报错。个人认为，定义变量作用域以及该操作都是为了实现共享变量的功能。</li>\n<li>变量作用域还可以为<code>tf.get_variable(&#39;name&#39;, ...)</code>设置默认的初始化分布！</li>\n<li>最重要的一点是，<strong>变量作用域<code>tf.variable_scope(&#39;name&#39;)</code>一旦开启，也就相当于间接开启了一个名称作用域<code>tf.name_scope(&#39;name&#39;)</code>！</strong></li>\n</ul>\n<p>总结来说，这些设计的目的大概这样的：</p>\n<ul>\n<li>为了区分变量和操作，定义了名称作用域。</li>\n<li>名称作用域和普通的变量创建操作有重复名称自动后缀加一的特性，因此无法实现变量共享，于是定义了<code>tf.get_variable</code>操作。</li>\n<li><code>tf.get_variable</code>操作也需要加前缀，于是定义了变量作用域。变量作用域相当于加强版的名称作用域！</li>\n</ul>\n<p>最后，给个测试代码：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">with</span> tf.variable_scope(<span class=\"string\">\"foo\"</span>):</span><br><span class=\"line\">    v = tf.get_variable(<span class=\"string\">\"v\"</span>, [<span class=\"number\">1</span>])</span><br><span class=\"line\">    x = <span class=\"number\">1.0</span> + v</span><br><span class=\"line\"><span class=\"keyword\">assert</span> v.name == <span class=\"string\">\"foo/v:0\"</span></span><br><span class=\"line\"><span class=\"keyword\">assert</span> x.op.name == <span class=\"string\">\"foo/add\"</span></span><br><span class=\"line\"><span class=\"keyword\">assert</span> x.name == <span class=\"string\">\"foo/add:0\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.variable_scope(<span class=\"string\">\"foo\"</span>, reuse = <span class=\"literal\">True</span>):</span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">\"bar\"</span>):</span><br><span class=\"line\">        v = tf.get_variable(<span class=\"string\">\"v\"</span>, [<span class=\"number\">1</span>])</span><br><span class=\"line\">        x = <span class=\"number\">1.0</span> + v</span><br><span class=\"line\">        y = <span class=\"number\">1.0</span> + x</span><br><span class=\"line\"><span class=\"keyword\">assert</span> v.name == <span class=\"string\">\"foo/v:0\"</span>  <span class=\"comment\"># 共享变量</span></span><br><span class=\"line\"><span class=\"keyword\">assert</span> x.op.name == <span class=\"string\">\"foo_1/bar/add\"</span>  <span class=\"comment\"># foo此时为名称作用域，重复定义，需要加一</span></span><br><span class=\"line\"><span class=\"keyword\">assert</span> x.name == <span class=\"string\">\"foo_1/bar/add:0\"</span></span><br><span class=\"line\"><span class=\"keyword\">assert</span> y.op.name == <span class=\"string\">\"foo_1/bar/add_1\"</span> <span class=\"comment\"># add操作重复定义，自动加一</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 还有一个关于名称作用域和变量作用域嵌套的问题，若使用对象而非字符串开启作用域，则该作用域不嵌套</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'t1'</span>) <span class=\"keyword\">as</span> scope:</span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'t2'</span>):</span><br><span class=\"line\">        <span class=\"keyword\">with</span> tf.name_scope(scope):</span><br><span class=\"line\">            x = tf.Variable(<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"keyword\">assert</span> x.op.name == <span class=\"string\">'t1/Variable'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'t1'</span>) <span class=\"keyword\">as</span> scope:</span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'t2'</span>):</span><br><span class=\"line\">        <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'t3'</span>):</span><br><span class=\"line\">            x = tf.Variable(<span class=\"number\">1</span>, name = scope) <span class=\"comment\"># 这样也不嵌套</span></span><br><span class=\"line\"><span class=\"keyword\">assert</span> x.op.name == <span class=\"string\">'t1_1'</span></span><br></pre></td></tr></table></figure>\n<p>关于<code>tf.variable_scope()</code>和<code>tf.get_variable()</code>的更多操作，可以看<a href=\"http://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/variable_scope.html\" target=\"_blank\" rel=\"noopener\">共享变量-极客学院Wiki</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>在定义复杂网络时，为了让变量和操作更加清晰，我们需要用作用域scope来为变量或者操作加前缀。在Tensorflow中，总共有以下几个定义域操作：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tf.name_scope()</span><br><span class=\"line\">tf.op_scope()</span><br><span class=\"line\">tf.variable_scope()</span><br><span class=\"line\">tf.variable_op_scope()</span><br></pre></td></tr></table></figure>\n<p>主要可以分为两类：变量作用域和名称作用域。其中<code>tf.name_scope</code>和<code>tf.op_scope</code>都属于名称作用域，这两者的唯一区别就是values的参数位置不同：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tf.name_scope(name, default_name=<span class=\"literal\">None</span>, values=<span class=\"literal\">None</span>)</span><br><span class=\"line\">tf.op_scope(values, name, default_name=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n<p><code>tf.variable_scope</code>和<code>tf.variable_op_scope</code>都属于变量作用域，两者区别跟上面是类似的。</p>\n<p>那么，变量作用域和名称作用域又有什么区别呢？</p>\n<p>对于名称作用域，顾名思义，就是一旦定义了该作用域，该代码块中的<strong>变量和操作</strong>，全部会加上该作用域前缀，若作用域名称相同，则名称后缀自动加一。但是，也有一个例外就是<code>tf.get_variable()</code>这个操作。</p>\n<p><code>tf.get_variable()</code>有以下的性质：</p>\n<ul>\n<li><code>tf.get_variable(&#39;name&#39;, ...)</code> 中的name是无视名称作用域的，也就是说，即使该操作在某名称作用域中，name也不会加上相应前缀。</li>\n<li>不同于<code>tf.Variable()</code>通过直接获取值来初始化，<code>tf.get_variable()</code>则是通过变量名以及定义初始化分布来进行初始化，若变量名已经存在，那么程序就会报错，相反，如果对于<code>tf.Variable()</code>，我们定义了相同的变量名，则程序会在变量名后缀上自动加一。</li>\n</ul>\n<p>从某种意义上说，变量作用域<code>tf.variable_scope</code>就是为了<code>tf.get_variable</code>而设计的。</p>\n<ul>\n<li><code>tf.get_variable(&#39;name&#39;, ...)</code>中的name会自动加上变量作用域的后缀。</li>\n<li>变量作用域可以设定<code>reuse = True</code>，从而定义相同名字的变量为共享变量，若名字不同，则会报错。个人认为，定义变量作用域以及该操作都是为了实现共享变量的功能。</li>\n<li>变量作用域还可以为<code>tf.get_variable(&#39;name&#39;, ...)</code>设置默认的初始化分布！</li>\n<li>最重要的一点是，<strong>变量作用域<code>tf.variable_scope(&#39;name&#39;)</code>一旦开启，也就相当于间接开启了一个名称作用域<code>tf.name_scope(&#39;name&#39;)</code>！</strong></li>\n</ul>\n<p>总结来说，这些设计的目的大概这样的：</p>\n<ul>\n<li>为了区分变量和操作，定义了名称作用域。</li>\n<li>名称作用域和普通的变量创建操作有重复名称自动后缀加一的特性，因此无法实现变量共享，于是定义了<code>tf.get_variable</code>操作。</li>\n<li><code>tf.get_variable</code>操作也需要加前缀，于是定义了变量作用域。变量作用域相当于加强版的名称作用域！</li>\n</ul>\n<p>最后，给个测试代码：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">with</span> tf.variable_scope(<span class=\"string\">\"foo\"</span>):</span><br><span class=\"line\">    v = tf.get_variable(<span class=\"string\">\"v\"</span>, [<span class=\"number\">1</span>])</span><br><span class=\"line\">    x = <span class=\"number\">1.0</span> + v</span><br><span class=\"line\"><span class=\"keyword\">assert</span> v.name == <span class=\"string\">\"foo/v:0\"</span></span><br><span class=\"line\"><span class=\"keyword\">assert</span> x.op.name == <span class=\"string\">\"foo/add\"</span></span><br><span class=\"line\"><span class=\"keyword\">assert</span> x.name == <span class=\"string\">\"foo/add:0\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.variable_scope(<span class=\"string\">\"foo\"</span>, reuse = <span class=\"literal\">True</span>):</span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">\"bar\"</span>):</span><br><span class=\"line\">        v = tf.get_variable(<span class=\"string\">\"v\"</span>, [<span class=\"number\">1</span>])</span><br><span class=\"line\">        x = <span class=\"number\">1.0</span> + v</span><br><span class=\"line\">        y = <span class=\"number\">1.0</span> + x</span><br><span class=\"line\"><span class=\"keyword\">assert</span> v.name == <span class=\"string\">\"foo/v:0\"</span>  <span class=\"comment\"># 共享变量</span></span><br><span class=\"line\"><span class=\"keyword\">assert</span> x.op.name == <span class=\"string\">\"foo_1/bar/add\"</span>  <span class=\"comment\"># foo此时为名称作用域，重复定义，需要加一</span></span><br><span class=\"line\"><span class=\"keyword\">assert</span> x.name == <span class=\"string\">\"foo_1/bar/add:0\"</span></span><br><span class=\"line\"><span class=\"keyword\">assert</span> y.op.name == <span class=\"string\">\"foo_1/bar/add_1\"</span> <span class=\"comment\"># add操作重复定义，自动加一</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 还有一个关于名称作用域和变量作用域嵌套的问题，若使用对象而非字符串开启作用域，则该作用域不嵌套</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'t1'</span>) <span class=\"keyword\">as</span> scope:</span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'t2'</span>):</span><br><span class=\"line\">        <span class=\"keyword\">with</span> tf.name_scope(scope):</span><br><span class=\"line\">            x = tf.Variable(<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"keyword\">assert</span> x.op.name == <span class=\"string\">'t1/Variable'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'t1'</span>) <span class=\"keyword\">as</span> scope:</span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'t2'</span>):</span><br><span class=\"line\">        <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'t3'</span>):</span><br><span class=\"line\">            x = tf.Variable(<span class=\"number\">1</span>, name = scope) <span class=\"comment\"># 这样也不嵌套</span></span><br><span class=\"line\"><span class=\"keyword\">assert</span> x.op.name == <span class=\"string\">'t1_1'</span></span><br></pre></td></tr></table></figure>\n<p>关于<code>tf.variable_scope()</code>和<code>tf.get_variable()</code>的更多操作，可以看<a href=\"http://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/variable_scope.html\" target=\"_blank\" rel=\"noopener\">共享变量-极客学院Wiki</a></p>\n"},{"title":"前端学习流程","date":"2019-08-10T14:06:02.000Z","_content":"\n\n\n **京华哥强推:**\n\n- [es6]( http://es6.ruanyifeng.com/) ===>java  \n\n- [react](https://www.runoob.com/react/react-tutorial.html)===>springboot  \n\n- [antd]( https://ant.design/components/menu-cn/)===>UI框架 \n\n\n\n**Joe哥整理**\n\n\n**第三方技术**\n（1）React全家桶：React、Redux、Sagas、immutableJS\n（2）框架：DVA、ANTD PRO\n（3）组件库：ANTD\n（4）打包：webpack4\n（5）服务端渲染：puppeteer\n\n\n**软件安装**\n（1）NodeJS v10.15.0+\n（2）Nginx 1.15.2+\n（3）开发工具 VSCode\n\n\n**优先学习**\nSaga: 副作用Effects管理\nredux: 状态机管理\ndva = redux + saga \n[Create react app](https://www.html.cn/create-react-app/docs/getting-started/) : 脚手架，快速创建react app\n\n\n**书籍推荐**\n- 初级：《HTML5权威指南》、《CSS权威指南》、《JAVASCRIPT权威指南》\n- 中级：《JAVASCRIPT 高级程序设计》、《DOM编程艺术》、《CSS世界》、《ES6标准入门》、《NodeJS深入浅出》\n- 高级：《你不知道的JAVASCRIPT上》、《你不知道的JAVASCRIPT中》、《你不知道的JAVASCRIPT下》、《CSS揭秘》、《Webkit技术内幕》\n\n**开源技术博客文档推荐**\n\n- React：[官方教程](https://reactjs.org/docs/getting-started.html)\n- Redux：[官方教程](https://www.redux.org.cn/)\n- Redux-saga：[官方文档](https://redux-saga-in-chinese.js.org/)\n- ImmutableJS：[结合 Immutable.JS 使用 Redux](https://cn.redux.js.org/docs/recipes/UsingImmutableJS.html)、[官方文档](https://immutable-js.github.io/immutable-js/docs/#/)\n- ANTD组件库：[官方文档](https://ant.design/docs/react/introduce-cn)、[相关社区精华，不了解就太遗憾了](https://ant.design/docs/react/recommendation-cn)","source":"_posts/前端开发/前端学习流程.md","raw":"---\ntitle: 前端学习流程\ndate: 2019-08-10 22:06:02\ntags: 前端\ncategories: Web开发\n---\n\n\n\n **京华哥强推:**\n\n- [es6]( http://es6.ruanyifeng.com/) ===>java  \n\n- [react](https://www.runoob.com/react/react-tutorial.html)===>springboot  \n\n- [antd]( https://ant.design/components/menu-cn/)===>UI框架 \n\n\n\n**Joe哥整理**\n\n\n**第三方技术**\n（1）React全家桶：React、Redux、Sagas、immutableJS\n（2）框架：DVA、ANTD PRO\n（3）组件库：ANTD\n（4）打包：webpack4\n（5）服务端渲染：puppeteer\n\n\n**软件安装**\n（1）NodeJS v10.15.0+\n（2）Nginx 1.15.2+\n（3）开发工具 VSCode\n\n\n**优先学习**\nSaga: 副作用Effects管理\nredux: 状态机管理\ndva = redux + saga \n[Create react app](https://www.html.cn/create-react-app/docs/getting-started/) : 脚手架，快速创建react app\n\n\n**书籍推荐**\n- 初级：《HTML5权威指南》、《CSS权威指南》、《JAVASCRIPT权威指南》\n- 中级：《JAVASCRIPT 高级程序设计》、《DOM编程艺术》、《CSS世界》、《ES6标准入门》、《NodeJS深入浅出》\n- 高级：《你不知道的JAVASCRIPT上》、《你不知道的JAVASCRIPT中》、《你不知道的JAVASCRIPT下》、《CSS揭秘》、《Webkit技术内幕》\n\n**开源技术博客文档推荐**\n\n- React：[官方教程](https://reactjs.org/docs/getting-started.html)\n- Redux：[官方教程](https://www.redux.org.cn/)\n- Redux-saga：[官方文档](https://redux-saga-in-chinese.js.org/)\n- ImmutableJS：[结合 Immutable.JS 使用 Redux](https://cn.redux.js.org/docs/recipes/UsingImmutableJS.html)、[官方文档](https://immutable-js.github.io/immutable-js/docs/#/)\n- ANTD组件库：[官方文档](https://ant.design/docs/react/introduce-cn)、[相关社区精华，不了解就太遗憾了](https://ant.design/docs/react/recommendation-cn)","slug":"前端开发/前端学习流程","published":1,"updated":"2022-09-15T03:46:43.359Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551o6000fjqrr8r6ix55h","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p> <strong>京华哥强推:</strong></p>\n<ul>\n<li><p><a href=\"http://es6.ruanyifeng.com/\" target=\"_blank\" rel=\"noopener\">es6</a> ===&gt;java  </p>\n</li>\n<li><p><a href=\"https://www.runoob.com/react/react-tutorial.html\" target=\"_blank\" rel=\"noopener\">react</a>===&gt;springboot  </p>\n</li>\n<li><p><a href=\"https://ant.design/components/menu-cn/\" target=\"_blank\" rel=\"noopener\">antd</a>===&gt;UI框架 </p>\n</li>\n</ul>\n<p><strong>Joe哥整理</strong></p>\n<p><strong>第三方技术</strong><br>（1）React全家桶：React、Redux、Sagas、immutableJS<br>（2）框架：DVA、ANTD PRO<br>（3）组件库：ANTD<br>（4）打包：webpack4<br>（5）服务端渲染：puppeteer</p>\n<p><strong>软件安装</strong><br>（1）NodeJS v10.15.0+<br>（2）Nginx 1.15.2+<br>（3）开发工具 VSCode</p>\n<p><strong>优先学习</strong><br>Saga: 副作用Effects管理<br>redux: 状态机管理<br>dva = redux + saga<br><a href=\"https://www.html.cn/create-react-app/docs/getting-started/\" target=\"_blank\" rel=\"noopener\">Create react app</a> : 脚手架，快速创建react app</p>\n<p><strong>书籍推荐</strong></p>\n<ul>\n<li>初级：《HTML5权威指南》、《CSS权威指南》、《JAVASCRIPT权威指南》</li>\n<li>中级：《JAVASCRIPT 高级程序设计》、《DOM编程艺术》、《CSS世界》、《ES6标准入门》、《NodeJS深入浅出》</li>\n<li>高级：《你不知道的JAVASCRIPT上》、《你不知道的JAVASCRIPT中》、《你不知道的JAVASCRIPT下》、《CSS揭秘》、《Webkit技术内幕》</li>\n</ul>\n<p><strong>开源技术博客文档推荐</strong></p>\n<ul>\n<li>React：<a href=\"https://reactjs.org/docs/getting-started.html\" target=\"_blank\" rel=\"noopener\">官方教程</a></li>\n<li>Redux：<a href=\"https://www.redux.org.cn/\" target=\"_blank\" rel=\"noopener\">官方教程</a></li>\n<li>Redux-saga：<a href=\"https://redux-saga-in-chinese.js.org/\" target=\"_blank\" rel=\"noopener\">官方文档</a></li>\n<li>ImmutableJS：<a href=\"https://cn.redux.js.org/docs/recipes/UsingImmutableJS.html\" target=\"_blank\" rel=\"noopener\">结合 Immutable.JS 使用 Redux</a>、<a href=\"https://immutable-js.github.io/immutable-js/docs/#/\" target=\"_blank\" rel=\"noopener\">官方文档</a></li>\n<li>ANTD组件库：<a href=\"https://ant.design/docs/react/introduce-cn\" target=\"_blank\" rel=\"noopener\">官方文档</a>、<a href=\"https://ant.design/docs/react/recommendation-cn\" target=\"_blank\" rel=\"noopener\">相关社区精华，不了解就太遗憾了</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p> <strong>京华哥强推:</strong></p>\n<ul>\n<li><p><a href=\"http://es6.ruanyifeng.com/\" target=\"_blank\" rel=\"noopener\">es6</a> ===&gt;java  </p>\n</li>\n<li><p><a href=\"https://www.runoob.com/react/react-tutorial.html\" target=\"_blank\" rel=\"noopener\">react</a>===&gt;springboot  </p>\n</li>\n<li><p><a href=\"https://ant.design/components/menu-cn/\" target=\"_blank\" rel=\"noopener\">antd</a>===&gt;UI框架 </p>\n</li>\n</ul>\n<p><strong>Joe哥整理</strong></p>\n<p><strong>第三方技术</strong><br>（1）React全家桶：React、Redux、Sagas、immutableJS<br>（2）框架：DVA、ANTD PRO<br>（3）组件库：ANTD<br>（4）打包：webpack4<br>（5）服务端渲染：puppeteer</p>\n<p><strong>软件安装</strong><br>（1）NodeJS v10.15.0+<br>（2）Nginx 1.15.2+<br>（3）开发工具 VSCode</p>\n<p><strong>优先学习</strong><br>Saga: 副作用Effects管理<br>redux: 状态机管理<br>dva = redux + saga<br><a href=\"https://www.html.cn/create-react-app/docs/getting-started/\" target=\"_blank\" rel=\"noopener\">Create react app</a> : 脚手架，快速创建react app</p>\n<p><strong>书籍推荐</strong></p>\n<ul>\n<li>初级：《HTML5权威指南》、《CSS权威指南》、《JAVASCRIPT权威指南》</li>\n<li>中级：《JAVASCRIPT 高级程序设计》、《DOM编程艺术》、《CSS世界》、《ES6标准入门》、《NodeJS深入浅出》</li>\n<li>高级：《你不知道的JAVASCRIPT上》、《你不知道的JAVASCRIPT中》、《你不知道的JAVASCRIPT下》、《CSS揭秘》、《Webkit技术内幕》</li>\n</ul>\n<p><strong>开源技术博客文档推荐</strong></p>\n<ul>\n<li>React：<a href=\"https://reactjs.org/docs/getting-started.html\" target=\"_blank\" rel=\"noopener\">官方教程</a></li>\n<li>Redux：<a href=\"https://www.redux.org.cn/\" target=\"_blank\" rel=\"noopener\">官方教程</a></li>\n<li>Redux-saga：<a href=\"https://redux-saga-in-chinese.js.org/\" target=\"_blank\" rel=\"noopener\">官方文档</a></li>\n<li>ImmutableJS：<a href=\"https://cn.redux.js.org/docs/recipes/UsingImmutableJS.html\" target=\"_blank\" rel=\"noopener\">结合 Immutable.JS 使用 Redux</a>、<a href=\"https://immutable-js.github.io/immutable-js/docs/#/\" target=\"_blank\" rel=\"noopener\">官方文档</a></li>\n<li>ANTD组件库：<a href=\"https://ant.design/docs/react/introduce-cn\" target=\"_blank\" rel=\"noopener\">官方文档</a>、<a href=\"https://ant.design/docs/react/recommendation-cn\" target=\"_blank\" rel=\"noopener\">相关社区精华，不了解就太遗憾了</a></li>\n</ul>\n"},{"title":"RSA加密算法","date":"2016-04-21T09:40:06.000Z","_content":"\n今天在了解公钥加密算法的时候看到了RSA加密算法，在理解其原理后觉得算法思想很是巧妙，感触颇深。\n\n- 不对称加密比对称加密算法好在能够在防止中间人攻击的情况下，减少系统的算法数。\n- 不对称加密要想完全防止中间人攻击，需要防止中间人伪造公钥，因此有一个国际数字证书认证机构，叫做 CA，会对每个提供 SSL 加密访问（https）的网站的公钥作一个签名认证。用户的浏览器事先内置了 CA 的公钥，每次收到目标网站传来的公钥，就用 CA 的公钥检验一下目标网站的公钥是否可靠。如果验证不通过，浏览器会发出警告。尤其是银行这样的网站，要注意其数字证书是否可靠。\n\n<!-- more -->\n\n详细算法原理，看[维基百科](https://zh.wikipedia.org/wiki/RSA%E5%8A%A0%E5%AF%86%E6%BC%94%E7%AE%97%E6%B3%95)。\n其算法核心思想还是利用大数质因数分解的困难性和复杂性，若是有人能发明一种快速质因数分解算法，那RSA加密就要无容身之地喽，但这个难度估计就是证明数学上那些有关质数的猜想了。。。\n\n","source":"_posts/信息安全/RSA加密算法.markdown","raw":"---\ntitle: RSA加密算法\ndate: 2016-04-21 17:40:06\ncategories: [信息安全]\n---\n\n今天在了解公钥加密算法的时候看到了RSA加密算法，在理解其原理后觉得算法思想很是巧妙，感触颇深。\n\n- 不对称加密比对称加密算法好在能够在防止中间人攻击的情况下，减少系统的算法数。\n- 不对称加密要想完全防止中间人攻击，需要防止中间人伪造公钥，因此有一个国际数字证书认证机构，叫做 CA，会对每个提供 SSL 加密访问（https）的网站的公钥作一个签名认证。用户的浏览器事先内置了 CA 的公钥，每次收到目标网站传来的公钥，就用 CA 的公钥检验一下目标网站的公钥是否可靠。如果验证不通过，浏览器会发出警告。尤其是银行这样的网站，要注意其数字证书是否可靠。\n\n<!-- more -->\n\n详细算法原理，看[维基百科](https://zh.wikipedia.org/wiki/RSA%E5%8A%A0%E5%AF%86%E6%BC%94%E7%AE%97%E6%B3%95)。\n其算法核心思想还是利用大数质因数分解的困难性和复杂性，若是有人能发明一种快速质因数分解算法，那RSA加密就要无容身之地喽，但这个难度估计就是证明数学上那些有关质数的猜想了。。。\n\n","slug":"信息安全/RSA加密算法","published":1,"updated":"2022-09-15T03:46:43.359Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551o7000kjqrr49g1eo8e","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>今天在了解公钥加密算法的时候看到了RSA加密算法，在理解其原理后觉得算法思想很是巧妙，感触颇深。</p>\n<ul>\n<li>不对称加密比对称加密算法好在能够在防止中间人攻击的情况下，减少系统的算法数。</li>\n<li>不对称加密要想完全防止中间人攻击，需要防止中间人伪造公钥，因此有一个国际数字证书认证机构，叫做 CA，会对每个提供 SSL 加密访问（https）的网站的公钥作一个签名认证。用户的浏览器事先内置了 CA 的公钥，每次收到目标网站传来的公钥，就用 CA 的公钥检验一下目标网站的公钥是否可靠。如果验证不通过，浏览器会发出警告。尤其是银行这样的网站，要注意其数字证书是否可靠。</li>\n</ul>\n<a id=\"more\"></a>\n<p>详细算法原理，看<a href=\"https://zh.wikipedia.org/wiki/RSA%E5%8A%A0%E5%AF%86%E6%BC%94%E7%AE%97%E6%B3%95\" target=\"_blank\" rel=\"noopener\">维基百科</a>。<br>其算法核心思想还是利用大数质因数分解的困难性和复杂性，若是有人能发明一种快速质因数分解算法，那RSA加密就要无容身之地喽，但这个难度估计就是证明数学上那些有关质数的猜想了。。。</p>\n","site":{"data":{}},"excerpt":"<p>今天在了解公钥加密算法的时候看到了RSA加密算法，在理解其原理后觉得算法思想很是巧妙，感触颇深。</p>\n<ul>\n<li>不对称加密比对称加密算法好在能够在防止中间人攻击的情况下，减少系统的算法数。</li>\n<li>不对称加密要想完全防止中间人攻击，需要防止中间人伪造公钥，因此有一个国际数字证书认证机构，叫做 CA，会对每个提供 SSL 加密访问（https）的网站的公钥作一个签名认证。用户的浏览器事先内置了 CA 的公钥，每次收到目标网站传来的公钥，就用 CA 的公钥检验一下目标网站的公钥是否可靠。如果验证不通过，浏览器会发出警告。尤其是银行这样的网站，要注意其数字证书是否可靠。</li>\n</ul>","more":"<p>详细算法原理，看<a href=\"https://zh.wikipedia.org/wiki/RSA%E5%8A%A0%E5%AF%86%E6%BC%94%E7%AE%97%E6%B3%95\" target=\"_blank\" rel=\"noopener\">维基百科</a>。<br>其算法核心思想还是利用大数质因数分解的困难性和复杂性，若是有人能发明一种快速质因数分解算法，那RSA加密就要无容身之地喽，但这个难度估计就是证明数学上那些有关质数的猜想了。。。</p>"},{"title":"前端开发环境配置","date":"2020-06-19T16:00:00.000Z","_content":"\n\n\n## Step 1 - VS code\n\n- 汉化插件: chinese simplied language\n- 格式化代码：Prettier\n\n```json\n// 修改settings.json\n{\n  \"diffEditor.ignoreTrimWhitespace\": true,\n  \"editor.suggestSelection\": \"first\",\n  // \"eslint.codeActionsOnSave\": true,\n  \"eslint.validate\": [\n    \"javascript\",\n    \"javascriptreact\",\n    \"typescript\",\n    \"typescriptreact\"\n  ],\n  \"javascript.implicitProjectConfig.experimentalDecorators\": true,\n  \"terminal.integrated.rendererType\": \"dom\",\n  \"vsintellicode.modify.editor.suggestSelection\": \"automaticallyOverrodeDefaultValue\",\n  \"window.zoomLevel\": 1,\n  \"workbench.colorTheme\": \"Visual Studio Dark\",\n  \"workbench.iconTheme\": \"material-icon-theme\",\n  \"[json]\": {\n    \"editor.defaultFormatter\": \"vscode.json-language-features\"\n  },\n  \"[html]\": {\n    \"editor.defaultFormatter\": \"HookyQR.beautify\"\n  },\n  \"[javascript]\": {\n    \"editor.defaultFormatter\": \"HookyQR.beautify\"\n  },\n  \"javascript.updateImportsOnFileMove.enabled\": \"always\",\n  \"files.exclude\": {\n    \"**/.classpath\": true,\n    \"**/.project\": true,\n    \"**/.settings\": true,\n    \"**/.factorypath\": true\n  },\n  \"files.associations\": {\n    \"*.py\": \"python\"\n  },\n  \"[less]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"[typescriptreact]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"powermode.enabled\": true,\n  \"powermode.presets\": \"flames\",\n  \"[javascriptreact]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"[typescript]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"typescript.updateImportsOnFileMove.enabled\": \"always\",\n  //   \"editor.codeActionsOnSave\": {\n  //     \"source.fixAll.eslint\": true\n  //   },\n  \"editor.formatOnSave\": true\n}\n\n\n// 配置文件, prettier.config.js or .prettierrc.js\nmodule.exports = {\n  // 一行最多 100 字符\n  printWidth: 100,\n  // 使用 4 个空格缩进\n  tabWidth: 2,\n  // 不使用缩进符，而使用空格\n  useTabs: false,\n  // 行尾需要有分号\n  semi: true,\n  // 使用单引号\n  singleQuote: true,\n  // 对象的 key 仅在必要时用引号\n  quoteProps: 'as-needed',\n  // jsx 不使用单引号，而使用双引号\n  jsxSingleQuote: false,\n  // 末尾不需要逗号\n  trailingComma: 'none',\n  // 大括号内的首尾需要空格\n  bracketSpacing: true,\n  // jsx 标签的反尖括号需要换行\n  jsxBracketSameLine: false,\n  // 箭头函数，只有一个参数的时候，也需要括号\n  arrowParens: 'always',\n  // parser: \"babylon\",\n  // 每个文件格式化的范围是文件的全部内容\n  rangeStart: 0,\n  rangeEnd: Infinity,\n  // 不需要写文件开头的 @prettier\n  requirePragma: false,\n  // 不需要自动在文件开头插入 @prettier\n  insertPragma: false,\n  // 根据显示样式决定 html 要不要折行\n  htmlWhitespaceSensitivity: 'css',\n  // 换行符使用 lf\n  endOfLine: 'lf'\n};\n\n```\n\n- 代码检查: ESLint\n\n  ```json\n  // 配置文件 .eslintrc.json\n  {\n    \"extends\": \"react-app\"\n  }\n  \n  // 忽略文件 .eslintignore\n  ```\n\n- 括号高亮: Bracket Pair Colorizer\n\n  \n\n## Step 2 - yarn\n\nFacebook开发的yarn, 类似JAVA的maven管理工具，比npm更好一点：\n\n```\n# 安装yarn \nnpm i -g yarn\n# 安装项目所有依赖\nyarn\n```\n\n","source":"_posts/前端开发/前端开发环境配置.md","raw":"---\ntitle: 前端开发环境配置\ndate: 2020-06-20\ntags: 前端\ncategories: Web开发\n\n---\n\n\n\n## Step 1 - VS code\n\n- 汉化插件: chinese simplied language\n- 格式化代码：Prettier\n\n```json\n// 修改settings.json\n{\n  \"diffEditor.ignoreTrimWhitespace\": true,\n  \"editor.suggestSelection\": \"first\",\n  // \"eslint.codeActionsOnSave\": true,\n  \"eslint.validate\": [\n    \"javascript\",\n    \"javascriptreact\",\n    \"typescript\",\n    \"typescriptreact\"\n  ],\n  \"javascript.implicitProjectConfig.experimentalDecorators\": true,\n  \"terminal.integrated.rendererType\": \"dom\",\n  \"vsintellicode.modify.editor.suggestSelection\": \"automaticallyOverrodeDefaultValue\",\n  \"window.zoomLevel\": 1,\n  \"workbench.colorTheme\": \"Visual Studio Dark\",\n  \"workbench.iconTheme\": \"material-icon-theme\",\n  \"[json]\": {\n    \"editor.defaultFormatter\": \"vscode.json-language-features\"\n  },\n  \"[html]\": {\n    \"editor.defaultFormatter\": \"HookyQR.beautify\"\n  },\n  \"[javascript]\": {\n    \"editor.defaultFormatter\": \"HookyQR.beautify\"\n  },\n  \"javascript.updateImportsOnFileMove.enabled\": \"always\",\n  \"files.exclude\": {\n    \"**/.classpath\": true,\n    \"**/.project\": true,\n    \"**/.settings\": true,\n    \"**/.factorypath\": true\n  },\n  \"files.associations\": {\n    \"*.py\": \"python\"\n  },\n  \"[less]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"[typescriptreact]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"powermode.enabled\": true,\n  \"powermode.presets\": \"flames\",\n  \"[javascriptreact]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"[typescript]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"typescript.updateImportsOnFileMove.enabled\": \"always\",\n  //   \"editor.codeActionsOnSave\": {\n  //     \"source.fixAll.eslint\": true\n  //   },\n  \"editor.formatOnSave\": true\n}\n\n\n// 配置文件, prettier.config.js or .prettierrc.js\nmodule.exports = {\n  // 一行最多 100 字符\n  printWidth: 100,\n  // 使用 4 个空格缩进\n  tabWidth: 2,\n  // 不使用缩进符，而使用空格\n  useTabs: false,\n  // 行尾需要有分号\n  semi: true,\n  // 使用单引号\n  singleQuote: true,\n  // 对象的 key 仅在必要时用引号\n  quoteProps: 'as-needed',\n  // jsx 不使用单引号，而使用双引号\n  jsxSingleQuote: false,\n  // 末尾不需要逗号\n  trailingComma: 'none',\n  // 大括号内的首尾需要空格\n  bracketSpacing: true,\n  // jsx 标签的反尖括号需要换行\n  jsxBracketSameLine: false,\n  // 箭头函数，只有一个参数的时候，也需要括号\n  arrowParens: 'always',\n  // parser: \"babylon\",\n  // 每个文件格式化的范围是文件的全部内容\n  rangeStart: 0,\n  rangeEnd: Infinity,\n  // 不需要写文件开头的 @prettier\n  requirePragma: false,\n  // 不需要自动在文件开头插入 @prettier\n  insertPragma: false,\n  // 根据显示样式决定 html 要不要折行\n  htmlWhitespaceSensitivity: 'css',\n  // 换行符使用 lf\n  endOfLine: 'lf'\n};\n\n```\n\n- 代码检查: ESLint\n\n  ```json\n  // 配置文件 .eslintrc.json\n  {\n    \"extends\": \"react-app\"\n  }\n  \n  // 忽略文件 .eslintignore\n  ```\n\n- 括号高亮: Bracket Pair Colorizer\n\n  \n\n## Step 2 - yarn\n\nFacebook开发的yarn, 类似JAVA的maven管理工具，比npm更好一点：\n\n```\n# 安装yarn \nnpm i -g yarn\n# 安装项目所有依赖\nyarn\n```\n\n","slug":"前端开发/前端开发环境配置","published":1,"updated":"2022-09-15T03:46:43.359Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551o7000njqrrk6e4vfg2","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"Step-1-VS-code\"><a href=\"#Step-1-VS-code\" class=\"headerlink\" title=\"Step 1 - VS code\"></a>Step 1 - VS code</h2><ul>\n<li>汉化插件: chinese simplied language</li>\n<li>格式化代码：Prettier</li>\n</ul>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 修改settings.json</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"attr\">\"diffEditor.ignoreTrimWhitespace\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">  <span class=\"attr\">\"editor.suggestSelection\"</span>: <span class=\"string\">\"first\"</span>,</span><br><span class=\"line\">  // \"eslint.codeActionsOnSave\": true,</span><br><span class=\"line\">  \"eslint.validate\": [</span><br><span class=\"line\">    \"javascript\",</span><br><span class=\"line\">    \"javascriptreact\",</span><br><span class=\"line\">    \"typescript\",</span><br><span class=\"line\">    <span class=\"string\">\"typescriptreact\"</span></span><br><span class=\"line\">  ],</span><br><span class=\"line\">  \"javascript.implicitProjectConfig.experimentalDecorators\": true,</span><br><span class=\"line\">  \"terminal.integrated.rendererType\": \"dom\",</span><br><span class=\"line\">  \"vsintellicode.modify.editor.suggestSelection\": \"automaticallyOverrodeDefaultValue\",</span><br><span class=\"line\">  \"window.zoomLevel\": 1,</span><br><span class=\"line\">  \"workbench.colorTheme\": \"Visual Studio Dark\",</span><br><span class=\"line\">  \"workbench.iconTheme\": \"material-icon-theme\",</span><br><span class=\"line\">  \"[json]\": &#123;</span><br><span class=\"line\">    \"editor.defaultFormatter\": \"vscode.json-language-features\"</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"[html]\": &#123;</span><br><span class=\"line\">    \"editor.defaultFormatter\": \"HookyQR.beautify\"</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"[javascript]\": &#123;</span><br><span class=\"line\">    \"editor.defaultFormatter\": \"HookyQR.beautify\"</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"javascript.updateImportsOnFileMove.enabled\": \"always\",</span><br><span class=\"line\">  \"files.exclude\": &#123;</span><br><span class=\"line\">    \"**/.classpath\": true,</span><br><span class=\"line\">    \"**/.project\": true,</span><br><span class=\"line\">    \"**/.settings\": true,</span><br><span class=\"line\">    \"**/.factorypath\": true</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"files.associations\": &#123;</span><br><span class=\"line\">    \"*.py\": \"python\"</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"[less]\": &#123;</span><br><span class=\"line\">    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"[typescriptreact]\": &#123;</span><br><span class=\"line\">    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"powermode.enabled\": true,</span><br><span class=\"line\">  \"powermode.presets\": \"flames\",</span><br><span class=\"line\">  \"[javascriptreact]\": &#123;</span><br><span class=\"line\">    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"[typescript]\": &#123;</span><br><span class=\"line\">    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"typescript.updateImportsOnFileMove.enabled\": \"always\",</span><br><span class=\"line\">  //   \"editor.codeActionsOnSave\": &#123;</span><br><span class=\"line\">  //     \"source.fixAll.eslint\": true</span><br><span class=\"line\">  //   &#125;,</span><br><span class=\"line\">  \"editor.formatOnSave\": true</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">// 配置文件, prettier.config.js or .prettierrc.js</span><br><span class=\"line\">module.exports = &#123;</span><br><span class=\"line\">  // 一行最多 100 字符</span><br><span class=\"line\">  printWidth: 100,</span><br><span class=\"line\">  // 使用 4 个空格缩进</span><br><span class=\"line\">  tabWidth: 2,</span><br><span class=\"line\">  // 不使用缩进符，而使用空格</span><br><span class=\"line\">  useTabs: false,</span><br><span class=\"line\">  // 行尾需要有分号</span><br><span class=\"line\">  semi: true,</span><br><span class=\"line\">  // 使用单引号</span><br><span class=\"line\">  singleQuote: true,</span><br><span class=\"line\">  // 对象的 key 仅在必要时用引号</span><br><span class=\"line\">  quoteProps: 'as-needed',</span><br><span class=\"line\">  // jsx 不使用单引号，而使用双引号</span><br><span class=\"line\">  jsxSingleQuote: false,</span><br><span class=\"line\">  // 末尾不需要逗号</span><br><span class=\"line\">  trailingComma: 'none',</span><br><span class=\"line\">  // 大括号内的首尾需要空格</span><br><span class=\"line\">  bracketSpacing: true,</span><br><span class=\"line\">  // jsx 标签的反尖括号需要换行</span><br><span class=\"line\">  jsxBracketSameLine: false,</span><br><span class=\"line\">  // 箭头函数，只有一个参数的时候，也需要括号</span><br><span class=\"line\">  arrowParens: 'always',</span><br><span class=\"line\">  // parser: \"babylon\",</span><br><span class=\"line\">  // 每个文件格式化的范围是文件的全部内容</span><br><span class=\"line\">  rangeStart: 0,</span><br><span class=\"line\">  rangeEnd: Infinity,</span><br><span class=\"line\">  // 不需要写文件开头的 @prettier</span><br><span class=\"line\">  requirePragma: false,</span><br><span class=\"line\">  // 不需要自动在文件开头插入 @prettier</span><br><span class=\"line\">  insertPragma: false,</span><br><span class=\"line\">  // 根据显示样式决定 html 要不要折行</span><br><span class=\"line\">  htmlWhitespaceSensitivity: 'css',</span><br><span class=\"line\">  // 换行符使用 lf</span><br><span class=\"line\">  endOfLine: 'lf'</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>代码检查: ESLint</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 配置文件 .eslintrc.json</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"attr\">\"extends\"</span>: <span class=\"string\">\"react-app\"</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// 忽略文件 .eslintignore</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>括号高亮: Bracket Pair Colorizer</p>\n</li>\n</ul>\n<h2 id=\"Step-2-yarn\"><a href=\"#Step-2-yarn\" class=\"headerlink\" title=\"Step 2 - yarn\"></a>Step 2 - yarn</h2><p>Facebook开发的yarn, 类似JAVA的maven管理工具，比npm更好一点：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 安装yarn </span><br><span class=\"line\">npm i -g yarn</span><br><span class=\"line\"># 安装项目所有依赖</span><br><span class=\"line\">yarn</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Step-1-VS-code\"><a href=\"#Step-1-VS-code\" class=\"headerlink\" title=\"Step 1 - VS code\"></a>Step 1 - VS code</h2><ul>\n<li>汉化插件: chinese simplied language</li>\n<li>格式化代码：Prettier</li>\n</ul>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 修改settings.json</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"attr\">\"diffEditor.ignoreTrimWhitespace\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">  <span class=\"attr\">\"editor.suggestSelection\"</span>: <span class=\"string\">\"first\"</span>,</span><br><span class=\"line\">  // \"eslint.codeActionsOnSave\": true,</span><br><span class=\"line\">  \"eslint.validate\": [</span><br><span class=\"line\">    \"javascript\",</span><br><span class=\"line\">    \"javascriptreact\",</span><br><span class=\"line\">    \"typescript\",</span><br><span class=\"line\">    <span class=\"string\">\"typescriptreact\"</span></span><br><span class=\"line\">  ],</span><br><span class=\"line\">  \"javascript.implicitProjectConfig.experimentalDecorators\": true,</span><br><span class=\"line\">  \"terminal.integrated.rendererType\": \"dom\",</span><br><span class=\"line\">  \"vsintellicode.modify.editor.suggestSelection\": \"automaticallyOverrodeDefaultValue\",</span><br><span class=\"line\">  \"window.zoomLevel\": 1,</span><br><span class=\"line\">  \"workbench.colorTheme\": \"Visual Studio Dark\",</span><br><span class=\"line\">  \"workbench.iconTheme\": \"material-icon-theme\",</span><br><span class=\"line\">  \"[json]\": &#123;</span><br><span class=\"line\">    \"editor.defaultFormatter\": \"vscode.json-language-features\"</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"[html]\": &#123;</span><br><span class=\"line\">    \"editor.defaultFormatter\": \"HookyQR.beautify\"</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"[javascript]\": &#123;</span><br><span class=\"line\">    \"editor.defaultFormatter\": \"HookyQR.beautify\"</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"javascript.updateImportsOnFileMove.enabled\": \"always\",</span><br><span class=\"line\">  \"files.exclude\": &#123;</span><br><span class=\"line\">    \"**/.classpath\": true,</span><br><span class=\"line\">    \"**/.project\": true,</span><br><span class=\"line\">    \"**/.settings\": true,</span><br><span class=\"line\">    \"**/.factorypath\": true</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"files.associations\": &#123;</span><br><span class=\"line\">    \"*.py\": \"python\"</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"[less]\": &#123;</span><br><span class=\"line\">    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"[typescriptreact]\": &#123;</span><br><span class=\"line\">    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"powermode.enabled\": true,</span><br><span class=\"line\">  \"powermode.presets\": \"flames\",</span><br><span class=\"line\">  \"[javascriptreact]\": &#123;</span><br><span class=\"line\">    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"[typescript]\": &#123;</span><br><span class=\"line\">    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  \"typescript.updateImportsOnFileMove.enabled\": \"always\",</span><br><span class=\"line\">  //   \"editor.codeActionsOnSave\": &#123;</span><br><span class=\"line\">  //     \"source.fixAll.eslint\": true</span><br><span class=\"line\">  //   &#125;,</span><br><span class=\"line\">  \"editor.formatOnSave\": true</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">// 配置文件, prettier.config.js or .prettierrc.js</span><br><span class=\"line\">module.exports = &#123;</span><br><span class=\"line\">  // 一行最多 100 字符</span><br><span class=\"line\">  printWidth: 100,</span><br><span class=\"line\">  // 使用 4 个空格缩进</span><br><span class=\"line\">  tabWidth: 2,</span><br><span class=\"line\">  // 不使用缩进符，而使用空格</span><br><span class=\"line\">  useTabs: false,</span><br><span class=\"line\">  // 行尾需要有分号</span><br><span class=\"line\">  semi: true,</span><br><span class=\"line\">  // 使用单引号</span><br><span class=\"line\">  singleQuote: true,</span><br><span class=\"line\">  // 对象的 key 仅在必要时用引号</span><br><span class=\"line\">  quoteProps: 'as-needed',</span><br><span class=\"line\">  // jsx 不使用单引号，而使用双引号</span><br><span class=\"line\">  jsxSingleQuote: false,</span><br><span class=\"line\">  // 末尾不需要逗号</span><br><span class=\"line\">  trailingComma: 'none',</span><br><span class=\"line\">  // 大括号内的首尾需要空格</span><br><span class=\"line\">  bracketSpacing: true,</span><br><span class=\"line\">  // jsx 标签的反尖括号需要换行</span><br><span class=\"line\">  jsxBracketSameLine: false,</span><br><span class=\"line\">  // 箭头函数，只有一个参数的时候，也需要括号</span><br><span class=\"line\">  arrowParens: 'always',</span><br><span class=\"line\">  // parser: \"babylon\",</span><br><span class=\"line\">  // 每个文件格式化的范围是文件的全部内容</span><br><span class=\"line\">  rangeStart: 0,</span><br><span class=\"line\">  rangeEnd: Infinity,</span><br><span class=\"line\">  // 不需要写文件开头的 @prettier</span><br><span class=\"line\">  requirePragma: false,</span><br><span class=\"line\">  // 不需要自动在文件开头插入 @prettier</span><br><span class=\"line\">  insertPragma: false,</span><br><span class=\"line\">  // 根据显示样式决定 html 要不要折行</span><br><span class=\"line\">  htmlWhitespaceSensitivity: 'css',</span><br><span class=\"line\">  // 换行符使用 lf</span><br><span class=\"line\">  endOfLine: 'lf'</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>代码检查: ESLint</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 配置文件 .eslintrc.json</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"attr\">\"extends\"</span>: <span class=\"string\">\"react-app\"</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// 忽略文件 .eslintignore</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>括号高亮: Bracket Pair Colorizer</p>\n</li>\n</ul>\n<h2 id=\"Step-2-yarn\"><a href=\"#Step-2-yarn\" class=\"headerlink\" title=\"Step 2 - yarn\"></a>Step 2 - yarn</h2><p>Facebook开发的yarn, 类似JAVA的maven管理工具，比npm更好一点：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 安装yarn </span><br><span class=\"line\">npm i -g yarn</span><br><span class=\"line\"># 安装项目所有依赖</span><br><span class=\"line\">yarn</span><br></pre></td></tr></table></figure>\n"},{"title":"Online Learning中的优化器","date":"2022-08-09T16:00:00.000Z","_content":"\n\n\n今天详细看了下推荐广告系统的online_learning，顾名思义，online_learning就是在线输入样本，更新模型，尽可能做到分钟级/小时级的模型更新，其实关键就是几个问题：\n\n- 模型怎么学习？\n- 怎么降低模型复杂度，保证inference的低延时？\n\n参考博文 : [FTRL 不太简短之介绍](https://liam.page/2019/08/31/a-not-so-simple-introduction-to-FTRL/)\n\n\n\n### 模型怎么学习？\n\n这个其实很简单，其实要求我们可以基于在线输入的样本，进行权重参数更新，基于类似随机梯度SGD的思想即可。\n\n\n\n### 怎么降低模性复杂度，也就是稀疏特征？\n\n答案自然是L1正则。但是问题来了，如果用SGD，我们很难保证L1正则的效果-即得到稀疏解。理由是：\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rtgsdh5j20y40u0aep.jpg\" alt=\"image-20201027185248600\" style=\"zoom: 50%;\" />\n\n即使全局梯度满足L1正则的稀疏条件，但是随机梯度下降因为其随机性，无法保证每次都能满足稀疏条件，所以即使用L1正则，还是难以得到稀疏特征。\n\n\n\n#### 替代SGD的方法\n\n总体而言，其实就是两个步骤：\n\n- 先按照次梯度更新权重（为什么是次梯度？因为L1正则在x=0的地方不可导！所以是次梯度）\n- 然后对梯度进行投影\n\n\n\n##### 简单截断法\n\n投影方法，就是直接设阈值，对梯度进行截断：\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rtta91fj21b00cg75k.jpg\" alt=\"image-20201027185706752\" style=\"zoom:40%;\" />\n\n##### Truncated Gradient\n\n投影方法，就是分段截断：\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rtz1wgcj21a40eiq4j.jpg\" alt=\"image-20201027185754986\" style=\"zoom:40%;\" />\n\n上面两种方法的图解：\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51ru20h2vj20yu0ce0t3.jpg\" alt=\"image-20201027185838385\" style=\"zoom:40%;\" />\n\n\n\n##### FOBOS\n\n投影方法，就是求最优化闭式解。\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51ruavat6j21au0bsdh1.jpg\" alt=\"image-20201027185919933\" style=\"zoom:40%;\" />\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rudmiu2j213k0agt9v.jpg\" alt=\"image-20201027190101940\" style=\"zoom:40%;\" />\n\n##### RDA (Regularized Dual Averaging)\n\n改进在于，利用前面t次累加的梯度。和 FOBOS 及之前的截断方法比较，RDA 最大的差别在于丢弃了梯度下降的那一项，换成了梯度的二次平均值。\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51ruguyw1j20wu054q37.jpg\" alt=\"image-20201027190202895\" style=\"zoom:50%;\" />![image-20201027190434418](https://tva1.sinaimg.cn/large/e6c9d24ely1h52t8hekgxj211m07m74v.jpg)\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h52t8os84hj211m07m74v.jpg\" alt=\"image-20201027190434418\" style=\"zoom:40%;\" />\n\n\n\n##### FTRL (Follow The Regularized Leader)\n\n也是我们目前通常在用的方法，结合了FOBOS和RDA两者的优势。\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rul5a3oj21d60l0dj9.jpg\" alt=\"image-20201027190550177\" style=\"zoom:40%;\" />\n\n","source":"_posts/搜推广/Online Learning中的优化器.md","raw":"---\ntitle: Online Learning中的优化器\ndate: 2022-08-10 \ncategories: 搜推广\n---\n\n\n\n今天详细看了下推荐广告系统的online_learning，顾名思义，online_learning就是在线输入样本，更新模型，尽可能做到分钟级/小时级的模型更新，其实关键就是几个问题：\n\n- 模型怎么学习？\n- 怎么降低模型复杂度，保证inference的低延时？\n\n参考博文 : [FTRL 不太简短之介绍](https://liam.page/2019/08/31/a-not-so-simple-introduction-to-FTRL/)\n\n\n\n### 模型怎么学习？\n\n这个其实很简单，其实要求我们可以基于在线输入的样本，进行权重参数更新，基于类似随机梯度SGD的思想即可。\n\n\n\n### 怎么降低模性复杂度，也就是稀疏特征？\n\n答案自然是L1正则。但是问题来了，如果用SGD，我们很难保证L1正则的效果-即得到稀疏解。理由是：\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rtgsdh5j20y40u0aep.jpg\" alt=\"image-20201027185248600\" style=\"zoom: 50%;\" />\n\n即使全局梯度满足L1正则的稀疏条件，但是随机梯度下降因为其随机性，无法保证每次都能满足稀疏条件，所以即使用L1正则，还是难以得到稀疏特征。\n\n\n\n#### 替代SGD的方法\n\n总体而言，其实就是两个步骤：\n\n- 先按照次梯度更新权重（为什么是次梯度？因为L1正则在x=0的地方不可导！所以是次梯度）\n- 然后对梯度进行投影\n\n\n\n##### 简单截断法\n\n投影方法，就是直接设阈值，对梯度进行截断：\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rtta91fj21b00cg75k.jpg\" alt=\"image-20201027185706752\" style=\"zoom:40%;\" />\n\n##### Truncated Gradient\n\n投影方法，就是分段截断：\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rtz1wgcj21a40eiq4j.jpg\" alt=\"image-20201027185754986\" style=\"zoom:40%;\" />\n\n上面两种方法的图解：\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51ru20h2vj20yu0ce0t3.jpg\" alt=\"image-20201027185838385\" style=\"zoom:40%;\" />\n\n\n\n##### FOBOS\n\n投影方法，就是求最优化闭式解。\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51ruavat6j21au0bsdh1.jpg\" alt=\"image-20201027185919933\" style=\"zoom:40%;\" />\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rudmiu2j213k0agt9v.jpg\" alt=\"image-20201027190101940\" style=\"zoom:40%;\" />\n\n##### RDA (Regularized Dual Averaging)\n\n改进在于，利用前面t次累加的梯度。和 FOBOS 及之前的截断方法比较，RDA 最大的差别在于丢弃了梯度下降的那一项，换成了梯度的二次平均值。\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51ruguyw1j20wu054q37.jpg\" alt=\"image-20201027190202895\" style=\"zoom:50%;\" />![image-20201027190434418](https://tva1.sinaimg.cn/large/e6c9d24ely1h52t8hekgxj211m07m74v.jpg)\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h52t8os84hj211m07m74v.jpg\" alt=\"image-20201027190434418\" style=\"zoom:40%;\" />\n\n\n\n##### FTRL (Follow The Regularized Leader)\n\n也是我们目前通常在用的方法，结合了FOBOS和RDA两者的优势。\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rul5a3oj21d60l0dj9.jpg\" alt=\"image-20201027190550177\" style=\"zoom:40%;\" />\n\n","slug":"搜推广/Online Learning中的优化器","published":1,"updated":"2022-09-15T03:46:43.360Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551o8000sjqrrda6qs3n8","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>今天详细看了下推荐广告系统的online_learning，顾名思义，online_learning就是在线输入样本，更新模型，尽可能做到分钟级/小时级的模型更新，其实关键就是几个问题：</p>\n<ul>\n<li>模型怎么学习？</li>\n<li>怎么降低模型复杂度，保证inference的低延时？</li>\n</ul>\n<p>参考博文 : <a href=\"https://liam.page/2019/08/31/a-not-so-simple-introduction-to-FTRL/\" target=\"_blank\" rel=\"noopener\">FTRL 不太简短之介绍</a></p>\n<h3 id=\"模型怎么学习？\"><a href=\"#模型怎么学习？\" class=\"headerlink\" title=\"模型怎么学习？\"></a>模型怎么学习？</h3><p>这个其实很简单，其实要求我们可以基于在线输入的样本，进行权重参数更新，基于类似随机梯度SGD的思想即可。</p>\n<h3 id=\"怎么降低模性复杂度，也就是稀疏特征？\"><a href=\"#怎么降低模性复杂度，也就是稀疏特征？\" class=\"headerlink\" title=\"怎么降低模性复杂度，也就是稀疏特征？\"></a>怎么降低模性复杂度，也就是稀疏特征？</h3><p>答案自然是L1正则。但是问题来了，如果用SGD，我们很难保证L1正则的效果-即得到稀疏解。理由是：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rtgsdh5j20y40u0aep.jpg\" alt=\"image-20201027185248600\" style=\"zoom: 50%;\"></p>\n<p>即使全局梯度满足L1正则的稀疏条件，但是随机梯度下降因为其随机性，无法保证每次都能满足稀疏条件，所以即使用L1正则，还是难以得到稀疏特征。</p>\n<h4 id=\"替代SGD的方法\"><a href=\"#替代SGD的方法\" class=\"headerlink\" title=\"替代SGD的方法\"></a>替代SGD的方法</h4><p>总体而言，其实就是两个步骤：</p>\n<ul>\n<li>先按照次梯度更新权重（为什么是次梯度？因为L1正则在x=0的地方不可导！所以是次梯度）</li>\n<li>然后对梯度进行投影</li>\n</ul>\n<h5 id=\"简单截断法\"><a href=\"#简单截断法\" class=\"headerlink\" title=\"简单截断法\"></a>简单截断法</h5><p>投影方法，就是直接设阈值，对梯度进行截断：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rtta91fj21b00cg75k.jpg\" alt=\"image-20201027185706752\" style=\"zoom:40%;\"></p>\n<h5 id=\"Truncated-Gradient\"><a href=\"#Truncated-Gradient\" class=\"headerlink\" title=\"Truncated Gradient\"></a>Truncated Gradient</h5><p>投影方法，就是分段截断：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rtz1wgcj21a40eiq4j.jpg\" alt=\"image-20201027185754986\" style=\"zoom:40%;\"></p>\n<p>上面两种方法的图解：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51ru20h2vj20yu0ce0t3.jpg\" alt=\"image-20201027185838385\" style=\"zoom:40%;\"></p>\n<h5 id=\"FOBOS\"><a href=\"#FOBOS\" class=\"headerlink\" title=\"FOBOS\"></a>FOBOS</h5><p>投影方法，就是求最优化闭式解。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51ruavat6j21au0bsdh1.jpg\" alt=\"image-20201027185919933\" style=\"zoom:40%;\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rudmiu2j213k0agt9v.jpg\" alt=\"image-20201027190101940\" style=\"zoom:40%;\"></p>\n<h5 id=\"RDA-Regularized-Dual-Averaging\"><a href=\"#RDA-Regularized-Dual-Averaging\" class=\"headerlink\" title=\"RDA (Regularized Dual Averaging)\"></a>RDA (Regularized Dual Averaging)</h5><p>改进在于，利用前面t次累加的梯度。和 FOBOS 及之前的截断方法比较，RDA 最大的差别在于丢弃了梯度下降的那一项，换成了梯度的二次平均值。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51ruguyw1j20wu054q37.jpg\" alt=\"image-20201027190202895\" style=\"zoom:50%;\"><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h52t8hekgxj211m07m74v.jpg\" alt=\"image-20201027190434418\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h52t8os84hj211m07m74v.jpg\" alt=\"image-20201027190434418\" style=\"zoom:40%;\"></p>\n<h5 id=\"FTRL-Follow-The-Regularized-Leader\"><a href=\"#FTRL-Follow-The-Regularized-Leader\" class=\"headerlink\" title=\"FTRL (Follow The Regularized Leader)\"></a>FTRL (Follow The Regularized Leader)</h5><p>也是我们目前通常在用的方法，结合了FOBOS和RDA两者的优势。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rul5a3oj21d60l0dj9.jpg\" alt=\"image-20201027190550177\" style=\"zoom:40%;\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>今天详细看了下推荐广告系统的online_learning，顾名思义，online_learning就是在线输入样本，更新模型，尽可能做到分钟级/小时级的模型更新，其实关键就是几个问题：</p>\n<ul>\n<li>模型怎么学习？</li>\n<li>怎么降低模型复杂度，保证inference的低延时？</li>\n</ul>\n<p>参考博文 : <a href=\"https://liam.page/2019/08/31/a-not-so-simple-introduction-to-FTRL/\" target=\"_blank\" rel=\"noopener\">FTRL 不太简短之介绍</a></p>\n<h3 id=\"模型怎么学习？\"><a href=\"#模型怎么学习？\" class=\"headerlink\" title=\"模型怎么学习？\"></a>模型怎么学习？</h3><p>这个其实很简单，其实要求我们可以基于在线输入的样本，进行权重参数更新，基于类似随机梯度SGD的思想即可。</p>\n<h3 id=\"怎么降低模性复杂度，也就是稀疏特征？\"><a href=\"#怎么降低模性复杂度，也就是稀疏特征？\" class=\"headerlink\" title=\"怎么降低模性复杂度，也就是稀疏特征？\"></a>怎么降低模性复杂度，也就是稀疏特征？</h3><p>答案自然是L1正则。但是问题来了，如果用SGD，我们很难保证L1正则的效果-即得到稀疏解。理由是：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rtgsdh5j20y40u0aep.jpg\" alt=\"image-20201027185248600\" style=\"zoom: 50%;\"></p>\n<p>即使全局梯度满足L1正则的稀疏条件，但是随机梯度下降因为其随机性，无法保证每次都能满足稀疏条件，所以即使用L1正则，还是难以得到稀疏特征。</p>\n<h4 id=\"替代SGD的方法\"><a href=\"#替代SGD的方法\" class=\"headerlink\" title=\"替代SGD的方法\"></a>替代SGD的方法</h4><p>总体而言，其实就是两个步骤：</p>\n<ul>\n<li>先按照次梯度更新权重（为什么是次梯度？因为L1正则在x=0的地方不可导！所以是次梯度）</li>\n<li>然后对梯度进行投影</li>\n</ul>\n<h5 id=\"简单截断法\"><a href=\"#简单截断法\" class=\"headerlink\" title=\"简单截断法\"></a>简单截断法</h5><p>投影方法，就是直接设阈值，对梯度进行截断：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rtta91fj21b00cg75k.jpg\" alt=\"image-20201027185706752\" style=\"zoom:40%;\"></p>\n<h5 id=\"Truncated-Gradient\"><a href=\"#Truncated-Gradient\" class=\"headerlink\" title=\"Truncated Gradient\"></a>Truncated Gradient</h5><p>投影方法，就是分段截断：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rtz1wgcj21a40eiq4j.jpg\" alt=\"image-20201027185754986\" style=\"zoom:40%;\"></p>\n<p>上面两种方法的图解：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51ru20h2vj20yu0ce0t3.jpg\" alt=\"image-20201027185838385\" style=\"zoom:40%;\"></p>\n<h5 id=\"FOBOS\"><a href=\"#FOBOS\" class=\"headerlink\" title=\"FOBOS\"></a>FOBOS</h5><p>投影方法，就是求最优化闭式解。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51ruavat6j21au0bsdh1.jpg\" alt=\"image-20201027185919933\" style=\"zoom:40%;\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rudmiu2j213k0agt9v.jpg\" alt=\"image-20201027190101940\" style=\"zoom:40%;\"></p>\n<h5 id=\"RDA-Regularized-Dual-Averaging\"><a href=\"#RDA-Regularized-Dual-Averaging\" class=\"headerlink\" title=\"RDA (Regularized Dual Averaging)\"></a>RDA (Regularized Dual Averaging)</h5><p>改进在于，利用前面t次累加的梯度。和 FOBOS 及之前的截断方法比较，RDA 最大的差别在于丢弃了梯度下降的那一项，换成了梯度的二次平均值。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51ruguyw1j20wu054q37.jpg\" alt=\"image-20201027190202895\" style=\"zoom:50%;\"><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h52t8hekgxj211m07m74v.jpg\" alt=\"image-20201027190434418\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h52t8os84hj211m07m74v.jpg\" alt=\"image-20201027190434418\" style=\"zoom:40%;\"></p>\n<h5 id=\"FTRL-Follow-The-Regularized-Leader\"><a href=\"#FTRL-Follow-The-Regularized-Leader\" class=\"headerlink\" title=\"FTRL (Follow The Regularized Leader)\"></a>FTRL (Follow The Regularized Leader)</h5><p>也是我们目前通常在用的方法，结合了FOBOS和RDA两者的优势。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rul5a3oj21d60l0dj9.jpg\" alt=\"image-20201027190550177\" style=\"zoom:40%;\"></p>\n"},{"title":"《推荐系统实战》笔记","date":"2020-07-22T11:28:44.000Z","_content":"\n\n\n最近看了项亮老师的《推荐系统实践》，做了相关的心得和笔记。\n\n\n\n### 一、推荐系统指标\n\n- 用户满意度：调查问卷等方式，也可以通过线上其他指标来衡量\n- 预测准确度：\n  - 评分预测：RMSE,MAE\n  - TopN推荐：准确率和召回率\n- 覆盖率：物品流行度之间的差异，指标如熵、基尼系数\n- 多样性：物品之间的相似性低，多样性高\n- 新颖性：一般来讲，物品平均流行度低，新颖性高\n  - 如何在不牺牲精度的情况下提高多样性和新颖性？\n- 惊喜度：与用户历史兴趣不同，但会让用户喜欢\n- 信任度\n- 实时性\n- 健壮性\n- 商业目标\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh03jbvuuzj31eo0ga76x.jpg\" alt=\"image-20200722220000325\" style=\"zoom:50%;\" />\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh03j7ho93j31dr0du78g.jpg\" alt=\"image-20200722220010615\" style=\"zoom:45%;\" />\n\n\n\n\n\n### 二、基于用户行为分析的推荐算法\n\n仅仅基于用户行为数据设计的推荐算法一般称为协同过滤算法，学术界对协同过滤算法 进行了深入研究，提出了很多方法，比如基于邻域的方法(neighborhood-based)、隐语义模型(latent factor model)、基于图的随机游走算法(random walk on graph)等。最终目的都是生成用户和物品之间的兴趣度。\n\n#### 基于领域的算法\n\n统计方法：\n\n- UserCF\n- ItemCF\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0o54pwxuj31dt0oz13l.jpg\" alt=\"image-20200723095329692\" style=\"zoom:50%;\" />\n\n\n\n#### 隐语义模型(Latent Factor Model)\n\n其实本质上就是训练得到用户的隐向量和物品的隐向量(Embedding的感觉)，然后再类似CTR预估。\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0o87nop6j30x40420tb.jpg\" alt=\"image-20200723095628676\" style=\"zoom:50%;\" />\n\n\n\n- 机器学习过程\n- 离线空间复杂度较低，时间复杂度较高\n- 实时性差，预测时候需要全量CTR预估再排序\n- 解释性差\n\n\n\n#### 基于图模型\n\n- 生成用户与物品的图，计算顶点之间的相似度\n- PersonalRank，随机游走，类似马尔科夫过程，对于每个用户节点，生成所有节点访问概率，根据物品节点的概率生成推荐列表\n\n\n\n### 三、冷启动问题\n\n主要分为三种问题：\n\n- 新用户冷启动\n- 新物品冷启动\n- 系统冷启动\n\n\n\n#### 针对新用户的冷启动\n\n- 非个性化的热门推荐\n\n- 利用用户的注册信息，例如年龄、性别等，做粗粒度的推荐。\n\n  - 相当于只利用用户的注册信息等特征做CTR预估。\n\n- 要求用户注册填写感兴趣的领域。\n\n  - 关键是如何选取有代表性、有区分度的领域。\n  - 算法：做一颗决策树，选取分裂节点时，选取方差最大的物品\n\n- 利用用户的社交网络，比如社交网络的好友推荐等，或者是外部网站的用户信息\n\n  \n\n#### 针对新物品的冷启动\n\n- 利用物品的自身内容，找计算物品相似度。\n  - 可能会用到文本模型，例如LSI ->PLSI -> LDA(目前主要是这个)等，来生成物品向量，并计算相似度\n- 专家标注\n\n\n\n### 四、利用用户标签数据的推荐算法\n\n标签相当于用户和物品之间的媒介(有点类似topic的感觉)，基于标签的推荐更加有解释性。\n\n- 基于标签的物品推荐算法：\n\n  - 简单来讲，就是将标签作为一个隐向量来计算用户和物品的兴趣：\n\n    <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0z5r4279j30dq039t8t.jpg\" alt=\"image-20200723161433032\" style=\"zoom:50%;\" />\n\n带上热门标签和热门物品的惩罚项：\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0z69qftej30o7053wez.jpg\" alt=\"image-20200723161512422\" style=\"zoom:50%;\" />\n\n- 标签拓展\n\n  - 有些物品标签很少，这时候可以拓展标签，寻找相似标签。类似于itemCF的标签相似度计算方法\n\n- 标签清理\n\n  - 如果我们要把标签呈现给用户，将其 作为给用户推荐某一个物品的解释，对标签的质量要求就很高。首先，这些标签不能包含没有意 义的停止词或者表示情绪的词。\n\n- 基于图的标签推荐算法\n\n  - 利用标签作为中间层，类似于一个栅栏图。然后利用personalRank等计算节点相关性。\n\n    <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0z8o963xj30py0jmag7.jpg\" alt=\"image-20200723161730568\" style=\"zoom:50%;\" />\n\n- 推荐打标签算法\n  \n  - 用户写标签的时候给他做推荐，很多算法：用户最常打标签，该物品最热门标签等\n\n\n\n### 五、利用上下文信息的推荐算法\n\n上下文信息对用户兴趣的影响是很大的，主要代表是时间上下文和地点上下文。\n\n\n\n####  引入时间上下文\n\n- 可以通过统计发现，时间对对于物品流行度的影响。\n\n- 推荐系统的时间多样性是很重要的(每天都有不同的推荐结果)，会影响用户满意度。\n\n- 如何将时间上下文引入推荐系统？几个算法：\n\n  - TItemCF: 在计算物品相似度，预测用户和物品相似度时，引入时间衰减：\n\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1119daluj30jd04w0t6.jpg\" alt=\"image-20200723171933421\" style=\"zoom:50%;\" />\n\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1b1eo7c6j30ly04edg4.jpg\" alt=\"image-20200723171951909\" style=\"zoom:50%;\" />\n\n  - TUserCF: 也是同理：\n\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh112rl1ulj30f705uwev.jpg\" alt=\"image-20200723172101864\" style=\"zoom:50%;\" />\n\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh112z8zs2j30hk044glu.jpg\" alt=\"image-20200723172115518\" style=\"zoom:50%;\" />\n\n  - 图模型：引入了时间段图模型，添加和时间有关的节点，然后再计算相关度，如果时间节点权重为0，就是普通的图。\n\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh114g1d01j30jn0hjwi3.jpg\" alt=\"image-20200723172237557\" style=\"zoom:50%;\" />\n\n  - 我自己检索了下如何在CTR预估模型里引入时间上下文。阿里有个Paper， DSTN，核心思想是在特征里引入上下文广告特征，这类似得引入了时空特征。\n\n    \n\n#### 引入地点上下文\n\n介绍LARS算法，简单介绍一下：\n\n- 对于有用户位置的数据，基于兴趣的本地性，按照不同区域划分数据集，做不同层的推荐，然后按照权重，将推荐列表线性相加：\n\n  <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh117zdp49j30nk0fgta3.jpg\" alt=\"image-20200723172604197\" style=\"zoom:50%;\" />\n\n- 对于有物品位置的数据，在最后的兴趣得分中添加惩罚项，当前物品与用户历史物品的平均位置的距离差。\n\n  <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1b1dzur4j30n20210sz.jpg\" alt=\"image-20200723172749452\" style=\"zoom:50%;\" />\n\n\n\n\n\n### 六、利用社交网络数据的推荐算法\n\n#### 基于社交网络的推荐\n\n- 好友推荐增加推荐的新任务：基于社交网络的推荐不一定提升离线实验的指标，重在提升用户的信任度和可解释性。\n- 可以解决新用户的冷启动问题，如前文所说\n\n相关算法：\n\n- 基于领域的社会化推荐算法\n  - 其实就是类似于UserCF，只是计算用户相似度的时候，不仅考虑用户兴趣相似度(通过用户历史行为)，还通过社交网络考虑用户好友相似度：\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1b1fknqlj309602vmx6.jpg\" alt=\"image-20200723183158908\" style=\"zoom:50%;\" />\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh134ues59j30gy0460t4.jpg\" alt=\"image-20200723183214171\" style=\"zoom:50%;\" />\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh134yzzlcj30ge03mwet.jpg\" alt=\"image-20200723183223785\" style=\"zoom:50%;\" />\n\n- 基于图的社会化推荐算法\n  - 就是通过社交网络增加用户与用户的边，同样可以再用personalRank。\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1361tvxfj30eg0g4mzj.jpg\" alt=\"image-20200723183323298\" style=\"zoom:50%;\" />\n\n#### 实际系统中的社会化推荐算法\n\n因为用户数太多，如果给用户推荐的时候，去计算所有用户的话，代价太大，两种方法：\n\n- 只取相似度高的N个用户\n- 设计一种特殊的数据存储结构：每个用户维护一个消息队列，其他相关用户产生一个物品行为，则在消息队列中添加该物品。这样的话，推荐计算的时候，只需读取自身的消息队列，然后通过队列里物品的相关信息来算即可。\n\n\n\n#### 社交网络好友推荐\n\n其实就是计算用户与用户之间的相似度，还是可以通过兴趣相似度和好友相似度来做。\n\n\n\n### 七、推荐系统实例\n\n一个真实的推荐网站有三部分组成：\n\n- 推荐系统\n\n- 前端页面：需要展示推荐物品的相关信息，推荐理由，用户反馈设计\n\n- 日志系统：不同的用户行为，有不同的规模大小和实时性需求，可能需要不同的数据存储结构\n\n  <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1706abmtj312i0dkjtt.jpg\" alt=\"image-20200723204606329\" style=\"zoom:50%;\" />\n\n\n\n一个推荐系统的组成：\n\n- 由不同的推荐引擎构成，来处理不同的推荐任务，比如个性化推荐、新颖性推荐、最新物品推荐等等\n- 由推荐系统再过滤、排名、解释等汇总组合各个推荐引擎结果。\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1728ehxcj31ec0gxae3.jpg\" alt=\"image-20200723204806073\" style=\"zoom:50%;\" />\n\n一个推荐引擎的架构，主要三部分：\n\n- 用户特征提取模块\n- 特征-物品推荐模块：也俗称召回模块，就是本书介绍的算法模型。\n- 对初始的推荐列表进行过滤、排名等处理，从而生成最终的推荐结果。排名模块里涉及到了CTR预估模型，也俗称精排模块。\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1746mn2fj31560sogrz.jpg\" alt=\"image-20200723204959419\" style=\"zoom:50%;\" />\n\n重点聊下排名模块：\n\n- 这个终于让我知道了CTR预估模型在推荐系统里的作用！**之前一直以为CTR预估模型也是类似CF等算法，但其实不是，CTR预估模型是针对推荐结果的精排**，想想也是，只有推荐结果的点击才有真实的正负样本可以来训练！前面的召回模型哪来的负样本呢..用户没购买，并不意味这不喜欢物品啊。**同时CTR预估模型也是计算广告系统非常重要的模型！CTR值直接影响了预算收益等。**\n- 排名模块包含很多：\n  - 新颖性排名：通过基于物品流行度来降低热门物品的权重\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh17af7pglj30fm03xmxc.jpg\" alt=\"image-20200723205559196\" style=\"zoom:50%;\" />\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1b1f5awnj30vs03gaaj.jpg\" alt=\"image-20200723205611181\" style=\"zoom:50%;\" />\n  - 多样性排名：1. 对物品按内容分类，不同类目分别取物品 2. 对相同推荐理由的物品进行降权采样\n  - 时间多样性：对于之前推荐过的物品进行降权采样\n  - 用户反馈：排名模块最重要的部分。通过用户反馈拿到正负样本，用CTR预估模型，特征有：\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh17dapx4hj31bz0agafm.jpg\" alt=\"image-20200723205845435\" style=\"zoom:50%;\" />\n\n\n\n### 八、评分预测问题\n\n评分预测算法介绍：离线评测指标RMSE/MAE\n\n- 平均值相关\n- 基于领域的方法，就类似UserCF，只是把r=1换成得分：\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh18ruzpaqj30hm04smxk.jpg\" alt=\"image-20200723214719938\" style=\"zoom:50%;\" />\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh18s7twz3j30ji04pq3d.jpg\" alt=\"image-20200723214741412\" style=\"zoom:50%;\" />\n\n- 隐语义模型与矩阵分解模型：\n  - SVD分解，取top k，再进行SVD计算，得到评分矩阵。缺点：SVD用户和物品的维度太大高，计算量太大\n  - LFM，通过梯度下降求解SVD的隐向量，换发新春。\n- 加入时间信息\n  - 基于邻域的模型融合时间信息：同之前TItemCF，TUserCF\n  - 基于矩阵分解的模型融合时间信息: 加入时间项\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1atyz1gyj30vf02ewet.jpg\" alt=\"image-20200723225835221\" style=\"zoom:50%;\" />\n- 模型融合：\n  - 模型级联融合：同adaboost\n  - 模型加权融合：同stacking\n\n\n\n### 结语：推荐系统十堂课\n\n1. 确定你真的需要推荐系统\n2.  确定商业目标和用户满意度之间的关系\n3. 选择合适的开发人员\n4. 忘记冷启动的问题\n5. 平衡数据和算法之间的关系\n6. 找到相关的物品很容易\n7.  不要浪费时间计算相似兴趣的用户，可以直接利用社会网络数据\n8. 需要不断地提升算法的扩展性\n9. 选择合适的用户反馈方式\n10. 设计合理的评测系统，时刻关注推荐系统各方面的性能\n\n","source":"_posts/搜推广/推荐系统实战.md","raw":"---\ntitle: 《推荐系统实战》笔记\ndate: 2020-07-22 19:28:44 \ncategories: 搜推广\ntags: 《推荐系统实战》\n---\n\n\n\n最近看了项亮老师的《推荐系统实践》，做了相关的心得和笔记。\n\n\n\n### 一、推荐系统指标\n\n- 用户满意度：调查问卷等方式，也可以通过线上其他指标来衡量\n- 预测准确度：\n  - 评分预测：RMSE,MAE\n  - TopN推荐：准确率和召回率\n- 覆盖率：物品流行度之间的差异，指标如熵、基尼系数\n- 多样性：物品之间的相似性低，多样性高\n- 新颖性：一般来讲，物品平均流行度低，新颖性高\n  - 如何在不牺牲精度的情况下提高多样性和新颖性？\n- 惊喜度：与用户历史兴趣不同，但会让用户喜欢\n- 信任度\n- 实时性\n- 健壮性\n- 商业目标\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh03jbvuuzj31eo0ga76x.jpg\" alt=\"image-20200722220000325\" style=\"zoom:50%;\" />\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh03j7ho93j31dr0du78g.jpg\" alt=\"image-20200722220010615\" style=\"zoom:45%;\" />\n\n\n\n\n\n### 二、基于用户行为分析的推荐算法\n\n仅仅基于用户行为数据设计的推荐算法一般称为协同过滤算法，学术界对协同过滤算法 进行了深入研究，提出了很多方法，比如基于邻域的方法(neighborhood-based)、隐语义模型(latent factor model)、基于图的随机游走算法(random walk on graph)等。最终目的都是生成用户和物品之间的兴趣度。\n\n#### 基于领域的算法\n\n统计方法：\n\n- UserCF\n- ItemCF\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0o54pwxuj31dt0oz13l.jpg\" alt=\"image-20200723095329692\" style=\"zoom:50%;\" />\n\n\n\n#### 隐语义模型(Latent Factor Model)\n\n其实本质上就是训练得到用户的隐向量和物品的隐向量(Embedding的感觉)，然后再类似CTR预估。\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0o87nop6j30x40420tb.jpg\" alt=\"image-20200723095628676\" style=\"zoom:50%;\" />\n\n\n\n- 机器学习过程\n- 离线空间复杂度较低，时间复杂度较高\n- 实时性差，预测时候需要全量CTR预估再排序\n- 解释性差\n\n\n\n#### 基于图模型\n\n- 生成用户与物品的图，计算顶点之间的相似度\n- PersonalRank，随机游走，类似马尔科夫过程，对于每个用户节点，生成所有节点访问概率，根据物品节点的概率生成推荐列表\n\n\n\n### 三、冷启动问题\n\n主要分为三种问题：\n\n- 新用户冷启动\n- 新物品冷启动\n- 系统冷启动\n\n\n\n#### 针对新用户的冷启动\n\n- 非个性化的热门推荐\n\n- 利用用户的注册信息，例如年龄、性别等，做粗粒度的推荐。\n\n  - 相当于只利用用户的注册信息等特征做CTR预估。\n\n- 要求用户注册填写感兴趣的领域。\n\n  - 关键是如何选取有代表性、有区分度的领域。\n  - 算法：做一颗决策树，选取分裂节点时，选取方差最大的物品\n\n- 利用用户的社交网络，比如社交网络的好友推荐等，或者是外部网站的用户信息\n\n  \n\n#### 针对新物品的冷启动\n\n- 利用物品的自身内容，找计算物品相似度。\n  - 可能会用到文本模型，例如LSI ->PLSI -> LDA(目前主要是这个)等，来生成物品向量，并计算相似度\n- 专家标注\n\n\n\n### 四、利用用户标签数据的推荐算法\n\n标签相当于用户和物品之间的媒介(有点类似topic的感觉)，基于标签的推荐更加有解释性。\n\n- 基于标签的物品推荐算法：\n\n  - 简单来讲，就是将标签作为一个隐向量来计算用户和物品的兴趣：\n\n    <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0z5r4279j30dq039t8t.jpg\" alt=\"image-20200723161433032\" style=\"zoom:50%;\" />\n\n带上热门标签和热门物品的惩罚项：\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0z69qftej30o7053wez.jpg\" alt=\"image-20200723161512422\" style=\"zoom:50%;\" />\n\n- 标签拓展\n\n  - 有些物品标签很少，这时候可以拓展标签，寻找相似标签。类似于itemCF的标签相似度计算方法\n\n- 标签清理\n\n  - 如果我们要把标签呈现给用户，将其 作为给用户推荐某一个物品的解释，对标签的质量要求就很高。首先，这些标签不能包含没有意 义的停止词或者表示情绪的词。\n\n- 基于图的标签推荐算法\n\n  - 利用标签作为中间层，类似于一个栅栏图。然后利用personalRank等计算节点相关性。\n\n    <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0z8o963xj30py0jmag7.jpg\" alt=\"image-20200723161730568\" style=\"zoom:50%;\" />\n\n- 推荐打标签算法\n  \n  - 用户写标签的时候给他做推荐，很多算法：用户最常打标签，该物品最热门标签等\n\n\n\n### 五、利用上下文信息的推荐算法\n\n上下文信息对用户兴趣的影响是很大的，主要代表是时间上下文和地点上下文。\n\n\n\n####  引入时间上下文\n\n- 可以通过统计发现，时间对对于物品流行度的影响。\n\n- 推荐系统的时间多样性是很重要的(每天都有不同的推荐结果)，会影响用户满意度。\n\n- 如何将时间上下文引入推荐系统？几个算法：\n\n  - TItemCF: 在计算物品相似度，预测用户和物品相似度时，引入时间衰减：\n\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1119daluj30jd04w0t6.jpg\" alt=\"image-20200723171933421\" style=\"zoom:50%;\" />\n\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1b1eo7c6j30ly04edg4.jpg\" alt=\"image-20200723171951909\" style=\"zoom:50%;\" />\n\n  - TUserCF: 也是同理：\n\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh112rl1ulj30f705uwev.jpg\" alt=\"image-20200723172101864\" style=\"zoom:50%;\" />\n\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh112z8zs2j30hk044glu.jpg\" alt=\"image-20200723172115518\" style=\"zoom:50%;\" />\n\n  - 图模型：引入了时间段图模型，添加和时间有关的节点，然后再计算相关度，如果时间节点权重为0，就是普通的图。\n\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh114g1d01j30jn0hjwi3.jpg\" alt=\"image-20200723172237557\" style=\"zoom:50%;\" />\n\n  - 我自己检索了下如何在CTR预估模型里引入时间上下文。阿里有个Paper， DSTN，核心思想是在特征里引入上下文广告特征，这类似得引入了时空特征。\n\n    \n\n#### 引入地点上下文\n\n介绍LARS算法，简单介绍一下：\n\n- 对于有用户位置的数据，基于兴趣的本地性，按照不同区域划分数据集，做不同层的推荐，然后按照权重，将推荐列表线性相加：\n\n  <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh117zdp49j30nk0fgta3.jpg\" alt=\"image-20200723172604197\" style=\"zoom:50%;\" />\n\n- 对于有物品位置的数据，在最后的兴趣得分中添加惩罚项，当前物品与用户历史物品的平均位置的距离差。\n\n  <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1b1dzur4j30n20210sz.jpg\" alt=\"image-20200723172749452\" style=\"zoom:50%;\" />\n\n\n\n\n\n### 六、利用社交网络数据的推荐算法\n\n#### 基于社交网络的推荐\n\n- 好友推荐增加推荐的新任务：基于社交网络的推荐不一定提升离线实验的指标，重在提升用户的信任度和可解释性。\n- 可以解决新用户的冷启动问题，如前文所说\n\n相关算法：\n\n- 基于领域的社会化推荐算法\n  - 其实就是类似于UserCF，只是计算用户相似度的时候，不仅考虑用户兴趣相似度(通过用户历史行为)，还通过社交网络考虑用户好友相似度：\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1b1fknqlj309602vmx6.jpg\" alt=\"image-20200723183158908\" style=\"zoom:50%;\" />\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh134ues59j30gy0460t4.jpg\" alt=\"image-20200723183214171\" style=\"zoom:50%;\" />\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh134yzzlcj30ge03mwet.jpg\" alt=\"image-20200723183223785\" style=\"zoom:50%;\" />\n\n- 基于图的社会化推荐算法\n  - 就是通过社交网络增加用户与用户的边，同样可以再用personalRank。\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1361tvxfj30eg0g4mzj.jpg\" alt=\"image-20200723183323298\" style=\"zoom:50%;\" />\n\n#### 实际系统中的社会化推荐算法\n\n因为用户数太多，如果给用户推荐的时候，去计算所有用户的话，代价太大，两种方法：\n\n- 只取相似度高的N个用户\n- 设计一种特殊的数据存储结构：每个用户维护一个消息队列，其他相关用户产生一个物品行为，则在消息队列中添加该物品。这样的话，推荐计算的时候，只需读取自身的消息队列，然后通过队列里物品的相关信息来算即可。\n\n\n\n#### 社交网络好友推荐\n\n其实就是计算用户与用户之间的相似度，还是可以通过兴趣相似度和好友相似度来做。\n\n\n\n### 七、推荐系统实例\n\n一个真实的推荐网站有三部分组成：\n\n- 推荐系统\n\n- 前端页面：需要展示推荐物品的相关信息，推荐理由，用户反馈设计\n\n- 日志系统：不同的用户行为，有不同的规模大小和实时性需求，可能需要不同的数据存储结构\n\n  <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1706abmtj312i0dkjtt.jpg\" alt=\"image-20200723204606329\" style=\"zoom:50%;\" />\n\n\n\n一个推荐系统的组成：\n\n- 由不同的推荐引擎构成，来处理不同的推荐任务，比如个性化推荐、新颖性推荐、最新物品推荐等等\n- 由推荐系统再过滤、排名、解释等汇总组合各个推荐引擎结果。\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1728ehxcj31ec0gxae3.jpg\" alt=\"image-20200723204806073\" style=\"zoom:50%;\" />\n\n一个推荐引擎的架构，主要三部分：\n\n- 用户特征提取模块\n- 特征-物品推荐模块：也俗称召回模块，就是本书介绍的算法模型。\n- 对初始的推荐列表进行过滤、排名等处理，从而生成最终的推荐结果。排名模块里涉及到了CTR预估模型，也俗称精排模块。\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1746mn2fj31560sogrz.jpg\" alt=\"image-20200723204959419\" style=\"zoom:50%;\" />\n\n重点聊下排名模块：\n\n- 这个终于让我知道了CTR预估模型在推荐系统里的作用！**之前一直以为CTR预估模型也是类似CF等算法，但其实不是，CTR预估模型是针对推荐结果的精排**，想想也是，只有推荐结果的点击才有真实的正负样本可以来训练！前面的召回模型哪来的负样本呢..用户没购买，并不意味这不喜欢物品啊。**同时CTR预估模型也是计算广告系统非常重要的模型！CTR值直接影响了预算收益等。**\n- 排名模块包含很多：\n  - 新颖性排名：通过基于物品流行度来降低热门物品的权重\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh17af7pglj30fm03xmxc.jpg\" alt=\"image-20200723205559196\" style=\"zoom:50%;\" />\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1b1f5awnj30vs03gaaj.jpg\" alt=\"image-20200723205611181\" style=\"zoom:50%;\" />\n  - 多样性排名：1. 对物品按内容分类，不同类目分别取物品 2. 对相同推荐理由的物品进行降权采样\n  - 时间多样性：对于之前推荐过的物品进行降权采样\n  - 用户反馈：排名模块最重要的部分。通过用户反馈拿到正负样本，用CTR预估模型，特征有：\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh17dapx4hj31bz0agafm.jpg\" alt=\"image-20200723205845435\" style=\"zoom:50%;\" />\n\n\n\n### 八、评分预测问题\n\n评分预测算法介绍：离线评测指标RMSE/MAE\n\n- 平均值相关\n- 基于领域的方法，就类似UserCF，只是把r=1换成得分：\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh18ruzpaqj30hm04smxk.jpg\" alt=\"image-20200723214719938\" style=\"zoom:50%;\" />\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh18s7twz3j30ji04pq3d.jpg\" alt=\"image-20200723214741412\" style=\"zoom:50%;\" />\n\n- 隐语义模型与矩阵分解模型：\n  - SVD分解，取top k，再进行SVD计算，得到评分矩阵。缺点：SVD用户和物品的维度太大高，计算量太大\n  - LFM，通过梯度下降求解SVD的隐向量，换发新春。\n- 加入时间信息\n  - 基于邻域的模型融合时间信息：同之前TItemCF，TUserCF\n  - 基于矩阵分解的模型融合时间信息: 加入时间项\n  - <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1atyz1gyj30vf02ewet.jpg\" alt=\"image-20200723225835221\" style=\"zoom:50%;\" />\n- 模型融合：\n  - 模型级联融合：同adaboost\n  - 模型加权融合：同stacking\n\n\n\n### 结语：推荐系统十堂课\n\n1. 确定你真的需要推荐系统\n2.  确定商业目标和用户满意度之间的关系\n3. 选择合适的开发人员\n4. 忘记冷启动的问题\n5. 平衡数据和算法之间的关系\n6. 找到相关的物品很容易\n7.  不要浪费时间计算相似兴趣的用户，可以直接利用社会网络数据\n8. 需要不断地提升算法的扩展性\n9. 选择合适的用户反馈方式\n10. 设计合理的评测系统，时刻关注推荐系统各方面的性能\n\n","slug":"搜推广/推荐系统实战","published":1,"updated":"2022-09-15T03:46:43.360Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551o9000ujqrr1x3e1y6p","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>最近看了项亮老师的《推荐系统实践》，做了相关的心得和笔记。</p>\n<h3 id=\"一、推荐系统指标\"><a href=\"#一、推荐系统指标\" class=\"headerlink\" title=\"一、推荐系统指标\"></a>一、推荐系统指标</h3><ul>\n<li>用户满意度：调查问卷等方式，也可以通过线上其他指标来衡量</li>\n<li>预测准确度：<ul>\n<li>评分预测：RMSE,MAE</li>\n<li>TopN推荐：准确率和召回率</li>\n</ul>\n</li>\n<li>覆盖率：物品流行度之间的差异，指标如熵、基尼系数</li>\n<li>多样性：物品之间的相似性低，多样性高</li>\n<li>新颖性：一般来讲，物品平均流行度低，新颖性高<ul>\n<li>如何在不牺牲精度的情况下提高多样性和新颖性？</li>\n</ul>\n</li>\n<li>惊喜度：与用户历史兴趣不同，但会让用户喜欢</li>\n<li>信任度</li>\n<li>实时性</li>\n<li>健壮性</li>\n<li>商业目标</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh03jbvuuzj31eo0ga76x.jpg\" alt=\"image-20200722220000325\" style=\"zoom:50%;\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh03j7ho93j31dr0du78g.jpg\" alt=\"image-20200722220010615\" style=\"zoom:45%;\"></p>\n<h3 id=\"二、基于用户行为分析的推荐算法\"><a href=\"#二、基于用户行为分析的推荐算法\" class=\"headerlink\" title=\"二、基于用户行为分析的推荐算法\"></a>二、基于用户行为分析的推荐算法</h3><p>仅仅基于用户行为数据设计的推荐算法一般称为协同过滤算法，学术界对协同过滤算法 进行了深入研究，提出了很多方法，比如基于邻域的方法(neighborhood-based)、隐语义模型(latent factor model)、基于图的随机游走算法(random walk on graph)等。最终目的都是生成用户和物品之间的兴趣度。</p>\n<h4 id=\"基于领域的算法\"><a href=\"#基于领域的算法\" class=\"headerlink\" title=\"基于领域的算法\"></a>基于领域的算法</h4><p>统计方法：</p>\n<ul>\n<li>UserCF</li>\n<li>ItemCF</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0o54pwxuj31dt0oz13l.jpg\" alt=\"image-20200723095329692\" style=\"zoom:50%;\"></p>\n<h4 id=\"隐语义模型-Latent-Factor-Model\"><a href=\"#隐语义模型-Latent-Factor-Model\" class=\"headerlink\" title=\"隐语义模型(Latent Factor Model)\"></a>隐语义模型(Latent Factor Model)</h4><p>其实本质上就是训练得到用户的隐向量和物品的隐向量(Embedding的感觉)，然后再类似CTR预估。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0o87nop6j30x40420tb.jpg\" alt=\"image-20200723095628676\" style=\"zoom:50%;\"></p>\n<ul>\n<li>机器学习过程</li>\n<li>离线空间复杂度较低，时间复杂度较高</li>\n<li>实时性差，预测时候需要全量CTR预估再排序</li>\n<li>解释性差</li>\n</ul>\n<h4 id=\"基于图模型\"><a href=\"#基于图模型\" class=\"headerlink\" title=\"基于图模型\"></a>基于图模型</h4><ul>\n<li>生成用户与物品的图，计算顶点之间的相似度</li>\n<li>PersonalRank，随机游走，类似马尔科夫过程，对于每个用户节点，生成所有节点访问概率，根据物品节点的概率生成推荐列表</li>\n</ul>\n<h3 id=\"三、冷启动问题\"><a href=\"#三、冷启动问题\" class=\"headerlink\" title=\"三、冷启动问题\"></a>三、冷启动问题</h3><p>主要分为三种问题：</p>\n<ul>\n<li>新用户冷启动</li>\n<li>新物品冷启动</li>\n<li>系统冷启动</li>\n</ul>\n<h4 id=\"针对新用户的冷启动\"><a href=\"#针对新用户的冷启动\" class=\"headerlink\" title=\"针对新用户的冷启动\"></a>针对新用户的冷启动</h4><ul>\n<li><p>非个性化的热门推荐</p>\n</li>\n<li><p>利用用户的注册信息，例如年龄、性别等，做粗粒度的推荐。</p>\n<ul>\n<li>相当于只利用用户的注册信息等特征做CTR预估。</li>\n</ul>\n</li>\n<li><p>要求用户注册填写感兴趣的领域。</p>\n<ul>\n<li>关键是如何选取有代表性、有区分度的领域。</li>\n<li>算法：做一颗决策树，选取分裂节点时，选取方差最大的物品</li>\n</ul>\n</li>\n<li><p>利用用户的社交网络，比如社交网络的好友推荐等，或者是外部网站的用户信息</p>\n</li>\n</ul>\n<h4 id=\"针对新物品的冷启动\"><a href=\"#针对新物品的冷启动\" class=\"headerlink\" title=\"针对新物品的冷启动\"></a>针对新物品的冷启动</h4><ul>\n<li>利用物品的自身内容，找计算物品相似度。<ul>\n<li>可能会用到文本模型，例如LSI -&gt;PLSI -&gt; LDA(目前主要是这个)等，来生成物品向量，并计算相似度</li>\n</ul>\n</li>\n<li>专家标注</li>\n</ul>\n<h3 id=\"四、利用用户标签数据的推荐算法\"><a href=\"#四、利用用户标签数据的推荐算法\" class=\"headerlink\" title=\"四、利用用户标签数据的推荐算法\"></a>四、利用用户标签数据的推荐算法</h3><p>标签相当于用户和物品之间的媒介(有点类似topic的感觉)，基于标签的推荐更加有解释性。</p>\n<ul>\n<li><p>基于标签的物品推荐算法：</p>\n<ul>\n<li><p>简单来讲，就是将标签作为一个隐向量来计算用户和物品的兴趣：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0z5r4279j30dq039t8t.jpg\" alt=\"image-20200723161433032\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n</li>\n</ul>\n<p>带上热门标签和热门物品的惩罚项：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0z69qftej30o7053wez.jpg\" alt=\"image-20200723161512422\" style=\"zoom:50%;\"></p>\n<ul>\n<li><p>标签拓展</p>\n<ul>\n<li>有些物品标签很少，这时候可以拓展标签，寻找相似标签。类似于itemCF的标签相似度计算方法</li>\n</ul>\n</li>\n<li><p>标签清理</p>\n<ul>\n<li>如果我们要把标签呈现给用户，将其 作为给用户推荐某一个物品的解释，对标签的质量要求就很高。首先，这些标签不能包含没有意 义的停止词或者表示情绪的词。</li>\n</ul>\n</li>\n<li><p>基于图的标签推荐算法</p>\n<ul>\n<li><p>利用标签作为中间层，类似于一个栅栏图。然后利用personalRank等计算节点相关性。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0z8o963xj30py0jmag7.jpg\" alt=\"image-20200723161730568\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n</li>\n<li><p>推荐打标签算法</p>\n<ul>\n<li>用户写标签的时候给他做推荐，很多算法：用户最常打标签，该物品最热门标签等</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"五、利用上下文信息的推荐算法\"><a href=\"#五、利用上下文信息的推荐算法\" class=\"headerlink\" title=\"五、利用上下文信息的推荐算法\"></a>五、利用上下文信息的推荐算法</h3><p>上下文信息对用户兴趣的影响是很大的，主要代表是时间上下文和地点上下文。</p>\n<h4 id=\"引入时间上下文\"><a href=\"#引入时间上下文\" class=\"headerlink\" title=\"引入时间上下文\"></a>引入时间上下文</h4><ul>\n<li><p>可以通过统计发现，时间对对于物品流行度的影响。</p>\n</li>\n<li><p>推荐系统的时间多样性是很重要的(每天都有不同的推荐结果)，会影响用户满意度。</p>\n</li>\n<li><p>如何将时间上下文引入推荐系统？几个算法：</p>\n<ul>\n<li><p>TItemCF: 在计算物品相似度，预测用户和物品相似度时，引入时间衰减：</p>\n</li>\n<li><p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1119daluj30jd04w0t6.jpg\" alt=\"image-20200723171933421\" style=\"zoom:50%;\"></p>\n</li>\n<li><p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1b1eo7c6j30ly04edg4.jpg\" alt=\"image-20200723171951909\" style=\"zoom:50%;\"></p>\n</li>\n<li><p>TUserCF: 也是同理：</p>\n</li>\n<li><p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh112rl1ulj30f705uwev.jpg\" alt=\"image-20200723172101864\" style=\"zoom:50%;\"></p>\n</li>\n<li><p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh112z8zs2j30hk044glu.jpg\" alt=\"image-20200723172115518\" style=\"zoom:50%;\"></p>\n</li>\n<li><p>图模型：引入了时间段图模型，添加和时间有关的节点，然后再计算相关度，如果时间节点权重为0，就是普通的图。</p>\n</li>\n<li><p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh114g1d01j30jn0hjwi3.jpg\" alt=\"image-20200723172237557\" style=\"zoom:50%;\"></p>\n</li>\n<li><p>我自己检索了下如何在CTR预估模型里引入时间上下文。阿里有个Paper， DSTN，核心思想是在特征里引入上下文广告特征，这类似得引入了时空特征。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"引入地点上下文\"><a href=\"#引入地点上下文\" class=\"headerlink\" title=\"引入地点上下文\"></a>引入地点上下文</h4><p>介绍LARS算法，简单介绍一下：</p>\n<ul>\n<li><p>对于有用户位置的数据，基于兴趣的本地性，按照不同区域划分数据集，做不同层的推荐，然后按照权重，将推荐列表线性相加：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh117zdp49j30nk0fgta3.jpg\" alt=\"image-20200723172604197\" style=\"zoom:50%;\"></p>\n</li>\n<li><p>对于有物品位置的数据，在最后的兴趣得分中添加惩罚项，当前物品与用户历史物品的平均位置的距离差。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1b1dzur4j30n20210sz.jpg\" alt=\"image-20200723172749452\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<h3 id=\"六、利用社交网络数据的推荐算法\"><a href=\"#六、利用社交网络数据的推荐算法\" class=\"headerlink\" title=\"六、利用社交网络数据的推荐算法\"></a>六、利用社交网络数据的推荐算法</h3><h4 id=\"基于社交网络的推荐\"><a href=\"#基于社交网络的推荐\" class=\"headerlink\" title=\"基于社交网络的推荐\"></a>基于社交网络的推荐</h4><ul>\n<li>好友推荐增加推荐的新任务：基于社交网络的推荐不一定提升离线实验的指标，重在提升用户的信任度和可解释性。</li>\n<li>可以解决新用户的冷启动问题，如前文所说</li>\n</ul>\n<p>相关算法：</p>\n<ul>\n<li><p>基于领域的社会化推荐算法</p>\n<ul>\n<li>其实就是类似于UserCF，只是计算用户相似度的时候，不仅考虑用户兴趣相似度(通过用户历史行为)，还通过社交网络考虑用户好友相似度：</li>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1b1fknqlj309602vmx6.jpg\" alt=\"image-20200723183158908\" style=\"zoom:50%;\"></li>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh134ues59j30gy0460t4.jpg\" alt=\"image-20200723183214171\" style=\"zoom:50%;\"></li>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh134yzzlcj30ge03mwet.jpg\" alt=\"image-20200723183223785\" style=\"zoom:50%;\"></li>\n</ul>\n</li>\n<li><p>基于图的社会化推荐算法</p>\n<ul>\n<li>就是通过社交网络增加用户与用户的边，同样可以再用personalRank。</li>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1361tvxfj30eg0g4mzj.jpg\" alt=\"image-20200723183323298\" style=\"zoom:50%;\"></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"实际系统中的社会化推荐算法\"><a href=\"#实际系统中的社会化推荐算法\" class=\"headerlink\" title=\"实际系统中的社会化推荐算法\"></a>实际系统中的社会化推荐算法</h4><p>因为用户数太多，如果给用户推荐的时候，去计算所有用户的话，代价太大，两种方法：</p>\n<ul>\n<li>只取相似度高的N个用户</li>\n<li>设计一种特殊的数据存储结构：每个用户维护一个消息队列，其他相关用户产生一个物品行为，则在消息队列中添加该物品。这样的话，推荐计算的时候，只需读取自身的消息队列，然后通过队列里物品的相关信息来算即可。</li>\n</ul>\n<h4 id=\"社交网络好友推荐\"><a href=\"#社交网络好友推荐\" class=\"headerlink\" title=\"社交网络好友推荐\"></a>社交网络好友推荐</h4><p>其实就是计算用户与用户之间的相似度，还是可以通过兴趣相似度和好友相似度来做。</p>\n<h3 id=\"七、推荐系统实例\"><a href=\"#七、推荐系统实例\" class=\"headerlink\" title=\"七、推荐系统实例\"></a>七、推荐系统实例</h3><p>一个真实的推荐网站有三部分组成：</p>\n<ul>\n<li><p>推荐系统</p>\n</li>\n<li><p>前端页面：需要展示推荐物品的相关信息，推荐理由，用户反馈设计</p>\n</li>\n<li><p>日志系统：不同的用户行为，有不同的规模大小和实时性需求，可能需要不同的数据存储结构</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1706abmtj312i0dkjtt.jpg\" alt=\"image-20200723204606329\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<p>一个推荐系统的组成：</p>\n<ul>\n<li>由不同的推荐引擎构成，来处理不同的推荐任务，比如个性化推荐、新颖性推荐、最新物品推荐等等</li>\n<li>由推荐系统再过滤、排名、解释等汇总组合各个推荐引擎结果。</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1728ehxcj31ec0gxae3.jpg\" alt=\"image-20200723204806073\" style=\"zoom:50%;\"></p>\n<p>一个推荐引擎的架构，主要三部分：</p>\n<ul>\n<li>用户特征提取模块</li>\n<li>特征-物品推荐模块：也俗称召回模块，就是本书介绍的算法模型。</li>\n<li>对初始的推荐列表进行过滤、排名等处理，从而生成最终的推荐结果。排名模块里涉及到了CTR预估模型，也俗称精排模块。</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1746mn2fj31560sogrz.jpg\" alt=\"image-20200723204959419\" style=\"zoom:50%;\"></p>\n<p>重点聊下排名模块：</p>\n<ul>\n<li>这个终于让我知道了CTR预估模型在推荐系统里的作用！<strong>之前一直以为CTR预估模型也是类似CF等算法，但其实不是，CTR预估模型是针对推荐结果的精排</strong>，想想也是，只有推荐结果的点击才有真实的正负样本可以来训练！前面的召回模型哪来的负样本呢..用户没购买，并不意味这不喜欢物品啊。<strong>同时CTR预估模型也是计算广告系统非常重要的模型！CTR值直接影响了预算收益等。</strong></li>\n<li>排名模块包含很多：<ul>\n<li>新颖性排名：通过基于物品流行度来降低热门物品的权重</li>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh17af7pglj30fm03xmxc.jpg\" alt=\"image-20200723205559196\" style=\"zoom:50%;\"></li>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1b1f5awnj30vs03gaaj.jpg\" alt=\"image-20200723205611181\" style=\"zoom:50%;\"></li>\n<li>多样性排名：1. 对物品按内容分类，不同类目分别取物品 2. 对相同推荐理由的物品进行降权采样</li>\n<li>时间多样性：对于之前推荐过的物品进行降权采样</li>\n<li>用户反馈：排名模块最重要的部分。通过用户反馈拿到正负样本，用CTR预估模型，特征有：</li>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh17dapx4hj31bz0agafm.jpg\" alt=\"image-20200723205845435\" style=\"zoom:50%;\"></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"八、评分预测问题\"><a href=\"#八、评分预测问题\" class=\"headerlink\" title=\"八、评分预测问题\"></a>八、评分预测问题</h3><p>评分预测算法介绍：离线评测指标RMSE/MAE</p>\n<ul>\n<li>平均值相关</li>\n<li>基于领域的方法，就类似UserCF，只是把r=1换成得分：<ul>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh18ruzpaqj30hm04smxk.jpg\" alt=\"image-20200723214719938\" style=\"zoom:50%;\"></li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh18s7twz3j30ji04pq3d.jpg\" alt=\"image-20200723214741412\" style=\"zoom:50%;\"></p>\n<ul>\n<li>隐语义模型与矩阵分解模型：<ul>\n<li>SVD分解，取top k，再进行SVD计算，得到评分矩阵。缺点：SVD用户和物品的维度太大高，计算量太大</li>\n<li>LFM，通过梯度下降求解SVD的隐向量，换发新春。</li>\n</ul>\n</li>\n<li>加入时间信息<ul>\n<li>基于邻域的模型融合时间信息：同之前TItemCF，TUserCF</li>\n<li>基于矩阵分解的模型融合时间信息: 加入时间项</li>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1atyz1gyj30vf02ewet.jpg\" alt=\"image-20200723225835221\" style=\"zoom:50%;\"></li>\n</ul>\n</li>\n<li>模型融合：<ul>\n<li>模型级联融合：同adaboost</li>\n<li>模型加权融合：同stacking</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"结语：推荐系统十堂课\"><a href=\"#结语：推荐系统十堂课\" class=\"headerlink\" title=\"结语：推荐系统十堂课\"></a>结语：推荐系统十堂课</h3><ol>\n<li>确定你真的需要推荐系统</li>\n<li>确定商业目标和用户满意度之间的关系</li>\n<li>选择合适的开发人员</li>\n<li>忘记冷启动的问题</li>\n<li>平衡数据和算法之间的关系</li>\n<li>找到相关的物品很容易</li>\n<li>不要浪费时间计算相似兴趣的用户，可以直接利用社会网络数据</li>\n<li>需要不断地提升算法的扩展性</li>\n<li>选择合适的用户反馈方式</li>\n<li>设计合理的评测系统，时刻关注推荐系统各方面的性能</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>最近看了项亮老师的《推荐系统实践》，做了相关的心得和笔记。</p>\n<h3 id=\"一、推荐系统指标\"><a href=\"#一、推荐系统指标\" class=\"headerlink\" title=\"一、推荐系统指标\"></a>一、推荐系统指标</h3><ul>\n<li>用户满意度：调查问卷等方式，也可以通过线上其他指标来衡量</li>\n<li>预测准确度：<ul>\n<li>评分预测：RMSE,MAE</li>\n<li>TopN推荐：准确率和召回率</li>\n</ul>\n</li>\n<li>覆盖率：物品流行度之间的差异，指标如熵、基尼系数</li>\n<li>多样性：物品之间的相似性低，多样性高</li>\n<li>新颖性：一般来讲，物品平均流行度低，新颖性高<ul>\n<li>如何在不牺牲精度的情况下提高多样性和新颖性？</li>\n</ul>\n</li>\n<li>惊喜度：与用户历史兴趣不同，但会让用户喜欢</li>\n<li>信任度</li>\n<li>实时性</li>\n<li>健壮性</li>\n<li>商业目标</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh03jbvuuzj31eo0ga76x.jpg\" alt=\"image-20200722220000325\" style=\"zoom:50%;\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh03j7ho93j31dr0du78g.jpg\" alt=\"image-20200722220010615\" style=\"zoom:45%;\"></p>\n<h3 id=\"二、基于用户行为分析的推荐算法\"><a href=\"#二、基于用户行为分析的推荐算法\" class=\"headerlink\" title=\"二、基于用户行为分析的推荐算法\"></a>二、基于用户行为分析的推荐算法</h3><p>仅仅基于用户行为数据设计的推荐算法一般称为协同过滤算法，学术界对协同过滤算法 进行了深入研究，提出了很多方法，比如基于邻域的方法(neighborhood-based)、隐语义模型(latent factor model)、基于图的随机游走算法(random walk on graph)等。最终目的都是生成用户和物品之间的兴趣度。</p>\n<h4 id=\"基于领域的算法\"><a href=\"#基于领域的算法\" class=\"headerlink\" title=\"基于领域的算法\"></a>基于领域的算法</h4><p>统计方法：</p>\n<ul>\n<li>UserCF</li>\n<li>ItemCF</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0o54pwxuj31dt0oz13l.jpg\" alt=\"image-20200723095329692\" style=\"zoom:50%;\"></p>\n<h4 id=\"隐语义模型-Latent-Factor-Model\"><a href=\"#隐语义模型-Latent-Factor-Model\" class=\"headerlink\" title=\"隐语义模型(Latent Factor Model)\"></a>隐语义模型(Latent Factor Model)</h4><p>其实本质上就是训练得到用户的隐向量和物品的隐向量(Embedding的感觉)，然后再类似CTR预估。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0o87nop6j30x40420tb.jpg\" alt=\"image-20200723095628676\" style=\"zoom:50%;\"></p>\n<ul>\n<li>机器学习过程</li>\n<li>离线空间复杂度较低，时间复杂度较高</li>\n<li>实时性差，预测时候需要全量CTR预估再排序</li>\n<li>解释性差</li>\n</ul>\n<h4 id=\"基于图模型\"><a href=\"#基于图模型\" class=\"headerlink\" title=\"基于图模型\"></a>基于图模型</h4><ul>\n<li>生成用户与物品的图，计算顶点之间的相似度</li>\n<li>PersonalRank，随机游走，类似马尔科夫过程，对于每个用户节点，生成所有节点访问概率，根据物品节点的概率生成推荐列表</li>\n</ul>\n<h3 id=\"三、冷启动问题\"><a href=\"#三、冷启动问题\" class=\"headerlink\" title=\"三、冷启动问题\"></a>三、冷启动问题</h3><p>主要分为三种问题：</p>\n<ul>\n<li>新用户冷启动</li>\n<li>新物品冷启动</li>\n<li>系统冷启动</li>\n</ul>\n<h4 id=\"针对新用户的冷启动\"><a href=\"#针对新用户的冷启动\" class=\"headerlink\" title=\"针对新用户的冷启动\"></a>针对新用户的冷启动</h4><ul>\n<li><p>非个性化的热门推荐</p>\n</li>\n<li><p>利用用户的注册信息，例如年龄、性别等，做粗粒度的推荐。</p>\n<ul>\n<li>相当于只利用用户的注册信息等特征做CTR预估。</li>\n</ul>\n</li>\n<li><p>要求用户注册填写感兴趣的领域。</p>\n<ul>\n<li>关键是如何选取有代表性、有区分度的领域。</li>\n<li>算法：做一颗决策树，选取分裂节点时，选取方差最大的物品</li>\n</ul>\n</li>\n<li><p>利用用户的社交网络，比如社交网络的好友推荐等，或者是外部网站的用户信息</p>\n</li>\n</ul>\n<h4 id=\"针对新物品的冷启动\"><a href=\"#针对新物品的冷启动\" class=\"headerlink\" title=\"针对新物品的冷启动\"></a>针对新物品的冷启动</h4><ul>\n<li>利用物品的自身内容，找计算物品相似度。<ul>\n<li>可能会用到文本模型，例如LSI -&gt;PLSI -&gt; LDA(目前主要是这个)等，来生成物品向量，并计算相似度</li>\n</ul>\n</li>\n<li>专家标注</li>\n</ul>\n<h3 id=\"四、利用用户标签数据的推荐算法\"><a href=\"#四、利用用户标签数据的推荐算法\" class=\"headerlink\" title=\"四、利用用户标签数据的推荐算法\"></a>四、利用用户标签数据的推荐算法</h3><p>标签相当于用户和物品之间的媒介(有点类似topic的感觉)，基于标签的推荐更加有解释性。</p>\n<ul>\n<li><p>基于标签的物品推荐算法：</p>\n<ul>\n<li><p>简单来讲，就是将标签作为一个隐向量来计算用户和物品的兴趣：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0z5r4279j30dq039t8t.jpg\" alt=\"image-20200723161433032\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n</li>\n</ul>\n<p>带上热门标签和热门物品的惩罚项：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0z69qftej30o7053wez.jpg\" alt=\"image-20200723161512422\" style=\"zoom:50%;\"></p>\n<ul>\n<li><p>标签拓展</p>\n<ul>\n<li>有些物品标签很少，这时候可以拓展标签，寻找相似标签。类似于itemCF的标签相似度计算方法</li>\n</ul>\n</li>\n<li><p>标签清理</p>\n<ul>\n<li>如果我们要把标签呈现给用户，将其 作为给用户推荐某一个物品的解释，对标签的质量要求就很高。首先，这些标签不能包含没有意 义的停止词或者表示情绪的词。</li>\n</ul>\n</li>\n<li><p>基于图的标签推荐算法</p>\n<ul>\n<li><p>利用标签作为中间层，类似于一个栅栏图。然后利用personalRank等计算节点相关性。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh0z8o963xj30py0jmag7.jpg\" alt=\"image-20200723161730568\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n</li>\n<li><p>推荐打标签算法</p>\n<ul>\n<li>用户写标签的时候给他做推荐，很多算法：用户最常打标签，该物品最热门标签等</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"五、利用上下文信息的推荐算法\"><a href=\"#五、利用上下文信息的推荐算法\" class=\"headerlink\" title=\"五、利用上下文信息的推荐算法\"></a>五、利用上下文信息的推荐算法</h3><p>上下文信息对用户兴趣的影响是很大的，主要代表是时间上下文和地点上下文。</p>\n<h4 id=\"引入时间上下文\"><a href=\"#引入时间上下文\" class=\"headerlink\" title=\"引入时间上下文\"></a>引入时间上下文</h4><ul>\n<li><p>可以通过统计发现，时间对对于物品流行度的影响。</p>\n</li>\n<li><p>推荐系统的时间多样性是很重要的(每天都有不同的推荐结果)，会影响用户满意度。</p>\n</li>\n<li><p>如何将时间上下文引入推荐系统？几个算法：</p>\n<ul>\n<li><p>TItemCF: 在计算物品相似度，预测用户和物品相似度时，引入时间衰减：</p>\n</li>\n<li><p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1119daluj30jd04w0t6.jpg\" alt=\"image-20200723171933421\" style=\"zoom:50%;\"></p>\n</li>\n<li><p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1b1eo7c6j30ly04edg4.jpg\" alt=\"image-20200723171951909\" style=\"zoom:50%;\"></p>\n</li>\n<li><p>TUserCF: 也是同理：</p>\n</li>\n<li><p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh112rl1ulj30f705uwev.jpg\" alt=\"image-20200723172101864\" style=\"zoom:50%;\"></p>\n</li>\n<li><p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh112z8zs2j30hk044glu.jpg\" alt=\"image-20200723172115518\" style=\"zoom:50%;\"></p>\n</li>\n<li><p>图模型：引入了时间段图模型，添加和时间有关的节点，然后再计算相关度，如果时间节点权重为0，就是普通的图。</p>\n</li>\n<li><p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh114g1d01j30jn0hjwi3.jpg\" alt=\"image-20200723172237557\" style=\"zoom:50%;\"></p>\n</li>\n<li><p>我自己检索了下如何在CTR预估模型里引入时间上下文。阿里有个Paper， DSTN，核心思想是在特征里引入上下文广告特征，这类似得引入了时空特征。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"引入地点上下文\"><a href=\"#引入地点上下文\" class=\"headerlink\" title=\"引入地点上下文\"></a>引入地点上下文</h4><p>介绍LARS算法，简单介绍一下：</p>\n<ul>\n<li><p>对于有用户位置的数据，基于兴趣的本地性，按照不同区域划分数据集，做不同层的推荐，然后按照权重，将推荐列表线性相加：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh117zdp49j30nk0fgta3.jpg\" alt=\"image-20200723172604197\" style=\"zoom:50%;\"></p>\n</li>\n<li><p>对于有物品位置的数据，在最后的兴趣得分中添加惩罚项，当前物品与用户历史物品的平均位置的距离差。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1b1dzur4j30n20210sz.jpg\" alt=\"image-20200723172749452\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<h3 id=\"六、利用社交网络数据的推荐算法\"><a href=\"#六、利用社交网络数据的推荐算法\" class=\"headerlink\" title=\"六、利用社交网络数据的推荐算法\"></a>六、利用社交网络数据的推荐算法</h3><h4 id=\"基于社交网络的推荐\"><a href=\"#基于社交网络的推荐\" class=\"headerlink\" title=\"基于社交网络的推荐\"></a>基于社交网络的推荐</h4><ul>\n<li>好友推荐增加推荐的新任务：基于社交网络的推荐不一定提升离线实验的指标，重在提升用户的信任度和可解释性。</li>\n<li>可以解决新用户的冷启动问题，如前文所说</li>\n</ul>\n<p>相关算法：</p>\n<ul>\n<li><p>基于领域的社会化推荐算法</p>\n<ul>\n<li>其实就是类似于UserCF，只是计算用户相似度的时候，不仅考虑用户兴趣相似度(通过用户历史行为)，还通过社交网络考虑用户好友相似度：</li>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1b1fknqlj309602vmx6.jpg\" alt=\"image-20200723183158908\" style=\"zoom:50%;\"></li>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh134ues59j30gy0460t4.jpg\" alt=\"image-20200723183214171\" style=\"zoom:50%;\"></li>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh134yzzlcj30ge03mwet.jpg\" alt=\"image-20200723183223785\" style=\"zoom:50%;\"></li>\n</ul>\n</li>\n<li><p>基于图的社会化推荐算法</p>\n<ul>\n<li>就是通过社交网络增加用户与用户的边，同样可以再用personalRank。</li>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1361tvxfj30eg0g4mzj.jpg\" alt=\"image-20200723183323298\" style=\"zoom:50%;\"></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"实际系统中的社会化推荐算法\"><a href=\"#实际系统中的社会化推荐算法\" class=\"headerlink\" title=\"实际系统中的社会化推荐算法\"></a>实际系统中的社会化推荐算法</h4><p>因为用户数太多，如果给用户推荐的时候，去计算所有用户的话，代价太大，两种方法：</p>\n<ul>\n<li>只取相似度高的N个用户</li>\n<li>设计一种特殊的数据存储结构：每个用户维护一个消息队列，其他相关用户产生一个物品行为，则在消息队列中添加该物品。这样的话，推荐计算的时候，只需读取自身的消息队列，然后通过队列里物品的相关信息来算即可。</li>\n</ul>\n<h4 id=\"社交网络好友推荐\"><a href=\"#社交网络好友推荐\" class=\"headerlink\" title=\"社交网络好友推荐\"></a>社交网络好友推荐</h4><p>其实就是计算用户与用户之间的相似度，还是可以通过兴趣相似度和好友相似度来做。</p>\n<h3 id=\"七、推荐系统实例\"><a href=\"#七、推荐系统实例\" class=\"headerlink\" title=\"七、推荐系统实例\"></a>七、推荐系统实例</h3><p>一个真实的推荐网站有三部分组成：</p>\n<ul>\n<li><p>推荐系统</p>\n</li>\n<li><p>前端页面：需要展示推荐物品的相关信息，推荐理由，用户反馈设计</p>\n</li>\n<li><p>日志系统：不同的用户行为，有不同的规模大小和实时性需求，可能需要不同的数据存储结构</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1706abmtj312i0dkjtt.jpg\" alt=\"image-20200723204606329\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<p>一个推荐系统的组成：</p>\n<ul>\n<li>由不同的推荐引擎构成，来处理不同的推荐任务，比如个性化推荐、新颖性推荐、最新物品推荐等等</li>\n<li>由推荐系统再过滤、排名、解释等汇总组合各个推荐引擎结果。</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1728ehxcj31ec0gxae3.jpg\" alt=\"image-20200723204806073\" style=\"zoom:50%;\"></p>\n<p>一个推荐引擎的架构，主要三部分：</p>\n<ul>\n<li>用户特征提取模块</li>\n<li>特征-物品推荐模块：也俗称召回模块，就是本书介绍的算法模型。</li>\n<li>对初始的推荐列表进行过滤、排名等处理，从而生成最终的推荐结果。排名模块里涉及到了CTR预估模型，也俗称精排模块。</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1746mn2fj31560sogrz.jpg\" alt=\"image-20200723204959419\" style=\"zoom:50%;\"></p>\n<p>重点聊下排名模块：</p>\n<ul>\n<li>这个终于让我知道了CTR预估模型在推荐系统里的作用！<strong>之前一直以为CTR预估模型也是类似CF等算法，但其实不是，CTR预估模型是针对推荐结果的精排</strong>，想想也是，只有推荐结果的点击才有真实的正负样本可以来训练！前面的召回模型哪来的负样本呢..用户没购买，并不意味这不喜欢物品啊。<strong>同时CTR预估模型也是计算广告系统非常重要的模型！CTR值直接影响了预算收益等。</strong></li>\n<li>排名模块包含很多：<ul>\n<li>新颖性排名：通过基于物品流行度来降低热门物品的权重</li>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh17af7pglj30fm03xmxc.jpg\" alt=\"image-20200723205559196\" style=\"zoom:50%;\"></li>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1b1f5awnj30vs03gaaj.jpg\" alt=\"image-20200723205611181\" style=\"zoom:50%;\"></li>\n<li>多样性排名：1. 对物品按内容分类，不同类目分别取物品 2. 对相同推荐理由的物品进行降权采样</li>\n<li>时间多样性：对于之前推荐过的物品进行降权采样</li>\n<li>用户反馈：排名模块最重要的部分。通过用户反馈拿到正负样本，用CTR预估模型，特征有：</li>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh17dapx4hj31bz0agafm.jpg\" alt=\"image-20200723205845435\" style=\"zoom:50%;\"></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"八、评分预测问题\"><a href=\"#八、评分预测问题\" class=\"headerlink\" title=\"八、评分预测问题\"></a>八、评分预测问题</h3><p>评分预测算法介绍：离线评测指标RMSE/MAE</p>\n<ul>\n<li>平均值相关</li>\n<li>基于领域的方法，就类似UserCF，只是把r=1换成得分：<ul>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh18ruzpaqj30hm04smxk.jpg\" alt=\"image-20200723214719938\" style=\"zoom:50%;\"></li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh18s7twz3j30ji04pq3d.jpg\" alt=\"image-20200723214741412\" style=\"zoom:50%;\"></p>\n<ul>\n<li>隐语义模型与矩阵分解模型：<ul>\n<li>SVD分解，取top k，再进行SVD计算，得到评分矩阵。缺点：SVD用户和物品的维度太大高，计算量太大</li>\n<li>LFM，通过梯度下降求解SVD的隐向量，换发新春。</li>\n</ul>\n</li>\n<li>加入时间信息<ul>\n<li>基于邻域的模型融合时间信息：同之前TItemCF，TUserCF</li>\n<li>基于矩阵分解的模型融合时间信息: 加入时间项</li>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh1atyz1gyj30vf02ewet.jpg\" alt=\"image-20200723225835221\" style=\"zoom:50%;\"></li>\n</ul>\n</li>\n<li>模型融合：<ul>\n<li>模型级联融合：同adaboost</li>\n<li>模型加权融合：同stacking</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"结语：推荐系统十堂课\"><a href=\"#结语：推荐系统十堂课\" class=\"headerlink\" title=\"结语：推荐系统十堂课\"></a>结语：推荐系统十堂课</h3><ol>\n<li>确定你真的需要推荐系统</li>\n<li>确定商业目标和用户满意度之间的关系</li>\n<li>选择合适的开发人员</li>\n<li>忘记冷启动的问题</li>\n<li>平衡数据和算法之间的关系</li>\n<li>找到相关的物品很容易</li>\n<li>不要浪费时间计算相似兴趣的用户，可以直接利用社会网络数据</li>\n<li>需要不断地提升算法的扩展性</li>\n<li>选择合适的用户反馈方式</li>\n<li>设计合理的评测系统，时刻关注推荐系统各方面的性能</li>\n</ol>\n"},{"title":"浅谈FM和FFM","date":"2022-08-09T16:00:00.000Z","_content":"\n### 梳理一下FM和FFM\n\n#### FM：\n\n- 参数复杂度：O(n*k)\n\n- 计算复杂度：O(n^2 * k)，但可以通过目标函数转换变为O(n * k)\n\n  <img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51s7wzr2jj20vi0o2jts.jpg\" alt=\"image-20201020184158031\" style=\"zoom:40%;\" />\n\n#### FFM:\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51s81aqi6j20z405waai.jpg\" alt=\"image-20201020184225396\" style=\"zoom:33%;\" />\n\n- 参数复杂度：O(nkF)\n\n- 计算复杂度：O(n^2 * k)，无法简化。**注意：每个特征都有自己所在的域，特征1和特征2交叉时，特征1的域向量选择特征2所在域F2，特征2的域向量选择特征1所在域F1**。其实FFM就是把一个one-hot 变量中FM对应的向量，变成一个矩阵。\n\n  \n\nFM与DeepFM的对应：\n\n- DeepFM的FM层，就是one-hot 到 embedding层，这个本质上就是对每个one-hot变量都做一个隐向量。因为一个one-hot同时只有一个维度为1，其余为0，所以同一个field之间没有内积，做field之间的内积本质上就FM。\n\nFFM与DeepFFM的对应：\n\n- 无非就是embeding层从一个向量，变成了一个矩阵，m * F（域的个数）。两个域内积的时候注意是对应的。\n\n  <img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h52t2v1247j214q0m8q6y.jpg\" alt=\"image-20201224111301818\" style=\"zoom:50%;\" />\n\n\n\n#### 总结\n\n传统的FFM公式，通常用神经网络来代替，通常做法就是将n个特征划分成若干个field，每个域做一个embedding，得到每个域的embedding向量和bias向量(相当于公式的一次项部分)。\n\n- Embedding层参数量：n*k，bias参数量：n\n\n紧接着有很多处理方式：\n\n- 如果是低阶特征抽取，那么就是两个域之间做inner product，得到二次项交叉特征。例如DeepFFM的wide层\n- 如果是高阶特征抽取，那么可以concat这些embedding层(维度为f*k)，后面接mlp层。例如DeepFFM的deep层\n- bias的话一般用于wide - LR层 or FM层\n\n\n\n### Ref-深度学习在CTR预估中的应用\n\nhttps://zhuanlan.zhihu.com/p/35484389\n\n![image-20200930165622880](https://tva1.sinaimg.cn/large/e6c9d24ely1h52t33n92ej212s0n4adv.jpg)\n\n\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h52t387vlhj20zs0u042t.jpg\" alt=\"image-20200930165727535\" style=\"zoom:50%;\" />\n\n\n","source":"_posts/搜推广/浅谈FM和FFM.md","raw":"---\ntitle: 浅谈FM和FFM\ndate: 2022-08-10\ncategories: 搜推广\n---\n\n### 梳理一下FM和FFM\n\n#### FM：\n\n- 参数复杂度：O(n*k)\n\n- 计算复杂度：O(n^2 * k)，但可以通过目标函数转换变为O(n * k)\n\n  <img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51s7wzr2jj20vi0o2jts.jpg\" alt=\"image-20201020184158031\" style=\"zoom:40%;\" />\n\n#### FFM:\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51s81aqi6j20z405waai.jpg\" alt=\"image-20201020184225396\" style=\"zoom:33%;\" />\n\n- 参数复杂度：O(nkF)\n\n- 计算复杂度：O(n^2 * k)，无法简化。**注意：每个特征都有自己所在的域，特征1和特征2交叉时，特征1的域向量选择特征2所在域F2，特征2的域向量选择特征1所在域F1**。其实FFM就是把一个one-hot 变量中FM对应的向量，变成一个矩阵。\n\n  \n\nFM与DeepFM的对应：\n\n- DeepFM的FM层，就是one-hot 到 embedding层，这个本质上就是对每个one-hot变量都做一个隐向量。因为一个one-hot同时只有一个维度为1，其余为0，所以同一个field之间没有内积，做field之间的内积本质上就FM。\n\nFFM与DeepFFM的对应：\n\n- 无非就是embeding层从一个向量，变成了一个矩阵，m * F（域的个数）。两个域内积的时候注意是对应的。\n\n  <img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h52t2v1247j214q0m8q6y.jpg\" alt=\"image-20201224111301818\" style=\"zoom:50%;\" />\n\n\n\n#### 总结\n\n传统的FFM公式，通常用神经网络来代替，通常做法就是将n个特征划分成若干个field，每个域做一个embedding，得到每个域的embedding向量和bias向量(相当于公式的一次项部分)。\n\n- Embedding层参数量：n*k，bias参数量：n\n\n紧接着有很多处理方式：\n\n- 如果是低阶特征抽取，那么就是两个域之间做inner product，得到二次项交叉特征。例如DeepFFM的wide层\n- 如果是高阶特征抽取，那么可以concat这些embedding层(维度为f*k)，后面接mlp层。例如DeepFFM的deep层\n- bias的话一般用于wide - LR层 or FM层\n\n\n\n### Ref-深度学习在CTR预估中的应用\n\nhttps://zhuanlan.zhihu.com/p/35484389\n\n![image-20200930165622880](https://tva1.sinaimg.cn/large/e6c9d24ely1h52t33n92ej212s0n4adv.jpg)\n\n\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h52t387vlhj20zs0u042t.jpg\" alt=\"image-20200930165727535\" style=\"zoom:50%;\" />\n\n\n","slug":"搜推广/浅谈FM和FFM","published":1,"updated":"2022-09-15T03:46:43.360Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551o9000yjqrriysoff9j","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"梳理一下FM和FFM\"><a href=\"#梳理一下FM和FFM\" class=\"headerlink\" title=\"梳理一下FM和FFM\"></a>梳理一下FM和FFM</h3><h4 id=\"FM：\"><a href=\"#FM：\" class=\"headerlink\" title=\"FM：\"></a>FM：</h4><ul>\n<li><p>参数复杂度：O(n*k)</p>\n</li>\n<li><p>计算复杂度：O(n^2 <em> k)，但可以通过目标函数转换变为O(n </em> k)</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51s7wzr2jj20vi0o2jts.jpg\" alt=\"image-20201020184158031\" style=\"zoom:40%;\"></p>\n</li>\n</ul>\n<h4 id=\"FFM\"><a href=\"#FFM\" class=\"headerlink\" title=\"FFM:\"></a>FFM:</h4><p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51s81aqi6j20z405waai.jpg\" alt=\"image-20201020184225396\" style=\"zoom:33%;\"></p>\n<ul>\n<li><p>参数复杂度：O(nkF)</p>\n</li>\n<li><p>计算复杂度：O(n^2 <em> k)，无法简化。<em>*注意：每个特征都有自己所在的域，特征1和特征2交叉时，特征1的域向量选择特征2所在域F2，特征2的域向量选择特征1所在域F1</em></em>。其实FFM就是把一个one-hot 变量中FM对应的向量，变成一个矩阵。</p>\n</li>\n</ul>\n<p>FM与DeepFM的对应：</p>\n<ul>\n<li>DeepFM的FM层，就是one-hot 到 embedding层，这个本质上就是对每个one-hot变量都做一个隐向量。因为一个one-hot同时只有一个维度为1，其余为0，所以同一个field之间没有内积，做field之间的内积本质上就FM。</li>\n</ul>\n<p>FFM与DeepFFM的对应：</p>\n<ul>\n<li><p>无非就是embeding层从一个向量，变成了一个矩阵，m * F（域的个数）。两个域内积的时候注意是对应的。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h52t2v1247j214q0m8q6y.jpg\" alt=\"image-20201224111301818\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<h4 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h4><p>传统的FFM公式，通常用神经网络来代替，通常做法就是将n个特征划分成若干个field，每个域做一个embedding，得到每个域的embedding向量和bias向量(相当于公式的一次项部分)。</p>\n<ul>\n<li>Embedding层参数量：n*k，bias参数量：n</li>\n</ul>\n<p>紧接着有很多处理方式：</p>\n<ul>\n<li>如果是低阶特征抽取，那么就是两个域之间做inner product，得到二次项交叉特征。例如DeepFFM的wide层</li>\n<li>如果是高阶特征抽取，那么可以concat这些embedding层(维度为f*k)，后面接mlp层。例如DeepFFM的deep层</li>\n<li>bias的话一般用于wide - LR层 or FM层</li>\n</ul>\n<h3 id=\"Ref-深度学习在CTR预估中的应用\"><a href=\"#Ref-深度学习在CTR预估中的应用\" class=\"headerlink\" title=\"Ref-深度学习在CTR预估中的应用\"></a>Ref-深度学习在CTR预估中的应用</h3><p><a href=\"https://zhuanlan.zhihu.com/p/35484389\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/35484389</a></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h52t33n92ej212s0n4adv.jpg\" alt=\"image-20200930165622880\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h52t387vlhj20zs0u042t.jpg\" alt=\"image-20200930165727535\" style=\"zoom:50%;\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"梳理一下FM和FFM\"><a href=\"#梳理一下FM和FFM\" class=\"headerlink\" title=\"梳理一下FM和FFM\"></a>梳理一下FM和FFM</h3><h4 id=\"FM：\"><a href=\"#FM：\" class=\"headerlink\" title=\"FM：\"></a>FM：</h4><ul>\n<li><p>参数复杂度：O(n*k)</p>\n</li>\n<li><p>计算复杂度：O(n^2 <em> k)，但可以通过目标函数转换变为O(n </em> k)</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51s7wzr2jj20vi0o2jts.jpg\" alt=\"image-20201020184158031\" style=\"zoom:40%;\"></p>\n</li>\n</ul>\n<h4 id=\"FFM\"><a href=\"#FFM\" class=\"headerlink\" title=\"FFM:\"></a>FFM:</h4><p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51s81aqi6j20z405waai.jpg\" alt=\"image-20201020184225396\" style=\"zoom:33%;\"></p>\n<ul>\n<li><p>参数复杂度：O(nkF)</p>\n</li>\n<li><p>计算复杂度：O(n^2 <em> k)，无法简化。<em>*注意：每个特征都有自己所在的域，特征1和特征2交叉时，特征1的域向量选择特征2所在域F2，特征2的域向量选择特征1所在域F1</em></em>。其实FFM就是把一个one-hot 变量中FM对应的向量，变成一个矩阵。</p>\n</li>\n</ul>\n<p>FM与DeepFM的对应：</p>\n<ul>\n<li>DeepFM的FM层，就是one-hot 到 embedding层，这个本质上就是对每个one-hot变量都做一个隐向量。因为一个one-hot同时只有一个维度为1，其余为0，所以同一个field之间没有内积，做field之间的内积本质上就FM。</li>\n</ul>\n<p>FFM与DeepFFM的对应：</p>\n<ul>\n<li><p>无非就是embeding层从一个向量，变成了一个矩阵，m * F（域的个数）。两个域内积的时候注意是对应的。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h52t2v1247j214q0m8q6y.jpg\" alt=\"image-20201224111301818\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<h4 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h4><p>传统的FFM公式，通常用神经网络来代替，通常做法就是将n个特征划分成若干个field，每个域做一个embedding，得到每个域的embedding向量和bias向量(相当于公式的一次项部分)。</p>\n<ul>\n<li>Embedding层参数量：n*k，bias参数量：n</li>\n</ul>\n<p>紧接着有很多处理方式：</p>\n<ul>\n<li>如果是低阶特征抽取，那么就是两个域之间做inner product，得到二次项交叉特征。例如DeepFFM的wide层</li>\n<li>如果是高阶特征抽取，那么可以concat这些embedding层(维度为f*k)，后面接mlp层。例如DeepFFM的deep层</li>\n<li>bias的话一般用于wide - LR层 or FM层</li>\n</ul>\n<h3 id=\"Ref-深度学习在CTR预估中的应用\"><a href=\"#Ref-深度学习在CTR预估中的应用\" class=\"headerlink\" title=\"Ref-深度学习在CTR预估中的应用\"></a>Ref-深度学习在CTR预估中的应用</h3><p><a href=\"https://zhuanlan.zhihu.com/p/35484389\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/35484389</a></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h52t33n92ej212s0n4adv.jpg\" alt=\"image-20200930165622880\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h52t387vlhj20zs0u042t.jpg\" alt=\"image-20200930165727535\" style=\"zoom:50%;\"></p>\n"},{"title":"计算广告基础概念","date":"2022-08-09T16:00:00.000Z","_content":"\n\n\n### 广告类型\n\n- 原生广告\n\n原生广告在视觉形式上与广告投放到的应用内容界面相契合，可为用户带来浑然一体的体验。这种类型的广告就是原生广告。（这个就是不容易让人发现它是一个广告）\n\n- 搜索广告\n\n搜索广告是以上下文查询词为粒度进行受众定向,并按照竞价方式售卖和CPC(即“按点击收费”)结算的广告产品。例如大家在百度上面搜索python，就会搜索出一堆培训机构放在前面，这就是搜索广告。\n\n- 信息流广告\n\n*信息流广告*是位于社交媒体用户的好友动态、或者资讯媒体和视听媒体内容流中的*广告*。\n\n\n\n首先它是原生广告，也就是和内容放在一起很难区分。例如大家在刷朋友圈的时候会有一条朋友圈内容挺具有真情实感的，有文字感想还有配图，但是一看备注是拼多多。\n\n- 直播广告\n\n\n\n### 定向过滤、频控流控、打散\n\n#### 定向过滤\n\n定向：在召回之前，每个广告都有自己的受众群体，例如这个广告只投男性之类的constraint。\n\n过略：例如用户已经安装了该app，那如果还投该app的下载广告就不合理。所以会设置一些过滤规则，这个也可以做在定向中，或者模型预估之后吧。\n\n\n\n#### 频控/流控\n\n频控：用户历史看过哪些广告，那这些广告再次曝光的话需要控制下频率。\n\n流控：广告的投放速度控制，如果一直投某类广告，预算消耗过快也是广告主不想看见的。\n\n这两步可以做在定向中，也就是模型预估前，也可以做在模型预估之后，看架构能力吧。\n\n\n\n#### 打散\n\n最终投放的广告很有可能是类似的，所以需要将其打散到不同位置或者不同次曝光中。我理解一般是预估之后。\n\n\n\n\n\n### RTA/RTB\n\nRTA就是在广告平台直投广告里，接入一个realtime api，在定向阶段，让广告主自己做定向。\n\nRTB就涉及到了adx和dsp，广告平台提供流量位和用户等信息，然后通过adx将这些信息发送到dsp(广告主平台)，他们基于这个流量，挑选出最好的广告创意(ctr和cvr预估)做出价，然后再发送给adx做竞价。现在oppo 信息流里就有adx广告\n\n参考文章：\n\n- [RTA 广告产品能力详解](https://zhuanlan.zhihu.com/p/125464058)\n- [广告投放平台DSP搭建：你需要了解的产品核心模块](http://www.woshipm.com/pd/1692791.html)\n\n\n\n### 竞价/定价模式\n\n分为两个阶段：竞价阶段+定价阶段。\n\n- 竞价阶段：通过每个广告的bid，ctr，cvr，得到该广告的ecpm，按照ecpm排序进行竞价\n- 定价阶段：为了得到truthful bidding，用GSP和VCG的方式来进行定价，这里会把ecpm(预计千次投放收益)转换成auction price(千次投放计费)\n\n\n\n### 几种方式\n\n#### CPM\n\n最简单的方式，按照投放计费：\n\n- 竞价：ecpm = bid * 1000，bid为单次投放出价\n- 定价：auction_price = f(ecpm)，price = auction_price  / 1000，price为单次投放计费\n\n\n\n#### CPC\n\n按照点击计费:\n\n- 竞价：ecpm = click_bid * ctr * 1000，click_bid为单次点击出价\n- 定价：auction_price = f(ecpm)，price = auction_price  / ctr / 1000，price为单次点击计费\n\n\n\n#### CPA/oCPC/oCPM\n\n按照转化(action)计费：\n\n- 竞价：ecpm = action_bid * ctr * cvr *1000，action_bid为单次转化出价\n- 定价：注意，这里三种方式有所区别\n  - CPA：price = auction_price  / ctr / cvr / 1000，price为单次转化计费。这种方式的问题在于，广告主可能作弊，因为他们如果不回传转化，就能薅羊毛了。\n  - oCPC：price = auction_price  / ctr / 1000，price为单次点击计费。如果是一价计费，那么price = action_bid * cvr\n  - oCPM：price = auction_price / 1000，price为单次投放计费。\n  - 从CPA -> oCPC -> oCPM，平台风险越来越低，广告主风险变高。\n\n\n\n字节现状：CPC -> oCPC ->  CPA(中小广告主) + oCPM(其他）\n\n\n\n\n\n### 如果ocpc模式下，预估cvr偏高会怎么样？\n\n最近发生了个事故，就是cvr预测失败，恒定返回0.5，达魁说这就会对广告主造成损失。理由如下：\n\n- 本身来讲，cvr和ctr预测不好，只会影响广告排序，不会直接造成损失。\n- 同样不会影响流失训练，无非负例变多，但会影响online auc，因为预估得不准了嘛\n- ocpc计费价格，在一价模式下，price = action_bid * cvr，如果cvr偏高，那么我们对单次点击的收费就会偏高，所以会对广告主多计费，但是广告主如果看后验cvr的话，发现转化没那么高，或者和以前相比，同样的预算，带来的实际收入却变低了，roi变低，那么广告主利益就受损，我们需要对广告主进行赔偿。\n\n\n\n\n\n### 关于广告主价值和游戏ecpm\n\n- 我们之前排序的时候，会计算广告的ecpm这个只是针对某个用户的，ctr*bid\n- 计算广告主价值（ad_estimated_ecpm）时，统计的是所有广告的，所以是会按照实际的点击次数/转化次数 * bid来算的（并不是针对某个用户的ctr * bid），只是说广告主价值还是预估的，并非实际消耗的，因为实际扣费会涉及到风控以及二价计费等。\n- 游戏归一化曝光价值也是如此(game_ecpm)，只是会用点击次数 * ltv / 曝光总数，就有点ctr的意思在里面。\n- 广告和游戏的arpu的话，就是实际产生的收入了。\n\n","source":"_posts/搜推广/计算广告基础概念.md","raw":"---\ntitle: 计算广告基础概念\ndate: 2022-08-10 \ncategories: 搜推广\n---\n\n\n\n### 广告类型\n\n- 原生广告\n\n原生广告在视觉形式上与广告投放到的应用内容界面相契合，可为用户带来浑然一体的体验。这种类型的广告就是原生广告。（这个就是不容易让人发现它是一个广告）\n\n- 搜索广告\n\n搜索广告是以上下文查询词为粒度进行受众定向,并按照竞价方式售卖和CPC(即“按点击收费”)结算的广告产品。例如大家在百度上面搜索python，就会搜索出一堆培训机构放在前面，这就是搜索广告。\n\n- 信息流广告\n\n*信息流广告*是位于社交媒体用户的好友动态、或者资讯媒体和视听媒体内容流中的*广告*。\n\n\n\n首先它是原生广告，也就是和内容放在一起很难区分。例如大家在刷朋友圈的时候会有一条朋友圈内容挺具有真情实感的，有文字感想还有配图，但是一看备注是拼多多。\n\n- 直播广告\n\n\n\n### 定向过滤、频控流控、打散\n\n#### 定向过滤\n\n定向：在召回之前，每个广告都有自己的受众群体，例如这个广告只投男性之类的constraint。\n\n过略：例如用户已经安装了该app，那如果还投该app的下载广告就不合理。所以会设置一些过滤规则，这个也可以做在定向中，或者模型预估之后吧。\n\n\n\n#### 频控/流控\n\n频控：用户历史看过哪些广告，那这些广告再次曝光的话需要控制下频率。\n\n流控：广告的投放速度控制，如果一直投某类广告，预算消耗过快也是广告主不想看见的。\n\n这两步可以做在定向中，也就是模型预估前，也可以做在模型预估之后，看架构能力吧。\n\n\n\n#### 打散\n\n最终投放的广告很有可能是类似的，所以需要将其打散到不同位置或者不同次曝光中。我理解一般是预估之后。\n\n\n\n\n\n### RTA/RTB\n\nRTA就是在广告平台直投广告里，接入一个realtime api，在定向阶段，让广告主自己做定向。\n\nRTB就涉及到了adx和dsp，广告平台提供流量位和用户等信息，然后通过adx将这些信息发送到dsp(广告主平台)，他们基于这个流量，挑选出最好的广告创意(ctr和cvr预估)做出价，然后再发送给adx做竞价。现在oppo 信息流里就有adx广告\n\n参考文章：\n\n- [RTA 广告产品能力详解](https://zhuanlan.zhihu.com/p/125464058)\n- [广告投放平台DSP搭建：你需要了解的产品核心模块](http://www.woshipm.com/pd/1692791.html)\n\n\n\n### 竞价/定价模式\n\n分为两个阶段：竞价阶段+定价阶段。\n\n- 竞价阶段：通过每个广告的bid，ctr，cvr，得到该广告的ecpm，按照ecpm排序进行竞价\n- 定价阶段：为了得到truthful bidding，用GSP和VCG的方式来进行定价，这里会把ecpm(预计千次投放收益)转换成auction price(千次投放计费)\n\n\n\n### 几种方式\n\n#### CPM\n\n最简单的方式，按照投放计费：\n\n- 竞价：ecpm = bid * 1000，bid为单次投放出价\n- 定价：auction_price = f(ecpm)，price = auction_price  / 1000，price为单次投放计费\n\n\n\n#### CPC\n\n按照点击计费:\n\n- 竞价：ecpm = click_bid * ctr * 1000，click_bid为单次点击出价\n- 定价：auction_price = f(ecpm)，price = auction_price  / ctr / 1000，price为单次点击计费\n\n\n\n#### CPA/oCPC/oCPM\n\n按照转化(action)计费：\n\n- 竞价：ecpm = action_bid * ctr * cvr *1000，action_bid为单次转化出价\n- 定价：注意，这里三种方式有所区别\n  - CPA：price = auction_price  / ctr / cvr / 1000，price为单次转化计费。这种方式的问题在于，广告主可能作弊，因为他们如果不回传转化，就能薅羊毛了。\n  - oCPC：price = auction_price  / ctr / 1000，price为单次点击计费。如果是一价计费，那么price = action_bid * cvr\n  - oCPM：price = auction_price / 1000，price为单次投放计费。\n  - 从CPA -> oCPC -> oCPM，平台风险越来越低，广告主风险变高。\n\n\n\n字节现状：CPC -> oCPC ->  CPA(中小广告主) + oCPM(其他）\n\n\n\n\n\n### 如果ocpc模式下，预估cvr偏高会怎么样？\n\n最近发生了个事故，就是cvr预测失败，恒定返回0.5，达魁说这就会对广告主造成损失。理由如下：\n\n- 本身来讲，cvr和ctr预测不好，只会影响广告排序，不会直接造成损失。\n- 同样不会影响流失训练，无非负例变多，但会影响online auc，因为预估得不准了嘛\n- ocpc计费价格，在一价模式下，price = action_bid * cvr，如果cvr偏高，那么我们对单次点击的收费就会偏高，所以会对广告主多计费，但是广告主如果看后验cvr的话，发现转化没那么高，或者和以前相比，同样的预算，带来的实际收入却变低了，roi变低，那么广告主利益就受损，我们需要对广告主进行赔偿。\n\n\n\n\n\n### 关于广告主价值和游戏ecpm\n\n- 我们之前排序的时候，会计算广告的ecpm这个只是针对某个用户的，ctr*bid\n- 计算广告主价值（ad_estimated_ecpm）时，统计的是所有广告的，所以是会按照实际的点击次数/转化次数 * bid来算的（并不是针对某个用户的ctr * bid），只是说广告主价值还是预估的，并非实际消耗的，因为实际扣费会涉及到风控以及二价计费等。\n- 游戏归一化曝光价值也是如此(game_ecpm)，只是会用点击次数 * ltv / 曝光总数，就有点ctr的意思在里面。\n- 广告和游戏的arpu的话，就是实际产生的收入了。\n\n","slug":"搜推广/计算广告基础概念","published":1,"updated":"2022-09-15T03:46:43.360Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551oa0011jqrr4mh5sjah","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"广告类型\"><a href=\"#广告类型\" class=\"headerlink\" title=\"广告类型\"></a>广告类型</h3><ul>\n<li>原生广告</li>\n</ul>\n<p>原生广告在视觉形式上与广告投放到的应用内容界面相契合，可为用户带来浑然一体的体验。这种类型的广告就是原生广告。（这个就是不容易让人发现它是一个广告）</p>\n<ul>\n<li>搜索广告</li>\n</ul>\n<p>搜索广告是以上下文查询词为粒度进行受众定向,并按照竞价方式售卖和CPC(即“按点击收费”)结算的广告产品。例如大家在百度上面搜索python，就会搜索出一堆培训机构放在前面，这就是搜索广告。</p>\n<ul>\n<li>信息流广告</li>\n</ul>\n<p><em>信息流广告</em>是位于社交媒体用户的好友动态、或者资讯媒体和视听媒体内容流中的<em>广告</em>。</p>\n<p>首先它是原生广告，也就是和内容放在一起很难区分。例如大家在刷朋友圈的时候会有一条朋友圈内容挺具有真情实感的，有文字感想还有配图，但是一看备注是拼多多。</p>\n<ul>\n<li>直播广告</li>\n</ul>\n<h3 id=\"定向过滤、频控流控、打散\"><a href=\"#定向过滤、频控流控、打散\" class=\"headerlink\" title=\"定向过滤、频控流控、打散\"></a>定向过滤、频控流控、打散</h3><h4 id=\"定向过滤\"><a href=\"#定向过滤\" class=\"headerlink\" title=\"定向过滤\"></a>定向过滤</h4><p>定向：在召回之前，每个广告都有自己的受众群体，例如这个广告只投男性之类的constraint。</p>\n<p>过略：例如用户已经安装了该app，那如果还投该app的下载广告就不合理。所以会设置一些过滤规则，这个也可以做在定向中，或者模型预估之后吧。</p>\n<h4 id=\"频控-流控\"><a href=\"#频控-流控\" class=\"headerlink\" title=\"频控/流控\"></a>频控/流控</h4><p>频控：用户历史看过哪些广告，那这些广告再次曝光的话需要控制下频率。</p>\n<p>流控：广告的投放速度控制，如果一直投某类广告，预算消耗过快也是广告主不想看见的。</p>\n<p>这两步可以做在定向中，也就是模型预估前，也可以做在模型预估之后，看架构能力吧。</p>\n<h4 id=\"打散\"><a href=\"#打散\" class=\"headerlink\" title=\"打散\"></a>打散</h4><p>最终投放的广告很有可能是类似的，所以需要将其打散到不同位置或者不同次曝光中。我理解一般是预估之后。</p>\n<h3 id=\"RTA-RTB\"><a href=\"#RTA-RTB\" class=\"headerlink\" title=\"RTA/RTB\"></a>RTA/RTB</h3><p>RTA就是在广告平台直投广告里，接入一个realtime api，在定向阶段，让广告主自己做定向。</p>\n<p>RTB就涉及到了adx和dsp，广告平台提供流量位和用户等信息，然后通过adx将这些信息发送到dsp(广告主平台)，他们基于这个流量，挑选出最好的广告创意(ctr和cvr预估)做出价，然后再发送给adx做竞价。现在oppo 信息流里就有adx广告</p>\n<p>参考文章：</p>\n<ul>\n<li><a href=\"https://zhuanlan.zhihu.com/p/125464058\" target=\"_blank\" rel=\"noopener\">RTA 广告产品能力详解</a></li>\n<li><a href=\"http://www.woshipm.com/pd/1692791.html\" target=\"_blank\" rel=\"noopener\">广告投放平台DSP搭建：你需要了解的产品核心模块</a></li>\n</ul>\n<h3 id=\"竞价-定价模式\"><a href=\"#竞价-定价模式\" class=\"headerlink\" title=\"竞价/定价模式\"></a>竞价/定价模式</h3><p>分为两个阶段：竞价阶段+定价阶段。</p>\n<ul>\n<li>竞价阶段：通过每个广告的bid，ctr，cvr，得到该广告的ecpm，按照ecpm排序进行竞价</li>\n<li>定价阶段：为了得到truthful bidding，用GSP和VCG的方式来进行定价，这里会把ecpm(预计千次投放收益)转换成auction price(千次投放计费)</li>\n</ul>\n<h3 id=\"几种方式\"><a href=\"#几种方式\" class=\"headerlink\" title=\"几种方式\"></a>几种方式</h3><h4 id=\"CPM\"><a href=\"#CPM\" class=\"headerlink\" title=\"CPM\"></a>CPM</h4><p>最简单的方式，按照投放计费：</p>\n<ul>\n<li>竞价：ecpm = bid * 1000，bid为单次投放出价</li>\n<li>定价：auction_price = f(ecpm)，price = auction_price  / 1000，price为单次投放计费</li>\n</ul>\n<h4 id=\"CPC\"><a href=\"#CPC\" class=\"headerlink\" title=\"CPC\"></a>CPC</h4><p>按照点击计费:</p>\n<ul>\n<li>竞价：ecpm = click_bid <em> ctr </em> 1000，click_bid为单次点击出价</li>\n<li>定价：auction_price = f(ecpm)，price = auction_price  / ctr / 1000，price为单次点击计费</li>\n</ul>\n<h4 id=\"CPA-oCPC-oCPM\"><a href=\"#CPA-oCPC-oCPM\" class=\"headerlink\" title=\"CPA/oCPC/oCPM\"></a>CPA/oCPC/oCPM</h4><p>按照转化(action)计费：</p>\n<ul>\n<li>竞价：ecpm = action_bid <em> ctr </em> cvr *1000，action_bid为单次转化出价</li>\n<li>定价：注意，这里三种方式有所区别<ul>\n<li>CPA：price = auction_price  / ctr / cvr / 1000，price为单次转化计费。这种方式的问题在于，广告主可能作弊，因为他们如果不回传转化，就能薅羊毛了。</li>\n<li>oCPC：price = auction_price  / ctr / 1000，price为单次点击计费。如果是一价计费，那么price = action_bid * cvr</li>\n<li>oCPM：price = auction_price / 1000，price为单次投放计费。</li>\n<li>从CPA -&gt; oCPC -&gt; oCPM，平台风险越来越低，广告主风险变高。</li>\n</ul>\n</li>\n</ul>\n<p>字节现状：CPC -&gt; oCPC -&gt;  CPA(中小广告主) + oCPM(其他）</p>\n<h3 id=\"如果ocpc模式下，预估cvr偏高会怎么样？\"><a href=\"#如果ocpc模式下，预估cvr偏高会怎么样？\" class=\"headerlink\" title=\"如果ocpc模式下，预估cvr偏高会怎么样？\"></a>如果ocpc模式下，预估cvr偏高会怎么样？</h3><p>最近发生了个事故，就是cvr预测失败，恒定返回0.5，达魁说这就会对广告主造成损失。理由如下：</p>\n<ul>\n<li>本身来讲，cvr和ctr预测不好，只会影响广告排序，不会直接造成损失。</li>\n<li>同样不会影响流失训练，无非负例变多，但会影响online auc，因为预估得不准了嘛</li>\n<li>ocpc计费价格，在一价模式下，price = action_bid * cvr，如果cvr偏高，那么我们对单次点击的收费就会偏高，所以会对广告主多计费，但是广告主如果看后验cvr的话，发现转化没那么高，或者和以前相比，同样的预算，带来的实际收入却变低了，roi变低，那么广告主利益就受损，我们需要对广告主进行赔偿。</li>\n</ul>\n<h3 id=\"关于广告主价值和游戏ecpm\"><a href=\"#关于广告主价值和游戏ecpm\" class=\"headerlink\" title=\"关于广告主价值和游戏ecpm\"></a>关于广告主价值和游戏ecpm</h3><ul>\n<li>我们之前排序的时候，会计算广告的ecpm这个只是针对某个用户的，ctr*bid</li>\n<li>计算广告主价值（ad_estimated_ecpm）时，统计的是所有广告的，所以是会按照实际的点击次数/转化次数 <em> bid来算的（并不是针对某个用户的ctr </em> bid），只是说广告主价值还是预估的，并非实际消耗的，因为实际扣费会涉及到风控以及二价计费等。</li>\n<li>游戏归一化曝光价值也是如此(game_ecpm)，只是会用点击次数 * ltv / 曝光总数，就有点ctr的意思在里面。</li>\n<li>广告和游戏的arpu的话，就是实际产生的收入了。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"广告类型\"><a href=\"#广告类型\" class=\"headerlink\" title=\"广告类型\"></a>广告类型</h3><ul>\n<li>原生广告</li>\n</ul>\n<p>原生广告在视觉形式上与广告投放到的应用内容界面相契合，可为用户带来浑然一体的体验。这种类型的广告就是原生广告。（这个就是不容易让人发现它是一个广告）</p>\n<ul>\n<li>搜索广告</li>\n</ul>\n<p>搜索广告是以上下文查询词为粒度进行受众定向,并按照竞价方式售卖和CPC(即“按点击收费”)结算的广告产品。例如大家在百度上面搜索python，就会搜索出一堆培训机构放在前面，这就是搜索广告。</p>\n<ul>\n<li>信息流广告</li>\n</ul>\n<p><em>信息流广告</em>是位于社交媒体用户的好友动态、或者资讯媒体和视听媒体内容流中的<em>广告</em>。</p>\n<p>首先它是原生广告，也就是和内容放在一起很难区分。例如大家在刷朋友圈的时候会有一条朋友圈内容挺具有真情实感的，有文字感想还有配图，但是一看备注是拼多多。</p>\n<ul>\n<li>直播广告</li>\n</ul>\n<h3 id=\"定向过滤、频控流控、打散\"><a href=\"#定向过滤、频控流控、打散\" class=\"headerlink\" title=\"定向过滤、频控流控、打散\"></a>定向过滤、频控流控、打散</h3><h4 id=\"定向过滤\"><a href=\"#定向过滤\" class=\"headerlink\" title=\"定向过滤\"></a>定向过滤</h4><p>定向：在召回之前，每个广告都有自己的受众群体，例如这个广告只投男性之类的constraint。</p>\n<p>过略：例如用户已经安装了该app，那如果还投该app的下载广告就不合理。所以会设置一些过滤规则，这个也可以做在定向中，或者模型预估之后吧。</p>\n<h4 id=\"频控-流控\"><a href=\"#频控-流控\" class=\"headerlink\" title=\"频控/流控\"></a>频控/流控</h4><p>频控：用户历史看过哪些广告，那这些广告再次曝光的话需要控制下频率。</p>\n<p>流控：广告的投放速度控制，如果一直投某类广告，预算消耗过快也是广告主不想看见的。</p>\n<p>这两步可以做在定向中，也就是模型预估前，也可以做在模型预估之后，看架构能力吧。</p>\n<h4 id=\"打散\"><a href=\"#打散\" class=\"headerlink\" title=\"打散\"></a>打散</h4><p>最终投放的广告很有可能是类似的，所以需要将其打散到不同位置或者不同次曝光中。我理解一般是预估之后。</p>\n<h3 id=\"RTA-RTB\"><a href=\"#RTA-RTB\" class=\"headerlink\" title=\"RTA/RTB\"></a>RTA/RTB</h3><p>RTA就是在广告平台直投广告里，接入一个realtime api，在定向阶段，让广告主自己做定向。</p>\n<p>RTB就涉及到了adx和dsp，广告平台提供流量位和用户等信息，然后通过adx将这些信息发送到dsp(广告主平台)，他们基于这个流量，挑选出最好的广告创意(ctr和cvr预估)做出价，然后再发送给adx做竞价。现在oppo 信息流里就有adx广告</p>\n<p>参考文章：</p>\n<ul>\n<li><a href=\"https://zhuanlan.zhihu.com/p/125464058\" target=\"_blank\" rel=\"noopener\">RTA 广告产品能力详解</a></li>\n<li><a href=\"http://www.woshipm.com/pd/1692791.html\" target=\"_blank\" rel=\"noopener\">广告投放平台DSP搭建：你需要了解的产品核心模块</a></li>\n</ul>\n<h3 id=\"竞价-定价模式\"><a href=\"#竞价-定价模式\" class=\"headerlink\" title=\"竞价/定价模式\"></a>竞价/定价模式</h3><p>分为两个阶段：竞价阶段+定价阶段。</p>\n<ul>\n<li>竞价阶段：通过每个广告的bid，ctr，cvr，得到该广告的ecpm，按照ecpm排序进行竞价</li>\n<li>定价阶段：为了得到truthful bidding，用GSP和VCG的方式来进行定价，这里会把ecpm(预计千次投放收益)转换成auction price(千次投放计费)</li>\n</ul>\n<h3 id=\"几种方式\"><a href=\"#几种方式\" class=\"headerlink\" title=\"几种方式\"></a>几种方式</h3><h4 id=\"CPM\"><a href=\"#CPM\" class=\"headerlink\" title=\"CPM\"></a>CPM</h4><p>最简单的方式，按照投放计费：</p>\n<ul>\n<li>竞价：ecpm = bid * 1000，bid为单次投放出价</li>\n<li>定价：auction_price = f(ecpm)，price = auction_price  / 1000，price为单次投放计费</li>\n</ul>\n<h4 id=\"CPC\"><a href=\"#CPC\" class=\"headerlink\" title=\"CPC\"></a>CPC</h4><p>按照点击计费:</p>\n<ul>\n<li>竞价：ecpm = click_bid <em> ctr </em> 1000，click_bid为单次点击出价</li>\n<li>定价：auction_price = f(ecpm)，price = auction_price  / ctr / 1000，price为单次点击计费</li>\n</ul>\n<h4 id=\"CPA-oCPC-oCPM\"><a href=\"#CPA-oCPC-oCPM\" class=\"headerlink\" title=\"CPA/oCPC/oCPM\"></a>CPA/oCPC/oCPM</h4><p>按照转化(action)计费：</p>\n<ul>\n<li>竞价：ecpm = action_bid <em> ctr </em> cvr *1000，action_bid为单次转化出价</li>\n<li>定价：注意，这里三种方式有所区别<ul>\n<li>CPA：price = auction_price  / ctr / cvr / 1000，price为单次转化计费。这种方式的问题在于，广告主可能作弊，因为他们如果不回传转化，就能薅羊毛了。</li>\n<li>oCPC：price = auction_price  / ctr / 1000，price为单次点击计费。如果是一价计费，那么price = action_bid * cvr</li>\n<li>oCPM：price = auction_price / 1000，price为单次投放计费。</li>\n<li>从CPA -&gt; oCPC -&gt; oCPM，平台风险越来越低，广告主风险变高。</li>\n</ul>\n</li>\n</ul>\n<p>字节现状：CPC -&gt; oCPC -&gt;  CPA(中小广告主) + oCPM(其他）</p>\n<h3 id=\"如果ocpc模式下，预估cvr偏高会怎么样？\"><a href=\"#如果ocpc模式下，预估cvr偏高会怎么样？\" class=\"headerlink\" title=\"如果ocpc模式下，预估cvr偏高会怎么样？\"></a>如果ocpc模式下，预估cvr偏高会怎么样？</h3><p>最近发生了个事故，就是cvr预测失败，恒定返回0.5，达魁说这就会对广告主造成损失。理由如下：</p>\n<ul>\n<li>本身来讲，cvr和ctr预测不好，只会影响广告排序，不会直接造成损失。</li>\n<li>同样不会影响流失训练，无非负例变多，但会影响online auc，因为预估得不准了嘛</li>\n<li>ocpc计费价格，在一价模式下，price = action_bid * cvr，如果cvr偏高，那么我们对单次点击的收费就会偏高，所以会对广告主多计费，但是广告主如果看后验cvr的话，发现转化没那么高，或者和以前相比，同样的预算，带来的实际收入却变低了，roi变低，那么广告主利益就受损，我们需要对广告主进行赔偿。</li>\n</ul>\n<h3 id=\"关于广告主价值和游戏ecpm\"><a href=\"#关于广告主价值和游戏ecpm\" class=\"headerlink\" title=\"关于广告主价值和游戏ecpm\"></a>关于广告主价值和游戏ecpm</h3><ul>\n<li>我们之前排序的时候，会计算广告的ecpm这个只是针对某个用户的，ctr*bid</li>\n<li>计算广告主价值（ad_estimated_ecpm）时，统计的是所有广告的，所以是会按照实际的点击次数/转化次数 <em> bid来算的（并不是针对某个用户的ctr </em> bid），只是说广告主价值还是预估的，并非实际消耗的，因为实际扣费会涉及到风控以及二价计费等。</li>\n<li>游戏归一化曝光价值也是如此(game_ecpm)，只是会用点击次数 * ltv / 曝光总数，就有点ctr的意思在里面。</li>\n<li>广告和游戏的arpu的话，就是实际产生的收入了。</li>\n</ul>\n"},{"title":"理解召回和LTR","date":"2022-08-09T16:00:00.000Z","_content":"\n参考文章：[万变不离其宗：用统一框架理解向量化召回](https://mp.weixin.qq.com/s/E5a4TF9P2aMrF6gVatAF8A)\n\n# 召回本质\n\n召回本质上和排序其实存在很大的区别：\n\n- 召回模型特征是解耦的，排序模型的特征是交叉的，这个是性能上的考虑。\n- 召回是样本的艺术，排序是特征的艺术。召回的负样本如果用的是曝光未点击，和排序类似的话，就有问题，这样召回的训练和预估的数据分布不一致了。因此召回的负样本是随机采样。\n\n\n\n# 召回的几种类型\n\n- i2i:拿用户喜欢的item找相似item。就比如work2vec这种，或者图构建item embeding这种，都是拿用户的点击序列去构建，然后计算item emb，然后找到用户喜欢的item的相似的emb。\n- u2i：直接给user找他可能喜欢的item。这种是目前应用最多的，例如基于DNN的FM双塔模型，就是用户一个emb，item一个emb，最后内积计算得分。\n- u2u2i:给user查找相似user，再把相似user喜欢的item推出去。\n\n\n\n# 召回的负采样\n\n召回负采样的做法不仅仅只是随机采样，一般会有类似work2vec的做法，对热门item正样本降权，负样本加权这种操作。\n\n负采样也分为easy negaitve和hard negative两种：\n\n- easy negaitve ：随机采样一般就是这种\n- Hard negaive ：比如正样本是狗，猫、大象明显是easy negative，而狼就和狗有几分相似，但又不是的称为hard negative。一般做法有基于业务逻辑自己加，还有FB的做法：上一个召回模型预估得分的中间位置作为下一个召回模型的hard negative。\n\n\n\n# LTR\n\nLearning to Rank其实是针对排序算法的统称，针对loss function，可分为三种：\n\n### Pointwise\n\n最为常见，像精排这种明确的正负样本，直接binary cross entropy计算label 准确度。缺点是没有关注到排序信息。\n\n\n\n### Pairwise\n\n更关系两个样本的排序顺序，一般像召回任务很多都是用pairwise，常见的几种loss有：\n\n\n\n#### sampled softmax loss\n\n![image-20210806211523927](https://tva1.sinaimg.cn/large/e6c9d24ely1h51rlpiypvj21c60jcq7e.jpg)\n\n这个就像word2vec里的计算的sampled softmax loss，值得注意的是，这个loss做梯度更新的方式，每一个样本喂进去之后都需要做负采样(会有个辅助emb矩阵，得到负样本分母的emb)，然后计算loss，然后更新梯度，不像常见的交叉熵的梯度更新。\n\n\n\n#### margin hinge loss\n\n![image-20210806211842642](https://tva1.sinaimg.cn/large/e6c9d24ely1h51rm81ox5j219u056754.jpg)\n\n#### BPR Loss\n\n![image-20210806211857913](https://tva1.sinaimg.cn/large/e6c9d24ely1h51rmbwy31j21co09cdhj.jpg)\n\n对于后面两种loss，样本都需要是三元形式，《u , item+,item-》，后面两个item都要过一遍nn得到emb。\n\n","source":"_posts/搜推广/理解召回和LTR.md","raw":"---\ntitle: 理解召回和LTR\ndate: 2022-08-10 \ncategories: 搜推广\n---\n\n参考文章：[万变不离其宗：用统一框架理解向量化召回](https://mp.weixin.qq.com/s/E5a4TF9P2aMrF6gVatAF8A)\n\n# 召回本质\n\n召回本质上和排序其实存在很大的区别：\n\n- 召回模型特征是解耦的，排序模型的特征是交叉的，这个是性能上的考虑。\n- 召回是样本的艺术，排序是特征的艺术。召回的负样本如果用的是曝光未点击，和排序类似的话，就有问题，这样召回的训练和预估的数据分布不一致了。因此召回的负样本是随机采样。\n\n\n\n# 召回的几种类型\n\n- i2i:拿用户喜欢的item找相似item。就比如work2vec这种，或者图构建item embeding这种，都是拿用户的点击序列去构建，然后计算item emb，然后找到用户喜欢的item的相似的emb。\n- u2i：直接给user找他可能喜欢的item。这种是目前应用最多的，例如基于DNN的FM双塔模型，就是用户一个emb，item一个emb，最后内积计算得分。\n- u2u2i:给user查找相似user，再把相似user喜欢的item推出去。\n\n\n\n# 召回的负采样\n\n召回负采样的做法不仅仅只是随机采样，一般会有类似work2vec的做法，对热门item正样本降权，负样本加权这种操作。\n\n负采样也分为easy negaitve和hard negative两种：\n\n- easy negaitve ：随机采样一般就是这种\n- Hard negaive ：比如正样本是狗，猫、大象明显是easy negative，而狼就和狗有几分相似，但又不是的称为hard negative。一般做法有基于业务逻辑自己加，还有FB的做法：上一个召回模型预估得分的中间位置作为下一个召回模型的hard negative。\n\n\n\n# LTR\n\nLearning to Rank其实是针对排序算法的统称，针对loss function，可分为三种：\n\n### Pointwise\n\n最为常见，像精排这种明确的正负样本，直接binary cross entropy计算label 准确度。缺点是没有关注到排序信息。\n\n\n\n### Pairwise\n\n更关系两个样本的排序顺序，一般像召回任务很多都是用pairwise，常见的几种loss有：\n\n\n\n#### sampled softmax loss\n\n![image-20210806211523927](https://tva1.sinaimg.cn/large/e6c9d24ely1h51rlpiypvj21c60jcq7e.jpg)\n\n这个就像word2vec里的计算的sampled softmax loss，值得注意的是，这个loss做梯度更新的方式，每一个样本喂进去之后都需要做负采样(会有个辅助emb矩阵，得到负样本分母的emb)，然后计算loss，然后更新梯度，不像常见的交叉熵的梯度更新。\n\n\n\n#### margin hinge loss\n\n![image-20210806211842642](https://tva1.sinaimg.cn/large/e6c9d24ely1h51rm81ox5j219u056754.jpg)\n\n#### BPR Loss\n\n![image-20210806211857913](https://tva1.sinaimg.cn/large/e6c9d24ely1h51rmbwy31j21co09cdhj.jpg)\n\n对于后面两种loss，样本都需要是三元形式，《u , item+,item-》，后面两个item都要过一遍nn得到emb。\n\n","slug":"搜推广/理解召回和LTR","published":1,"updated":"2022-09-15T03:46:43.360Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551oa0016jqrrhzie1mbm","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>参考文章：<a href=\"https://mp.weixin.qq.com/s/E5a4TF9P2aMrF6gVatAF8A\" target=\"_blank\" rel=\"noopener\">万变不离其宗：用统一框架理解向量化召回</a></p>\n<h1 id=\"召回本质\"><a href=\"#召回本质\" class=\"headerlink\" title=\"召回本质\"></a>召回本质</h1><p>召回本质上和排序其实存在很大的区别：</p>\n<ul>\n<li>召回模型特征是解耦的，排序模型的特征是交叉的，这个是性能上的考虑。</li>\n<li>召回是样本的艺术，排序是特征的艺术。召回的负样本如果用的是曝光未点击，和排序类似的话，就有问题，这样召回的训练和预估的数据分布不一致了。因此召回的负样本是随机采样。</li>\n</ul>\n<h1 id=\"召回的几种类型\"><a href=\"#召回的几种类型\" class=\"headerlink\" title=\"召回的几种类型\"></a>召回的几种类型</h1><ul>\n<li>i2i:拿用户喜欢的item找相似item。就比如work2vec这种，或者图构建item embeding这种，都是拿用户的点击序列去构建，然后计算item emb，然后找到用户喜欢的item的相似的emb。</li>\n<li>u2i：直接给user找他可能喜欢的item。这种是目前应用最多的，例如基于DNN的FM双塔模型，就是用户一个emb，item一个emb，最后内积计算得分。</li>\n<li>u2u2i:给user查找相似user，再把相似user喜欢的item推出去。</li>\n</ul>\n<h1 id=\"召回的负采样\"><a href=\"#召回的负采样\" class=\"headerlink\" title=\"召回的负采样\"></a>召回的负采样</h1><p>召回负采样的做法不仅仅只是随机采样，一般会有类似work2vec的做法，对热门item正样本降权，负样本加权这种操作。</p>\n<p>负采样也分为easy negaitve和hard negative两种：</p>\n<ul>\n<li>easy negaitve ：随机采样一般就是这种</li>\n<li>Hard negaive ：比如正样本是狗，猫、大象明显是easy negative，而狼就和狗有几分相似，但又不是的称为hard negative。一般做法有基于业务逻辑自己加，还有FB的做法：上一个召回模型预估得分的中间位置作为下一个召回模型的hard negative。</li>\n</ul>\n<h1 id=\"LTR\"><a href=\"#LTR\" class=\"headerlink\" title=\"LTR\"></a>LTR</h1><p>Learning to Rank其实是针对排序算法的统称，针对loss function，可分为三种：</p>\n<h3 id=\"Pointwise\"><a href=\"#Pointwise\" class=\"headerlink\" title=\"Pointwise\"></a>Pointwise</h3><p>最为常见，像精排这种明确的正负样本，直接binary cross entropy计算label 准确度。缺点是没有关注到排序信息。</p>\n<h3 id=\"Pairwise\"><a href=\"#Pairwise\" class=\"headerlink\" title=\"Pairwise\"></a>Pairwise</h3><p>更关系两个样本的排序顺序，一般像召回任务很多都是用pairwise，常见的几种loss有：</p>\n<h4 id=\"sampled-softmax-loss\"><a href=\"#sampled-softmax-loss\" class=\"headerlink\" title=\"sampled softmax loss\"></a>sampled softmax loss</h4><p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rlpiypvj21c60jcq7e.jpg\" alt=\"image-20210806211523927\"></p>\n<p>这个就像word2vec里的计算的sampled softmax loss，值得注意的是，这个loss做梯度更新的方式，每一个样本喂进去之后都需要做负采样(会有个辅助emb矩阵，得到负样本分母的emb)，然后计算loss，然后更新梯度，不像常见的交叉熵的梯度更新。</p>\n<h4 id=\"margin-hinge-loss\"><a href=\"#margin-hinge-loss\" class=\"headerlink\" title=\"margin hinge loss\"></a>margin hinge loss</h4><p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rm81ox5j219u056754.jpg\" alt=\"image-20210806211842642\"></p>\n<h4 id=\"BPR-Loss\"><a href=\"#BPR-Loss\" class=\"headerlink\" title=\"BPR Loss\"></a>BPR Loss</h4><p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rmbwy31j21co09cdhj.jpg\" alt=\"image-20210806211857913\"></p>\n<p>对于后面两种loss，样本都需要是三元形式，《u , item+,item-》，后面两个item都要过一遍nn得到emb。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>参考文章：<a href=\"https://mp.weixin.qq.com/s/E5a4TF9P2aMrF6gVatAF8A\" target=\"_blank\" rel=\"noopener\">万变不离其宗：用统一框架理解向量化召回</a></p>\n<h1 id=\"召回本质\"><a href=\"#召回本质\" class=\"headerlink\" title=\"召回本质\"></a>召回本质</h1><p>召回本质上和排序其实存在很大的区别：</p>\n<ul>\n<li>召回模型特征是解耦的，排序模型的特征是交叉的，这个是性能上的考虑。</li>\n<li>召回是样本的艺术，排序是特征的艺术。召回的负样本如果用的是曝光未点击，和排序类似的话，就有问题，这样召回的训练和预估的数据分布不一致了。因此召回的负样本是随机采样。</li>\n</ul>\n<h1 id=\"召回的几种类型\"><a href=\"#召回的几种类型\" class=\"headerlink\" title=\"召回的几种类型\"></a>召回的几种类型</h1><ul>\n<li>i2i:拿用户喜欢的item找相似item。就比如work2vec这种，或者图构建item embeding这种，都是拿用户的点击序列去构建，然后计算item emb，然后找到用户喜欢的item的相似的emb。</li>\n<li>u2i：直接给user找他可能喜欢的item。这种是目前应用最多的，例如基于DNN的FM双塔模型，就是用户一个emb，item一个emb，最后内积计算得分。</li>\n<li>u2u2i:给user查找相似user，再把相似user喜欢的item推出去。</li>\n</ul>\n<h1 id=\"召回的负采样\"><a href=\"#召回的负采样\" class=\"headerlink\" title=\"召回的负采样\"></a>召回的负采样</h1><p>召回负采样的做法不仅仅只是随机采样，一般会有类似work2vec的做法，对热门item正样本降权，负样本加权这种操作。</p>\n<p>负采样也分为easy negaitve和hard negative两种：</p>\n<ul>\n<li>easy negaitve ：随机采样一般就是这种</li>\n<li>Hard negaive ：比如正样本是狗，猫、大象明显是easy negative，而狼就和狗有几分相似，但又不是的称为hard negative。一般做法有基于业务逻辑自己加，还有FB的做法：上一个召回模型预估得分的中间位置作为下一个召回模型的hard negative。</li>\n</ul>\n<h1 id=\"LTR\"><a href=\"#LTR\" class=\"headerlink\" title=\"LTR\"></a>LTR</h1><p>Learning to Rank其实是针对排序算法的统称，针对loss function，可分为三种：</p>\n<h3 id=\"Pointwise\"><a href=\"#Pointwise\" class=\"headerlink\" title=\"Pointwise\"></a>Pointwise</h3><p>最为常见，像精排这种明确的正负样本，直接binary cross entropy计算label 准确度。缺点是没有关注到排序信息。</p>\n<h3 id=\"Pairwise\"><a href=\"#Pairwise\" class=\"headerlink\" title=\"Pairwise\"></a>Pairwise</h3><p>更关系两个样本的排序顺序，一般像召回任务很多都是用pairwise，常见的几种loss有：</p>\n<h4 id=\"sampled-softmax-loss\"><a href=\"#sampled-softmax-loss\" class=\"headerlink\" title=\"sampled softmax loss\"></a>sampled softmax loss</h4><p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rlpiypvj21c60jcq7e.jpg\" alt=\"image-20210806211523927\"></p>\n<p>这个就像word2vec里的计算的sampled softmax loss，值得注意的是，这个loss做梯度更新的方式，每一个样本喂进去之后都需要做负采样(会有个辅助emb矩阵，得到负样本分母的emb)，然后计算loss，然后更新梯度，不像常见的交叉熵的梯度更新。</p>\n<h4 id=\"margin-hinge-loss\"><a href=\"#margin-hinge-loss\" class=\"headerlink\" title=\"margin hinge loss\"></a>margin hinge loss</h4><p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rm81ox5j219u056754.jpg\" alt=\"image-20210806211842642\"></p>\n<h4 id=\"BPR-Loss\"><a href=\"#BPR-Loss\" class=\"headerlink\" title=\"BPR Loss\"></a>BPR Loss</h4><p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rmbwy31j21co09cdhj.jpg\" alt=\"image-20210806211857913\"></p>\n<p>对于后面两种loss，样本都需要是三元形式，《u , item+,item-》，后面两个item都要过一遍nn得到emb。</p>\n"},{"title":"关于凸、P和NP","date":"2019-08-27T11:28:44.000Z","_content":"\n> 优化问题本质上分为凸和非凸两大类。\n\n凸问题有着巨大的优势：\n\n- 成熟有效的求解算法求得全局最优解。(内点法、椭圆法、梯度下降法等)\n\n- 计算复杂度基本上是多项式的，基本是P的。\n\n![image-20200605162015414](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhkonh5dj30ui02jmy3.jpg) \n\n非凸问题则求解比较困难，实际上大部分的解法都是将非凸问题转化为凸问题。\n\n \n\n> P，NP，NP-hard， NPC则是计算复杂度的表示。\n\n- P代表多项式内可求解的问题\n- NP代表多项式内可验证的问题\n- NP-hard表示所有NP问题都可以归约到该问题的问题\n-  NPC表示即是NP-hard，本身又是NP问题的问题\n\n \n\n如果证明P=NP，其实意味着世界上所有的密码系统都被破解了。\n\n因为加密是P的，解密验证是NP的，如果P=NP，说明解密也可以是P的，也就是任何解密算法都可以是多项式内求解的，那么解密就没有时间成本了，随意破解了。\n\n\n\n> 组合优化、混合整数规划等问题一般都是NP-hard问题，例如TSP，背包问题、汉密尔顿回路问题等等。\n\n因为P应该不等NP，这种问题也就是说很难找到多项式时间内的求解算法得到最优解。现在对这些算法的最优求解一般都是指数或者阶乘复杂度的，可参考acm题，算法的话有分支定界之类的。\n\n但如果想要求解近似解，就可以是多项式时间的算法，例如先松弛成凸问题啊之类的。\n\n \n\n> 以前一直以为非凸问题就是没有多项式时间的算法求最优解，其实我理解错了，非凸问题很多都是可以转成凸问题的，例如log-log convex等问题。\n\n \n\n \n\n> 典型的一些凸函数：\n\n- 仿射函数\n-  绝对值\n- 最大值\n-  p！= 0的所有范数\n-  指数函数\n- a> 1或者 <0的幂函数\n- xlogx\n- 以及一系列的保凸运算。。\n\n![image-20200605162217125](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhmvitpaj30gp07i3zh.jpg) \n\n\n\n> 典型的凸问题(等式约束一定要是仿射的！)：\n\n- 线性规划 （LP）\n- 二次规划  (QP)\n- 半正定规划(不等式约束为LMI，线性矩阵不等式)(SDP)\n- 锥规划(CP)\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhoq7muvj30z50j840g.jpg\" alt=\"image-20200605162259121\" style=\"zoom: 50%;\" />\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhoovacoj30ku0dz0u6.jpg\" alt=\"image-20200605162313667\" style=\"zoom:67%;\" />\n\n\n\n> 对称的正定矩阵一定代表了是个凸锥。\n\n![image-20200605162344236](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhopmtpvj30jr0djgmu.jpg)","source":"_posts/数学/关于凸、P和NP.md","raw":"---\ntitle: 关于凸、P和NP\ndate: 2019-08-27 19:28:44 \ncategories: 数学\n---\n\n> 优化问题本质上分为凸和非凸两大类。\n\n凸问题有着巨大的优势：\n\n- 成熟有效的求解算法求得全局最优解。(内点法、椭圆法、梯度下降法等)\n\n- 计算复杂度基本上是多项式的，基本是P的。\n\n![image-20200605162015414](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhkonh5dj30ui02jmy3.jpg) \n\n非凸问题则求解比较困难，实际上大部分的解法都是将非凸问题转化为凸问题。\n\n \n\n> P，NP，NP-hard， NPC则是计算复杂度的表示。\n\n- P代表多项式内可求解的问题\n- NP代表多项式内可验证的问题\n- NP-hard表示所有NP问题都可以归约到该问题的问题\n-  NPC表示即是NP-hard，本身又是NP问题的问题\n\n \n\n如果证明P=NP，其实意味着世界上所有的密码系统都被破解了。\n\n因为加密是P的，解密验证是NP的，如果P=NP，说明解密也可以是P的，也就是任何解密算法都可以是多项式内求解的，那么解密就没有时间成本了，随意破解了。\n\n\n\n> 组合优化、混合整数规划等问题一般都是NP-hard问题，例如TSP，背包问题、汉密尔顿回路问题等等。\n\n因为P应该不等NP，这种问题也就是说很难找到多项式时间内的求解算法得到最优解。现在对这些算法的最优求解一般都是指数或者阶乘复杂度的，可参考acm题，算法的话有分支定界之类的。\n\n但如果想要求解近似解，就可以是多项式时间的算法，例如先松弛成凸问题啊之类的。\n\n \n\n> 以前一直以为非凸问题就是没有多项式时间的算法求最优解，其实我理解错了，非凸问题很多都是可以转成凸问题的，例如log-log convex等问题。\n\n \n\n \n\n> 典型的一些凸函数：\n\n- 仿射函数\n-  绝对值\n- 最大值\n-  p！= 0的所有范数\n-  指数函数\n- a> 1或者 <0的幂函数\n- xlogx\n- 以及一系列的保凸运算。。\n\n![image-20200605162217125](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhmvitpaj30gp07i3zh.jpg) \n\n\n\n> 典型的凸问题(等式约束一定要是仿射的！)：\n\n- 线性规划 （LP）\n- 二次规划  (QP)\n- 半正定规划(不等式约束为LMI，线性矩阵不等式)(SDP)\n- 锥规划(CP)\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhoq7muvj30z50j840g.jpg\" alt=\"image-20200605162259121\" style=\"zoom: 50%;\" />\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhoovacoj30ku0dz0u6.jpg\" alt=\"image-20200605162313667\" style=\"zoom:67%;\" />\n\n\n\n> 对称的正定矩阵一定代表了是个凸锥。\n\n![image-20200605162344236](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhopmtpvj30jr0djgmu.jpg)","slug":"数学/关于凸、P和NP","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551ob0018jqrr9b5eb9vx","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><blockquote>\n<p>优化问题本质上分为凸和非凸两大类。</p>\n</blockquote>\n<p>凸问题有着巨大的优势：</p>\n<ul>\n<li><p>成熟有效的求解算法求得全局最优解。(内点法、椭圆法、梯度下降法等)</p>\n</li>\n<li><p>计算复杂度基本上是多项式的，基本是P的。</p>\n</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhkonh5dj30ui02jmy3.jpg\" alt=\"image-20200605162015414\"> </p>\n<p>非凸问题则求解比较困难，实际上大部分的解法都是将非凸问题转化为凸问题。</p>\n<blockquote>\n<p>P，NP，NP-hard， NPC则是计算复杂度的表示。</p>\n</blockquote>\n<ul>\n<li>P代表多项式内可求解的问题</li>\n<li>NP代表多项式内可验证的问题</li>\n<li>NP-hard表示所有NP问题都可以归约到该问题的问题</li>\n<li>NPC表示即是NP-hard，本身又是NP问题的问题</li>\n</ul>\n<p>如果证明P=NP，其实意味着世界上所有的密码系统都被破解了。</p>\n<p>因为加密是P的，解密验证是NP的，如果P=NP，说明解密也可以是P的，也就是任何解密算法都可以是多项式内求解的，那么解密就没有时间成本了，随意破解了。</p>\n<blockquote>\n<p>组合优化、混合整数规划等问题一般都是NP-hard问题，例如TSP，背包问题、汉密尔顿回路问题等等。</p>\n</blockquote>\n<p>因为P应该不等NP，这种问题也就是说很难找到多项式时间内的求解算法得到最优解。现在对这些算法的最优求解一般都是指数或者阶乘复杂度的，可参考acm题，算法的话有分支定界之类的。</p>\n<p>但如果想要求解近似解，就可以是多项式时间的算法，例如先松弛成凸问题啊之类的。</p>\n<blockquote>\n<p>以前一直以为非凸问题就是没有多项式时间的算法求最优解，其实我理解错了，非凸问题很多都是可以转成凸问题的，例如log-log convex等问题。</p>\n<p>典型的一些凸函数：</p>\n</blockquote>\n<ul>\n<li>仿射函数</li>\n<li>绝对值</li>\n<li>最大值</li>\n<li>p！= 0的所有范数</li>\n<li>指数函数</li>\n<li>a&gt; 1或者 &lt;0的幂函数</li>\n<li>xlogx</li>\n<li>以及一系列的保凸运算。。</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhmvitpaj30gp07i3zh.jpg\" alt=\"image-20200605162217125\"> </p>\n<blockquote>\n<p>典型的凸问题(等式约束一定要是仿射的！)：</p>\n</blockquote>\n<ul>\n<li>线性规划 （LP）</li>\n<li>二次规划  (QP)</li>\n<li>半正定规划(不等式约束为LMI，线性矩阵不等式)(SDP)</li>\n<li>锥规划(CP)</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhoq7muvj30z50j840g.jpg\" alt=\"image-20200605162259121\" style=\"zoom: 50%;\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhoovacoj30ku0dz0u6.jpg\" alt=\"image-20200605162313667\" style=\"zoom:67%;\"></p>\n<blockquote>\n<p>对称的正定矩阵一定代表了是个凸锥。</p>\n</blockquote>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhopmtpvj30jr0djgmu.jpg\" alt=\"image-20200605162344236\"></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>优化问题本质上分为凸和非凸两大类。</p>\n</blockquote>\n<p>凸问题有着巨大的优势：</p>\n<ul>\n<li><p>成熟有效的求解算法求得全局最优解。(内点法、椭圆法、梯度下降法等)</p>\n</li>\n<li><p>计算复杂度基本上是多项式的，基本是P的。</p>\n</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhkonh5dj30ui02jmy3.jpg\" alt=\"image-20200605162015414\"> </p>\n<p>非凸问题则求解比较困难，实际上大部分的解法都是将非凸问题转化为凸问题。</p>\n<blockquote>\n<p>P，NP，NP-hard， NPC则是计算复杂度的表示。</p>\n</blockquote>\n<ul>\n<li>P代表多项式内可求解的问题</li>\n<li>NP代表多项式内可验证的问题</li>\n<li>NP-hard表示所有NP问题都可以归约到该问题的问题</li>\n<li>NPC表示即是NP-hard，本身又是NP问题的问题</li>\n</ul>\n<p>如果证明P=NP，其实意味着世界上所有的密码系统都被破解了。</p>\n<p>因为加密是P的，解密验证是NP的，如果P=NP，说明解密也可以是P的，也就是任何解密算法都可以是多项式内求解的，那么解密就没有时间成本了，随意破解了。</p>\n<blockquote>\n<p>组合优化、混合整数规划等问题一般都是NP-hard问题，例如TSP，背包问题、汉密尔顿回路问题等等。</p>\n</blockquote>\n<p>因为P应该不等NP，这种问题也就是说很难找到多项式时间内的求解算法得到最优解。现在对这些算法的最优求解一般都是指数或者阶乘复杂度的，可参考acm题，算法的话有分支定界之类的。</p>\n<p>但如果想要求解近似解，就可以是多项式时间的算法，例如先松弛成凸问题啊之类的。</p>\n<blockquote>\n<p>以前一直以为非凸问题就是没有多项式时间的算法求最优解，其实我理解错了，非凸问题很多都是可以转成凸问题的，例如log-log convex等问题。</p>\n<p>典型的一些凸函数：</p>\n</blockquote>\n<ul>\n<li>仿射函数</li>\n<li>绝对值</li>\n<li>最大值</li>\n<li>p！= 0的所有范数</li>\n<li>指数函数</li>\n<li>a&gt; 1或者 &lt;0的幂函数</li>\n<li>xlogx</li>\n<li>以及一系列的保凸运算。。</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhmvitpaj30gp07i3zh.jpg\" alt=\"image-20200605162217125\"> </p>\n<blockquote>\n<p>典型的凸问题(等式约束一定要是仿射的！)：</p>\n</blockquote>\n<ul>\n<li>线性规划 （LP）</li>\n<li>二次规划  (QP)</li>\n<li>半正定规划(不等式约束为LMI，线性矩阵不等式)(SDP)</li>\n<li>锥规划(CP)</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhoq7muvj30z50j840g.jpg\" alt=\"image-20200605162259121\" style=\"zoom: 50%;\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhoovacoj30ku0dz0u6.jpg\" alt=\"image-20200605162313667\" style=\"zoom:67%;\"></p>\n<blockquote>\n<p>对称的正定矩阵一定代表了是个凸锥。</p>\n</blockquote>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhopmtpvj30jr0djgmu.jpg\" alt=\"image-20200605162344236\"></p>\n"},{"title":"内积、叉积和外积","date":"2021-01-07T16:00:00.000Z","_content":"\n\n\n### 内积\n\n首先介绍点积(dot product)，点积是一种接受两个等长的数字序列（通常是坐标向量）、返回单个数字的代数运算。\n\n而内积(inner product)就是两个笛卡尔坐标向量的点积。\n\n符号：$a \\cdot b $\n\n\n\n### 叉积\n\n叉积(cross product)，又称向量积(vector product)。\n\n![image-20210108170711278](https://tva1.sinaimg.cn/large/008eGmZEly1gmgeeg3kivj31c405q3zj.jpg)\n\n\n\n### 外积\n\n首先介绍张量积(tensor product)，记为$\\otimes$，可以应用于不同的上下文中如[向量](https://zh.wikipedia.org/wiki/向量)、[矩阵](https://zh.wikipedia.org/wiki/矩阵)、[张量](https://zh.wikipedia.org/wiki/张量)、[向量空间](https://zh.wikipedia.org/wiki/向量空间)、[代数](https://zh.wikipedia.org/wiki/代数)、[拓扑向量空间](https://zh.wikipedia.org/wiki/拓扑向量空间)和[模](https://zh.wikipedia.org/wiki/模) ，表示最一般的双线性运算。\n\n在矩阵中就是克罗内克积(Kronecker product)：\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmgeihxb8aj30eu05uglq.jpg\" alt=\"image-20210108171101862\" style=\"zoom:50%;\" />\n\n在向量中就是外积(outer product)：\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmgeivje1ej30nu068mxq.jpg\" alt=\"image-20210108171128823\" style=\"zoom:50%;\" />\n\n\n\n### 哈达玛积\n\n![image-20210628171415434](https://tva1.sinaimg.cn/large/008i3skNly1gry3kg98e4j30ve024wet.jpg)","source":"_posts/数学/内积、叉积和外积.md","raw":"---\ntitle: 内积、叉积和外积\ndate: 2021-01-08 \ncategories: 数学\n---\n\n\n\n### 内积\n\n首先介绍点积(dot product)，点积是一种接受两个等长的数字序列（通常是坐标向量）、返回单个数字的代数运算。\n\n而内积(inner product)就是两个笛卡尔坐标向量的点积。\n\n符号：$a \\cdot b $\n\n\n\n### 叉积\n\n叉积(cross product)，又称向量积(vector product)。\n\n![image-20210108170711278](https://tva1.sinaimg.cn/large/008eGmZEly1gmgeeg3kivj31c405q3zj.jpg)\n\n\n\n### 外积\n\n首先介绍张量积(tensor product)，记为$\\otimes$，可以应用于不同的上下文中如[向量](https://zh.wikipedia.org/wiki/向量)、[矩阵](https://zh.wikipedia.org/wiki/矩阵)、[张量](https://zh.wikipedia.org/wiki/张量)、[向量空间](https://zh.wikipedia.org/wiki/向量空间)、[代数](https://zh.wikipedia.org/wiki/代数)、[拓扑向量空间](https://zh.wikipedia.org/wiki/拓扑向量空间)和[模](https://zh.wikipedia.org/wiki/模) ，表示最一般的双线性运算。\n\n在矩阵中就是克罗内克积(Kronecker product)：\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmgeihxb8aj30eu05uglq.jpg\" alt=\"image-20210108171101862\" style=\"zoom:50%;\" />\n\n在向量中就是外积(outer product)：\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmgeivje1ej30nu068mxq.jpg\" alt=\"image-20210108171128823\" style=\"zoom:50%;\" />\n\n\n\n### 哈达玛积\n\n![image-20210628171415434](https://tva1.sinaimg.cn/large/008i3skNly1gry3kg98e4j30ve024wet.jpg)","slug":"数学/内积、叉积和外积","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551oc001cjqrroh79fjhl","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"内积\"><a href=\"#内积\" class=\"headerlink\" title=\"内积\"></a>内积</h3><p>首先介绍点积(dot product)，点积是一种接受两个等长的数字序列（通常是坐标向量）、返回单个数字的代数运算。</p>\n<p>而内积(inner product)就是两个笛卡尔坐标向量的点积。</p>\n<p>符号：$a \\cdot b $</p>\n<h3 id=\"叉积\"><a href=\"#叉积\" class=\"headerlink\" title=\"叉积\"></a>叉积</h3><p>叉积(cross product)，又称向量积(vector product)。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmgeeg3kivj31c405q3zj.jpg\" alt=\"image-20210108170711278\"></p>\n<h3 id=\"外积\"><a href=\"#外积\" class=\"headerlink\" title=\"外积\"></a>外积</h3><p>首先介绍张量积(tensor product)，记为$\\otimes$，可以应用于不同的上下文中如<a href=\"https://zh.wikipedia.org/wiki/向量\" target=\"_blank\" rel=\"noopener\">向量</a>、<a href=\"https://zh.wikipedia.org/wiki/矩阵\" target=\"_blank\" rel=\"noopener\">矩阵</a>、<a href=\"https://zh.wikipedia.org/wiki/张量\" target=\"_blank\" rel=\"noopener\">张量</a>、<a href=\"https://zh.wikipedia.org/wiki/向量空间\" target=\"_blank\" rel=\"noopener\">向量空间</a>、<a href=\"https://zh.wikipedia.org/wiki/代数\" target=\"_blank\" rel=\"noopener\">代数</a>、<a href=\"https://zh.wikipedia.org/wiki/拓扑向量空间\" target=\"_blank\" rel=\"noopener\">拓扑向量空间</a>和<a href=\"https://zh.wikipedia.org/wiki/模\" target=\"_blank\" rel=\"noopener\">模</a> ，表示最一般的双线性运算。</p>\n<p>在矩阵中就是克罗内克积(Kronecker product)：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmgeihxb8aj30eu05uglq.jpg\" alt=\"image-20210108171101862\" style=\"zoom:50%;\"></p>\n<p>在向量中就是外积(outer product)：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmgeivje1ej30nu068mxq.jpg\" alt=\"image-20210108171128823\" style=\"zoom:50%;\"></p>\n<h3 id=\"哈达玛积\"><a href=\"#哈达玛积\" class=\"headerlink\" title=\"哈达玛积\"></a>哈达玛积</h3><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gry3kg98e4j30ve024wet.jpg\" alt=\"image-20210628171415434\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"内积\"><a href=\"#内积\" class=\"headerlink\" title=\"内积\"></a>内积</h3><p>首先介绍点积(dot product)，点积是一种接受两个等长的数字序列（通常是坐标向量）、返回单个数字的代数运算。</p>\n<p>而内积(inner product)就是两个笛卡尔坐标向量的点积。</p>\n<p>符号：$a \\cdot b $</p>\n<h3 id=\"叉积\"><a href=\"#叉积\" class=\"headerlink\" title=\"叉积\"></a>叉积</h3><p>叉积(cross product)，又称向量积(vector product)。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmgeeg3kivj31c405q3zj.jpg\" alt=\"image-20210108170711278\"></p>\n<h3 id=\"外积\"><a href=\"#外积\" class=\"headerlink\" title=\"外积\"></a>外积</h3><p>首先介绍张量积(tensor product)，记为$\\otimes$，可以应用于不同的上下文中如<a href=\"https://zh.wikipedia.org/wiki/向量\" target=\"_blank\" rel=\"noopener\">向量</a>、<a href=\"https://zh.wikipedia.org/wiki/矩阵\" target=\"_blank\" rel=\"noopener\">矩阵</a>、<a href=\"https://zh.wikipedia.org/wiki/张量\" target=\"_blank\" rel=\"noopener\">张量</a>、<a href=\"https://zh.wikipedia.org/wiki/向量空间\" target=\"_blank\" rel=\"noopener\">向量空间</a>、<a href=\"https://zh.wikipedia.org/wiki/代数\" target=\"_blank\" rel=\"noopener\">代数</a>、<a href=\"https://zh.wikipedia.org/wiki/拓扑向量空间\" target=\"_blank\" rel=\"noopener\">拓扑向量空间</a>和<a href=\"https://zh.wikipedia.org/wiki/模\" target=\"_blank\" rel=\"noopener\">模</a> ，表示最一般的双线性运算。</p>\n<p>在矩阵中就是克罗内克积(Kronecker product)：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmgeihxb8aj30eu05uglq.jpg\" alt=\"image-20210108171101862\" style=\"zoom:50%;\"></p>\n<p>在向量中就是外积(outer product)：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmgeivje1ej30nu068mxq.jpg\" alt=\"image-20210108171128823\" style=\"zoom:50%;\"></p>\n<h3 id=\"哈达玛积\"><a href=\"#哈达玛积\" class=\"headerlink\" title=\"哈达玛积\"></a>哈达玛积</h3><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gry3kg98e4j30ve024wet.jpg\" alt=\"image-20210628171415434\"></p>\n"},{"title":"伪多项式时间复杂度","date":"2020-07-20T11:28:44.000Z","_content":"\n\n\n背包问题是典型的NPC问题，用动规求解的话，其复杂度为$O(mn)$，m为物品个数，n为背包大小。所以你可能奇怪，为什么这个复杂度看着明明是多项式时间，但为什么是NP问题？\n\n\n\n这里就涉及到了伪多项式时间复杂度这个概念，请参考[知乎回答](https://www.zhihu.com/question/20013122/answer/44460397)。\n\n\n\n一句话归纳：\n\n> ​\t如果时间复杂度和输入数据的本身数值大小有关(传统公式里输入数据只代表规模，例如n个int整数)，那就是伪时间复杂度。","source":"_posts/数学/伪多项式时间复杂度.md","raw":"---\ntitle: 伪多项式时间复杂度\ndate: 2020-07-20 19:28:44 \ncategories: 数学\n---\n\n\n\n背包问题是典型的NPC问题，用动规求解的话，其复杂度为$O(mn)$，m为物品个数，n为背包大小。所以你可能奇怪，为什么这个复杂度看着明明是多项式时间，但为什么是NP问题？\n\n\n\n这里就涉及到了伪多项式时间复杂度这个概念，请参考[知乎回答](https://www.zhihu.com/question/20013122/answer/44460397)。\n\n\n\n一句话归纳：\n\n> ​\t如果时间复杂度和输入数据的本身数值大小有关(传统公式里输入数据只代表规模，例如n个int整数)，那就是伪时间复杂度。","slug":"数学/伪多项式时间复杂度","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551oc001ejqrrgjo6gx06","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>背包问题是典型的NPC问题，用动规求解的话，其复杂度为$O(mn)$，m为物品个数，n为背包大小。所以你可能奇怪，为什么这个复杂度看着明明是多项式时间，但为什么是NP问题？</p>\n<p>这里就涉及到了伪多项式时间复杂度这个概念，请参考<a href=\"https://www.zhihu.com/question/20013122/answer/44460397\" target=\"_blank\" rel=\"noopener\">知乎回答</a>。</p>\n<p>一句话归纳：</p>\n<blockquote>\n<p>​    如果时间复杂度和输入数据的本身数值大小有关(传统公式里输入数据只代表规模，例如n个int整数)，那就是伪时间复杂度。</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<p>背包问题是典型的NPC问题，用动规求解的话，其复杂度为$O(mn)$，m为物品个数，n为背包大小。所以你可能奇怪，为什么这个复杂度看着明明是多项式时间，但为什么是NP问题？</p>\n<p>这里就涉及到了伪多项式时间复杂度这个概念，请参考<a href=\"https://www.zhihu.com/question/20013122/answer/44460397\" target=\"_blank\" rel=\"noopener\">知乎回答</a>。</p>\n<p>一句话归纳：</p>\n<blockquote>\n<p>​    如果时间复杂度和输入数据的本身数值大小有关(传统公式里输入数据只代表规模，例如n个int整数)，那就是伪时间复杂度。</p>\n</blockquote>\n"},{"title":"可导和可微","date":"2019-08-26T11:28:44.000Z","_content":"\n一般可导指可偏导，可微指可全微分，也就是各个方向都可偏导，存在一个与其相切的平面。\n\n处处偏导又不一定可微，参考圆锥体。\n\n![image-20200605162544872](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhqevzrfj30l10g3jy9.jpg)","source":"_posts/数学/可导和可微.md","raw":"---\ntitle: 可导和可微\ndate: 2019-08-26 19:28:44 \ncategories: 数学\n---\n\n一般可导指可偏导，可微指可全微分，也就是各个方向都可偏导，存在一个与其相切的平面。\n\n处处偏导又不一定可微，参考圆锥体。\n\n![image-20200605162544872](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhqevzrfj30l10g3jy9.jpg)","slug":"数学/可导和可微","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551od001ijqrr9zummokm","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>一般可导指可偏导，可微指可全微分，也就是各个方向都可偏导，存在一个与其相切的平面。</p>\n<p>处处偏导又不一定可微，参考圆锥体。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhqevzrfj30l10g3jy9.jpg\" alt=\"image-20200605162544872\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>一般可导指可偏导，可微指可全微分，也就是各个方向都可偏导，存在一个与其相切的平面。</p>\n<p>处处偏导又不一定可微，参考圆锥体。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhqevzrfj30l10g3jy9.jpg\" alt=\"image-20200605162544872\"></p>\n"},{"title":"Uplift model理解","date":"2022-10-24T16:00:00.000Z","_content":"\n\n\n# 背景\n\n在一些文档中看到了uplift模型，此类模型在一些用户增长(营销发券)，甚至广告模型中都有用到，因此做了一些查阅，发现确实是个蛮有意思的方向，从另一个切入点来建模广告营销场景，整理成blog记录下。\n\n[参考文献](https://www.6aiq.com/article/1585121131929)\n\n\n\n# 建模\n\n<img src=\"https://tva1.sinaimg.cn/large/008vxvgGgy1h7hom6obdxj30mg0gydh0.jpg\" alt=\"image-20221025174957436\" style=\"zoom: 67%;\" />\n\n以cvr模型为例，传统的cvr模型预估的是假设给用户曝光广告后的转化率，而没有考虑假设不曝光广告的自然转化率，uplift建模的则是该差值，并且期望找到的用户群体为：未曝光则不转化，曝光后则转化的这类群体。\n\n\n\n# 算法\n\nuplift算法有多种：\n\n- two model: 本质上还是两个cvr模型，一个是有曝光样本，一个是自然样本，建模两个模型，然后差值算uplift\n- one model: 本质还是建模cvr，只是将曝光与否作为特征送入模型\n- 基于树模型的uplift model: 直接建模uplift，方法比较巧妙，借鉴了决策树的思想，期望让分裂的左右子树的uplift差异尽可能大。\n\n评估：auuc方法\n","source":"_posts/搜推广/uplift model理解.md","raw":"---\ntitle: Uplift model理解\ndate: 2022-10-25\ncategories: 搜推广\n---\n\n\n\n# 背景\n\n在一些文档中看到了uplift模型，此类模型在一些用户增长(营销发券)，甚至广告模型中都有用到，因此做了一些查阅，发现确实是个蛮有意思的方向，从另一个切入点来建模广告营销场景，整理成blog记录下。\n\n[参考文献](https://www.6aiq.com/article/1585121131929)\n\n\n\n# 建模\n\n<img src=\"https://tva1.sinaimg.cn/large/008vxvgGgy1h7hom6obdxj30mg0gydh0.jpg\" alt=\"image-20221025174957436\" style=\"zoom: 67%;\" />\n\n以cvr模型为例，传统的cvr模型预估的是假设给用户曝光广告后的转化率，而没有考虑假设不曝光广告的自然转化率，uplift建模的则是该差值，并且期望找到的用户群体为：未曝光则不转化，曝光后则转化的这类群体。\n\n\n\n# 算法\n\nuplift算法有多种：\n\n- two model: 本质上还是两个cvr模型，一个是有曝光样本，一个是自然样本，建模两个模型，然后差值算uplift\n- one model: 本质还是建模cvr，只是将曝光与否作为特征送入模型\n- 基于树模型的uplift model: 直接建模uplift，方法比较巧妙，借鉴了决策树的思想，期望让分裂的左右子树的uplift差异尽可能大。\n\n评估：auuc方法\n","slug":"搜推广/uplift model理解","published":1,"updated":"2022-10-25T11:46:08.282Z","_id":"cl9o551od001kjqrr601f2cnb","comments":1,"layout":"post","photos":[],"link":"","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h1><p>在一些文档中看到了uplift模型，此类模型在一些用户增长(营销发券)，甚至广告模型中都有用到，因此做了一些查阅，发现确实是个蛮有意思的方向，从另一个切入点来建模广告营销场景，整理成blog记录下。</p>\n<p><a href=\"https://www.6aiq.com/article/1585121131929\" target=\"_blank\" rel=\"noopener\">参考文献</a></p>\n<h1 id=\"建模\"><a href=\"#建模\" class=\"headerlink\" title=\"建模\"></a>建模</h1><p><img src=\"https://tva1.sinaimg.cn/large/008vxvgGgy1h7hom6obdxj30mg0gydh0.jpg\" alt=\"image-20221025174957436\" style=\"zoom: 67%;\"></p>\n<p>以cvr模型为例，传统的cvr模型预估的是假设给用户曝光广告后的转化率，而没有考虑假设不曝光广告的自然转化率，uplift建模的则是该差值，并且期望找到的用户群体为：未曝光则不转化，曝光后则转化的这类群体。</p>\n<h1 id=\"算法\"><a href=\"#算法\" class=\"headerlink\" title=\"算法\"></a>算法</h1><p>uplift算法有多种：</p>\n<ul>\n<li>two model: 本质上还是两个cvr模型，一个是有曝光样本，一个是自然样本，建模两个模型，然后差值算uplift</li>\n<li>one model: 本质还是建模cvr，只是将曝光与否作为特征送入模型</li>\n<li>基于树模型的uplift model: 直接建模uplift，方法比较巧妙，借鉴了决策树的思想，期望让分裂的左右子树的uplift差异尽可能大。</li>\n</ul>\n<p>评估：auuc方法</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h1><p>在一些文档中看到了uplift模型，此类模型在一些用户增长(营销发券)，甚至广告模型中都有用到，因此做了一些查阅，发现确实是个蛮有意思的方向，从另一个切入点来建模广告营销场景，整理成blog记录下。</p>\n<p><a href=\"https://www.6aiq.com/article/1585121131929\" target=\"_blank\" rel=\"noopener\">参考文献</a></p>\n<h1 id=\"建模\"><a href=\"#建模\" class=\"headerlink\" title=\"建模\"></a>建模</h1><p><img src=\"https://tva1.sinaimg.cn/large/008vxvgGgy1h7hom6obdxj30mg0gydh0.jpg\" alt=\"image-20221025174957436\" style=\"zoom: 67%;\"></p>\n<p>以cvr模型为例，传统的cvr模型预估的是假设给用户曝光广告后的转化率，而没有考虑假设不曝光广告的自然转化率，uplift建模的则是该差值，并且期望找到的用户群体为：未曝光则不转化，曝光后则转化的这类群体。</p>\n<h1 id=\"算法\"><a href=\"#算法\" class=\"headerlink\" title=\"算法\"></a>算法</h1><p>uplift算法有多种：</p>\n<ul>\n<li>two model: 本质上还是两个cvr模型，一个是有曝光样本，一个是自然样本，建模两个模型，然后差值算uplift</li>\n<li>one model: 本质还是建模cvr，只是将曝光与否作为特征送入模型</li>\n<li>基于树模型的uplift model: 直接建模uplift，方法比较巧妙，借鉴了决策树的思想，期望让分裂的左右子树的uplift差异尽可能大。</li>\n</ul>\n<p>评估：auuc方法</p>\n"},{"title":"拉格朗日对偶","date":"2019-08-26T11:28:44.000Z","_content":"\n\n\n- 拉格朗日对偶问题的上界一定小于原问题的下界：\n\n![image-20200605162458767](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhpm71pqj30rb09mac6.jpg)\n\n- 拉格朗日强对偶条件：\n\n对于凸问题，不等式约束严格可行，存在<0， \n\n \n\n- 对于凸问题，KKT条件满足，则全局最优点，KKT条件是充分必要条件；对于优化问题，KKT是必要条件。\n\n ","source":"_posts/数学/拉格朗日对偶.md","raw":"---\ntitle: 拉格朗日对偶\ndate: 2019-08-26 19:28:44 \ncategories: 数学\n---\n\n\n\n- 拉格朗日对偶问题的上界一定小于原问题的下界：\n\n![image-20200605162458767](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhpm71pqj30rb09mac6.jpg)\n\n- 拉格朗日强对偶条件：\n\n对于凸问题，不等式约束严格可行，存在<0， \n\n \n\n- 对于凸问题，KKT条件满足，则全局最优点，KKT条件是充分必要条件；对于优化问题，KKT是必要条件。\n\n ","slug":"数学/拉格朗日对偶","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551oe001njqrrvw7gu8s8","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><ul>\n<li>拉格朗日对偶问题的上界一定小于原问题的下界：</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhpm71pqj30rb09mac6.jpg\" alt=\"image-20200605162458767\"></p>\n<ul>\n<li>拉格朗日强对偶条件：</li>\n</ul>\n<p>对于凸问题，不等式约束严格可行，存在&lt;0， </p>\n<ul>\n<li>对于凸问题，KKT条件满足，则全局最优点，KKT条件是充分必要条件；对于优化问题，KKT是必要条件。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li>拉格朗日对偶问题的上界一定小于原问题的下界：</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhpm71pqj30rb09mac6.jpg\" alt=\"image-20200605162458767\"></p>\n<ul>\n<li>拉格朗日强对偶条件：</li>\n</ul>\n<p>对于凸问题，不等式约束严格可行，存在&lt;0， </p>\n<ul>\n<li>对于凸问题，KKT条件满足，则全局最优点，KKT条件是充分必要条件；对于优化问题，KKT是必要条件。</li>\n</ul>\n"},{"title":"整数规划中的分支定界和分支切割","date":"2019-08-28T11:28:44.000Z","_content":"\n- branch and bound： 分支定界\n\n- branch and cut：分支切割\n\n \n\n![image-20200605161627142](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhgs60g1j30lo0det98.jpg)\n\n例如一个问题：\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhihzolmj30d80ao40p.jpg\" alt=\"image-20200605161805736\" style=\"zoom: 50%;\" />\n\n<img src=\"/Users/didi/Library/Application Support/typora-user-images/image-20200605161826739.png\" alt=\"image-20200605161826739\" style=\"zoom:67%;\" />\n\nbranch and cut： 在每个node上寻找切割不等式，最后的得到的最优解很可能大于上界，该node就被切割掉了。\n\n如何选址cut不等式就是一门学问了。。有实数切割UserCut，也有整数切割LazyCut\n\n \n\n","source":"_posts/数学/整数规划中的分支定界和分支切割.md","raw":"---\ntitle: 整数规划中的分支定界和分支切割\ndate: 2019-08-28 19:28:44 \ncategories: 数学\n---\n\n- branch and bound： 分支定界\n\n- branch and cut：分支切割\n\n \n\n![image-20200605161627142](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhgs60g1j30lo0det98.jpg)\n\n例如一个问题：\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhihzolmj30d80ao40p.jpg\" alt=\"image-20200605161805736\" style=\"zoom: 50%;\" />\n\n<img src=\"/Users/didi/Library/Application Support/typora-user-images/image-20200605161826739.png\" alt=\"image-20200605161826739\" style=\"zoom:67%;\" />\n\nbranch and cut： 在每个node上寻找切割不等式，最后的得到的最优解很可能大于上界，该node就被切割掉了。\n\n如何选址cut不等式就是一门学问了。。有实数切割UserCut，也有整数切割LazyCut\n\n \n\n","slug":"数学/整数规划中的分支定界和分支切割","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551oe001pjqrr58mmv7nd","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><ul>\n<li><p>branch and bound： 分支定界</p>\n</li>\n<li><p>branch and cut：分支切割</p>\n</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhgs60g1j30lo0det98.jpg\" alt=\"image-20200605161627142\"></p>\n<p>例如一个问题：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhihzolmj30d80ao40p.jpg\" alt=\"image-20200605161805736\" style=\"zoom: 50%;\"></p>\n<p><img src=\"/Users/didi/Library/Application Support/typora-user-images/image-20200605161826739.png\" alt=\"image-20200605161826739\" style=\"zoom:67%;\"></p>\n<p>branch and cut： 在每个node上寻找切割不等式，最后的得到的最优解很可能大于上界，该node就被切割掉了。</p>\n<p>如何选址cut不等式就是一门学问了。。有实数切割UserCut，也有整数切割LazyCut</p>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li><p>branch and bound： 分支定界</p>\n</li>\n<li><p>branch and cut：分支切割</p>\n</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhgs60g1j30lo0det98.jpg\" alt=\"image-20200605161627142\"></p>\n<p>例如一个问题：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhihzolmj30d80ao40p.jpg\" alt=\"image-20200605161805736\" style=\"zoom: 50%;\"></p>\n<p><img src=\"/Users/didi/Library/Application Support/typora-user-images/image-20200605161826739.png\" alt=\"image-20200605161826739\" style=\"zoom:67%;\"></p>\n<p>branch and cut： 在每个node上寻找切割不等式，最后的得到的最优解很可能大于上界，该node就被切割掉了。</p>\n<p>如何选址cut不等式就是一门学问了。。有实数切割UserCut，也有整数切割LazyCut</p>\n"},{"title":"计算复杂度通用公式","date":"2020-06-21T16:00:00.000Z","_content":"\n\n\n计算复杂度的计算存在一个通用公式，对于$T(n) = a*T(n / b) + c * n^k$ 这种，复杂度为：\n\n如果$k > log_b(a)$，则$T(n) = O(n^k)$\n\n如果$k < log_b(a)$，则$T(n) = O(n^{log_b(a)})$\n\n如果$k = log_b(a)$，则$T(n) = O(n^klog(n))$\n\n\n\n> 一个例子：\n>\n> $T(n) = 25*T(n/5) + n^2$, 则$T(n) = n^2log(n)$\n\n","source":"_posts/数学/计算复杂度公式.md","raw":"---\ntitle: 计算复杂度通用公式\ndate: 2020-06-22\ncategories: 数学\n---\n\n\n\n计算复杂度的计算存在一个通用公式，对于$T(n) = a*T(n / b) + c * n^k$ 这种，复杂度为：\n\n如果$k > log_b(a)$，则$T(n) = O(n^k)$\n\n如果$k < log_b(a)$，则$T(n) = O(n^{log_b(a)})$\n\n如果$k = log_b(a)$，则$T(n) = O(n^klog(n))$\n\n\n\n> 一个例子：\n>\n> $T(n) = 25*T(n/5) + n^2$, 则$T(n) = n^2log(n)$\n\n","slug":"数学/计算复杂度公式","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551og001sjqrrh4bi3hnm","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>计算复杂度的计算存在一个通用公式，对于$T(n) = a<em>T(n / b) + c </em> n^k$ 这种，复杂度为：</p>\n<p>如果$k &gt; log_b(a)$，则$T(n) = O(n^k)$</p>\n<p>如果$k &lt; log_b(a)$，则$T(n) = O(n^{log_b(a)})$</p>\n<p>如果$k = log_b(a)$，则$T(n) = O(n^klog(n))$</p>\n<blockquote>\n<p>一个例子：</p>\n<p>$T(n) = 25*T(n/5) + n^2$, 则$T(n) = n^2log(n)$</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<p>计算复杂度的计算存在一个通用公式，对于$T(n) = a<em>T(n / b) + c </em> n^k$ 这种，复杂度为：</p>\n<p>如果$k &gt; log_b(a)$，则$T(n) = O(n^k)$</p>\n<p>如果$k &lt; log_b(a)$，则$T(n) = O(n^{log_b(a)})$</p>\n<p>如果$k = log_b(a)$，则$T(n) = O(n^klog(n))$</p>\n<blockquote>\n<p>一个例子：</p>\n<p>$T(n) = 25*T(n/5) + n^2$, 则$T(n) = n^2log(n)$</p>\n</blockquote>\n"},{"title":"CART与普通决策树的区别","date":"2019-04-29T11:28:44.000Z","_content":"\n\n\nCART可以说是最常用的数，gbdt,xgboost等等...\n\n归纳一下其与普通决策树（ID3，C4.5）的区别：\n\n- 既可以分类，也可以回归。在分类时使用基尼系数，在回归时使用平方误差。\n- 只划分左右子树，也就是生成一个二叉树。普通决策树生成多个子树\n- 特征在被选择后，在接下来的树中还能被继续使用。普通决策树只使用特征一次。\n- 连续特征，n个值，从n-1个中间值中选择；离散特征，n个值，有$2^{(n-1)} - 1$个选择可能(通常是one hot编码)。\n\n","source":"_posts/机器学习/CART与普通决策树的区别.md","raw":"---\ntitle: CART与普通决策树的区别\ndate: 2019-04-29 19:28:44 \ntags: CART\ncategories: 机器学习\n---\n\n\n\nCART可以说是最常用的数，gbdt,xgboost等等...\n\n归纳一下其与普通决策树（ID3，C4.5）的区别：\n\n- 既可以分类，也可以回归。在分类时使用基尼系数，在回归时使用平方误差。\n- 只划分左右子树，也就是生成一个二叉树。普通决策树生成多个子树\n- 特征在被选择后，在接下来的树中还能被继续使用。普通决策树只使用特征一次。\n- 连续特征，n个值，从n-1个中间值中选择；离散特征，n个值，有$2^{(n-1)} - 1$个选择可能(通常是one hot编码)。\n\n","slug":"机器学习/CART与普通决策树的区别","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551og001ujqrrzi9rqj6k","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>CART可以说是最常用的数，gbdt,xgboost等等…</p>\n<p>归纳一下其与普通决策树（ID3，C4.5）的区别：</p>\n<ul>\n<li>既可以分类，也可以回归。在分类时使用基尼系数，在回归时使用平方误差。</li>\n<li>只划分左右子树，也就是生成一个二叉树。普通决策树生成多个子树</li>\n<li>特征在被选择后，在接下来的树中还能被继续使用。普通决策树只使用特征一次。</li>\n<li>连续特征，n个值，从n-1个中间值中选择；离散特征，n个值，有$2^{(n-1)} - 1$个选择可能(通常是one hot编码)。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>CART可以说是最常用的数，gbdt,xgboost等等…</p>\n<p>归纳一下其与普通决策树（ID3，C4.5）的区别：</p>\n<ul>\n<li>既可以分类，也可以回归。在分类时使用基尼系数，在回归时使用平方误差。</li>\n<li>只划分左右子树，也就是生成一个二叉树。普通决策树生成多个子树</li>\n<li>特征在被选择后，在接下来的树中还能被继续使用。普通决策树只使用特征一次。</li>\n<li>连续特征，n个值，从n-1个中间值中选择；离散特征，n个值，有$2^{(n-1)} - 1$个选择可能(通常是one hot编码)。</li>\n</ul>\n"},{"title":"XGBoost和LightGBM调参","date":"2018-12-05T11:28:44.000Z","_content":"\n\n有个应用上的重大区别：\n\n- Xgboost只处理数值特征，因此Xgboost无法直接处理离散特征(categorical feature)，需要数据预处理，要么labelEncoder转换为数值特征，当做连续值处理，要么one-hot编码，当做离散值处理。\n\n- LightGBM则有对离散特征的单独处理，需要首先利用labelEncoder转换为数值，然后会利用[On Grouping for Maximum Homogeneity](http://link.zhihu.com/?target=https%3A//www.researchgate.net/publication/242580910_On_Grouping_for_Maximum_Homogeneity)提到的算法找到最优值，是从2^(n-1)-1个分区划分中选出最优optimal split，而不像OHE一样是n个划分，因此效果优于OHE。\n\n  ![image-20200605155935227](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgz8kjolj30hp0b7dhl.jpg)","source":"_posts/机器学习/Xgboost和LightGBM调参.md","raw":"---\ntitle: XGBoost和LightGBM调参\ndate: 2018-12-05 19:28:44 \ntags: XGBoost\ncategories: 机器学习\n---\n\n\n有个应用上的重大区别：\n\n- Xgboost只处理数值特征，因此Xgboost无法直接处理离散特征(categorical feature)，需要数据预处理，要么labelEncoder转换为数值特征，当做连续值处理，要么one-hot编码，当做离散值处理。\n\n- LightGBM则有对离散特征的单独处理，需要首先利用labelEncoder转换为数值，然后会利用[On Grouping for Maximum Homogeneity](http://link.zhihu.com/?target=https%3A//www.researchgate.net/publication/242580910_On_Grouping_for_Maximum_Homogeneity)提到的算法找到最优值，是从2^(n-1)-1个分区划分中选出最优optimal split，而不像OHE一样是n个划分，因此效果优于OHE。\n\n  ![image-20200605155935227](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgz8kjolj30hp0b7dhl.jpg)","slug":"机器学习/Xgboost和LightGBM调参","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551oh001xjqrr5kgple8s","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>有个应用上的重大区别：</p>\n<ul>\n<li><p>Xgboost只处理数值特征，因此Xgboost无法直接处理离散特征(categorical feature)，需要数据预处理，要么labelEncoder转换为数值特征，当做连续值处理，要么one-hot编码，当做离散值处理。</p>\n</li>\n<li><p>LightGBM则有对离散特征的单独处理，需要首先利用labelEncoder转换为数值，然后会利用<a href=\"http://link.zhihu.com/?target=https%3A//www.researchgate.net/publication/242580910_On_Grouping_for_Maximum_Homogeneity\" target=\"_blank\" rel=\"noopener\">On Grouping for Maximum Homogeneity</a>提到的算法找到最优值，是从2^(n-1)-1个分区划分中选出最优optimal split，而不像OHE一样是n个划分，因此效果优于OHE。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgz8kjolj30hp0b7dhl.jpg\" alt=\"image-20200605155935227\"></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>有个应用上的重大区别：</p>\n<ul>\n<li><p>Xgboost只处理数值特征，因此Xgboost无法直接处理离散特征(categorical feature)，需要数据预处理，要么labelEncoder转换为数值特征，当做连续值处理，要么one-hot编码，当做离散值处理。</p>\n</li>\n<li><p>LightGBM则有对离散特征的单独处理，需要首先利用labelEncoder转换为数值，然后会利用<a href=\"http://link.zhihu.com/?target=https%3A//www.researchgate.net/publication/242580910_On_Grouping_for_Maximum_Homogeneity\" target=\"_blank\" rel=\"noopener\">On Grouping for Maximum Homogeneity</a>提到的算法找到最优值，是从2^(n-1)-1个分区划分中选出最优optimal split，而不像OHE一样是n个划分，因此效果优于OHE。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgz8kjolj30hp0b7dhl.jpg\" alt=\"image-20200605155935227\"></p>\n</li>\n</ul>\n"},{"title":"时间序列中的随机过程","date":"2020-07-20T11:28:44.000Z","_content":"\n\n\n哎，心累，上个月mac电脑进水导致硬盘坏了，写好的4-5篇博客全部丢失了，包含写好的一系列时间序列文章。懒得再码一遍了，我就贴一下之前的参考博客和课程吧。\n\n- 总结得很好的[博客](https://blog.nex3z.com/tag/time-series/)，包含平稳性介绍、自相关函数、偏自相关函数、ARIMA模型、指数平滑模型等知识点。\n\n- 北大金融数学硕士课程：[金融时间序列分析讲义](http://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/index.html) ，包含线性时间序列(ARMIA模型、指数平滑、单位根过程等)，资产波动率模型(ARCH模型，GARCH模型等)\n- 北大金融数学系本科课程：[金融事件序列分析](http://www.math.pku.edu.cn/teachers/lidf/course/atsa/atsanotes/html/_atsanotes/index.html)，以基础为主。\n\n","source":"_posts/数学/时间序列中随机过程.md","raw":"---\ntitle: 时间序列中的随机过程\ndate: 2020-07-20 19:28:44 \ncategories: 数学\ntags: 时间序列\n---\n\n\n\n哎，心累，上个月mac电脑进水导致硬盘坏了，写好的4-5篇博客全部丢失了，包含写好的一系列时间序列文章。懒得再码一遍了，我就贴一下之前的参考博客和课程吧。\n\n- 总结得很好的[博客](https://blog.nex3z.com/tag/time-series/)，包含平稳性介绍、自相关函数、偏自相关函数、ARIMA模型、指数平滑模型等知识点。\n\n- 北大金融数学硕士课程：[金融时间序列分析讲义](http://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/index.html) ，包含线性时间序列(ARMIA模型、指数平滑、单位根过程等)，资产波动率模型(ARCH模型，GARCH模型等)\n- 北大金融数学系本科课程：[金融事件序列分析](http://www.math.pku.edu.cn/teachers/lidf/course/atsa/atsanotes/html/_atsanotes/index.html)，以基础为主。\n\n","slug":"数学/时间序列中随机过程","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551oh001zjqrrus0alk49","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>哎，心累，上个月mac电脑进水导致硬盘坏了，写好的4-5篇博客全部丢失了，包含写好的一系列时间序列文章。懒得再码一遍了，我就贴一下之前的参考博客和课程吧。</p>\n<ul>\n<li><p>总结得很好的<a href=\"https://blog.nex3z.com/tag/time-series/\" target=\"_blank\" rel=\"noopener\">博客</a>，包含平稳性介绍、自相关函数、偏自相关函数、ARIMA模型、指数平滑模型等知识点。</p>\n</li>\n<li><p>北大金融数学硕士课程：<a href=\"http://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/index.html\" target=\"_blank\" rel=\"noopener\">金融时间序列分析讲义</a> ，包含线性时间序列(ARMIA模型、指数平滑、单位根过程等)，资产波动率模型(ARCH模型，GARCH模型等)</p>\n</li>\n<li>北大金融数学系本科课程：<a href=\"http://www.math.pku.edu.cn/teachers/lidf/course/atsa/atsanotes/html/_atsanotes/index.html\" target=\"_blank\" rel=\"noopener\">金融事件序列分析</a>，以基础为主。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>哎，心累，上个月mac电脑进水导致硬盘坏了，写好的4-5篇博客全部丢失了，包含写好的一系列时间序列文章。懒得再码一遍了，我就贴一下之前的参考博客和课程吧。</p>\n<ul>\n<li><p>总结得很好的<a href=\"https://blog.nex3z.com/tag/time-series/\" target=\"_blank\" rel=\"noopener\">博客</a>，包含平稳性介绍、自相关函数、偏自相关函数、ARIMA模型、指数平滑模型等知识点。</p>\n</li>\n<li><p>北大金融数学硕士课程：<a href=\"http://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/index.html\" target=\"_blank\" rel=\"noopener\">金融时间序列分析讲义</a> ，包含线性时间序列(ARMIA模型、指数平滑、单位根过程等)，资产波动率模型(ARCH模型，GARCH模型等)</p>\n</li>\n<li>北大金融数学系本科课程：<a href=\"http://www.math.pku.edu.cn/teachers/lidf/course/atsa/atsanotes/html/_atsanotes/index.html\" target=\"_blank\" rel=\"noopener\">金融事件序列分析</a>，以基础为主。</li>\n</ul>\n"},{"title":"XGBoost调参","date":"2018-06-20T11:28:44.000Z","_content":"\n\n\n- 选择较高的**学习速率(learning rate)**。一般情况下，学习速率的值为0.1。但是，对于不同的问题，理想的学习速率有时候会在0.05到0.3之间波动。选择**对应于此学习速率的理想决策树数量**。XGBoost有一个很有用的函数“cv”，这个函数可以在每一次迭代中使用交叉验证，并返回理想的决策树数量。\n\n- 对于给定的学习速率和决策树数量，进行**决策树特定参数调优**(max_depth, min_child_weight, gamma, subsample, colsample_bytree)。在确定一棵树的过程中，我们可以选择不同的参数，待会儿我会举例说明。\n\n- xgboost的**正则化参数**的调优。(lambda, alpha)。这些参数可以降低模型的复杂度，从而提高模型的表现。\n\n- 降低学习速率，确定理想参数。\n\n \n\nxgboost第n颗树的第n层的分裂准则：\n\n![image-20200605153827635](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgd9bwxhj30ns0c7dj5.jpg)","source":"_posts/机器学习/xgboost调参.md","raw":"---\ntitle: XGBoost调参\ndate: 2018-06-20 19:28:44 \ntags: XGBoost\ncategories: 机器学习\n---\n\n\n\n- 选择较高的**学习速率(learning rate)**。一般情况下，学习速率的值为0.1。但是，对于不同的问题，理想的学习速率有时候会在0.05到0.3之间波动。选择**对应于此学习速率的理想决策树数量**。XGBoost有一个很有用的函数“cv”，这个函数可以在每一次迭代中使用交叉验证，并返回理想的决策树数量。\n\n- 对于给定的学习速率和决策树数量，进行**决策树特定参数调优**(max_depth, min_child_weight, gamma, subsample, colsample_bytree)。在确定一棵树的过程中，我们可以选择不同的参数，待会儿我会举例说明。\n\n- xgboost的**正则化参数**的调优。(lambda, alpha)。这些参数可以降低模型的复杂度，从而提高模型的表现。\n\n- 降低学习速率，确定理想参数。\n\n \n\nxgboost第n颗树的第n层的分裂准则：\n\n![image-20200605153827635](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgd9bwxhj30ns0c7dj5.jpg)","slug":"机器学习/xgboost调参","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551oj0022jqrr45mc7xxd","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><ul>\n<li><p>选择较高的<strong>学习速率(learning rate)</strong>。一般情况下，学习速率的值为0.1。但是，对于不同的问题，理想的学习速率有时候会在0.05到0.3之间波动。选择<strong>对应于此学习速率的理想决策树数量</strong>。XGBoost有一个很有用的函数“cv”，这个函数可以在每一次迭代中使用交叉验证，并返回理想的决策树数量。</p>\n</li>\n<li><p>对于给定的学习速率和决策树数量，进行<strong>决策树特定参数调优</strong>(max_depth, min_child_weight, gamma, subsample, colsample_bytree)。在确定一棵树的过程中，我们可以选择不同的参数，待会儿我会举例说明。</p>\n</li>\n<li><p>xgboost的<strong>正则化参数</strong>的调优。(lambda, alpha)。这些参数可以降低模型的复杂度，从而提高模型的表现。</p>\n</li>\n<li><p>降低学习速率，确定理想参数。</p>\n</li>\n</ul>\n<p>xgboost第n颗树的第n层的分裂准则：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgd9bwxhj30ns0c7dj5.jpg\" alt=\"image-20200605153827635\"></p>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li><p>选择较高的<strong>学习速率(learning rate)</strong>。一般情况下，学习速率的值为0.1。但是，对于不同的问题，理想的学习速率有时候会在0.05到0.3之间波动。选择<strong>对应于此学习速率的理想决策树数量</strong>。XGBoost有一个很有用的函数“cv”，这个函数可以在每一次迭代中使用交叉验证，并返回理想的决策树数量。</p>\n</li>\n<li><p>对于给定的学习速率和决策树数量，进行<strong>决策树特定参数调优</strong>(max_depth, min_child_weight, gamma, subsample, colsample_bytree)。在确定一棵树的过程中，我们可以选择不同的参数，待会儿我会举例说明。</p>\n</li>\n<li><p>xgboost的<strong>正则化参数</strong>的调优。(lambda, alpha)。这些参数可以降低模型的复杂度，从而提高模型的表现。</p>\n</li>\n<li><p>降低学习速率，确定理想参数。</p>\n</li>\n</ul>\n<p>xgboost第n颗树的第n层的分裂准则：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgd9bwxhj30ns0c7dj5.jpg\" alt=\"image-20200605153827635\"></p>\n"},{"title":"关于PCA和SVD分解","date":"2020-04-24T16:00:00.000Z","_content":"","source":"_posts/机器学习/关于PCA和SVD分解.md","raw":"---\ntitle: 关于PCA和SVD分解\ndate: 2020-04-25 \ncategories: 机器学习\n---\n","slug":"机器学习/关于PCA和SVD分解","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551ok0023jqrrtof4eir3","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script>","site":{"data":{}},"excerpt":"","more":""},{"title":"关于模型选型","date":"2019-05-16T11:28:44.000Z","_content":"\n模型可以分为高偏差/低方差和低偏差/高方差两种。前者一般指简单的模型，如生成式模型(NB)，后者一般指复杂模型，如判别式模型之类的。\n\n \n\n在学习曲线上来看：\n\n高偏差/低方差：训练样本很少的情况下就可以达到渐进线(低方差)，但是偏差较高，持续增加样本也没用。所以小样本的情况，建议用该类模型。\n\n低偏差/高方差：训练样本很少时，容易过拟合，无法达到渐进线。当训练样本变多时，训练曲线和测试曲线达到渐进线，此时偏差又低，所以该模型适合大样本情况。\n\n","source":"_posts/机器学习/关于模型选型.md","raw":"---\ntitle: 关于模型选型\ndate: 2019-05-16 19:28:44 \ncategories: 机器学习\n---\n\n模型可以分为高偏差/低方差和低偏差/高方差两种。前者一般指简单的模型，如生成式模型(NB)，后者一般指复杂模型，如判别式模型之类的。\n\n \n\n在学习曲线上来看：\n\n高偏差/低方差：训练样本很少的情况下就可以达到渐进线(低方差)，但是偏差较高，持续增加样本也没用。所以小样本的情况，建议用该类模型。\n\n低偏差/高方差：训练样本很少时，容易过拟合，无法达到渐进线。当训练样本变多时，训练曲线和测试曲线达到渐进线，此时偏差又低，所以该模型适合大样本情况。\n\n","slug":"机器学习/关于模型选型","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551ok0027jqrri2c1ns9f","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>模型可以分为高偏差/低方差和低偏差/高方差两种。前者一般指简单的模型，如生成式模型(NB)，后者一般指复杂模型，如判别式模型之类的。</p>\n<p>在学习曲线上来看：</p>\n<p>高偏差/低方差：训练样本很少的情况下就可以达到渐进线(低方差)，但是偏差较高，持续增加样本也没用。所以小样本的情况，建议用该类模型。</p>\n<p>低偏差/高方差：训练样本很少时，容易过拟合，无法达到渐进线。当训练样本变多时，训练曲线和测试曲线达到渐进线，此时偏差又低，所以该模型适合大样本情况。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>模型可以分为高偏差/低方差和低偏差/高方差两种。前者一般指简单的模型，如生成式模型(NB)，后者一般指复杂模型，如判别式模型之类的。</p>\n<p>在学习曲线上来看：</p>\n<p>高偏差/低方差：训练样本很少的情况下就可以达到渐进线(低方差)，但是偏差较高，持续增加样本也没用。所以小样本的情况，建议用该类模型。</p>\n<p>低偏差/高方差：训练样本很少时，容易过拟合，无法达到渐进线。当训练样本变多时，训练曲线和测试曲线达到渐进线，此时偏差又低，所以该模型适合大样本情况。</p>\n"},{"title":"关于特征值分布不均匀的问题","date":"2018-12-06T11:28:44.000Z","_content":"\n之前city_id作为特征后导致模型预测结果差异很大这一点，一直让我耿耿于怀，仔细思考后，其实可以这样解释：\n\n- 首先特征属性不对，我应该将其设为离散特征，做OHE处理，再放入模型训练。\n\n- 特征值分布不均匀，事实上不会影响该特征值的选择，假如该特征值确实区分了样本，即使树的左右子节点样本数量相差很大，也是照样划分啊！\n\n- 之前的结果很大一部分原因，还是类别分布不均匀导致的！杭州的值普遍大且样本多，宁波的值普遍小且样本少，导致结果值偏大，这就类似与分类问题正样本少，负样本多，导致结果偏向于为负。\n\n  ","source":"_posts/机器学习/关于特征值分布不均匀的问题.md","raw":"---\ntitle: 关于特征值分布不均匀的问题\ndate: 2018-12-06 19:28:44 \ntags: 特征工程\ncategories: 机器学习\n---\n\n之前city_id作为特征后导致模型预测结果差异很大这一点，一直让我耿耿于怀，仔细思考后，其实可以这样解释：\n\n- 首先特征属性不对，我应该将其设为离散特征，做OHE处理，再放入模型训练。\n\n- 特征值分布不均匀，事实上不会影响该特征值的选择，假如该特征值确实区分了样本，即使树的左右子节点样本数量相差很大，也是照样划分啊！\n\n- 之前的结果很大一部分原因，还是类别分布不均匀导致的！杭州的值普遍大且样本多，宁波的值普遍小且样本少，导致结果值偏大，这就类似与分类问题正样本少，负样本多，导致结果偏向于为负。\n\n  ","slug":"机器学习/关于特征值分布不均匀的问题","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551ol0029jqrrvaytn3k9","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>之前city_id作为特征后导致模型预测结果差异很大这一点，一直让我耿耿于怀，仔细思考后，其实可以这样解释：</p>\n<ul>\n<li><p>首先特征属性不对，我应该将其设为离散特征，做OHE处理，再放入模型训练。</p>\n</li>\n<li><p>特征值分布不均匀，事实上不会影响该特征值的选择，假如该特征值确实区分了样本，即使树的左右子节点样本数量相差很大，也是照样划分啊！</p>\n</li>\n<li><p>之前的结果很大一部分原因，还是类别分布不均匀导致的！杭州的值普遍大且样本多，宁波的值普遍小且样本少，导致结果值偏大，这就类似与分类问题正样本少，负样本多，导致结果偏向于为负。</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>之前city_id作为特征后导致模型预测结果差异很大这一点，一直让我耿耿于怀，仔细思考后，其实可以这样解释：</p>\n<ul>\n<li><p>首先特征属性不对，我应该将其设为离散特征，做OHE处理，再放入模型训练。</p>\n</li>\n<li><p>特征值分布不均匀，事实上不会影响该特征值的选择，假如该特征值确实区分了样本，即使树的左右子节点样本数量相差很大，也是照样划分啊！</p>\n</li>\n<li><p>之前的结果很大一部分原因，还是类别分布不均匀导致的！杭州的值普遍大且样本多，宁波的值普遍小且样本少，导致结果值偏大，这就类似与分类问题正样本少，负样本多，导致结果偏向于为负。</p>\n</li>\n</ul>\n"},{"title":"关于特征工程","date":"2018-12-06T11:28:44.000Z","_content":"\n特征工程和模型选择是提升算法的两类途径。\n\n- 特征工程：数据清洗，(降维)，特征选择，特征组合。\n- 特征组合变换好坏都有，一方面能提高模型的表达能力，另一方面有可能引起过拟合，增加冗余特征，降低模型解释力。\n  - 特征变换还可以是将连续特征转换为离散特征。\n- 模型的选择和特征工程是耦合的。因为不同模型对特征工程的需求不一样。\n  - 树模型不需要归一化处理，不需要特征选择，因为这些模型都能做到。\n  - 神经网络则不需要特征组合变换。\n  - 广义线性模型的效果则对数据清洗，特征选择，特征组合很敏感。这就是为啥计算广告领域后续衍生了FM,FFM等等\n\n","source":"_posts/机器学习/关于特征工程.md","raw":"---\ntitle: 关于特征工程\ndate: 2018-12-06 19:28:44 \ntags: 特征工程\ncategories: 机器学习\n---\n\n特征工程和模型选择是提升算法的两类途径。\n\n- 特征工程：数据清洗，(降维)，特征选择，特征组合。\n- 特征组合变换好坏都有，一方面能提高模型的表达能力，另一方面有可能引起过拟合，增加冗余特征，降低模型解释力。\n  - 特征变换还可以是将连续特征转换为离散特征。\n- 模型的选择和特征工程是耦合的。因为不同模型对特征工程的需求不一样。\n  - 树模型不需要归一化处理，不需要特征选择，因为这些模型都能做到。\n  - 神经网络则不需要特征组合变换。\n  - 广义线性模型的效果则对数据清洗，特征选择，特征组合很敏感。这就是为啥计算广告领域后续衍生了FM,FFM等等\n\n","slug":"机器学习/关于特征工程","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551om002bjqrrgs1jv5nv","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>特征工程和模型选择是提升算法的两类途径。</p>\n<ul>\n<li>特征工程：数据清洗，(降维)，特征选择，特征组合。</li>\n<li>特征组合变换好坏都有，一方面能提高模型的表达能力，另一方面有可能引起过拟合，增加冗余特征，降低模型解释力。<ul>\n<li>特征变换还可以是将连续特征转换为离散特征。</li>\n</ul>\n</li>\n<li>模型的选择和特征工程是耦合的。因为不同模型对特征工程的需求不一样。<ul>\n<li>树模型不需要归一化处理，不需要特征选择，因为这些模型都能做到。</li>\n<li>神经网络则不需要特征组合变换。</li>\n<li>广义线性模型的效果则对数据清洗，特征选择，特征组合很敏感。这就是为啥计算广告领域后续衍生了FM,FFM等等</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>特征工程和模型选择是提升算法的两类途径。</p>\n<ul>\n<li>特征工程：数据清洗，(降维)，特征选择，特征组合。</li>\n<li>特征组合变换好坏都有，一方面能提高模型的表达能力，另一方面有可能引起过拟合，增加冗余特征，降低模型解释力。<ul>\n<li>特征变换还可以是将连续特征转换为离散特征。</li>\n</ul>\n</li>\n<li>模型的选择和特征工程是耦合的。因为不同模型对特征工程的需求不一样。<ul>\n<li>树模型不需要归一化处理，不需要特征选择，因为这些模型都能做到。</li>\n<li>神经网络则不需要特征组合变换。</li>\n<li>广义线性模型的效果则对数据清洗，特征选择，特征组合很敏感。这就是为啥计算广告领域后续衍生了FM,FFM等等</li>\n</ul>\n</li>\n</ul>\n"},{"title":"关于特征归一化的一些理解","date":"2018-11-21T11:28:44.000Z","_content":"\n\n\n**归一化会加快梯度下降法的收敛速度了**\n\n这个是显然的，不多说了。\n\n但是这里需要注意的是，像LR这种单纯的梯度下降法求解，只是增加收敛速度罢了，并不会让解更加精确，因为最终这个最优解的系数值是和特征值比例成反比的。\n\n \n\n**归一化有可能会提升算法精度**\n\n注意，这里是可能，因为就像前文所有，对于LR，是不会提升精度的，但是归一化对某些模型也是会提升精度的：\n\n- 对于KNN(跟梯度下降法无法)，需要计算欧式距离，如果不归一化，那么欧式距离就主要取决于大的特征值，从而影响精度。\n- 对于有L1,L2正则的算法，如果不做归一化，那么系数值会受到特征值大小的影响，从而导致值小的特征对应的系数大，从而导致该特征受到影响。\n\n \n\n树模型不需要归一化。。。\n\n","source":"_posts/机器学习/关于特征归一化的一些理解.md","raw":"---\ntitle: 关于特征归一化的一些理解\ndate: 2018-11-21 19:28:44 \ntags: 特征工程\ncategories: 机器学习\n---\n\n\n\n**归一化会加快梯度下降法的收敛速度了**\n\n这个是显然的，不多说了。\n\n但是这里需要注意的是，像LR这种单纯的梯度下降法求解，只是增加收敛速度罢了，并不会让解更加精确，因为最终这个最优解的系数值是和特征值比例成反比的。\n\n \n\n**归一化有可能会提升算法精度**\n\n注意，这里是可能，因为就像前文所有，对于LR，是不会提升精度的，但是归一化对某些模型也是会提升精度的：\n\n- 对于KNN(跟梯度下降法无法)，需要计算欧式距离，如果不归一化，那么欧式距离就主要取决于大的特征值，从而影响精度。\n- 对于有L1,L2正则的算法，如果不做归一化，那么系数值会受到特征值大小的影响，从而导致值小的特征对应的系数大，从而导致该特征受到影响。\n\n \n\n树模型不需要归一化。。。\n\n","slug":"机器学习/关于特征归一化的一些理解","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551om002fjqrrlyxp15pu","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p><strong>归一化会加快梯度下降法的收敛速度了</strong></p>\n<p>这个是显然的，不多说了。</p>\n<p>但是这里需要注意的是，像LR这种单纯的梯度下降法求解，只是增加收敛速度罢了，并不会让解更加精确，因为最终这个最优解的系数值是和特征值比例成反比的。</p>\n<p><strong>归一化有可能会提升算法精度</strong></p>\n<p>注意，这里是可能，因为就像前文所有，对于LR，是不会提升精度的，但是归一化对某些模型也是会提升精度的：</p>\n<ul>\n<li>对于KNN(跟梯度下降法无法)，需要计算欧式距离，如果不归一化，那么欧式距离就主要取决于大的特征值，从而影响精度。</li>\n<li>对于有L1,L2正则的算法，如果不做归一化，那么系数值会受到特征值大小的影响，从而导致值小的特征对应的系数大，从而导致该特征受到影响。</li>\n</ul>\n<p>树模型不需要归一化。。。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>归一化会加快梯度下降法的收敛速度了</strong></p>\n<p>这个是显然的，不多说了。</p>\n<p>但是这里需要注意的是，像LR这种单纯的梯度下降法求解，只是增加收敛速度罢了，并不会让解更加精确，因为最终这个最优解的系数值是和特征值比例成反比的。</p>\n<p><strong>归一化有可能会提升算法精度</strong></p>\n<p>注意，这里是可能，因为就像前文所有，对于LR，是不会提升精度的，但是归一化对某些模型也是会提升精度的：</p>\n<ul>\n<li>对于KNN(跟梯度下降法无法)，需要计算欧式距离，如果不归一化，那么欧式距离就主要取决于大的特征值，从而影响精度。</li>\n<li>对于有L1,L2正则的算法，如果不做归一化，那么系数值会受到特征值大小的影响，从而导致值小的特征对应的系数大，从而导致该特征受到影响。</li>\n</ul>\n<p>树模型不需要归一化。。。</p>\n"},{"title":"损失函数之交叉熵和MSE","date":"2019-11-18T11:28:44.000Z","_content":"\n\n\n一般神经网络都是用交叉熵，回归问题用MSE，分类问题用交叉熵。\n\n网友分析了一下，发现MSE对梯度有个不友好的地方，有时候误差越大，梯度越小，而交叉熵是正比的。\n\n![image-20200605153953308](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgeotc0dj30kb0e0wh3.jpg)\n\nMSE : $A^2 * (1-A)$\n\ncross entropy : A\n\n \n\n另外，一般推动神经网络BP算法的时候，用的都是MSE，如果用cross entry和softmax的话，会比较复杂一点。\n\n ","source":"_posts/机器学习/损失函数之交叉熵和MSE.md","raw":"---\ntitle: 损失函数之交叉熵和MSE\ndate: 2019-11-18 19:28:44 \ncategories: 机器学习\n---\n\n\n\n一般神经网络都是用交叉熵，回归问题用MSE，分类问题用交叉熵。\n\n网友分析了一下，发现MSE对梯度有个不友好的地方，有时候误差越大，梯度越小，而交叉熵是正比的。\n\n![image-20200605153953308](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgeotc0dj30kb0e0wh3.jpg)\n\nMSE : $A^2 * (1-A)$\n\ncross entropy : A\n\n \n\n另外，一般推动神经网络BP算法的时候，用的都是MSE，如果用cross entry和softmax的话，会比较复杂一点。\n\n ","slug":"机器学习/损失函数之交叉熵和MSE","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551on002hjqrrss8ropzp","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>一般神经网络都是用交叉熵，回归问题用MSE，分类问题用交叉熵。</p>\n<p>网友分析了一下，发现MSE对梯度有个不友好的地方，有时候误差越大，梯度越小，而交叉熵是正比的。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgeotc0dj30kb0e0wh3.jpg\" alt=\"image-20200605153953308\"></p>\n<p>MSE : $A^2 * (1-A)$</p>\n<p>cross entropy : A</p>\n<p>另外，一般推动神经网络BP算法的时候，用的都是MSE，如果用cross entry和softmax的话，会比较复杂一点。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>一般神经网络都是用交叉熵，回归问题用MSE，分类问题用交叉熵。</p>\n<p>网友分析了一下，发现MSE对梯度有个不友好的地方，有时候误差越大，梯度越小，而交叉熵是正比的。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgeotc0dj30kb0e0wh3.jpg\" alt=\"image-20200605153953308\"></p>\n<p>MSE : $A^2 * (1-A)$</p>\n<p>cross entropy : A</p>\n<p>另外，一般推动神经网络BP算法的时候，用的都是MSE，如果用cross entry和softmax的话，会比较复杂一点。</p>\n"},{"title":"支持向量机","date":"2016-05-10T11:28:44.000Z","_content":"\n之前上了斯坦福大学Andrew Ng的机器学习课程后，以为自己的支持向量机SVM有了一番了解，只是在logistic regression上做一点改进，另外还有核函数加入拓展数据特征，然后今天看了详细的支持向量机推导过程后，才发现之前自己的理解很肤浅。\n\n\n[这篇文章](http://taop.marchtea.com/07.02.svm.html)详细介绍了支持向量机的概念及求解，对于更深入的SMO算法以及损耗分析，需要去看《支持向量机导论》这本书。\n\n支持向量机被称为最好的监督学习分类器，我认为原因有下：\n\n* 不像logistic regression一样有$h(x)$这个logistic函数，而是\n\n  $$\n  \\begin{equation}\n  g(z) = \n  \\begin{cases}\n  1, &z \\geq 0 \\\\\\\n  -1, &z < 0\n  \\end{cases}\n  \\end{equation}\n  $$\n\n* 它的分类原理使得不同类别的间隔达到了最大。\n\n* 对于线性不可分的情况，可以将本来的特征无限拓展到高维， 也就是系数$w$可以无限高维度，但我们却可以在求解过程中不需要知道具体维度，只要用核函数就可以求解！\n\n\n\n\n\n","source":"_posts/机器学习/支持向量机.markdown","raw":"---\ntitle: 支持向量机\ndate: 2016-05-10 19:28:44 \ntags: SVM\ncategories: 机器学习\n---\n\n之前上了斯坦福大学Andrew Ng的机器学习课程后，以为自己的支持向量机SVM有了一番了解，只是在logistic regression上做一点改进，另外还有核函数加入拓展数据特征，然后今天看了详细的支持向量机推导过程后，才发现之前自己的理解很肤浅。\n\n\n[这篇文章](http://taop.marchtea.com/07.02.svm.html)详细介绍了支持向量机的概念及求解，对于更深入的SMO算法以及损耗分析，需要去看《支持向量机导论》这本书。\n\n支持向量机被称为最好的监督学习分类器，我认为原因有下：\n\n* 不像logistic regression一样有$h(x)$这个logistic函数，而是\n\n  $$\n  \\begin{equation}\n  g(z) = \n  \\begin{cases}\n  1, &z \\geq 0 \\\\\\\n  -1, &z < 0\n  \\end{cases}\n  \\end{equation}\n  $$\n\n* 它的分类原理使得不同类别的间隔达到了最大。\n\n* 对于线性不可分的情况，可以将本来的特征无限拓展到高维， 也就是系数$w$可以无限高维度，但我们却可以在求解过程中不需要知道具体维度，只要用核函数就可以求解！\n\n\n\n\n\n","slug":"机器学习/支持向量机","published":1,"updated":"2022-09-15T03:46:43.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551op002ljqrrq7npbk4m","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>之前上了斯坦福大学Andrew Ng的机器学习课程后，以为自己的支持向量机SVM有了一番了解，只是在logistic regression上做一点改进，另外还有核函数加入拓展数据特征，然后今天看了详细的支持向量机推导过程后，才发现之前自己的理解很肤浅。</p>\n<p><a href=\"http://taop.marchtea.com/07.02.svm.html\" target=\"_blank\" rel=\"noopener\">这篇文章</a>详细介绍了支持向量机的概念及求解，对于更深入的SMO算法以及损耗分析，需要去看《支持向量机导论》这本书。</p>\n<p>支持向量机被称为最好的监督学习分类器，我认为原因有下：</p>\n<ul>\n<li><p>不像logistic regression一样有$h(x)$这个logistic函数，而是</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\ng(z) = \n\\begin{cases}\n1, &z \\geq 0 \\\\\\\n-1, &z < 0\n\\end{cases}\n\\end{equation}</script></li>\n<li><p>它的分类原理使得不同类别的间隔达到了最大。</p>\n</li>\n<li><p>对于线性不可分的情况，可以将本来的特征无限拓展到高维， 也就是系数$w$可以无限高维度，但我们却可以在求解过程中不需要知道具体维度，只要用核函数就可以求解！</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>之前上了斯坦福大学Andrew Ng的机器学习课程后，以为自己的支持向量机SVM有了一番了解，只是在logistic regression上做一点改进，另外还有核函数加入拓展数据特征，然后今天看了详细的支持向量机推导过程后，才发现之前自己的理解很肤浅。</p>\n<p><a href=\"http://taop.marchtea.com/07.02.svm.html\" target=\"_blank\" rel=\"noopener\">这篇文章</a>详细介绍了支持向量机的概念及求解，对于更深入的SMO算法以及损耗分析，需要去看《支持向量机导论》这本书。</p>\n<p>支持向量机被称为最好的监督学习分类器，我认为原因有下：</p>\n<ul>\n<li><p>不像logistic regression一样有$h(x)$这个logistic函数，而是</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\ng(z) = \n\\begin{cases}\n1, &z \\geq 0 \\\\\\\n-1, &z < 0\n\\end{cases}\n\\end{equation}</script></li>\n<li><p>它的分类原理使得不同类别的间隔达到了最大。</p>\n</li>\n<li><p>对于线性不可分的情况，可以将本来的特征无限拓展到高维， 也就是系数$w$可以无限高维度，但我们却可以在求解过程中不需要知道具体维度，只要用核函数就可以求解！</p>\n</li>\n</ul>\n"},{"title":"最大熵与最大似然估计","date":"2020-05-24T11:28:44.000Z","_content":"\n","source":"_posts/机器学习/最大熵与最大似然估计.md","raw":"---\ntitle: 最大熵与最大似然估计\ndate: 2020-05-24 19:28:44 \ncategories: 机器学习\n---\n\n","slug":"机器学习/最大熵与最大似然估计","published":1,"updated":"2022-09-15T03:46:43.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551oq002njqrrmmbb3alb","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script>","site":{"data":{}},"excerpt":"","more":""},{"title":"生成模型和判别模型的直观解释","date":"2019-11-01T11:28:44.000Z","_content":"\nhttps://www.cnblogs.com/tenosdoit/p/3721074.html\n\n\n\n","source":"_posts/机器学习/生成模型和判别模型的直观解释.md","raw":"---\ntitle: 生成模型和判别模型的直观解释\ndate: 2019-11-01 19:28:44 \ncategories: 机器学习\n---\n\nhttps://www.cnblogs.com/tenosdoit/p/3721074.html\n\n\n\n","slug":"机器学习/生成模型和判别模型的直观解释","published":1,"updated":"2022-09-15T03:46:43.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551or002rjqrr1rjecr5f","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p><a href=\"https://www.cnblogs.com/tenosdoit/p/3721074.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/tenosdoit/p/3721074.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.cnblogs.com/tenosdoit/p/3721074.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/tenosdoit/p/3721074.html</a></p>\n"},{"title":"特征是否越多越好？","date":"2018-12-06T11:28:44.000Z","_content":"\n\n\n树模型对冗余特征鲁棒性强，树模型有特征选择能力。\n\n但树模型没有特征交叉组合的能力，神经网络有...\n\n\n\n![image-20200605161214027](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhcf1i1mj30o70800uh.jpg)","source":"_posts/机器学习/特征是否越多越好.md","raw":"---\ntitle: 特征是否越多越好？\ndate: 2018-12-06 19:28:44 \ntags: 特征工程\ncategories: 机器学习\n---\n\n\n\n树模型对冗余特征鲁棒性强，树模型有特征选择能力。\n\n但树模型没有特征交叉组合的能力，神经网络有...\n\n\n\n![image-20200605161214027](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhcf1i1mj30o70800uh.jpg)","slug":"机器学习/特征是否越多越好","published":1,"updated":"2022-09-15T03:46:43.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551or002tjqrr31k973aa","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>树模型对冗余特征鲁棒性强，树模型有特征选择能力。</p>\n<p>但树模型没有特征交叉组合的能力，神经网络有…</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhcf1i1mj30o70800uh.jpg\" alt=\"image-20200605161214027\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>树模型对冗余特征鲁棒性强，树模型有特征选择能力。</p>\n<p>但树模型没有特征交叉组合的能力，神经网络有…</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhhcf1i1mj30o70800uh.jpg\" alt=\"image-20200605161214027\"></p>\n"},{"title":"类别不均衡问题的调参","date":"2019-04-24T11:28:44.000Z","_content":"\n对于类别不均衡问题，处理方法有：\n\n- 正样本过采样\n\n-  负样本降采样\n\n- 调整阈值\n\n主要是这三种，实际算法处理过程往往是这样的：\n\n- 先对负样本进行降采样or正样本过采样来提取训练样本，以保证模型的AUC尽量高。\n\n- 过采样or降采样之后模型输出的概率已经失去原本的意义，所以在测试集上如果看其他评价指标如交叉熵，那loss是很大的，当然不影响AUC。所以，我们需要对输出概率再做调整，恢复到真正实际的概率值。\n\n \n\n实际样例：\n\nCTR预估模型之GBDT+LR：对负样本进行以w频率进行降采样，然后对预测概率值重新调整：（AUC只保序，通过calibration校正概率阈值）\n\n![image-20200605155725174](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgxszy1tj30fx02z3z3.jpg)\n\nXgboost:设置了scale_pos_weight参数，该参数的合理值= 负样本数/正样本数，该参数的意义是让正样本梯度（也就是loss）的权重值变大，也就是更加关注正样本的loss,有点类似于正样本的过采样。scale_pos_weight只适用于AUC，也就是只适用于将样本进行二分类，最终概率值并非真实概率值。\n\n \n\n关于Weighted LR中正样本过采样还是正样本梯度加权重这两种方式：\n\n> 这两种训练方法得到的结果是不一样的，比如要抽样10倍，对于第一种方法，就是把一条样本重复10倍，这样优化的过程中，每遇到一条这个样本，就会用梯度更新一下参数，然后用更新后的参数再去计算下一条样本上的梯度，如果逐步计算并更新梯度10次；但对于第二种方法，则是一次性更新了单条梯度乘以10这么多的梯度，是一种一次到位的做法。\n>\n> \n>\n> 直观一些来讲，第一种方法更像是给予一条样本10倍的关注，愿意花更多时间和精力来对待这条样本，是一种更细致的方法，第二种则比较粗暴了，不愿意花太多功夫，直接给你10倍权重。","source":"_posts/机器学习/类别不均衡问题的调参.md","raw":"---\ntitle: 类别不均衡问题的调参\ndate: 2019-04-24 19:28:44 \ntags: 特征工程\ncategories: 机器学习\n---\n\n对于类别不均衡问题，处理方法有：\n\n- 正样本过采样\n\n-  负样本降采样\n\n- 调整阈值\n\n主要是这三种，实际算法处理过程往往是这样的：\n\n- 先对负样本进行降采样or正样本过采样来提取训练样本，以保证模型的AUC尽量高。\n\n- 过采样or降采样之后模型输出的概率已经失去原本的意义，所以在测试集上如果看其他评价指标如交叉熵，那loss是很大的，当然不影响AUC。所以，我们需要对输出概率再做调整，恢复到真正实际的概率值。\n\n \n\n实际样例：\n\nCTR预估模型之GBDT+LR：对负样本进行以w频率进行降采样，然后对预测概率值重新调整：（AUC只保序，通过calibration校正概率阈值）\n\n![image-20200605155725174](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgxszy1tj30fx02z3z3.jpg)\n\nXgboost:设置了scale_pos_weight参数，该参数的合理值= 负样本数/正样本数，该参数的意义是让正样本梯度（也就是loss）的权重值变大，也就是更加关注正样本的loss,有点类似于正样本的过采样。scale_pos_weight只适用于AUC，也就是只适用于将样本进行二分类，最终概率值并非真实概率值。\n\n \n\n关于Weighted LR中正样本过采样还是正样本梯度加权重这两种方式：\n\n> 这两种训练方法得到的结果是不一样的，比如要抽样10倍，对于第一种方法，就是把一条样本重复10倍，这样优化的过程中，每遇到一条这个样本，就会用梯度更新一下参数，然后用更新后的参数再去计算下一条样本上的梯度，如果逐步计算并更新梯度10次；但对于第二种方法，则是一次性更新了单条梯度乘以10这么多的梯度，是一种一次到位的做法。\n>\n> \n>\n> 直观一些来讲，第一种方法更像是给予一条样本10倍的关注，愿意花更多时间和精力来对待这条样本，是一种更细致的方法，第二种则比较粗暴了，不愿意花太多功夫，直接给你10倍权重。","slug":"机器学习/类别不均衡问题的调参","published":1,"updated":"2022-09-15T03:46:43.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551os002xjqrrmon6agv1","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>对于类别不均衡问题，处理方法有：</p>\n<ul>\n<li><p>正样本过采样</p>\n</li>\n<li><p>负样本降采样</p>\n</li>\n<li><p>调整阈值</p>\n</li>\n</ul>\n<p>主要是这三种，实际算法处理过程往往是这样的：</p>\n<ul>\n<li><p>先对负样本进行降采样or正样本过采样来提取训练样本，以保证模型的AUC尽量高。</p>\n</li>\n<li><p>过采样or降采样之后模型输出的概率已经失去原本的意义，所以在测试集上如果看其他评价指标如交叉熵，那loss是很大的，当然不影响AUC。所以，我们需要对输出概率再做调整，恢复到真正实际的概率值。</p>\n</li>\n</ul>\n<p>实际样例：</p>\n<p>CTR预估模型之GBDT+LR：对负样本进行以w频率进行降采样，然后对预测概率值重新调整：（AUC只保序，通过calibration校正概率阈值）</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgxszy1tj30fx02z3z3.jpg\" alt=\"image-20200605155725174\"></p>\n<p>Xgboost:设置了scale_pos_weight参数，该参数的合理值= 负样本数/正样本数，该参数的意义是让正样本梯度（也就是loss）的权重值变大，也就是更加关注正样本的loss,有点类似于正样本的过采样。scale_pos_weight只适用于AUC，也就是只适用于将样本进行二分类，最终概率值并非真实概率值。</p>\n<p>关于Weighted LR中正样本过采样还是正样本梯度加权重这两种方式：</p>\n<blockquote>\n<p>这两种训练方法得到的结果是不一样的，比如要抽样10倍，对于第一种方法，就是把一条样本重复10倍，这样优化的过程中，每遇到一条这个样本，就会用梯度更新一下参数，然后用更新后的参数再去计算下一条样本上的梯度，如果逐步计算并更新梯度10次；但对于第二种方法，则是一次性更新了单条梯度乘以10这么多的梯度，是一种一次到位的做法。</p>\n<p>直观一些来讲，第一种方法更像是给予一条样本10倍的关注，愿意花更多时间和精力来对待这条样本，是一种更细致的方法，第二种则比较粗暴了，不愿意花太多功夫，直接给你10倍权重。</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<p>对于类别不均衡问题，处理方法有：</p>\n<ul>\n<li><p>正样本过采样</p>\n</li>\n<li><p>负样本降采样</p>\n</li>\n<li><p>调整阈值</p>\n</li>\n</ul>\n<p>主要是这三种，实际算法处理过程往往是这样的：</p>\n<ul>\n<li><p>先对负样本进行降采样or正样本过采样来提取训练样本，以保证模型的AUC尽量高。</p>\n</li>\n<li><p>过采样or降采样之后模型输出的概率已经失去原本的意义，所以在测试集上如果看其他评价指标如交叉熵，那loss是很大的，当然不影响AUC。所以，我们需要对输出概率再做调整，恢复到真正实际的概率值。</p>\n</li>\n</ul>\n<p>实际样例：</p>\n<p>CTR预估模型之GBDT+LR：对负样本进行以w频率进行降采样，然后对预测概率值重新调整：（AUC只保序，通过calibration校正概率阈值）</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgxszy1tj30fx02z3z3.jpg\" alt=\"image-20200605155725174\"></p>\n<p>Xgboost:设置了scale_pos_weight参数，该参数的合理值= 负样本数/正样本数，该参数的意义是让正样本梯度（也就是loss）的权重值变大，也就是更加关注正样本的loss,有点类似于正样本的过采样。scale_pos_weight只适用于AUC，也就是只适用于将样本进行二分类，最终概率值并非真实概率值。</p>\n<p>关于Weighted LR中正样本过采样还是正样本梯度加权重这两种方式：</p>\n<blockquote>\n<p>这两种训练方法得到的结果是不一样的，比如要抽样10倍，对于第一种方法，就是把一条样本重复10倍，这样优化的过程中，每遇到一条这个样本，就会用梯度更新一下参数，然后用更新后的参数再去计算下一条样本上的梯度，如果逐步计算并更新梯度10次；但对于第二种方法，则是一次性更新了单条梯度乘以10这么多的梯度，是一种一次到位的做法。</p>\n<p>直观一些来讲，第一种方法更像是给予一条样本10倍的关注，愿意花更多时间和精力来对待这条样本，是一种更细致的方法，第二种则比较粗暴了，不愿意花太多功夫，直接给你10倍权重。</p>\n</blockquote>\n"},{"title":"Dead ReLu问题","date":"2019-05-16T11:28:44.000Z","_content":"\n\n\n原因很简单，是因为函数的负数区间值为0，导数为0，导致权重不更新。\n\n \n\n但实际上，真要出现永久dead还是很严苛的：\n\n- 所用训练样本x在该神经元的输入值都是 < 0\n-  一般都是网络第一层，前面没有隐藏层。因为如果有隐藏层，隐藏层不死的话，隐藏层输出值还是会变，同样的x, 输入到该层还是有可能被激活。\n\n \n\nBP经典公式：\n\n该神经元某条链路w导数 = 前面的导数累计 * 该神经元导数值 * 该链路输入值x\n\n","source":"_posts/深度学习/Dead ReLu问题.md","raw":"---\ntitle: Dead ReLu问题\ndate: 2019-05-16 19:28:44 \ncategories: 深度学习\n---\n\n\n\n原因很简单，是因为函数的负数区间值为0，导数为0，导致权重不更新。\n\n \n\n但实际上，真要出现永久dead还是很严苛的：\n\n- 所用训练样本x在该神经元的输入值都是 < 0\n-  一般都是网络第一层，前面没有隐藏层。因为如果有隐藏层，隐藏层不死的话，隐藏层输出值还是会变，同样的x, 输入到该层还是有可能被激活。\n\n \n\nBP经典公式：\n\n该神经元某条链路w导数 = 前面的导数累计 * 该神经元导数值 * 该链路输入值x\n\n","slug":"深度学习/Dead ReLu问题","published":1,"updated":"2022-09-15T03:46:43.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551ou0030jqrresgqmqim","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>原因很简单，是因为函数的负数区间值为0，导数为0，导致权重不更新。</p>\n<p>但实际上，真要出现永久dead还是很严苛的：</p>\n<ul>\n<li>所用训练样本x在该神经元的输入值都是 &lt; 0</li>\n<li>一般都是网络第一层，前面没有隐藏层。因为如果有隐藏层，隐藏层不死的话，隐藏层输出值还是会变，同样的x, 输入到该层还是有可能被激活。</li>\n</ul>\n<p>BP经典公式：</p>\n<p>该神经元某条链路w导数 = 前面的导数累计 <em> 该神经元导数值 </em> 该链路输入值x</p>\n","site":{"data":{}},"excerpt":"","more":"<p>原因很简单，是因为函数的负数区间值为0，导数为0，导致权重不更新。</p>\n<p>但实际上，真要出现永久dead还是很严苛的：</p>\n<ul>\n<li>所用训练样本x在该神经元的输入值都是 &lt; 0</li>\n<li>一般都是网络第一层，前面没有隐藏层。因为如果有隐藏层，隐藏层不死的话，隐藏层输出值还是会变，同样的x, 输入到该层还是有可能被激活。</li>\n</ul>\n<p>BP经典公式：</p>\n<p>该神经元某条链路w导数 = 前面的导数累计 <em> 该神经元导数值 </em> 该链路输入值x</p>\n"},{"title":"ML2020笔记-基于RNN的生成模型和Attention","date":"2020-04-02T16:00:00.000Z","_content":"\n","source":"_posts/深度学习/ML2020笔记-基于RNN的生成模型和Attention.md","raw":"---\ntitle: ML2020笔记-基于RNN的生成模型和Attention\ndate: 2020-04-03\ncategories: 深度学习\ntags: 李宏毅-ML2020\n---\n\n","slug":"深度学习/ML2020笔记-基于RNN的生成模型和Attention","published":1,"updated":"2022-09-15T03:46:43.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551ov0034jqrrpj3w6872","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script>","site":{"data":{}},"excerpt":"","more":""},{"title":"ML2020笔记-ELMO、BERT和GPT","date":"2020-04-01T16:00:00.000Z","_content":"\n\n\n\n\n- RNN-based Language Model\n\n<img src=\"/Users/didi/Library/Application Support/typora-user-images/image-20200727110754850.png\" alt=\"image-20200727110754850\" style=\"zoom:50%;\" />\n\n<img src=\"/Users/didi/Library/Application Support/typora-user-images/image-20200727110949830.png\" alt=\"image-20200727110949830\" style=\"zoom:50%;\" />\n\n<img src=\"/Users/didi/Library/Application Support/typora-user-images/image-20200727111415304.png\" alt=\"image-20200727111415304\" style=\"zoom:50%;\" />\n\n\n\n\n\n","source":"_posts/深度学习/ML2020笔记-ELMO、BERT和GPT.md","raw":"---\ntitle: ML2020笔记-ELMO、BERT和GPT\ndate: 2020-04-02\ncategories: 深度学习\ntags: 李宏毅-ML2020\n---\n\n\n\n\n\n- RNN-based Language Model\n\n<img src=\"/Users/didi/Library/Application Support/typora-user-images/image-20200727110754850.png\" alt=\"image-20200727110754850\" style=\"zoom:50%;\" />\n\n<img src=\"/Users/didi/Library/Application Support/typora-user-images/image-20200727110949830.png\" alt=\"image-20200727110949830\" style=\"zoom:50%;\" />\n\n<img src=\"/Users/didi/Library/Application Support/typora-user-images/image-20200727111415304.png\" alt=\"image-20200727111415304\" style=\"zoom:50%;\" />\n\n\n\n\n\n","slug":"深度学习/ML2020笔记-ELMO、BERT和GPT","published":1,"updated":"2022-09-15T03:46:43.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551ow0037jqrrtowvws4s","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><ul>\n<li>RNN-based Language Model</li>\n</ul>\n<p><img src=\"/Users/didi/Library/Application Support/typora-user-images/image-20200727110754850.png\" alt=\"image-20200727110754850\" style=\"zoom:50%;\"></p>\n<p><img src=\"/Users/didi/Library/Application Support/typora-user-images/image-20200727110949830.png\" alt=\"image-20200727110949830\" style=\"zoom:50%;\"></p>\n<p><img src=\"/Users/didi/Library/Application Support/typora-user-images/image-20200727111415304.png\" alt=\"image-20200727111415304\" style=\"zoom:50%;\"></p>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li>RNN-based Language Model</li>\n</ul>\n<p><img src=\"/Users/didi/Library/Application Support/typora-user-images/image-20200727110754850.png\" alt=\"image-20200727110754850\" style=\"zoom:50%;\"></p>\n<p><img src=\"/Users/didi/Library/Application Support/typora-user-images/image-20200727110949830.png\" alt=\"image-20200727110949830\" style=\"zoom:50%;\"></p>\n<p><img src=\"/Users/didi/Library/Application Support/typora-user-images/image-20200727111415304.png\" alt=\"image-20200727111415304\" style=\"zoom:50%;\"></p>\n"},{"title":"RNN的BPTT","date":"2021-01-07T16:00:00.000Z","_content":"\n\n\nRNN采用的梯度更新策略是BPTT，梯度分为两部分：\n\n- 竖直方向的输出层权重：这个和传统反向传播没什么区别，因为这一层的权重只与当前loss有关\n- 竖直方向的输入层和水平权重：这个就稍微复杂点，因为rnn的总loss是所有时刻loss相加的，同时每个时刻的loss又会影响到这里所说的所有权重，所以操作是：\n  - 计算某个时刻Et的误差项，通过反向传播来计算，最后计算梯度。\n  - 汇总所有的时刻计算的梯度。\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmgf10qmerj30f207ogmg.jpg\" alt=\"image-20210108172855248\" style=\"zoom:50%;\" />\n\n[参考资料](https://www.cnblogs.com/wacc/p/5341670.html)\n\n","source":"_posts/深度学习/RNN的BPTT.md","raw":"---\ntitle: RNN的BPTT\ndate: 2021-01-08\ncategories: 深度学习\n---\n\n\n\nRNN采用的梯度更新策略是BPTT，梯度分为两部分：\n\n- 竖直方向的输出层权重：这个和传统反向传播没什么区别，因为这一层的权重只与当前loss有关\n- 竖直方向的输入层和水平权重：这个就稍微复杂点，因为rnn的总loss是所有时刻loss相加的，同时每个时刻的loss又会影响到这里所说的所有权重，所以操作是：\n  - 计算某个时刻Et的误差项，通过反向传播来计算，最后计算梯度。\n  - 汇总所有的时刻计算的梯度。\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmgf10qmerj30f207ogmg.jpg\" alt=\"image-20210108172855248\" style=\"zoom:50%;\" />\n\n[参考资料](https://www.cnblogs.com/wacc/p/5341670.html)\n\n","slug":"深度学习/RNN的BPTT","published":1,"updated":"2022-09-15T03:46:43.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551ox003bjqrrc5jvcdmr","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>RNN采用的梯度更新策略是BPTT，梯度分为两部分：</p>\n<ul>\n<li>竖直方向的输出层权重：这个和传统反向传播没什么区别，因为这一层的权重只与当前loss有关</li>\n<li>竖直方向的输入层和水平权重：这个就稍微复杂点，因为rnn的总loss是所有时刻loss相加的，同时每个时刻的loss又会影响到这里所说的所有权重，所以操作是：<ul>\n<li>计算某个时刻Et的误差项，通过反向传播来计算，最后计算梯度。</li>\n<li>汇总所有的时刻计算的梯度。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmgf10qmerj30f207ogmg.jpg\" alt=\"image-20210108172855248\" style=\"zoom:50%;\"></p>\n<p><a href=\"https://www.cnblogs.com/wacc/p/5341670.html\" target=\"_blank\" rel=\"noopener\">参考资料</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>RNN采用的梯度更新策略是BPTT，梯度分为两部分：</p>\n<ul>\n<li>竖直方向的输出层权重：这个和传统反向传播没什么区别，因为这一层的权重只与当前loss有关</li>\n<li>竖直方向的输入层和水平权重：这个就稍微复杂点，因为rnn的总loss是所有时刻loss相加的，同时每个时刻的loss又会影响到这里所说的所有权重，所以操作是：<ul>\n<li>计算某个时刻Et的误差项，通过反向传播来计算，最后计算梯度。</li>\n<li>汇总所有的时刻计算的梯度。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmgf10qmerj30f207ogmg.jpg\" alt=\"image-20210108172855248\" style=\"zoom:50%;\"></p>\n<p><a href=\"https://www.cnblogs.com/wacc/p/5341670.html\" target=\"_blank\" rel=\"noopener\">参考资料</a></p>\n"},{"title":"NAS系列文章解读","date":"2020-11-01T16:00:00.000Z","_content":"\n\n\nNAS最近几年是AutoML领域比较火热的方向，主要是神经网络结构的自动搜索。最近看了几篇NAS文章，下面按照发展历史做个总结。\n\n\n\n参考博客：\n\n- [炼丹术的终结](https://zhuanlan.zhihu.com/p/36301731)\n- [你想要的神经网络自动设计，谷歌大脑帮你实现了：用参数共享高效地搜索神经网络架构（ENAS）]([http://nooverfit.com/wp/%E4%BD%A0%E6%83%B3%E8%A6%81%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%87%AA%E5%8A%A8%E8%AE%BE%E8%AE%A1%EF%BC%8C%E8%B0%B7%E6%AD%8C%E5%A4%A7%E8%84%91%E5%B8%AE%E4%BD%A0%E5%AE%9E%E7%8E%B0%E4%BA%86/](http://nooverfit.com/wp/你想要的神经网络自动设计，谷歌大脑帮你实现了/))\n\n\n\n### 一、NAS的提出\n\n文献：《NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING》\n\n本质上就是确定通过一个rnn的controller，来生成神经网网络的结构。\n\n\n\n例如卷积神经网络，那么无非就是要确定卷积核的数目、高、宽，stride的高和宽，也就是利用controller来生成这个五个参数。\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkbtsqq13vj312a0dewmu.jpg\" alt=\"image-20201102192353768\" style=\"zoom:50%;\" />\n\ncontroller得到5个参数的概率，然后通过sample得到网络结构，再基于该网络结构得到其在验证集上的accuracy，再利用该accuracy去更新controller的权重。这一步就类似于强化学习的policy network，我在之前的博客中也有介绍，其实本质上就是一种优化算法，当目标变量的函数未知的情况下，优化目标的一种优化算法，这里是最大化accuracy，在无法知道结构和accuracy的关系，用神经网络去逼近。\n\n\n\n关于网络的深度，还是靠人为去设置的，这里的话是每sample 1600次，就将深度加深2。所以其实这个计算成本是很高的，每次深度加深，又要重新计算该模型结构的精度...文章最好的cifar-10上的最佳cnn结构是这样的：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb32ujvkrj30u00uj1ar.jpg\" alt=\"image-20201102200659882\" style=\"zoom:40%;\" />\n\n\n\n### 二、NAS的改进\n\n文献：《Learning Transferable Architectures for Scalable Image Recognitio》\n\n原先NAS的缺点就是复杂度太高，每次都要评估生成的整个网络结构，因此本文提出一种思想：其实在经典的VGG、Inception等结构中，往往都是反复利用一种卷积结构做堆叠生成的，因此我们只需搜索这种卷积结构的最优解就行。\n\n\n\n文章提出了Normal Cell和Reduce Cell，整个网络结构就是这两种cell的重复。注意，整个网络重复的次数N，还是人为拍的。\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb36xh65lj30rw0zsq65.jpg\" alt=\"image-20201102201054713\" style=\"zoom:40%;\" />\n\n我们只需搜索这两种cell的结构，搜索过程是这样的：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb37orljrj310l0u0tg3.jpg\" alt=\"image-20201102201138849\" style=\"zoom:40%;\" />\n\n假设一个Cell里有B个block，每个block生成步骤为：\n\n1. 从hi和hi-1或上一步中得到的隐含状态中选择一个作为输入一。\n2. 从从hi和hi-1或上一步中得到的隐含状态中选择一个作为输入二。（可以与第一个一样）\n3. 从操作集合中选择一个操作应用在输入一上。\n4. 从操作集合中选择一个操作应用在输入二上。\n5. 选择一个方法将第三步和第四步的结果合并。\n\n\n\n### 三、PNAS\n\n文献：《Progressive Neural Architecture Search》\n\n即使改进后，搜索一个神经网络结构，我们依然需要花800个GPU花4天的时间，我们可以进一步的降低复杂度。PNAS的思想是更为贪心的搜索。假设B=5，总共的复杂度为：\n\n对于第一次运行生成方法，只有两个输入，因而，选取两次，得到2x2种可能。有八种operator，选取两次，得到8x8中可能，因而第一次运行该方法的空间是22x82。而对于第二次运行生成方法，operator选择的可能性没有变化，但因为上一步有一个隐含状态输出，所以输入变成了3x3中可能。以此类推，五次运行生成算法的搜索空间是：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb3ecta8pj30zk02ewfh.jpg\" alt=\"image-20201102201802212\" style=\"zoom:50%;\" />\n\n\n\n而PNAS的话，我们第一步得到2^2 * 8^2 = 256种可能后，就用controller生成网络结构进行256种可能的搜索，找到top k的最优结构。然后之后第二步，就基于这top k结构来搜索，这样相当于进行了剪枝，减少了大量的计算空间。\n\n整体步骤：\n\n- 完全训练生成算法第一步的所有可能的候选(256 / 2 = 136个，因为对称性)\n\n- 训练启发式搜索算法\n\n- 对于生成算法的后面几步的每一步：\n\n- - 取得所有候选结构\n  - 预测候选结构在某数据集上的准确率，按照准确率排序。\n  - 取出准确率最高的top-K模型结构，进行训练。\n  - 训练启发式搜索算法\n\n\n\nPNAS提升：模型数目减小为五分之一，而总速度降低为八分之一。\n\n\n\n### 四 、ENAS\n\n文献：《Efficient Neural Architecture Search via Parameter Sharing》\n\n最后是目前最常用的方法ENAS，ENAS利用参数共享的思想把复杂度提升到了原来的千分之一。ENAS的思想是把要搜索的结构想像成一个node，所有的node构成一个大的DAG，而我们要搜索的可能就是一个子图结构，但是所有node之间的权重是共享的，不需要每搜索一次子图，就重新计算子图node之间的权重。\n\n![image-20201102202954216](https://tva1.sinaimg.cn/large/0081Kckwgy1gkb3qototnj31fm094gnm.jpg)\n\n之前的NAS是对候选子模型逐个从头训练，事实上子模型的结构许多都是相似的，所以许多**Wi,j** (第i个节点与第j个节点的权重矩阵) **是可以复用的**，没有必要从头开始训练。这样的共享权重在文中被称作**shared model**。\n\n\n\n最终我们要搜索的是子图，也就是红线流向：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb3so8j7xj30ia094jrz.jpg\" alt=\"image-20201102203149727\" style=\"zoom:50%;\" />\n\n再讲一下ENAS的训练，显然我们需要训练两个参数：\n\n- 共享权重参数\n- controller的参数\n\n整个训练过程是这样的：\n\n- **self.train_shared()** 。在模型架构固定的情况下，基于训练集，更新和共享内部参数权重**Wi,j**，使得内部权重得到更好收敛。\n- **self.train_controller()** 充分使用共享的内部权重，从controller RNN中抽样出一些候选子模型，在这些模型中选择在验证集上表现最好的架构，继续步骤1的计算。\n\n相当于以前的NAS我们通过**self.train_controller**采样得到模型结构，然后**每个模型各自训练**，最后平均得到accuracy来更新controller。而ENAS的话我们采样得到模型结构后，不需要进行训练，直接基于当前共享权重，得到这些模型中表现最好的架构。然后再基于该模型架构，更新共享权重。\n\n\n\n###  五、DARTS\n\n文献：《DARTS- Differentiable Architecture Search》\n\n依然是基于参数共享的理念，但是以往我们都是通过controller来控制node之间的信息流向，但是DARTS通过权重系数alpha直接来控制，不再需要controller：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkbtejwrlrj30qs0cs42u.jpg\" alt=\"image-20201103111749052\" style=\"zoom:50%;\" />\n\n所以DARTS算法的流程是：\n\n1. 对每个模型结构选择的地方，建立一个mixed operation。这个mixed operation有参数a（每个Node(i, j)都有一个operation维度总数的系数向量），作为权重。模型本身的参数我们设置为w\n\n2. 当模型还没有收敛时，做：\n\n3. 1. 更新mixed operation的模型结构参数a。使用gradient descent：grad(a, Lvalid(w*(a), a)). 这里的w*指在a结构下，训练到converge之后最佳的模型本身的参数w\n   2. 对模型本身的参数w做gradient descent。\n\n4. 如果像之前Multi Trials AutoML的方式，每次求解最后converge最佳参数w代价很高。类似ENAS，我们用单步优化的w来近似最优的w*，这样效率更好。因此对a的gradient变为：grad(a, Lvalid)(w - eps*grad(w, Ltrain(w, a), a)。实际上因为之后对w也会做gradient descent，这里直接用first order approximation即可，eps = 0，直接变为grad(a, Lvalid)(w, a)。这样每次计算量大大降低。\n\n   \n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkbthoiklrj31eg0bcq5f.jpg\" alt=\"image-20201103112025371\" style=\"zoom:50%;\" />\n\n\n\n### 总结\n\n其实上述这些神经网络架构搜索，也不是完全的智能搜索，还是需要人为来确定一个搜索空间，然后基于某类优化算法来求解优化问题罢了。优化算法可以有很多，比如暴力搜索、random search、贝叶斯优化、DQN、粒子群、policy network等等。像这种我们不知道x（网络架构）和y（模型准确度）这种关系的优化，用policy network的方法是一种很直观的想法。\n\n","source":"_posts/深度学习/NAS系列文章解读.md","raw":"---\ntitle: NAS系列文章解读\ndate: 2020-11-02\ncategories: [深度学习, AutoML]\n---\n\n\n\nNAS最近几年是AutoML领域比较火热的方向，主要是神经网络结构的自动搜索。最近看了几篇NAS文章，下面按照发展历史做个总结。\n\n\n\n参考博客：\n\n- [炼丹术的终结](https://zhuanlan.zhihu.com/p/36301731)\n- [你想要的神经网络自动设计，谷歌大脑帮你实现了：用参数共享高效地搜索神经网络架构（ENAS）]([http://nooverfit.com/wp/%E4%BD%A0%E6%83%B3%E8%A6%81%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%87%AA%E5%8A%A8%E8%AE%BE%E8%AE%A1%EF%BC%8C%E8%B0%B7%E6%AD%8C%E5%A4%A7%E8%84%91%E5%B8%AE%E4%BD%A0%E5%AE%9E%E7%8E%B0%E4%BA%86/](http://nooverfit.com/wp/你想要的神经网络自动设计，谷歌大脑帮你实现了/))\n\n\n\n### 一、NAS的提出\n\n文献：《NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING》\n\n本质上就是确定通过一个rnn的controller，来生成神经网网络的结构。\n\n\n\n例如卷积神经网络，那么无非就是要确定卷积核的数目、高、宽，stride的高和宽，也就是利用controller来生成这个五个参数。\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkbtsqq13vj312a0dewmu.jpg\" alt=\"image-20201102192353768\" style=\"zoom:50%;\" />\n\ncontroller得到5个参数的概率，然后通过sample得到网络结构，再基于该网络结构得到其在验证集上的accuracy，再利用该accuracy去更新controller的权重。这一步就类似于强化学习的policy network，我在之前的博客中也有介绍，其实本质上就是一种优化算法，当目标变量的函数未知的情况下，优化目标的一种优化算法，这里是最大化accuracy，在无法知道结构和accuracy的关系，用神经网络去逼近。\n\n\n\n关于网络的深度，还是靠人为去设置的，这里的话是每sample 1600次，就将深度加深2。所以其实这个计算成本是很高的，每次深度加深，又要重新计算该模型结构的精度...文章最好的cifar-10上的最佳cnn结构是这样的：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb32ujvkrj30u00uj1ar.jpg\" alt=\"image-20201102200659882\" style=\"zoom:40%;\" />\n\n\n\n### 二、NAS的改进\n\n文献：《Learning Transferable Architectures for Scalable Image Recognitio》\n\n原先NAS的缺点就是复杂度太高，每次都要评估生成的整个网络结构，因此本文提出一种思想：其实在经典的VGG、Inception等结构中，往往都是反复利用一种卷积结构做堆叠生成的，因此我们只需搜索这种卷积结构的最优解就行。\n\n\n\n文章提出了Normal Cell和Reduce Cell，整个网络结构就是这两种cell的重复。注意，整个网络重复的次数N，还是人为拍的。\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb36xh65lj30rw0zsq65.jpg\" alt=\"image-20201102201054713\" style=\"zoom:40%;\" />\n\n我们只需搜索这两种cell的结构，搜索过程是这样的：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb37orljrj310l0u0tg3.jpg\" alt=\"image-20201102201138849\" style=\"zoom:40%;\" />\n\n假设一个Cell里有B个block，每个block生成步骤为：\n\n1. 从hi和hi-1或上一步中得到的隐含状态中选择一个作为输入一。\n2. 从从hi和hi-1或上一步中得到的隐含状态中选择一个作为输入二。（可以与第一个一样）\n3. 从操作集合中选择一个操作应用在输入一上。\n4. 从操作集合中选择一个操作应用在输入二上。\n5. 选择一个方法将第三步和第四步的结果合并。\n\n\n\n### 三、PNAS\n\n文献：《Progressive Neural Architecture Search》\n\n即使改进后，搜索一个神经网络结构，我们依然需要花800个GPU花4天的时间，我们可以进一步的降低复杂度。PNAS的思想是更为贪心的搜索。假设B=5，总共的复杂度为：\n\n对于第一次运行生成方法，只有两个输入，因而，选取两次，得到2x2种可能。有八种operator，选取两次，得到8x8中可能，因而第一次运行该方法的空间是22x82。而对于第二次运行生成方法，operator选择的可能性没有变化，但因为上一步有一个隐含状态输出，所以输入变成了3x3中可能。以此类推，五次运行生成算法的搜索空间是：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb3ecta8pj30zk02ewfh.jpg\" alt=\"image-20201102201802212\" style=\"zoom:50%;\" />\n\n\n\n而PNAS的话，我们第一步得到2^2 * 8^2 = 256种可能后，就用controller生成网络结构进行256种可能的搜索，找到top k的最优结构。然后之后第二步，就基于这top k结构来搜索，这样相当于进行了剪枝，减少了大量的计算空间。\n\n整体步骤：\n\n- 完全训练生成算法第一步的所有可能的候选(256 / 2 = 136个，因为对称性)\n\n- 训练启发式搜索算法\n\n- 对于生成算法的后面几步的每一步：\n\n- - 取得所有候选结构\n  - 预测候选结构在某数据集上的准确率，按照准确率排序。\n  - 取出准确率最高的top-K模型结构，进行训练。\n  - 训练启发式搜索算法\n\n\n\nPNAS提升：模型数目减小为五分之一，而总速度降低为八分之一。\n\n\n\n### 四 、ENAS\n\n文献：《Efficient Neural Architecture Search via Parameter Sharing》\n\n最后是目前最常用的方法ENAS，ENAS利用参数共享的思想把复杂度提升到了原来的千分之一。ENAS的思想是把要搜索的结构想像成一个node，所有的node构成一个大的DAG，而我们要搜索的可能就是一个子图结构，但是所有node之间的权重是共享的，不需要每搜索一次子图，就重新计算子图node之间的权重。\n\n![image-20201102202954216](https://tva1.sinaimg.cn/large/0081Kckwgy1gkb3qototnj31fm094gnm.jpg)\n\n之前的NAS是对候选子模型逐个从头训练，事实上子模型的结构许多都是相似的，所以许多**Wi,j** (第i个节点与第j个节点的权重矩阵) **是可以复用的**，没有必要从头开始训练。这样的共享权重在文中被称作**shared model**。\n\n\n\n最终我们要搜索的是子图，也就是红线流向：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb3so8j7xj30ia094jrz.jpg\" alt=\"image-20201102203149727\" style=\"zoom:50%;\" />\n\n再讲一下ENAS的训练，显然我们需要训练两个参数：\n\n- 共享权重参数\n- controller的参数\n\n整个训练过程是这样的：\n\n- **self.train_shared()** 。在模型架构固定的情况下，基于训练集，更新和共享内部参数权重**Wi,j**，使得内部权重得到更好收敛。\n- **self.train_controller()** 充分使用共享的内部权重，从controller RNN中抽样出一些候选子模型，在这些模型中选择在验证集上表现最好的架构，继续步骤1的计算。\n\n相当于以前的NAS我们通过**self.train_controller**采样得到模型结构，然后**每个模型各自训练**，最后平均得到accuracy来更新controller。而ENAS的话我们采样得到模型结构后，不需要进行训练，直接基于当前共享权重，得到这些模型中表现最好的架构。然后再基于该模型架构，更新共享权重。\n\n\n\n###  五、DARTS\n\n文献：《DARTS- Differentiable Architecture Search》\n\n依然是基于参数共享的理念，但是以往我们都是通过controller来控制node之间的信息流向，但是DARTS通过权重系数alpha直接来控制，不再需要controller：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkbtejwrlrj30qs0cs42u.jpg\" alt=\"image-20201103111749052\" style=\"zoom:50%;\" />\n\n所以DARTS算法的流程是：\n\n1. 对每个模型结构选择的地方，建立一个mixed operation。这个mixed operation有参数a（每个Node(i, j)都有一个operation维度总数的系数向量），作为权重。模型本身的参数我们设置为w\n\n2. 当模型还没有收敛时，做：\n\n3. 1. 更新mixed operation的模型结构参数a。使用gradient descent：grad(a, Lvalid(w*(a), a)). 这里的w*指在a结构下，训练到converge之后最佳的模型本身的参数w\n   2. 对模型本身的参数w做gradient descent。\n\n4. 如果像之前Multi Trials AutoML的方式，每次求解最后converge最佳参数w代价很高。类似ENAS，我们用单步优化的w来近似最优的w*，这样效率更好。因此对a的gradient变为：grad(a, Lvalid)(w - eps*grad(w, Ltrain(w, a), a)。实际上因为之后对w也会做gradient descent，这里直接用first order approximation即可，eps = 0，直接变为grad(a, Lvalid)(w, a)。这样每次计算量大大降低。\n\n   \n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkbthoiklrj31eg0bcq5f.jpg\" alt=\"image-20201103112025371\" style=\"zoom:50%;\" />\n\n\n\n### 总结\n\n其实上述这些神经网络架构搜索，也不是完全的智能搜索，还是需要人为来确定一个搜索空间，然后基于某类优化算法来求解优化问题罢了。优化算法可以有很多，比如暴力搜索、random search、贝叶斯优化、DQN、粒子群、policy network等等。像这种我们不知道x（网络架构）和y（模型准确度）这种关系的优化，用policy network的方法是一种很直观的想法。\n\n","slug":"深度学习/NAS系列文章解读","published":1,"updated":"2022-09-15T03:46:43.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551ox003cjqrrcrt5xhdg","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>NAS最近几年是AutoML领域比较火热的方向，主要是神经网络结构的自动搜索。最近看了几篇NAS文章，下面按照发展历史做个总结。</p>\n<p>参考博客：</p>\n<ul>\n<li><a href=\"https://zhuanlan.zhihu.com/p/36301731\" target=\"_blank\" rel=\"noopener\">炼丹术的终结</a></li>\n<li><a href=\"[http://nooverfit.com/wp/%E4%BD%A0%E6%83%B3%E8%A6%81%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%87%AA%E5%8A%A8%E8%AE%BE%E8%AE%A1%EF%BC%8C%E8%B0%B7%E6%AD%8C%E5%A4%A7%E8%84%91%E5%B8%AE%E4%BD%A0%E5%AE%9E%E7%8E%B0%E4%BA%86/](http://nooverfit.com/wp/你想要的神经网络自动设计，谷歌大脑帮你实现了/\">你想要的神经网络自动设计，谷歌大脑帮你实现了：用参数共享高效地搜索神经网络架构（ENAS）</a>)</li>\n</ul>\n<h3 id=\"一、NAS的提出\"><a href=\"#一、NAS的提出\" class=\"headerlink\" title=\"一、NAS的提出\"></a>一、NAS的提出</h3><p>文献：《NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING》</p>\n<p>本质上就是确定通过一个rnn的controller，来生成神经网网络的结构。</p>\n<p>例如卷积神经网络，那么无非就是要确定卷积核的数目、高、宽，stride的高和宽，也就是利用controller来生成这个五个参数。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkbtsqq13vj312a0dewmu.jpg\" alt=\"image-20201102192353768\" style=\"zoom:50%;\"></p>\n<p>controller得到5个参数的概率，然后通过sample得到网络结构，再基于该网络结构得到其在验证集上的accuracy，再利用该accuracy去更新controller的权重。这一步就类似于强化学习的policy network，我在之前的博客中也有介绍，其实本质上就是一种优化算法，当目标变量的函数未知的情况下，优化目标的一种优化算法，这里是最大化accuracy，在无法知道结构和accuracy的关系，用神经网络去逼近。</p>\n<p>关于网络的深度，还是靠人为去设置的，这里的话是每sample 1600次，就将深度加深2。所以其实这个计算成本是很高的，每次深度加深，又要重新计算该模型结构的精度…文章最好的cifar-10上的最佳cnn结构是这样的：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb32ujvkrj30u00uj1ar.jpg\" alt=\"image-20201102200659882\" style=\"zoom:40%;\"></p>\n<h3 id=\"二、NAS的改进\"><a href=\"#二、NAS的改进\" class=\"headerlink\" title=\"二、NAS的改进\"></a>二、NAS的改进</h3><p>文献：《Learning Transferable Architectures for Scalable Image Recognitio》</p>\n<p>原先NAS的缺点就是复杂度太高，每次都要评估生成的整个网络结构，因此本文提出一种思想：其实在经典的VGG、Inception等结构中，往往都是反复利用一种卷积结构做堆叠生成的，因此我们只需搜索这种卷积结构的最优解就行。</p>\n<p>文章提出了Normal Cell和Reduce Cell，整个网络结构就是这两种cell的重复。注意，整个网络重复的次数N，还是人为拍的。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb36xh65lj30rw0zsq65.jpg\" alt=\"image-20201102201054713\" style=\"zoom:40%;\"></p>\n<p>我们只需搜索这两种cell的结构，搜索过程是这样的：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb37orljrj310l0u0tg3.jpg\" alt=\"image-20201102201138849\" style=\"zoom:40%;\"></p>\n<p>假设一个Cell里有B个block，每个block生成步骤为：</p>\n<ol>\n<li>从hi和hi-1或上一步中得到的隐含状态中选择一个作为输入一。</li>\n<li>从从hi和hi-1或上一步中得到的隐含状态中选择一个作为输入二。（可以与第一个一样）</li>\n<li>从操作集合中选择一个操作应用在输入一上。</li>\n<li>从操作集合中选择一个操作应用在输入二上。</li>\n<li>选择一个方法将第三步和第四步的结果合并。</li>\n</ol>\n<h3 id=\"三、PNAS\"><a href=\"#三、PNAS\" class=\"headerlink\" title=\"三、PNAS\"></a>三、PNAS</h3><p>文献：《Progressive Neural Architecture Search》</p>\n<p>即使改进后，搜索一个神经网络结构，我们依然需要花800个GPU花4天的时间，我们可以进一步的降低复杂度。PNAS的思想是更为贪心的搜索。假设B=5，总共的复杂度为：</p>\n<p>对于第一次运行生成方法，只有两个输入，因而，选取两次，得到2x2种可能。有八种operator，选取两次，得到8x8中可能，因而第一次运行该方法的空间是22x82。而对于第二次运行生成方法，operator选择的可能性没有变化，但因为上一步有一个隐含状态输出，所以输入变成了3x3中可能。以此类推，五次运行生成算法的搜索空间是：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb3ecta8pj30zk02ewfh.jpg\" alt=\"image-20201102201802212\" style=\"zoom:50%;\"></p>\n<p>而PNAS的话，我们第一步得到2^2 * 8^2 = 256种可能后，就用controller生成网络结构进行256种可能的搜索，找到top k的最优结构。然后之后第二步，就基于这top k结构来搜索，这样相当于进行了剪枝，减少了大量的计算空间。</p>\n<p>整体步骤：</p>\n<ul>\n<li><p>完全训练生成算法第一步的所有可能的候选(256 / 2 = 136个，因为对称性)</p>\n</li>\n<li><p>训练启发式搜索算法</p>\n</li>\n<li><p>对于生成算法的后面几步的每一步：</p>\n</li>\n<li><ul>\n<li>取得所有候选结构</li>\n<li>预测候选结构在某数据集上的准确率，按照准确率排序。</li>\n<li>取出准确率最高的top-K模型结构，进行训练。</li>\n<li>训练启发式搜索算法</li>\n</ul>\n</li>\n</ul>\n<p>PNAS提升：模型数目减小为五分之一，而总速度降低为八分之一。</p>\n<h3 id=\"四-、ENAS\"><a href=\"#四-、ENAS\" class=\"headerlink\" title=\"四 、ENAS\"></a>四 、ENAS</h3><p>文献：《Efficient Neural Architecture Search via Parameter Sharing》</p>\n<p>最后是目前最常用的方法ENAS，ENAS利用参数共享的思想把复杂度提升到了原来的千分之一。ENAS的思想是把要搜索的结构想像成一个node，所有的node构成一个大的DAG，而我们要搜索的可能就是一个子图结构，但是所有node之间的权重是共享的，不需要每搜索一次子图，就重新计算子图node之间的权重。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb3qototnj31fm094gnm.jpg\" alt=\"image-20201102202954216\"></p>\n<p>之前的NAS是对候选子模型逐个从头训练，事实上子模型的结构许多都是相似的，所以许多<strong>Wi,j</strong> (第i个节点与第j个节点的权重矩阵) <strong>是可以复用的</strong>，没有必要从头开始训练。这样的共享权重在文中被称作<strong>shared model</strong>。</p>\n<p>最终我们要搜索的是子图，也就是红线流向：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb3so8j7xj30ia094jrz.jpg\" alt=\"image-20201102203149727\" style=\"zoom:50%;\"></p>\n<p>再讲一下ENAS的训练，显然我们需要训练两个参数：</p>\n<ul>\n<li>共享权重参数</li>\n<li>controller的参数</li>\n</ul>\n<p>整个训练过程是这样的：</p>\n<ul>\n<li><strong>self.train_shared()</strong> 。在模型架构固定的情况下，基于训练集，更新和共享内部参数权重<strong>Wi,j</strong>，使得内部权重得到更好收敛。</li>\n<li><strong>self.train_controller()</strong> 充分使用共享的内部权重，从controller RNN中抽样出一些候选子模型，在这些模型中选择在验证集上表现最好的架构，继续步骤1的计算。</li>\n</ul>\n<p>相当于以前的NAS我们通过<strong>self.train_controller</strong>采样得到模型结构，然后<strong>每个模型各自训练</strong>，最后平均得到accuracy来更新controller。而ENAS的话我们采样得到模型结构后，不需要进行训练，直接基于当前共享权重，得到这些模型中表现最好的架构。然后再基于该模型架构，更新共享权重。</p>\n<h3 id=\"五、DARTS\"><a href=\"#五、DARTS\" class=\"headerlink\" title=\"五、DARTS\"></a>五、DARTS</h3><p>文献：《DARTS- Differentiable Architecture Search》</p>\n<p>依然是基于参数共享的理念，但是以往我们都是通过controller来控制node之间的信息流向，但是DARTS通过权重系数alpha直接来控制，不再需要controller：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkbtejwrlrj30qs0cs42u.jpg\" alt=\"image-20201103111749052\" style=\"zoom:50%;\"></p>\n<p>所以DARTS算法的流程是：</p>\n<ol>\n<li><p>对每个模型结构选择的地方，建立一个mixed operation。这个mixed operation有参数a（每个Node(i, j)都有一个operation维度总数的系数向量），作为权重。模型本身的参数我们设置为w</p>\n</li>\n<li><p>当模型还没有收敛时，做：</p>\n</li>\n<li><ol>\n<li>更新mixed operation的模型结构参数a。使用gradient descent：grad(a, Lvalid(w<em>(a), a)). 这里的w</em>指在a结构下，训练到converge之后最佳的模型本身的参数w</li>\n<li>对模型本身的参数w做gradient descent。</li>\n</ol>\n</li>\n<li><p>如果像之前Multi Trials AutoML的方式，每次求解最后converge最佳参数w代价很高。类似ENAS，我们用单步优化的w来近似最优的w<em>，这样效率更好。因此对a的gradient变为：grad(a, Lvalid)(w - eps</em>grad(w, Ltrain(w, a), a)。实际上因为之后对w也会做gradient descent，这里直接用first order approximation即可，eps = 0，直接变为grad(a, Lvalid)(w, a)。这样每次计算量大大降低。</p>\n</li>\n</ol>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkbthoiklrj31eg0bcq5f.jpg\" alt=\"image-20201103112025371\" style=\"zoom:50%;\"></p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>其实上述这些神经网络架构搜索，也不是完全的智能搜索，还是需要人为来确定一个搜索空间，然后基于某类优化算法来求解优化问题罢了。优化算法可以有很多，比如暴力搜索、random search、贝叶斯优化、DQN、粒子群、policy network等等。像这种我们不知道x（网络架构）和y（模型准确度）这种关系的优化，用policy network的方法是一种很直观的想法。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>NAS最近几年是AutoML领域比较火热的方向，主要是神经网络结构的自动搜索。最近看了几篇NAS文章，下面按照发展历史做个总结。</p>\n<p>参考博客：</p>\n<ul>\n<li><a href=\"https://zhuanlan.zhihu.com/p/36301731\" target=\"_blank\" rel=\"noopener\">炼丹术的终结</a></li>\n<li><a href=\"[http://nooverfit.com/wp/%E4%BD%A0%E6%83%B3%E8%A6%81%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%87%AA%E5%8A%A8%E8%AE%BE%E8%AE%A1%EF%BC%8C%E8%B0%B7%E6%AD%8C%E5%A4%A7%E8%84%91%E5%B8%AE%E4%BD%A0%E5%AE%9E%E7%8E%B0%E4%BA%86/](http://nooverfit.com/wp/你想要的神经网络自动设计，谷歌大脑帮你实现了/\">你想要的神经网络自动设计，谷歌大脑帮你实现了：用参数共享高效地搜索神经网络架构（ENAS）</a>)</li>\n</ul>\n<h3 id=\"一、NAS的提出\"><a href=\"#一、NAS的提出\" class=\"headerlink\" title=\"一、NAS的提出\"></a>一、NAS的提出</h3><p>文献：《NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING》</p>\n<p>本质上就是确定通过一个rnn的controller，来生成神经网网络的结构。</p>\n<p>例如卷积神经网络，那么无非就是要确定卷积核的数目、高、宽，stride的高和宽，也就是利用controller来生成这个五个参数。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkbtsqq13vj312a0dewmu.jpg\" alt=\"image-20201102192353768\" style=\"zoom:50%;\"></p>\n<p>controller得到5个参数的概率，然后通过sample得到网络结构，再基于该网络结构得到其在验证集上的accuracy，再利用该accuracy去更新controller的权重。这一步就类似于强化学习的policy network，我在之前的博客中也有介绍，其实本质上就是一种优化算法，当目标变量的函数未知的情况下，优化目标的一种优化算法，这里是最大化accuracy，在无法知道结构和accuracy的关系，用神经网络去逼近。</p>\n<p>关于网络的深度，还是靠人为去设置的，这里的话是每sample 1600次，就将深度加深2。所以其实这个计算成本是很高的，每次深度加深，又要重新计算该模型结构的精度…文章最好的cifar-10上的最佳cnn结构是这样的：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb32ujvkrj30u00uj1ar.jpg\" alt=\"image-20201102200659882\" style=\"zoom:40%;\"></p>\n<h3 id=\"二、NAS的改进\"><a href=\"#二、NAS的改进\" class=\"headerlink\" title=\"二、NAS的改进\"></a>二、NAS的改进</h3><p>文献：《Learning Transferable Architectures for Scalable Image Recognitio》</p>\n<p>原先NAS的缺点就是复杂度太高，每次都要评估生成的整个网络结构，因此本文提出一种思想：其实在经典的VGG、Inception等结构中，往往都是反复利用一种卷积结构做堆叠生成的，因此我们只需搜索这种卷积结构的最优解就行。</p>\n<p>文章提出了Normal Cell和Reduce Cell，整个网络结构就是这两种cell的重复。注意，整个网络重复的次数N，还是人为拍的。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb36xh65lj30rw0zsq65.jpg\" alt=\"image-20201102201054713\" style=\"zoom:40%;\"></p>\n<p>我们只需搜索这两种cell的结构，搜索过程是这样的：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb37orljrj310l0u0tg3.jpg\" alt=\"image-20201102201138849\" style=\"zoom:40%;\"></p>\n<p>假设一个Cell里有B个block，每个block生成步骤为：</p>\n<ol>\n<li>从hi和hi-1或上一步中得到的隐含状态中选择一个作为输入一。</li>\n<li>从从hi和hi-1或上一步中得到的隐含状态中选择一个作为输入二。（可以与第一个一样）</li>\n<li>从操作集合中选择一个操作应用在输入一上。</li>\n<li>从操作集合中选择一个操作应用在输入二上。</li>\n<li>选择一个方法将第三步和第四步的结果合并。</li>\n</ol>\n<h3 id=\"三、PNAS\"><a href=\"#三、PNAS\" class=\"headerlink\" title=\"三、PNAS\"></a>三、PNAS</h3><p>文献：《Progressive Neural Architecture Search》</p>\n<p>即使改进后，搜索一个神经网络结构，我们依然需要花800个GPU花4天的时间，我们可以进一步的降低复杂度。PNAS的思想是更为贪心的搜索。假设B=5，总共的复杂度为：</p>\n<p>对于第一次运行生成方法，只有两个输入，因而，选取两次，得到2x2种可能。有八种operator，选取两次，得到8x8中可能，因而第一次运行该方法的空间是22x82。而对于第二次运行生成方法，operator选择的可能性没有变化，但因为上一步有一个隐含状态输出，所以输入变成了3x3中可能。以此类推，五次运行生成算法的搜索空间是：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb3ecta8pj30zk02ewfh.jpg\" alt=\"image-20201102201802212\" style=\"zoom:50%;\"></p>\n<p>而PNAS的话，我们第一步得到2^2 * 8^2 = 256种可能后，就用controller生成网络结构进行256种可能的搜索，找到top k的最优结构。然后之后第二步，就基于这top k结构来搜索，这样相当于进行了剪枝，减少了大量的计算空间。</p>\n<p>整体步骤：</p>\n<ul>\n<li><p>完全训练生成算法第一步的所有可能的候选(256 / 2 = 136个，因为对称性)</p>\n</li>\n<li><p>训练启发式搜索算法</p>\n</li>\n<li><p>对于生成算法的后面几步的每一步：</p>\n</li>\n<li><ul>\n<li>取得所有候选结构</li>\n<li>预测候选结构在某数据集上的准确率，按照准确率排序。</li>\n<li>取出准确率最高的top-K模型结构，进行训练。</li>\n<li>训练启发式搜索算法</li>\n</ul>\n</li>\n</ul>\n<p>PNAS提升：模型数目减小为五分之一，而总速度降低为八分之一。</p>\n<h3 id=\"四-、ENAS\"><a href=\"#四-、ENAS\" class=\"headerlink\" title=\"四 、ENAS\"></a>四 、ENAS</h3><p>文献：《Efficient Neural Architecture Search via Parameter Sharing》</p>\n<p>最后是目前最常用的方法ENAS，ENAS利用参数共享的思想把复杂度提升到了原来的千分之一。ENAS的思想是把要搜索的结构想像成一个node，所有的node构成一个大的DAG，而我们要搜索的可能就是一个子图结构，但是所有node之间的权重是共享的，不需要每搜索一次子图，就重新计算子图node之间的权重。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb3qototnj31fm094gnm.jpg\" alt=\"image-20201102202954216\"></p>\n<p>之前的NAS是对候选子模型逐个从头训练，事实上子模型的结构许多都是相似的，所以许多<strong>Wi,j</strong> (第i个节点与第j个节点的权重矩阵) <strong>是可以复用的</strong>，没有必要从头开始训练。这样的共享权重在文中被称作<strong>shared model</strong>。</p>\n<p>最终我们要搜索的是子图，也就是红线流向：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkb3so8j7xj30ia094jrz.jpg\" alt=\"image-20201102203149727\" style=\"zoom:50%;\"></p>\n<p>再讲一下ENAS的训练，显然我们需要训练两个参数：</p>\n<ul>\n<li>共享权重参数</li>\n<li>controller的参数</li>\n</ul>\n<p>整个训练过程是这样的：</p>\n<ul>\n<li><strong>self.train_shared()</strong> 。在模型架构固定的情况下，基于训练集，更新和共享内部参数权重<strong>Wi,j</strong>，使得内部权重得到更好收敛。</li>\n<li><strong>self.train_controller()</strong> 充分使用共享的内部权重，从controller RNN中抽样出一些候选子模型，在这些模型中选择在验证集上表现最好的架构，继续步骤1的计算。</li>\n</ul>\n<p>相当于以前的NAS我们通过<strong>self.train_controller</strong>采样得到模型结构，然后<strong>每个模型各自训练</strong>，最后平均得到accuracy来更新controller。而ENAS的话我们采样得到模型结构后，不需要进行训练，直接基于当前共享权重，得到这些模型中表现最好的架构。然后再基于该模型架构，更新共享权重。</p>\n<h3 id=\"五、DARTS\"><a href=\"#五、DARTS\" class=\"headerlink\" title=\"五、DARTS\"></a>五、DARTS</h3><p>文献：《DARTS- Differentiable Architecture Search》</p>\n<p>依然是基于参数共享的理念，但是以往我们都是通过controller来控制node之间的信息流向，但是DARTS通过权重系数alpha直接来控制，不再需要controller：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkbtejwrlrj30qs0cs42u.jpg\" alt=\"image-20201103111749052\" style=\"zoom:50%;\"></p>\n<p>所以DARTS算法的流程是：</p>\n<ol>\n<li><p>对每个模型结构选择的地方，建立一个mixed operation。这个mixed operation有参数a（每个Node(i, j)都有一个operation维度总数的系数向量），作为权重。模型本身的参数我们设置为w</p>\n</li>\n<li><p>当模型还没有收敛时，做：</p>\n</li>\n<li><ol>\n<li>更新mixed operation的模型结构参数a。使用gradient descent：grad(a, Lvalid(w<em>(a), a)). 这里的w</em>指在a结构下，训练到converge之后最佳的模型本身的参数w</li>\n<li>对模型本身的参数w做gradient descent。</li>\n</ol>\n</li>\n<li><p>如果像之前Multi Trials AutoML的方式，每次求解最后converge最佳参数w代价很高。类似ENAS，我们用单步优化的w来近似最优的w<em>，这样效率更好。因此对a的gradient变为：grad(a, Lvalid)(w - eps</em>grad(w, Ltrain(w, a), a)。实际上因为之后对w也会做gradient descent，这里直接用first order approximation即可，eps = 0，直接变为grad(a, Lvalid)(w, a)。这样每次计算量大大降低。</p>\n</li>\n</ol>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwgy1gkbthoiklrj31eg0bcq5f.jpg\" alt=\"image-20201103112025371\" style=\"zoom:50%;\"></p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>其实上述这些神经网络架构搜索，也不是完全的智能搜索，还是需要人为来确定一个搜索空间，然后基于某类优化算法来求解优化问题罢了。优化算法可以有很多，比如暴力搜索、random search、贝叶斯优化、DQN、粒子群、policy network等等。像这种我们不知道x（网络架构）和y（模型准确度）这种关系的优化，用policy network的方法是一种很直观的想法。</p>\n"},{"title":"关于Policy Network","date":"2020-10-29T16:00:00.000Z","_content":"\n\n\n最近在看NAS（neural architecture search）的论文，里面讲到了强化学习的policy network，然后我就研究了下这个东西，发现是个蛮有意思的概念，确实和nas有共同之处。有意思的点主要其实是在loss function的设计上，下面详细讲下我的理解。\n\n\n\n正常来讲，我们做一个Neural Network来解决Classification or Regression task， loss function往往就是涉及一个真实label和一个esitimated label，也就是NN预测一个概率，然后拿真实的概率去做cross entropy或者等价的最大似然函数作为loss function。但是对于强化学习任务，我们通过NN预测一个动作的概率 $\\pi(a|s, \\theta)$，但是无法知道这个动作的真实label是什么？那要怎么来设计Loss function呢？\n\n\n\n其实想法也很intuitive，Policy Network设计一个评价指标$f(a, s)$，你也可以认为是做出这个动作a之后取得的reward，然后这个loss function为：\n$$\nL(\\theta) = \\sum f(a, s) log{\\pi(a|s, \\theta)}\n$$\n其实你仔细一看，发现对比正常loss function - $\\sum p(x) log{\\hat{p}(x)}\\$，无非就是把真实label的概率换成$f(a, s)$罢了。这样的loss function其实本质上就是等价于 最大化评价指标$f(a, s)$，推到过程如下：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gk7e3apzp5j312u0ju0xf.jpg\" alt=\"image-20201030152538474\" style=\"zoom:50%;\" />\n\n\n\n最后，衍生到NAS上，其实本质和Policy Network是一样的。NAS里我们想要得到一个神经网络结构的概率，然后评价指标，就是用这个结构得到其在验证集上的精度。\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gk7e5gww8wj312e05qdhk.jpg\" alt=\"image-20201030152746965\" style=\"zoom:50%;\" />","source":"_posts/深度学习/关于policy network.md","raw":"---\ntitle: 关于Policy Network\ndate: 2020-10-30\ncategories: [深度学习,强化学习]\n---\n\n\n\n最近在看NAS（neural architecture search）的论文，里面讲到了强化学习的policy network，然后我就研究了下这个东西，发现是个蛮有意思的概念，确实和nas有共同之处。有意思的点主要其实是在loss function的设计上，下面详细讲下我的理解。\n\n\n\n正常来讲，我们做一个Neural Network来解决Classification or Regression task， loss function往往就是涉及一个真实label和一个esitimated label，也就是NN预测一个概率，然后拿真实的概率去做cross entropy或者等价的最大似然函数作为loss function。但是对于强化学习任务，我们通过NN预测一个动作的概率 $\\pi(a|s, \\theta)$，但是无法知道这个动作的真实label是什么？那要怎么来设计Loss function呢？\n\n\n\n其实想法也很intuitive，Policy Network设计一个评价指标$f(a, s)$，你也可以认为是做出这个动作a之后取得的reward，然后这个loss function为：\n$$\nL(\\theta) = \\sum f(a, s) log{\\pi(a|s, \\theta)}\n$$\n其实你仔细一看，发现对比正常loss function - $\\sum p(x) log{\\hat{p}(x)}\\$，无非就是把真实label的概率换成$f(a, s)$罢了。这样的loss function其实本质上就是等价于 最大化评价指标$f(a, s)$，推到过程如下：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gk7e3apzp5j312u0ju0xf.jpg\" alt=\"image-20201030152538474\" style=\"zoom:50%;\" />\n\n\n\n最后，衍生到NAS上，其实本质和Policy Network是一样的。NAS里我们想要得到一个神经网络结构的概率，然后评价指标，就是用这个结构得到其在验证集上的精度。\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gk7e5gww8wj312e05qdhk.jpg\" alt=\"image-20201030152746965\" style=\"zoom:50%;\" />","slug":"深度学习/关于policy network","published":1,"updated":"2022-09-15T03:46:43.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551oz003hjqrrkmyigdj1","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>最近在看NAS（neural architecture search）的论文，里面讲到了强化学习的policy network，然后我就研究了下这个东西，发现是个蛮有意思的概念，确实和nas有共同之处。有意思的点主要其实是在loss function的设计上，下面详细讲下我的理解。</p>\n<p>正常来讲，我们做一个Neural Network来解决Classification or Regression task， loss function往往就是涉及一个真实label和一个esitimated label，也就是NN预测一个概率，然后拿真实的概率去做cross entropy或者等价的最大似然函数作为loss function。但是对于强化学习任务，我们通过NN预测一个动作的概率 $\\pi(a|s, \\theta)$，但是无法知道这个动作的真实label是什么？那要怎么来设计Loss function呢？</p>\n<p>其实想法也很intuitive，Policy Network设计一个评价指标$f(a, s)$，你也可以认为是做出这个动作a之后取得的reward，然后这个loss function为：</p>\n<script type=\"math/tex; mode=display\">\nL(\\theta) = \\sum f(a, s) log{\\pi(a|s, \\theta)}</script><p>其实你仔细一看，发现对比正常loss function - $\\sum p(x) log{\\hat{p}(x)}$，无非就是把真实label的概率换成$f(a, s)$罢了。这样的loss function其实本质上就是等价于 最大化评价指标$f(a, s)$，推到过程如下：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gk7e3apzp5j312u0ju0xf.jpg\" alt=\"image-20201030152538474\" style=\"zoom:50%;\"></p>\n<p>最后，衍生到NAS上，其实本质和Policy Network是一样的。NAS里我们想要得到一个神经网络结构的概率，然后评价指标，就是用这个结构得到其在验证集上的精度。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gk7e5gww8wj312e05qdhk.jpg\" alt=\"image-20201030152746965\" style=\"zoom:50%;\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>最近在看NAS（neural architecture search）的论文，里面讲到了强化学习的policy network，然后我就研究了下这个东西，发现是个蛮有意思的概念，确实和nas有共同之处。有意思的点主要其实是在loss function的设计上，下面详细讲下我的理解。</p>\n<p>正常来讲，我们做一个Neural Network来解决Classification or Regression task， loss function往往就是涉及一个真实label和一个esitimated label，也就是NN预测一个概率，然后拿真实的概率去做cross entropy或者等价的最大似然函数作为loss function。但是对于强化学习任务，我们通过NN预测一个动作的概率 $\\pi(a|s, \\theta)$，但是无法知道这个动作的真实label是什么？那要怎么来设计Loss function呢？</p>\n<p>其实想法也很intuitive，Policy Network设计一个评价指标$f(a, s)$，你也可以认为是做出这个动作a之后取得的reward，然后这个loss function为：</p>\n<script type=\"math/tex; mode=display\">\nL(\\theta) = \\sum f(a, s) log{\\pi(a|s, \\theta)}</script><p>其实你仔细一看，发现对比正常loss function - $\\sum p(x) log{\\hat{p}(x)}$，无非就是把真实label的概率换成$f(a, s)$罢了。这样的loss function其实本质上就是等价于 最大化评价指标$f(a, s)$，推到过程如下：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gk7e3apzp5j312u0ju0xf.jpg\" alt=\"image-20201030152538474\" style=\"zoom:50%;\"></p>\n<p>最后，衍生到NAS上，其实本质和Policy Network是一样的。NAS里我们想要得到一个神经网络结构的概率，然后评价指标，就是用这个结构得到其在验证集上的精度。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gk7e5gww8wj312e05qdhk.jpg\" alt=\"image-20201030152746965\" style=\"zoom:50%;\"></p>\n"},{"title":"Github代理加速","date":"2020-06-04T16:00:00.000Z","_content":"\n\n\n```shell\n## 开启代理\ngit config --global http.proxy 'socks5://127.0.0.1:7891'\ngit config --global https.proxy 'socks5://127.0.0.1:7891'\n\n## 关闭代理\ngit config --global --unset http.proxy\ngit config --global --unset https.proxy\n\n```\n\n\n\n同时需要在你的代理软件中开启全局模式：\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhkh034lhj30m40ceq7k.jpg\" alt=\"image-20200605180018041\" style=\"zoom:50%;\" />\n\n注意，socks5的端口号根据代理软件设置的端口号来开(我的是7891)","source":"_posts/编程开发/Github代理加速.md","raw":"---\ntitle: Github代理加速\ndate: 2020-06-05\ncategories: [编程开发]\n---\n\n\n\n```shell\n## 开启代理\ngit config --global http.proxy 'socks5://127.0.0.1:7891'\ngit config --global https.proxy 'socks5://127.0.0.1:7891'\n\n## 关闭代理\ngit config --global --unset http.proxy\ngit config --global --unset https.proxy\n\n```\n\n\n\n同时需要在你的代理软件中开启全局模式：\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhkh034lhj30m40ceq7k.jpg\" alt=\"image-20200605180018041\" style=\"zoom:50%;\" />\n\n注意，socks5的端口号根据代理软件设置的端口号来开(我的是7891)","slug":"编程开发/Github代理加速","published":1,"updated":"2022-09-15T03:46:43.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551p0003ijqrr8fh0ou6g","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span># 开启代理</span><br><span class=\"line\">git config --global http.proxy 'socks5://127.0.0.1:7891'</span><br><span class=\"line\">git config --global https.proxy 'socks5://127.0.0.1:7891'</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span># 关闭代理</span><br><span class=\"line\">git config --global --unset http.proxy</span><br><span class=\"line\">git config --global --unset https.proxy</span><br></pre></td></tr></table></figure>\n<p>同时需要在你的代理软件中开启全局模式：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhkh034lhj30m40ceq7k.jpg\" alt=\"image-20200605180018041\" style=\"zoom:50%;\"></p>\n<p>注意，socks5的端口号根据代理软件设置的端口号来开(我的是7891)</p>\n","site":{"data":{}},"excerpt":"","more":"<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span># 开启代理</span><br><span class=\"line\">git config --global http.proxy 'socks5://127.0.0.1:7891'</span><br><span class=\"line\">git config --global https.proxy 'socks5://127.0.0.1:7891'</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span># 关闭代理</span><br><span class=\"line\">git config --global --unset http.proxy</span><br><span class=\"line\">git config --global --unset https.proxy</span><br></pre></td></tr></table></figure>\n<p>同时需要在你的代理软件中开启全局模式：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhkh034lhj30m40ceq7k.jpg\" alt=\"image-20200605180018041\" style=\"zoom:50%;\"></p>\n<p>注意，socks5的端口号根据代理软件设置的端口号来开(我的是7891)</p>\n"},{"title":"Attention和Transformer","date":"2022-08-09T16:00:00.000Z","_content":"\n## 一、背景\n\nAttention是目前最热的深度学习方向，最开始从NLP领域的机器翻译方向发源，到如今百花齐放到各个领域，包括推荐搜索，计算广告等等，万物皆可embedding，万物皆可attention，因为attention的本质就是为了更好的做embedding。\n\n本篇文章按照attention发展的顺序来阐述：\n\n- Seq2Seq模型\n- Attention机制\n- Transformer的Self-Attention\n- Bert\n\n\n\n## 二、Seq2Seq模型\n\n最开始做机器学习的时候，我们用rnn模型做encoder-decoder，encoder输出最后的隐层向量，然后decoder逐个输入进行解码。\n\n对于encoder-decoder的方式，要注意训练和预测的不同：\n\n- 训练：decoder的输入是当前单词的embedding\n- 预测：decoder的输入是上个rnn的输出\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rorn4x1j21340l2myx.jpg\" alt=\"image-20210202171847909\" style=\"zoom:50%;\" />\n\n对于这种Seq2Seq的方式，很明显最大的问题就是将encoder压缩在了最后一个rnn输出上，RNN机制实际中存在长程梯度消失的问题，对于较长的句子，我们很难寄希望于将输入的序列转化为定长的向量而保存所有的有效信息，所以随着所需翻译句子的长度的增加，这种结构的效果会显著下降。\n\n\n\n## 三、Attention机制\n\n基于Seq2Seq，学术界提出了attention机制：\n\n- 不用将encoder的最后一层喂给decoder。\n- 在decoder的时候，除了当前的输入外，我们还会附加一个context_vector，这个vector利用上一层的隐层输出与encoder做attention得到，这样的话就充分得利用了encoder里每个词的信息。\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51roxlem4j215w0u0q5f.jpg\" alt=\"image-20210202172909409\" style=\"zoom:50%;\" />\n\n参考[博客](https://www.cnblogs.com/ydcode/p/11038064.html)。\n\n详细讲讲attention的做法，其实本质上就是生成Q,K,V三个向量：\n\n- Q是查询向量，一般就是我们要查的item生成的向量\n- K是被检索向量的key\n- V是被检索向量的value，一般而言K和V都是被检索item生成的向量\n- 具体计算方式如下：本质上就是Q和K点积先生成Q在每个被检索item的权重，然后对每个被检索item的V进行加权求和，得到检索item最终的向量。\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rp2mnu7j21320gyjsk.jpg\" alt=\"image-20210202175527001\" style=\"zoom: 50%;\" />\n\n对于encoder-decoder模型，K和V就是encoder每个rnn单元的隐层向量，Q就是decoder的前一个rnn单元的隐层向量。\n\n这里除以根号dk的原因：\n\n- 以数组为例，2个长度是len，均值是0，方差是1的数组点积会生成长度是len，均值是0，方差是len的数组。而方差变大会导致softmax的输入推向正无穷或负无穷，这时的梯度会无限趋近于0，不利于训练的收敛。因此除以len的开方，可以是数组的方差重新回归到1，有利于训练的收敛。\n\n\n\n## 四、Transformer的Self-Attention\n\n谷歌在[Attention is All you need](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1706.03762)首次提出来transformer模型，其中就是提出了self-attention的概念，本质上就是代替了原先的rnn单元，因为rnn单元是串行训练的，无法并行化，效率很低，而且无法充分利用上下文的信息，self-attention就是当前的item同时产生Q,K,V，然后不同item之间做attention，所以这也是为什么叫self-attention。\n\n下图是transformer的架构，也是有encoder-decoder组成的，其中最重要的就是multi-head attention部分。\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpbn61pj20ke0s6768.jpg\" alt=\"preview\" style=\"zoom:50%;\" />\n\nMulti-head attention的架构图如下，所谓的multi-head就是用了多个QKV，最后concatenate之后，再经过一个线性变换，最后生成和输入一样维度的向量，中间Q,K,V的向量维度是自定义的。\n\n- 一个multi-head attention单元，每个item的输入embed维度和输出embed维度是一样的，类似经过了一个变换单元。\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpfq7s8j213w0mctaz.jpg\" alt=\"img\" style=\"zoom: 50%;\" />\n\n- encoder的话就是就是经过了N个multi-head attention单元，输出每个item的隐层向量\n\n- decoder的话有所不同，首先是生成当前item的输入向量，这个也是经过multi-head attention单元，但是会有个mask，就是只用当前item之前的item做attention，最终生成当前item的输出向量后作为Q，而K和V则是encoder的输出，这样再经过一个multi-head attention单元，生成当前item的最终输出向量，可以看下面这个图片示意：\n\n  <img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpj4z0pj213m0k60tg.jpg\" alt=\"image-20210202210714371\" style=\"zoom:50%;\" />\n\n## 五、Bert\n\nBert就是transformer的encoder部分进行更多堆叠的结果，如下图所示。当输入有多少个embedding，那么输出也就有相同数量的embedding，可以采用和RNN采用相同的叫法，把输出叫做隐向量。在做具体NLP任务的时候，只需要从中取对应的隐向量作为输出即可。\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpmpavzj20as0eamxe.jpg\" alt=\"img\" style=\"zoom:75%;\" />\n\nbert本质上即使一个大型的预训练模型，然后拿预训练的词向量放到特定的nlp任务里做微调，就可以得到非常好的效果。和bert类似的还有GPT，ELMo，区别如下图：\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpq0qjsj213q09oq53.jpg\" alt=\"image-20210202214339626\" style=\"zoom:50%;\" />\n\n\n\nbert的预训练方法有如下几种：\n\n- masked language model：在一句话中mask掉几个单词然后对mask掉的单词做预测\n- next sentence prediction：判断两句话是否为上下文的关系\n- 这两个训练任务是同时进行的，最后做加权loss\n\n\n\n#  六、代码参考\n\n具体transformer encoder的写法，可以参考这个代码：这个代码是BST的写法，bst就是对用户行为序列做multi head self attention。\n\n```python\ndef BST(behavior_seq, mask, behavior='refine_expose', pooling='sum_sqrt'):\n    max_length = int(behavior_seq.shape[1])\n    in_features = int(behavior_seq.shape[-1])\n\n    mask = tf.cast(mask, tf.float32)\n\n    pe = M.get_variable('{}_position_encoding'.format(behavior), shape=[1, max_length, in_features], initializer=initializers.HeNormal())/10\n    \n    behavior_seq += pe\n\n    def layer_norm(x, name, epsilon=1e-6):\n\n        filters = x.get_shape()[-1]\n        scale = M.get_variable(\n            \"{}_layer_norm_scale_{}\".format(behavior, name), [1, 1, filters], initializer=initializers.Ones())\n        bias = M.get_variable(\n            \"{}_layer_norm_bias_{}\".format(behavior, name), [1, 1, filters], initializer=initializers.Zeros())\n        mean = tf.reduce_mean(x, axis=[-1], keepdims=True)\n        variance = tf.reduce_mean(tf.square(x - mean), axis=[-1], keepdims=True)\n        norm_x = (x - mean) * tf.rsqrt(variance + epsilon)\n\n        return norm_x * scale + bias\n\n\n    def block(seq, name=0):\n        heads=2\n        attout =          (seq, dqk=2, heads=heads, dv=int(in_features/heads), seq_mask=mask)\n        attout = tf.keras.layers.Dropout(rate=0.05)(layers.Relu()(attout))\n        attout = layer_norm(attout + seq, '{}_1'.format(name))\n\n        out = layers.Dense(in_features*2, kernel_initializer=initializers.HeNormal())(attout)\n        out = layers.Dense(in_features, kernel_initializer=initializers.HeNormal())(out)\n        out = tf.keras.layers.Dropout(rate=0.05)(layers.Relu()(out))\n        out = layer_norm(attout + out, '{}_2'.format(name))\n\n        return out\n    \n\n    def bst_pooling(seq):\n        print('bst pooling:\\t', pooling)\n        if pooling=='sum':\n            return tf.math.reduce_sum(seq*mask, axis=1)\n        elif pooling=='mean':\n            seq_len = tf.math.reduce_sum(mask, axis=1, keepdims=True)\n            return tf.math.reduce_sum(seq*mask/seq_len, axis=1)\n        elif pooling=='sum_sqrt':\n            seq_len = tf.math.reduce_sum(mask, axis=1, keepdims=True)\n            return tf.math.reduce_sum(seq*mask / tf.math.sqrt(seq_len), axis=1)\n        elif pooling=='concat':\n            return tf.reshape(seq*mask, [-1, int(seq.shape[1])*int(seq.shape[2])])\n        elif pooling=='max':\n            return tf.math.reduce_max(seq*mask, axis=1) \n        elif pooling=='selfAtt':\n            pass\n        else:\n            raise Exception('unkown pooling method:\\t', pooling)\n\n    out_seq = block(behavior_seq, 0) # b * len * f\n    out = bst_pooling(out_seq) # b * ?\n    return out\n```\n","source":"_posts/深度学习/Attention和Transformer.md","raw":"---\ntitle: Attention和Transformer\ndate: 2022-08-10\ncategories: 深度学习\n---\n\n## 一、背景\n\nAttention是目前最热的深度学习方向，最开始从NLP领域的机器翻译方向发源，到如今百花齐放到各个领域，包括推荐搜索，计算广告等等，万物皆可embedding，万物皆可attention，因为attention的本质就是为了更好的做embedding。\n\n本篇文章按照attention发展的顺序来阐述：\n\n- Seq2Seq模型\n- Attention机制\n- Transformer的Self-Attention\n- Bert\n\n\n\n## 二、Seq2Seq模型\n\n最开始做机器学习的时候，我们用rnn模型做encoder-decoder，encoder输出最后的隐层向量，然后decoder逐个输入进行解码。\n\n对于encoder-decoder的方式，要注意训练和预测的不同：\n\n- 训练：decoder的输入是当前单词的embedding\n- 预测：decoder的输入是上个rnn的输出\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rorn4x1j21340l2myx.jpg\" alt=\"image-20210202171847909\" style=\"zoom:50%;\" />\n\n对于这种Seq2Seq的方式，很明显最大的问题就是将encoder压缩在了最后一个rnn输出上，RNN机制实际中存在长程梯度消失的问题，对于较长的句子，我们很难寄希望于将输入的序列转化为定长的向量而保存所有的有效信息，所以随着所需翻译句子的长度的增加，这种结构的效果会显著下降。\n\n\n\n## 三、Attention机制\n\n基于Seq2Seq，学术界提出了attention机制：\n\n- 不用将encoder的最后一层喂给decoder。\n- 在decoder的时候，除了当前的输入外，我们还会附加一个context_vector，这个vector利用上一层的隐层输出与encoder做attention得到，这样的话就充分得利用了encoder里每个词的信息。\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51roxlem4j215w0u0q5f.jpg\" alt=\"image-20210202172909409\" style=\"zoom:50%;\" />\n\n参考[博客](https://www.cnblogs.com/ydcode/p/11038064.html)。\n\n详细讲讲attention的做法，其实本质上就是生成Q,K,V三个向量：\n\n- Q是查询向量，一般就是我们要查的item生成的向量\n- K是被检索向量的key\n- V是被检索向量的value，一般而言K和V都是被检索item生成的向量\n- 具体计算方式如下：本质上就是Q和K点积先生成Q在每个被检索item的权重，然后对每个被检索item的V进行加权求和，得到检索item最终的向量。\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rp2mnu7j21320gyjsk.jpg\" alt=\"image-20210202175527001\" style=\"zoom: 50%;\" />\n\n对于encoder-decoder模型，K和V就是encoder每个rnn单元的隐层向量，Q就是decoder的前一个rnn单元的隐层向量。\n\n这里除以根号dk的原因：\n\n- 以数组为例，2个长度是len，均值是0，方差是1的数组点积会生成长度是len，均值是0，方差是len的数组。而方差变大会导致softmax的输入推向正无穷或负无穷，这时的梯度会无限趋近于0，不利于训练的收敛。因此除以len的开方，可以是数组的方差重新回归到1，有利于训练的收敛。\n\n\n\n## 四、Transformer的Self-Attention\n\n谷歌在[Attention is All you need](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1706.03762)首次提出来transformer模型，其中就是提出了self-attention的概念，本质上就是代替了原先的rnn单元，因为rnn单元是串行训练的，无法并行化，效率很低，而且无法充分利用上下文的信息，self-attention就是当前的item同时产生Q,K,V，然后不同item之间做attention，所以这也是为什么叫self-attention。\n\n下图是transformer的架构，也是有encoder-decoder组成的，其中最重要的就是multi-head attention部分。\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpbn61pj20ke0s6768.jpg\" alt=\"preview\" style=\"zoom:50%;\" />\n\nMulti-head attention的架构图如下，所谓的multi-head就是用了多个QKV，最后concatenate之后，再经过一个线性变换，最后生成和输入一样维度的向量，中间Q,K,V的向量维度是自定义的。\n\n- 一个multi-head attention单元，每个item的输入embed维度和输出embed维度是一样的，类似经过了一个变换单元。\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpfq7s8j213w0mctaz.jpg\" alt=\"img\" style=\"zoom: 50%;\" />\n\n- encoder的话就是就是经过了N个multi-head attention单元，输出每个item的隐层向量\n\n- decoder的话有所不同，首先是生成当前item的输入向量，这个也是经过multi-head attention单元，但是会有个mask，就是只用当前item之前的item做attention，最终生成当前item的输出向量后作为Q，而K和V则是encoder的输出，这样再经过一个multi-head attention单元，生成当前item的最终输出向量，可以看下面这个图片示意：\n\n  <img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpj4z0pj213m0k60tg.jpg\" alt=\"image-20210202210714371\" style=\"zoom:50%;\" />\n\n## 五、Bert\n\nBert就是transformer的encoder部分进行更多堆叠的结果，如下图所示。当输入有多少个embedding，那么输出也就有相同数量的embedding，可以采用和RNN采用相同的叫法，把输出叫做隐向量。在做具体NLP任务的时候，只需要从中取对应的隐向量作为输出即可。\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpmpavzj20as0eamxe.jpg\" alt=\"img\" style=\"zoom:75%;\" />\n\nbert本质上即使一个大型的预训练模型，然后拿预训练的词向量放到特定的nlp任务里做微调，就可以得到非常好的效果。和bert类似的还有GPT，ELMo，区别如下图：\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpq0qjsj213q09oq53.jpg\" alt=\"image-20210202214339626\" style=\"zoom:50%;\" />\n\n\n\nbert的预训练方法有如下几种：\n\n- masked language model：在一句话中mask掉几个单词然后对mask掉的单词做预测\n- next sentence prediction：判断两句话是否为上下文的关系\n- 这两个训练任务是同时进行的，最后做加权loss\n\n\n\n#  六、代码参考\n\n具体transformer encoder的写法，可以参考这个代码：这个代码是BST的写法，bst就是对用户行为序列做multi head self attention。\n\n```python\ndef BST(behavior_seq, mask, behavior='refine_expose', pooling='sum_sqrt'):\n    max_length = int(behavior_seq.shape[1])\n    in_features = int(behavior_seq.shape[-1])\n\n    mask = tf.cast(mask, tf.float32)\n\n    pe = M.get_variable('{}_position_encoding'.format(behavior), shape=[1, max_length, in_features], initializer=initializers.HeNormal())/10\n    \n    behavior_seq += pe\n\n    def layer_norm(x, name, epsilon=1e-6):\n\n        filters = x.get_shape()[-1]\n        scale = M.get_variable(\n            \"{}_layer_norm_scale_{}\".format(behavior, name), [1, 1, filters], initializer=initializers.Ones())\n        bias = M.get_variable(\n            \"{}_layer_norm_bias_{}\".format(behavior, name), [1, 1, filters], initializer=initializers.Zeros())\n        mean = tf.reduce_mean(x, axis=[-1], keepdims=True)\n        variance = tf.reduce_mean(tf.square(x - mean), axis=[-1], keepdims=True)\n        norm_x = (x - mean) * tf.rsqrt(variance + epsilon)\n\n        return norm_x * scale + bias\n\n\n    def block(seq, name=0):\n        heads=2\n        attout =          (seq, dqk=2, heads=heads, dv=int(in_features/heads), seq_mask=mask)\n        attout = tf.keras.layers.Dropout(rate=0.05)(layers.Relu()(attout))\n        attout = layer_norm(attout + seq, '{}_1'.format(name))\n\n        out = layers.Dense(in_features*2, kernel_initializer=initializers.HeNormal())(attout)\n        out = layers.Dense(in_features, kernel_initializer=initializers.HeNormal())(out)\n        out = tf.keras.layers.Dropout(rate=0.05)(layers.Relu()(out))\n        out = layer_norm(attout + out, '{}_2'.format(name))\n\n        return out\n    \n\n    def bst_pooling(seq):\n        print('bst pooling:\\t', pooling)\n        if pooling=='sum':\n            return tf.math.reduce_sum(seq*mask, axis=1)\n        elif pooling=='mean':\n            seq_len = tf.math.reduce_sum(mask, axis=1, keepdims=True)\n            return tf.math.reduce_sum(seq*mask/seq_len, axis=1)\n        elif pooling=='sum_sqrt':\n            seq_len = tf.math.reduce_sum(mask, axis=1, keepdims=True)\n            return tf.math.reduce_sum(seq*mask / tf.math.sqrt(seq_len), axis=1)\n        elif pooling=='concat':\n            return tf.reshape(seq*mask, [-1, int(seq.shape[1])*int(seq.shape[2])])\n        elif pooling=='max':\n            return tf.math.reduce_max(seq*mask, axis=1) \n        elif pooling=='selfAtt':\n            pass\n        else:\n            raise Exception('unkown pooling method:\\t', pooling)\n\n    out_seq = block(behavior_seq, 0) # b * len * f\n    out = bst_pooling(out_seq) # b * ?\n    return out\n```\n","slug":"深度学习/Attention和Transformer","published":1,"updated":"2022-10-18T07:53:31.165Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551p1003mjqrrwyezymh8","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h2><p>Attention是目前最热的深度学习方向，最开始从NLP领域的机器翻译方向发源，到如今百花齐放到各个领域，包括推荐搜索，计算广告等等，万物皆可embedding，万物皆可attention，因为attention的本质就是为了更好的做embedding。</p>\n<p>本篇文章按照attention发展的顺序来阐述：</p>\n<ul>\n<li>Seq2Seq模型</li>\n<li>Attention机制</li>\n<li>Transformer的Self-Attention</li>\n<li>Bert</li>\n</ul>\n<h2 id=\"二、Seq2Seq模型\"><a href=\"#二、Seq2Seq模型\" class=\"headerlink\" title=\"二、Seq2Seq模型\"></a>二、Seq2Seq模型</h2><p>最开始做机器学习的时候，我们用rnn模型做encoder-decoder，encoder输出最后的隐层向量，然后decoder逐个输入进行解码。</p>\n<p>对于encoder-decoder的方式，要注意训练和预测的不同：</p>\n<ul>\n<li>训练：decoder的输入是当前单词的embedding</li>\n<li>预测：decoder的输入是上个rnn的输出</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rorn4x1j21340l2myx.jpg\" alt=\"image-20210202171847909\" style=\"zoom:50%;\"></p>\n<p>对于这种Seq2Seq的方式，很明显最大的问题就是将encoder压缩在了最后一个rnn输出上，RNN机制实际中存在长程梯度消失的问题，对于较长的句子，我们很难寄希望于将输入的序列转化为定长的向量而保存所有的有效信息，所以随着所需翻译句子的长度的增加，这种结构的效果会显著下降。</p>\n<h2 id=\"三、Attention机制\"><a href=\"#三、Attention机制\" class=\"headerlink\" title=\"三、Attention机制\"></a>三、Attention机制</h2><p>基于Seq2Seq，学术界提出了attention机制：</p>\n<ul>\n<li>不用将encoder的最后一层喂给decoder。</li>\n<li>在decoder的时候，除了当前的输入外，我们还会附加一个context_vector，这个vector利用上一层的隐层输出与encoder做attention得到，这样的话就充分得利用了encoder里每个词的信息。</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51roxlem4j215w0u0q5f.jpg\" alt=\"image-20210202172909409\" style=\"zoom:50%;\"></p>\n<p>参考<a href=\"https://www.cnblogs.com/ydcode/p/11038064.html\" target=\"_blank\" rel=\"noopener\">博客</a>。</p>\n<p>详细讲讲attention的做法，其实本质上就是生成Q,K,V三个向量：</p>\n<ul>\n<li>Q是查询向量，一般就是我们要查的item生成的向量</li>\n<li>K是被检索向量的key</li>\n<li>V是被检索向量的value，一般而言K和V都是被检索item生成的向量</li>\n<li>具体计算方式如下：本质上就是Q和K点积先生成Q在每个被检索item的权重，然后对每个被检索item的V进行加权求和，得到检索item最终的向量。</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rp2mnu7j21320gyjsk.jpg\" alt=\"image-20210202175527001\" style=\"zoom: 50%;\"></p>\n<p>对于encoder-decoder模型，K和V就是encoder每个rnn单元的隐层向量，Q就是decoder的前一个rnn单元的隐层向量。</p>\n<p>这里除以根号dk的原因：</p>\n<ul>\n<li>以数组为例，2个长度是len，均值是0，方差是1的数组点积会生成长度是len，均值是0，方差是len的数组。而方差变大会导致softmax的输入推向正无穷或负无穷，这时的梯度会无限趋近于0，不利于训练的收敛。因此除以len的开方，可以是数组的方差重新回归到1，有利于训练的收敛。</li>\n</ul>\n<h2 id=\"四、Transformer的Self-Attention\"><a href=\"#四、Transformer的Self-Attention\" class=\"headerlink\" title=\"四、Transformer的Self-Attention\"></a>四、Transformer的Self-Attention</h2><p>谷歌在<a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1706.03762\" target=\"_blank\" rel=\"noopener\">Attention is All you need</a>首次提出来transformer模型，其中就是提出了self-attention的概念，本质上就是代替了原先的rnn单元，因为rnn单元是串行训练的，无法并行化，效率很低，而且无法充分利用上下文的信息，self-attention就是当前的item同时产生Q,K,V，然后不同item之间做attention，所以这也是为什么叫self-attention。</p>\n<p>下图是transformer的架构，也是有encoder-decoder组成的，其中最重要的就是multi-head attention部分。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpbn61pj20ke0s6768.jpg\" alt=\"preview\" style=\"zoom:50%;\"></p>\n<p>Multi-head attention的架构图如下，所谓的multi-head就是用了多个QKV，最后concatenate之后，再经过一个线性变换，最后生成和输入一样维度的向量，中间Q,K,V的向量维度是自定义的。</p>\n<ul>\n<li>一个multi-head attention单元，每个item的输入embed维度和输出embed维度是一样的，类似经过了一个变换单元。</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpfq7s8j213w0mctaz.jpg\" alt=\"img\" style=\"zoom: 50%;\"></p>\n<ul>\n<li><p>encoder的话就是就是经过了N个multi-head attention单元，输出每个item的隐层向量</p>\n</li>\n<li><p>decoder的话有所不同，首先是生成当前item的输入向量，这个也是经过multi-head attention单元，但是会有个mask，就是只用当前item之前的item做attention，最终生成当前item的输出向量后作为Q，而K和V则是encoder的输出，这样再经过一个multi-head attention单元，生成当前item的最终输出向量，可以看下面这个图片示意：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpj4z0pj213m0k60tg.jpg\" alt=\"image-20210202210714371\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<h2 id=\"五、Bert\"><a href=\"#五、Bert\" class=\"headerlink\" title=\"五、Bert\"></a>五、Bert</h2><p>Bert就是transformer的encoder部分进行更多堆叠的结果，如下图所示。当输入有多少个embedding，那么输出也就有相同数量的embedding，可以采用和RNN采用相同的叫法，把输出叫做隐向量。在做具体NLP任务的时候，只需要从中取对应的隐向量作为输出即可。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpmpavzj20as0eamxe.jpg\" alt=\"img\" style=\"zoom:75%;\"></p>\n<p>bert本质上即使一个大型的预训练模型，然后拿预训练的词向量放到特定的nlp任务里做微调，就可以得到非常好的效果。和bert类似的还有GPT，ELMo，区别如下图：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpq0qjsj213q09oq53.jpg\" alt=\"image-20210202214339626\" style=\"zoom:50%;\"></p>\n<p>bert的预训练方法有如下几种：</p>\n<ul>\n<li>masked language model：在一句话中mask掉几个单词然后对mask掉的单词做预测</li>\n<li>next sentence prediction：判断两句话是否为上下文的关系</li>\n<li>这两个训练任务是同时进行的，最后做加权loss</li>\n</ul>\n<h1 id=\"六、代码参考\"><a href=\"#六、代码参考\" class=\"headerlink\" title=\"六、代码参考\"></a>六、代码参考</h1><p>具体transformer encoder的写法，可以参考这个代码：这个代码是BST的写法，bst就是对用户行为序列做multi head self attention。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">BST</span><span class=\"params\">(behavior_seq, mask, behavior=<span class=\"string\">'refine_expose'</span>, pooling=<span class=\"string\">'sum_sqrt'</span>)</span>:</span></span><br><span class=\"line\">    max_length = int(behavior_seq.shape[<span class=\"number\">1</span>])</span><br><span class=\"line\">    in_features = int(behavior_seq.shape[<span class=\"number\">-1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    mask = tf.cast(mask, tf.float32)</span><br><span class=\"line\"></span><br><span class=\"line\">    pe = M.get_variable(<span class=\"string\">'&#123;&#125;_position_encoding'</span>.format(behavior), shape=[<span class=\"number\">1</span>, max_length, in_features], initializer=initializers.HeNormal())/<span class=\"number\">10</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    behavior_seq += pe</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">layer_norm</span><span class=\"params\">(x, name, epsilon=<span class=\"number\">1e-6</span>)</span>:</span></span><br><span class=\"line\"></span><br><span class=\"line\">        filters = x.get_shape()[<span class=\"number\">-1</span>]</span><br><span class=\"line\">        scale = M.get_variable(</span><br><span class=\"line\">            <span class=\"string\">\"&#123;&#125;_layer_norm_scale_&#123;&#125;\"</span>.format(behavior, name), [<span class=\"number\">1</span>, <span class=\"number\">1</span>, filters], initializer=initializers.Ones())</span><br><span class=\"line\">        bias = M.get_variable(</span><br><span class=\"line\">            <span class=\"string\">\"&#123;&#125;_layer_norm_bias_&#123;&#125;\"</span>.format(behavior, name), [<span class=\"number\">1</span>, <span class=\"number\">1</span>, filters], initializer=initializers.Zeros())</span><br><span class=\"line\">        mean = tf.reduce_mean(x, axis=[<span class=\"number\">-1</span>], keepdims=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        variance = tf.reduce_mean(tf.square(x - mean), axis=[<span class=\"number\">-1</span>], keepdims=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        norm_x = (x - mean) * tf.rsqrt(variance + epsilon)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> norm_x * scale + bias</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">block</span><span class=\"params\">(seq, name=<span class=\"number\">0</span>)</span>:</span></span><br><span class=\"line\">        heads=<span class=\"number\">2</span></span><br><span class=\"line\">        attout =          (seq, dqk=<span class=\"number\">2</span>, heads=heads, dv=int(in_features/heads), seq_mask=mask)</span><br><span class=\"line\">        attout = tf.keras.layers.Dropout(rate=<span class=\"number\">0.05</span>)(layers.Relu()(attout))</span><br><span class=\"line\">        attout = layer_norm(attout + seq, <span class=\"string\">'&#123;&#125;_1'</span>.format(name))</span><br><span class=\"line\"></span><br><span class=\"line\">        out = layers.Dense(in_features*<span class=\"number\">2</span>, kernel_initializer=initializers.HeNormal())(attout)</span><br><span class=\"line\">        out = layers.Dense(in_features, kernel_initializer=initializers.HeNormal())(out)</span><br><span class=\"line\">        out = tf.keras.layers.Dropout(rate=<span class=\"number\">0.05</span>)(layers.Relu()(out))</span><br><span class=\"line\">        out = layer_norm(attout + out, <span class=\"string\">'&#123;&#125;_2'</span>.format(name))</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bst_pooling</span><span class=\"params\">(seq)</span>:</span></span><br><span class=\"line\">        print(<span class=\"string\">'bst pooling:\\t'</span>, pooling)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> pooling==<span class=\"string\">'sum'</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> tf.math.reduce_sum(seq*mask, axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> pooling==<span class=\"string\">'mean'</span>:</span><br><span class=\"line\">            seq_len = tf.math.reduce_sum(mask, axis=<span class=\"number\">1</span>, keepdims=<span class=\"literal\">True</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> tf.math.reduce_sum(seq*mask/seq_len, axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> pooling==<span class=\"string\">'sum_sqrt'</span>:</span><br><span class=\"line\">            seq_len = tf.math.reduce_sum(mask, axis=<span class=\"number\">1</span>, keepdims=<span class=\"literal\">True</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> tf.math.reduce_sum(seq*mask / tf.math.sqrt(seq_len), axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> pooling==<span class=\"string\">'concat'</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> tf.reshape(seq*mask, [<span class=\"number\">-1</span>, int(seq.shape[<span class=\"number\">1</span>])*int(seq.shape[<span class=\"number\">2</span>])])</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> pooling==<span class=\"string\">'max'</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> tf.math.reduce_max(seq*mask, axis=<span class=\"number\">1</span>) </span><br><span class=\"line\">        <span class=\"keyword\">elif</span> pooling==<span class=\"string\">'selfAtt'</span>:</span><br><span class=\"line\">            <span class=\"keyword\">pass</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">raise</span> Exception(<span class=\"string\">'unkown pooling method:\\t'</span>, pooling)</span><br><span class=\"line\"></span><br><span class=\"line\">    out_seq = block(behavior_seq, <span class=\"number\">0</span>) <span class=\"comment\"># b * len * f</span></span><br><span class=\"line\">    out = bst_pooling(out_seq) <span class=\"comment\"># b * ?</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> out</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h2><p>Attention是目前最热的深度学习方向，最开始从NLP领域的机器翻译方向发源，到如今百花齐放到各个领域，包括推荐搜索，计算广告等等，万物皆可embedding，万物皆可attention，因为attention的本质就是为了更好的做embedding。</p>\n<p>本篇文章按照attention发展的顺序来阐述：</p>\n<ul>\n<li>Seq2Seq模型</li>\n<li>Attention机制</li>\n<li>Transformer的Self-Attention</li>\n<li>Bert</li>\n</ul>\n<h2 id=\"二、Seq2Seq模型\"><a href=\"#二、Seq2Seq模型\" class=\"headerlink\" title=\"二、Seq2Seq模型\"></a>二、Seq2Seq模型</h2><p>最开始做机器学习的时候，我们用rnn模型做encoder-decoder，encoder输出最后的隐层向量，然后decoder逐个输入进行解码。</p>\n<p>对于encoder-decoder的方式，要注意训练和预测的不同：</p>\n<ul>\n<li>训练：decoder的输入是当前单词的embedding</li>\n<li>预测：decoder的输入是上个rnn的输出</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rorn4x1j21340l2myx.jpg\" alt=\"image-20210202171847909\" style=\"zoom:50%;\"></p>\n<p>对于这种Seq2Seq的方式，很明显最大的问题就是将encoder压缩在了最后一个rnn输出上，RNN机制实际中存在长程梯度消失的问题，对于较长的句子，我们很难寄希望于将输入的序列转化为定长的向量而保存所有的有效信息，所以随着所需翻译句子的长度的增加，这种结构的效果会显著下降。</p>\n<h2 id=\"三、Attention机制\"><a href=\"#三、Attention机制\" class=\"headerlink\" title=\"三、Attention机制\"></a>三、Attention机制</h2><p>基于Seq2Seq，学术界提出了attention机制：</p>\n<ul>\n<li>不用将encoder的最后一层喂给decoder。</li>\n<li>在decoder的时候，除了当前的输入外，我们还会附加一个context_vector，这个vector利用上一层的隐层输出与encoder做attention得到，这样的话就充分得利用了encoder里每个词的信息。</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51roxlem4j215w0u0q5f.jpg\" alt=\"image-20210202172909409\" style=\"zoom:50%;\"></p>\n<p>参考<a href=\"https://www.cnblogs.com/ydcode/p/11038064.html\" target=\"_blank\" rel=\"noopener\">博客</a>。</p>\n<p>详细讲讲attention的做法，其实本质上就是生成Q,K,V三个向量：</p>\n<ul>\n<li>Q是查询向量，一般就是我们要查的item生成的向量</li>\n<li>K是被检索向量的key</li>\n<li>V是被检索向量的value，一般而言K和V都是被检索item生成的向量</li>\n<li>具体计算方式如下：本质上就是Q和K点积先生成Q在每个被检索item的权重，然后对每个被检索item的V进行加权求和，得到检索item最终的向量。</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rp2mnu7j21320gyjsk.jpg\" alt=\"image-20210202175527001\" style=\"zoom: 50%;\"></p>\n<p>对于encoder-decoder模型，K和V就是encoder每个rnn单元的隐层向量，Q就是decoder的前一个rnn单元的隐层向量。</p>\n<p>这里除以根号dk的原因：</p>\n<ul>\n<li>以数组为例，2个长度是len，均值是0，方差是1的数组点积会生成长度是len，均值是0，方差是len的数组。而方差变大会导致softmax的输入推向正无穷或负无穷，这时的梯度会无限趋近于0，不利于训练的收敛。因此除以len的开方，可以是数组的方差重新回归到1，有利于训练的收敛。</li>\n</ul>\n<h2 id=\"四、Transformer的Self-Attention\"><a href=\"#四、Transformer的Self-Attention\" class=\"headerlink\" title=\"四、Transformer的Self-Attention\"></a>四、Transformer的Self-Attention</h2><p>谷歌在<a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1706.03762\" target=\"_blank\" rel=\"noopener\">Attention is All you need</a>首次提出来transformer模型，其中就是提出了self-attention的概念，本质上就是代替了原先的rnn单元，因为rnn单元是串行训练的，无法并行化，效率很低，而且无法充分利用上下文的信息，self-attention就是当前的item同时产生Q,K,V，然后不同item之间做attention，所以这也是为什么叫self-attention。</p>\n<p>下图是transformer的架构，也是有encoder-decoder组成的，其中最重要的就是multi-head attention部分。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpbn61pj20ke0s6768.jpg\" alt=\"preview\" style=\"zoom:50%;\"></p>\n<p>Multi-head attention的架构图如下，所谓的multi-head就是用了多个QKV，最后concatenate之后，再经过一个线性变换，最后生成和输入一样维度的向量，中间Q,K,V的向量维度是自定义的。</p>\n<ul>\n<li>一个multi-head attention单元，每个item的输入embed维度和输出embed维度是一样的，类似经过了一个变换单元。</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpfq7s8j213w0mctaz.jpg\" alt=\"img\" style=\"zoom: 50%;\"></p>\n<ul>\n<li><p>encoder的话就是就是经过了N个multi-head attention单元，输出每个item的隐层向量</p>\n</li>\n<li><p>decoder的话有所不同，首先是生成当前item的输入向量，这个也是经过multi-head attention单元，但是会有个mask，就是只用当前item之前的item做attention，最终生成当前item的输出向量后作为Q，而K和V则是encoder的输出，这样再经过一个multi-head attention单元，生成当前item的最终输出向量，可以看下面这个图片示意：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpj4z0pj213m0k60tg.jpg\" alt=\"image-20210202210714371\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<h2 id=\"五、Bert\"><a href=\"#五、Bert\" class=\"headerlink\" title=\"五、Bert\"></a>五、Bert</h2><p>Bert就是transformer的encoder部分进行更多堆叠的结果，如下图所示。当输入有多少个embedding，那么输出也就有相同数量的embedding，可以采用和RNN采用相同的叫法，把输出叫做隐向量。在做具体NLP任务的时候，只需要从中取对应的隐向量作为输出即可。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpmpavzj20as0eamxe.jpg\" alt=\"img\" style=\"zoom:75%;\"></p>\n<p>bert本质上即使一个大型的预训练模型，然后拿预训练的词向量放到特定的nlp任务里做微调，就可以得到非常好的效果。和bert类似的还有GPT，ELMo，区别如下图：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rpq0qjsj213q09oq53.jpg\" alt=\"image-20210202214339626\" style=\"zoom:50%;\"></p>\n<p>bert的预训练方法有如下几种：</p>\n<ul>\n<li>masked language model：在一句话中mask掉几个单词然后对mask掉的单词做预测</li>\n<li>next sentence prediction：判断两句话是否为上下文的关系</li>\n<li>这两个训练任务是同时进行的，最后做加权loss</li>\n</ul>\n<h1 id=\"六、代码参考\"><a href=\"#六、代码参考\" class=\"headerlink\" title=\"六、代码参考\"></a>六、代码参考</h1><p>具体transformer encoder的写法，可以参考这个代码：这个代码是BST的写法，bst就是对用户行为序列做multi head self attention。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">BST</span><span class=\"params\">(behavior_seq, mask, behavior=<span class=\"string\">'refine_expose'</span>, pooling=<span class=\"string\">'sum_sqrt'</span>)</span>:</span></span><br><span class=\"line\">    max_length = int(behavior_seq.shape[<span class=\"number\">1</span>])</span><br><span class=\"line\">    in_features = int(behavior_seq.shape[<span class=\"number\">-1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    mask = tf.cast(mask, tf.float32)</span><br><span class=\"line\"></span><br><span class=\"line\">    pe = M.get_variable(<span class=\"string\">'&#123;&#125;_position_encoding'</span>.format(behavior), shape=[<span class=\"number\">1</span>, max_length, in_features], initializer=initializers.HeNormal())/<span class=\"number\">10</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    behavior_seq += pe</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">layer_norm</span><span class=\"params\">(x, name, epsilon=<span class=\"number\">1e-6</span>)</span>:</span></span><br><span class=\"line\"></span><br><span class=\"line\">        filters = x.get_shape()[<span class=\"number\">-1</span>]</span><br><span class=\"line\">        scale = M.get_variable(</span><br><span class=\"line\">            <span class=\"string\">\"&#123;&#125;_layer_norm_scale_&#123;&#125;\"</span>.format(behavior, name), [<span class=\"number\">1</span>, <span class=\"number\">1</span>, filters], initializer=initializers.Ones())</span><br><span class=\"line\">        bias = M.get_variable(</span><br><span class=\"line\">            <span class=\"string\">\"&#123;&#125;_layer_norm_bias_&#123;&#125;\"</span>.format(behavior, name), [<span class=\"number\">1</span>, <span class=\"number\">1</span>, filters], initializer=initializers.Zeros())</span><br><span class=\"line\">        mean = tf.reduce_mean(x, axis=[<span class=\"number\">-1</span>], keepdims=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        variance = tf.reduce_mean(tf.square(x - mean), axis=[<span class=\"number\">-1</span>], keepdims=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        norm_x = (x - mean) * tf.rsqrt(variance + epsilon)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> norm_x * scale + bias</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">block</span><span class=\"params\">(seq, name=<span class=\"number\">0</span>)</span>:</span></span><br><span class=\"line\">        heads=<span class=\"number\">2</span></span><br><span class=\"line\">        attout =          (seq, dqk=<span class=\"number\">2</span>, heads=heads, dv=int(in_features/heads), seq_mask=mask)</span><br><span class=\"line\">        attout = tf.keras.layers.Dropout(rate=<span class=\"number\">0.05</span>)(layers.Relu()(attout))</span><br><span class=\"line\">        attout = layer_norm(attout + seq, <span class=\"string\">'&#123;&#125;_1'</span>.format(name))</span><br><span class=\"line\"></span><br><span class=\"line\">        out = layers.Dense(in_features*<span class=\"number\">2</span>, kernel_initializer=initializers.HeNormal())(attout)</span><br><span class=\"line\">        out = layers.Dense(in_features, kernel_initializer=initializers.HeNormal())(out)</span><br><span class=\"line\">        out = tf.keras.layers.Dropout(rate=<span class=\"number\">0.05</span>)(layers.Relu()(out))</span><br><span class=\"line\">        out = layer_norm(attout + out, <span class=\"string\">'&#123;&#125;_2'</span>.format(name))</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bst_pooling</span><span class=\"params\">(seq)</span>:</span></span><br><span class=\"line\">        print(<span class=\"string\">'bst pooling:\\t'</span>, pooling)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> pooling==<span class=\"string\">'sum'</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> tf.math.reduce_sum(seq*mask, axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> pooling==<span class=\"string\">'mean'</span>:</span><br><span class=\"line\">            seq_len = tf.math.reduce_sum(mask, axis=<span class=\"number\">1</span>, keepdims=<span class=\"literal\">True</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> tf.math.reduce_sum(seq*mask/seq_len, axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> pooling==<span class=\"string\">'sum_sqrt'</span>:</span><br><span class=\"line\">            seq_len = tf.math.reduce_sum(mask, axis=<span class=\"number\">1</span>, keepdims=<span class=\"literal\">True</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> tf.math.reduce_sum(seq*mask / tf.math.sqrt(seq_len), axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> pooling==<span class=\"string\">'concat'</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> tf.reshape(seq*mask, [<span class=\"number\">-1</span>, int(seq.shape[<span class=\"number\">1</span>])*int(seq.shape[<span class=\"number\">2</span>])])</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> pooling==<span class=\"string\">'max'</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> tf.math.reduce_max(seq*mask, axis=<span class=\"number\">1</span>) </span><br><span class=\"line\">        <span class=\"keyword\">elif</span> pooling==<span class=\"string\">'selfAtt'</span>:</span><br><span class=\"line\">            <span class=\"keyword\">pass</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">raise</span> Exception(<span class=\"string\">'unkown pooling method:\\t'</span>, pooling)</span><br><span class=\"line\"></span><br><span class=\"line\">    out_seq = block(behavior_seq, <span class=\"number\">0</span>) <span class=\"comment\"># b * len * f</span></span><br><span class=\"line\">    out = bst_pooling(out_seq) <span class=\"comment\"># b * ?</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> out</span><br></pre></td></tr></table></figure>\n"},{"title":"各语言对象和变量的关系","date":"2020-01-07T10:13:30.000Z","_content":"\n# 变量和对象\n\n任何语言都是由变量和对象组成的。\n\n变量和对象可能是存在一块的（变量代表内存，内存存放的的是对象二进制），也可能是分开存的，这种情况就是对象存放在其他内存，而变量存放的是那块内存的地址。\n\n\n\n具体方式在不同语言中有很大区别，不同语言在底层可能做了很多优化，例如JVM的栈变量共享等。\n\n```\nint a = 3;\nint b = 3;\n```\n\n对于上述代码，C++的话就是分配了两个值类型变量在不同栈空间，同时分配2个对，内存各自写3。\n\n而对于java，也是分配了两个值类型变量在不同栈空间，但是对象3却是在栈空间单独存在的，值类型变量都是指向这个对象3，虽说是值类型，但是存放的也是地址。但是依然是值类型，有点像python的不可变对象传递。\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmvjxiyzp0j30ok0wogq5.jpg\" alt=\"image-20210121194155398\" style=\"zoom:50%;\" />\n\n# 变量类型\n\n在各种语言中，变量一般分为值类型和引用类型。\n\n### 值类型\n\n变量直接存放对象的二进制数据(JVM的栈变量共享除外)，如果对变量取地址，那么就是这段内存的地址名，例如\"0xc00001c100\"。\n\n这里的内存空间一般是栈空间，变量和对象都是在栈空间的。\n\n\n\n### 引用类型\n\n引用类型的变量存放的是对象的地址，变量位于栈空间，而对象则是位于堆空间。例如a是引用变量，其内容是”0x12335423341“，这段地址是堆空间的地址，指向堆空间的对象，而自己的地址可能是”0x51314241“，是在栈空间的地址。\n\n引用类型有个巨大的好处是自动垃圾回收GC，通过引用计数可以释放没有引用的对象。\n\n\n\n### 不同语言总结\n\n- Java：\n\n  - 值类型：基本数据类型int/float/short/long/double/byte/char/bool\n  - 引用类型：其余全是\n\n- Python\n\n  - 全是引用类型，python的对象基本是heap空间\n\n- Go：\n\n  - 值类型：基本数据类型int, float,bool, string，以及数组和struct\n  - 引用类型：其余全是，Go存在指针\n\n- C++：\n\n  - 全是值类型\n  - 引用类型：通过指针，引用&，shared_ptr等实现。\n\n  \n\n# 栈空间堆空间\n\n正如前文所说，栈空间一般是值类型的对象和变量空间，堆空间是引用变量的对象空间，堆空间一般都是new或malloc出来的，在C++中需要进行手动创建和释放，程序结束也不一定可以正确释放，容易造成内存泄漏(所以后面有类似java的shared_ptr，做引用计数的垃圾回收)。\n\n\n\n除栈空间和堆空间，一般还有\n\n- 静态空间：存放全局变量、static变量，在程序结束会自动释放\n- 常量空间：类似java的string类型，final修饰的变量\n- 代码空间：存放程序代码\n\n\n\n## java\n\n- 对象分为基本数据类型和其他对象，同理变量也就分为基本数据类型的变量和引用变量\n- 基本数据类型的变量操作，产生新的对象，不再指向同一个对象。变量传递相当于对象值传递。\n\n```\n例子：int a = 3;int b;b = a; // 两个变量指向同一个栈对象a = 30; // a指向新的栈对象，b=3不会变\n```\n\n- 引用变量操作，还是指向同一个对象，类似C/C++的指针/引用。变量操作相当于对象地址传递。\n\n```\n例子：Class a = new Class();Class b = new Class();b = a; // 两个变量指向同一个堆对象a.set(something); // a,b两个引用变量依然指向同一个堆对象\n```\n\n- 基本类型的变量和对象，引用变量都放在栈中，引用对象放在堆中。\n- 栈空间的数据对象是共享的，但是堆空间是不共享的。\n\n```\nint a = 3; int b = 3; //这个时候3的栈对象已经存在，共享， a == b\n```\n\n## python\n\n- 对象分为可变对象和不可变对象，同理变量也就分为不可变对象的变量和可变对象的变量\n- 不可变对象(整型、字符串和元组)的变量操作，产生新的对象，不再指向同一个对象。变量传递相当于对象值传递。\n\n```\n例子：a = 3; b = a; // 两个变量指向同一个对象a = 30; // a指向新的对象，b=3不会变\n```\n\n- 可变对象的变量操作，还是指向同一个对象，类似C/C++的指针/引用。变量操作相当于对象地址传递。\n\n```\n例子：a = Class();b = a; // 两个变量指向同一个对象a.set(something); // a,b两个变量依然指向同一个对象\n```\n\n## C/C++\n\n- 变量有变量的值和地址，对象有对象的值和地址\n- 通过指针来实现对同一个对象的操作，指针的自由度更高，但是代码上相比java和python就更加复杂了，引用变量多方便啊。。\n- C/C++也有指针的高级封装-引用！\n\n```\nint a =4 ; int &b = a; b=3 //a = b = 3\n```\n\n- 即使是基本数据类型，也可以操作为同一个对象\n\n```\nint a = 3;int* p = &a;a = 4; // *p和a指向同一个对象\n```","source":"_posts/编程开发/各语言对象和变量的关系.md","raw":"---\ntitle: 各语言对象和变量的关系\ndate: 2020-01-07 18:13:30\ncategories: [编程开发]\n---\n\n# 变量和对象\n\n任何语言都是由变量和对象组成的。\n\n变量和对象可能是存在一块的（变量代表内存，内存存放的的是对象二进制），也可能是分开存的，这种情况就是对象存放在其他内存，而变量存放的是那块内存的地址。\n\n\n\n具体方式在不同语言中有很大区别，不同语言在底层可能做了很多优化，例如JVM的栈变量共享等。\n\n```\nint a = 3;\nint b = 3;\n```\n\n对于上述代码，C++的话就是分配了两个值类型变量在不同栈空间，同时分配2个对，内存各自写3。\n\n而对于java，也是分配了两个值类型变量在不同栈空间，但是对象3却是在栈空间单独存在的，值类型变量都是指向这个对象3，虽说是值类型，但是存放的也是地址。但是依然是值类型，有点像python的不可变对象传递。\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmvjxiyzp0j30ok0wogq5.jpg\" alt=\"image-20210121194155398\" style=\"zoom:50%;\" />\n\n# 变量类型\n\n在各种语言中，变量一般分为值类型和引用类型。\n\n### 值类型\n\n变量直接存放对象的二进制数据(JVM的栈变量共享除外)，如果对变量取地址，那么就是这段内存的地址名，例如\"0xc00001c100\"。\n\n这里的内存空间一般是栈空间，变量和对象都是在栈空间的。\n\n\n\n### 引用类型\n\n引用类型的变量存放的是对象的地址，变量位于栈空间，而对象则是位于堆空间。例如a是引用变量，其内容是”0x12335423341“，这段地址是堆空间的地址，指向堆空间的对象，而自己的地址可能是”0x51314241“，是在栈空间的地址。\n\n引用类型有个巨大的好处是自动垃圾回收GC，通过引用计数可以释放没有引用的对象。\n\n\n\n### 不同语言总结\n\n- Java：\n\n  - 值类型：基本数据类型int/float/short/long/double/byte/char/bool\n  - 引用类型：其余全是\n\n- Python\n\n  - 全是引用类型，python的对象基本是heap空间\n\n- Go：\n\n  - 值类型：基本数据类型int, float,bool, string，以及数组和struct\n  - 引用类型：其余全是，Go存在指针\n\n- C++：\n\n  - 全是值类型\n  - 引用类型：通过指针，引用&，shared_ptr等实现。\n\n  \n\n# 栈空间堆空间\n\n正如前文所说，栈空间一般是值类型的对象和变量空间，堆空间是引用变量的对象空间，堆空间一般都是new或malloc出来的，在C++中需要进行手动创建和释放，程序结束也不一定可以正确释放，容易造成内存泄漏(所以后面有类似java的shared_ptr，做引用计数的垃圾回收)。\n\n\n\n除栈空间和堆空间，一般还有\n\n- 静态空间：存放全局变量、static变量，在程序结束会自动释放\n- 常量空间：类似java的string类型，final修饰的变量\n- 代码空间：存放程序代码\n\n\n\n## java\n\n- 对象分为基本数据类型和其他对象，同理变量也就分为基本数据类型的变量和引用变量\n- 基本数据类型的变量操作，产生新的对象，不再指向同一个对象。变量传递相当于对象值传递。\n\n```\n例子：int a = 3;int b;b = a; // 两个变量指向同一个栈对象a = 30; // a指向新的栈对象，b=3不会变\n```\n\n- 引用变量操作，还是指向同一个对象，类似C/C++的指针/引用。变量操作相当于对象地址传递。\n\n```\n例子：Class a = new Class();Class b = new Class();b = a; // 两个变量指向同一个堆对象a.set(something); // a,b两个引用变量依然指向同一个堆对象\n```\n\n- 基本类型的变量和对象，引用变量都放在栈中，引用对象放在堆中。\n- 栈空间的数据对象是共享的，但是堆空间是不共享的。\n\n```\nint a = 3; int b = 3; //这个时候3的栈对象已经存在，共享， a == b\n```\n\n## python\n\n- 对象分为可变对象和不可变对象，同理变量也就分为不可变对象的变量和可变对象的变量\n- 不可变对象(整型、字符串和元组)的变量操作，产生新的对象，不再指向同一个对象。变量传递相当于对象值传递。\n\n```\n例子：a = 3; b = a; // 两个变量指向同一个对象a = 30; // a指向新的对象，b=3不会变\n```\n\n- 可变对象的变量操作，还是指向同一个对象，类似C/C++的指针/引用。变量操作相当于对象地址传递。\n\n```\n例子：a = Class();b = a; // 两个变量指向同一个对象a.set(something); // a,b两个变量依然指向同一个对象\n```\n\n## C/C++\n\n- 变量有变量的值和地址，对象有对象的值和地址\n- 通过指针来实现对同一个对象的操作，指针的自由度更高，但是代码上相比java和python就更加复杂了，引用变量多方便啊。。\n- C/C++也有指针的高级封装-引用！\n\n```\nint a =4 ; int &b = a; b=3 //a = b = 3\n```\n\n- 即使是基本数据类型，也可以操作为同一个对象\n\n```\nint a = 3;int* p = &a;a = 4; // *p和a指向同一个对象\n```","slug":"编程开发/各语言对象和变量的关系","published":1,"updated":"2022-09-15T03:46:43.368Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551p1003ojqrrdm9cv33m","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"变量和对象\"><a href=\"#变量和对象\" class=\"headerlink\" title=\"变量和对象\"></a>变量和对象</h1><p>任何语言都是由变量和对象组成的。</p>\n<p>变量和对象可能是存在一块的（变量代表内存，内存存放的的是对象二进制），也可能是分开存的，这种情况就是对象存放在其他内存，而变量存放的是那块内存的地址。</p>\n<p>具体方式在不同语言中有很大区别，不同语言在底层可能做了很多优化，例如JVM的栈变量共享等。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int a = 3;</span><br><span class=\"line\">int b = 3;</span><br></pre></td></tr></table></figure>\n<p>对于上述代码，C++的话就是分配了两个值类型变量在不同栈空间，同时分配2个对，内存各自写3。</p>\n<p>而对于java，也是分配了两个值类型变量在不同栈空间，但是对象3却是在栈空间单独存在的，值类型变量都是指向这个对象3，虽说是值类型，但是存放的也是地址。但是依然是值类型，有点像python的不可变对象传递。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmvjxiyzp0j30ok0wogq5.jpg\" alt=\"image-20210121194155398\" style=\"zoom:50%;\"></p>\n<h1 id=\"变量类型\"><a href=\"#变量类型\" class=\"headerlink\" title=\"变量类型\"></a>变量类型</h1><p>在各种语言中，变量一般分为值类型和引用类型。</p>\n<h3 id=\"值类型\"><a href=\"#值类型\" class=\"headerlink\" title=\"值类型\"></a>值类型</h3><p>变量直接存放对象的二进制数据(JVM的栈变量共享除外)，如果对变量取地址，那么就是这段内存的地址名，例如”0xc00001c100”。</p>\n<p>这里的内存空间一般是栈空间，变量和对象都是在栈空间的。</p>\n<h3 id=\"引用类型\"><a href=\"#引用类型\" class=\"headerlink\" title=\"引用类型\"></a>引用类型</h3><p>引用类型的变量存放的是对象的地址，变量位于栈空间，而对象则是位于堆空间。例如a是引用变量，其内容是”0x12335423341“，这段地址是堆空间的地址，指向堆空间的对象，而自己的地址可能是”0x51314241“，是在栈空间的地址。</p>\n<p>引用类型有个巨大的好处是自动垃圾回收GC，通过引用计数可以释放没有引用的对象。</p>\n<h3 id=\"不同语言总结\"><a href=\"#不同语言总结\" class=\"headerlink\" title=\"不同语言总结\"></a>不同语言总结</h3><ul>\n<li><p>Java：</p>\n<ul>\n<li>值类型：基本数据类型int/float/short/long/double/byte/char/bool</li>\n<li>引用类型：其余全是</li>\n</ul>\n</li>\n<li><p>Python</p>\n<ul>\n<li>全是引用类型，python的对象基本是heap空间</li>\n</ul>\n</li>\n<li><p>Go：</p>\n<ul>\n<li>值类型：基本数据类型int, float,bool, string，以及数组和struct</li>\n<li>引用类型：其余全是，Go存在指针</li>\n</ul>\n</li>\n<li><p>C++：</p>\n<ul>\n<li>全是值类型</li>\n<li>引用类型：通过指针，引用&amp;，shared_ptr等实现。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"栈空间堆空间\"><a href=\"#栈空间堆空间\" class=\"headerlink\" title=\"栈空间堆空间\"></a>栈空间堆空间</h1><p>正如前文所说，栈空间一般是值类型的对象和变量空间，堆空间是引用变量的对象空间，堆空间一般都是new或malloc出来的，在C++中需要进行手动创建和释放，程序结束也不一定可以正确释放，容易造成内存泄漏(所以后面有类似java的shared_ptr，做引用计数的垃圾回收)。</p>\n<p>除栈空间和堆空间，一般还有</p>\n<ul>\n<li>静态空间：存放全局变量、static变量，在程序结束会自动释放</li>\n<li>常量空间：类似java的string类型，final修饰的变量</li>\n<li>代码空间：存放程序代码</li>\n</ul>\n<h2 id=\"java\"><a href=\"#java\" class=\"headerlink\" title=\"java\"></a>java</h2><ul>\n<li>对象分为基本数据类型和其他对象，同理变量也就分为基本数据类型的变量和引用变量</li>\n<li>基本数据类型的变量操作，产生新的对象，不再指向同一个对象。变量传递相当于对象值传递。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">例子：int a = 3;int b;b = a; // 两个变量指向同一个栈对象a = 30; // a指向新的栈对象，b=3不会变</span><br></pre></td></tr></table></figure>\n<ul>\n<li>引用变量操作，还是指向同一个对象，类似C/C++的指针/引用。变量操作相当于对象地址传递。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">例子：Class a = new Class();Class b = new Class();b = a; // 两个变量指向同一个堆对象a.set(something); // a,b两个引用变量依然指向同一个堆对象</span><br></pre></td></tr></table></figure>\n<ul>\n<li>基本类型的变量和对象，引用变量都放在栈中，引用对象放在堆中。</li>\n<li>栈空间的数据对象是共享的，但是堆空间是不共享的。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int a = 3; int b = 3; //这个时候3的栈对象已经存在，共享， a == b</span><br></pre></td></tr></table></figure>\n<h2 id=\"python\"><a href=\"#python\" class=\"headerlink\" title=\"python\"></a>python</h2><ul>\n<li>对象分为可变对象和不可变对象，同理变量也就分为不可变对象的变量和可变对象的变量</li>\n<li>不可变对象(整型、字符串和元组)的变量操作，产生新的对象，不再指向同一个对象。变量传递相当于对象值传递。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">例子：a = 3; b = a; // 两个变量指向同一个对象a = 30; // a指向新的对象，b=3不会变</span><br></pre></td></tr></table></figure>\n<ul>\n<li>可变对象的变量操作，还是指向同一个对象，类似C/C++的指针/引用。变量操作相当于对象地址传递。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">例子：a = Class();b = a; // 两个变量指向同一个对象a.set(something); // a,b两个变量依然指向同一个对象</span><br></pre></td></tr></table></figure>\n<h2 id=\"C-C\"><a href=\"#C-C\" class=\"headerlink\" title=\"C/C++\"></a>C/C++</h2><ul>\n<li>变量有变量的值和地址，对象有对象的值和地址</li>\n<li>通过指针来实现对同一个对象的操作，指针的自由度更高，但是代码上相比java和python就更加复杂了，引用变量多方便啊。。</li>\n<li>C/C++也有指针的高级封装-引用！</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int a =4 ; int &amp;b = a; b=3 //a = b = 3</span><br></pre></td></tr></table></figure>\n<ul>\n<li>即使是基本数据类型，也可以操作为同一个对象</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int a = 3;int* p = &amp;a;a = 4; // *p和a指向同一个对象</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"变量和对象\"><a href=\"#变量和对象\" class=\"headerlink\" title=\"变量和对象\"></a>变量和对象</h1><p>任何语言都是由变量和对象组成的。</p>\n<p>变量和对象可能是存在一块的（变量代表内存，内存存放的的是对象二进制），也可能是分开存的，这种情况就是对象存放在其他内存，而变量存放的是那块内存的地址。</p>\n<p>具体方式在不同语言中有很大区别，不同语言在底层可能做了很多优化，例如JVM的栈变量共享等。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int a = 3;</span><br><span class=\"line\">int b = 3;</span><br></pre></td></tr></table></figure>\n<p>对于上述代码，C++的话就是分配了两个值类型变量在不同栈空间，同时分配2个对，内存各自写3。</p>\n<p>而对于java，也是分配了两个值类型变量在不同栈空间，但是对象3却是在栈空间单独存在的，值类型变量都是指向这个对象3，虽说是值类型，但是存放的也是地址。但是依然是值类型，有点像python的不可变对象传递。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gmvjxiyzp0j30ok0wogq5.jpg\" alt=\"image-20210121194155398\" style=\"zoom:50%;\"></p>\n<h1 id=\"变量类型\"><a href=\"#变量类型\" class=\"headerlink\" title=\"变量类型\"></a>变量类型</h1><p>在各种语言中，变量一般分为值类型和引用类型。</p>\n<h3 id=\"值类型\"><a href=\"#值类型\" class=\"headerlink\" title=\"值类型\"></a>值类型</h3><p>变量直接存放对象的二进制数据(JVM的栈变量共享除外)，如果对变量取地址，那么就是这段内存的地址名，例如”0xc00001c100”。</p>\n<p>这里的内存空间一般是栈空间，变量和对象都是在栈空间的。</p>\n<h3 id=\"引用类型\"><a href=\"#引用类型\" class=\"headerlink\" title=\"引用类型\"></a>引用类型</h3><p>引用类型的变量存放的是对象的地址，变量位于栈空间，而对象则是位于堆空间。例如a是引用变量，其内容是”0x12335423341“，这段地址是堆空间的地址，指向堆空间的对象，而自己的地址可能是”0x51314241“，是在栈空间的地址。</p>\n<p>引用类型有个巨大的好处是自动垃圾回收GC，通过引用计数可以释放没有引用的对象。</p>\n<h3 id=\"不同语言总结\"><a href=\"#不同语言总结\" class=\"headerlink\" title=\"不同语言总结\"></a>不同语言总结</h3><ul>\n<li><p>Java：</p>\n<ul>\n<li>值类型：基本数据类型int/float/short/long/double/byte/char/bool</li>\n<li>引用类型：其余全是</li>\n</ul>\n</li>\n<li><p>Python</p>\n<ul>\n<li>全是引用类型，python的对象基本是heap空间</li>\n</ul>\n</li>\n<li><p>Go：</p>\n<ul>\n<li>值类型：基本数据类型int, float,bool, string，以及数组和struct</li>\n<li>引用类型：其余全是，Go存在指针</li>\n</ul>\n</li>\n<li><p>C++：</p>\n<ul>\n<li>全是值类型</li>\n<li>引用类型：通过指针，引用&amp;，shared_ptr等实现。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"栈空间堆空间\"><a href=\"#栈空间堆空间\" class=\"headerlink\" title=\"栈空间堆空间\"></a>栈空间堆空间</h1><p>正如前文所说，栈空间一般是值类型的对象和变量空间，堆空间是引用变量的对象空间，堆空间一般都是new或malloc出来的，在C++中需要进行手动创建和释放，程序结束也不一定可以正确释放，容易造成内存泄漏(所以后面有类似java的shared_ptr，做引用计数的垃圾回收)。</p>\n<p>除栈空间和堆空间，一般还有</p>\n<ul>\n<li>静态空间：存放全局变量、static变量，在程序结束会自动释放</li>\n<li>常量空间：类似java的string类型，final修饰的变量</li>\n<li>代码空间：存放程序代码</li>\n</ul>\n<h2 id=\"java\"><a href=\"#java\" class=\"headerlink\" title=\"java\"></a>java</h2><ul>\n<li>对象分为基本数据类型和其他对象，同理变量也就分为基本数据类型的变量和引用变量</li>\n<li>基本数据类型的变量操作，产生新的对象，不再指向同一个对象。变量传递相当于对象值传递。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">例子：int a = 3;int b;b = a; // 两个变量指向同一个栈对象a = 30; // a指向新的栈对象，b=3不会变</span><br></pre></td></tr></table></figure>\n<ul>\n<li>引用变量操作，还是指向同一个对象，类似C/C++的指针/引用。变量操作相当于对象地址传递。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">例子：Class a = new Class();Class b = new Class();b = a; // 两个变量指向同一个堆对象a.set(something); // a,b两个引用变量依然指向同一个堆对象</span><br></pre></td></tr></table></figure>\n<ul>\n<li>基本类型的变量和对象，引用变量都放在栈中，引用对象放在堆中。</li>\n<li>栈空间的数据对象是共享的，但是堆空间是不共享的。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int a = 3; int b = 3; //这个时候3的栈对象已经存在，共享， a == b</span><br></pre></td></tr></table></figure>\n<h2 id=\"python\"><a href=\"#python\" class=\"headerlink\" title=\"python\"></a>python</h2><ul>\n<li>对象分为可变对象和不可变对象，同理变量也就分为不可变对象的变量和可变对象的变量</li>\n<li>不可变对象(整型、字符串和元组)的变量操作，产生新的对象，不再指向同一个对象。变量传递相当于对象值传递。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">例子：a = 3; b = a; // 两个变量指向同一个对象a = 30; // a指向新的对象，b=3不会变</span><br></pre></td></tr></table></figure>\n<ul>\n<li>可变对象的变量操作，还是指向同一个对象，类似C/C++的指针/引用。变量操作相当于对象地址传递。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">例子：a = Class();b = a; // 两个变量指向同一个对象a.set(something); // a,b两个变量依然指向同一个对象</span><br></pre></td></tr></table></figure>\n<h2 id=\"C-C\"><a href=\"#C-C\" class=\"headerlink\" title=\"C/C++\"></a>C/C++</h2><ul>\n<li>变量有变量的值和地址，对象有对象的值和地址</li>\n<li>通过指针来实现对同一个对象的操作，指针的自由度更高，但是代码上相比java和python就更加复杂了，引用变量多方便啊。。</li>\n<li>C/C++也有指针的高级封装-引用！</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int a =4 ; int &amp;b = a; b=3 //a = b = 3</span><br></pre></td></tr></table></figure>\n<ul>\n<li>即使是基本数据类型，也可以操作为同一个对象</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int a = 3;int* p = &amp;a;a = 4; // *p和a指向同一个对象</span><br></pre></td></tr></table></figure>"},{"title":"后端技术栈","date":"2020-11-09T16:00:00.000Z","_content":"\n\n\n## 微服务\n\n一种将整个后端服务，按照领域、模块分解为若干独立小应用的一种架构方式。微服务有如下特点\n\n- 服务可以单独编写、发布、测试、部署，相比于所有功能集中于一体的单体服务，可维护性更强\n- 服务彼此之间**依赖服务通信的方式松耦合**\n- 按照业务领域来组织服务，每个团队维护各自的服务\n\n\n\n引申出了RPC框架，比较有代表性的：\n\n- Thrift - Facebook\n- Dubbo - 阿里\n- Spring Cloud\n\n为了更好地管理服务实例，负载均衡之类的，就需要服务注册中心：\n\n- Zookeeper\n- Consul\n\n\n\n## 数据库\n\n#### 关系型数据库(SQL)\n\n代表就是MySQL，二维表结构，结构清晰\n\n- 优点：开源、体积小、成本低，支持复杂查询\n\n- 缺点：高并发支持差，海量查询慢，横向拓展支持差\n\n  \n\n#### 非关系型数据库(NoSQL，not only SQL)\n\n- Redis：KV存储，基于分布式缓存(目前一般都是基于proxy的集群化方案，zk+codis)，高性能，速度快。\n\n  ![image-20201015165936575](https://tva1.sinaimg.cn/large/0081Kckwly1gkkcyfsdenj31300ocwsl.jpg)\n\n- Hbase：海量数据存储，基于列式存储，row按照key - value存\n\n- Elastic Search：倒排索引，对于模糊查询，例如查询文档中的模糊词汇，MySQL -> 文档分词 -> 全量contains查询，ES则存储每个单词对应的文档。\n\n\n\n### 消息队列(MQ)\n\n伴随着业务的复杂，我们往往会遇到这个场景，一个数据操作后，需要触发下游若干个子操作。例如外卖场景，用户下订单成功，要通知商家用户订单，要物流平台对订单进行调度和派单，要触发一些后置的风控逻辑对订单合法性进行校验等。如果是同步的设计，需要在订单完成后对后续的操作一一进行API调用，**这样的做法让订单流程依赖更多外部服务，提升了业务复杂度，降低了服务的稳定性**，所以我们需要消息中间件来解耦操作。依赖的服务依赖下单消息，而不是在下单结束后，通过接口调用的方式触发。\n\n我们可以把消息队列（MQ）比作是一个存放消息的容器，Producer 负责生产消息，将消息发送到MQ，Consumer取出消息**供自己使用**。如图所示：\n\n![image-20201015170419880](https://tva1.sinaimg.cn/large/0081Kckwly1gkkcymoo3yj311y0k4wig.jpg)\n\n#### Kafka\n\n![image-20201015170454563](https://tva1.sinaimg.cn/large/0081Kckwly1gkkcyppscvj31bg0oagv0.jpg)\n\n- Producer：产生topic\n- Parition：topic分成不同的partition处理，每个parition里保证有序\n- Replica：每个分区都有一份完整topic副本\n- Broker：启动一个Kafka就是一个Broker，多个Brokder构成一个Kafka集群\n- Consumer：消费任何Topic的数据，多个Consume组成一个消费者组。\n\n通过定义producer和consumer类，启动实例和zk就可已启动kafka服务。\n\n\n\n## 负载均衡\n\n- Nginx\n- Zookeeper\n\n\n\n## 个人总结\n\n- 基本上离线任务用MySQL+redis的存储方案可以cover大部分场景，实时任务用kafka做。\n- 大厂会自己改造开源组件，字节有abase之类的\n- 上面这些组件基本感觉都会设置一个中心调度器来管理，类似zookeeper这种，框架的共通性。","source":"_posts/编程开发/后端技术栈.md","raw":"---\ntitle: 后端技术栈\ndate: 2020-11-10\ncategories: [编程开发]\n---\n\n\n\n## 微服务\n\n一种将整个后端服务，按照领域、模块分解为若干独立小应用的一种架构方式。微服务有如下特点\n\n- 服务可以单独编写、发布、测试、部署，相比于所有功能集中于一体的单体服务，可维护性更强\n- 服务彼此之间**依赖服务通信的方式松耦合**\n- 按照业务领域来组织服务，每个团队维护各自的服务\n\n\n\n引申出了RPC框架，比较有代表性的：\n\n- Thrift - Facebook\n- Dubbo - 阿里\n- Spring Cloud\n\n为了更好地管理服务实例，负载均衡之类的，就需要服务注册中心：\n\n- Zookeeper\n- Consul\n\n\n\n## 数据库\n\n#### 关系型数据库(SQL)\n\n代表就是MySQL，二维表结构，结构清晰\n\n- 优点：开源、体积小、成本低，支持复杂查询\n\n- 缺点：高并发支持差，海量查询慢，横向拓展支持差\n\n  \n\n#### 非关系型数据库(NoSQL，not only SQL)\n\n- Redis：KV存储，基于分布式缓存(目前一般都是基于proxy的集群化方案，zk+codis)，高性能，速度快。\n\n  ![image-20201015165936575](https://tva1.sinaimg.cn/large/0081Kckwly1gkkcyfsdenj31300ocwsl.jpg)\n\n- Hbase：海量数据存储，基于列式存储，row按照key - value存\n\n- Elastic Search：倒排索引，对于模糊查询，例如查询文档中的模糊词汇，MySQL -> 文档分词 -> 全量contains查询，ES则存储每个单词对应的文档。\n\n\n\n### 消息队列(MQ)\n\n伴随着业务的复杂，我们往往会遇到这个场景，一个数据操作后，需要触发下游若干个子操作。例如外卖场景，用户下订单成功，要通知商家用户订单，要物流平台对订单进行调度和派单，要触发一些后置的风控逻辑对订单合法性进行校验等。如果是同步的设计，需要在订单完成后对后续的操作一一进行API调用，**这样的做法让订单流程依赖更多外部服务，提升了业务复杂度，降低了服务的稳定性**，所以我们需要消息中间件来解耦操作。依赖的服务依赖下单消息，而不是在下单结束后，通过接口调用的方式触发。\n\n我们可以把消息队列（MQ）比作是一个存放消息的容器，Producer 负责生产消息，将消息发送到MQ，Consumer取出消息**供自己使用**。如图所示：\n\n![image-20201015170419880](https://tva1.sinaimg.cn/large/0081Kckwly1gkkcymoo3yj311y0k4wig.jpg)\n\n#### Kafka\n\n![image-20201015170454563](https://tva1.sinaimg.cn/large/0081Kckwly1gkkcyppscvj31bg0oagv0.jpg)\n\n- Producer：产生topic\n- Parition：topic分成不同的partition处理，每个parition里保证有序\n- Replica：每个分区都有一份完整topic副本\n- Broker：启动一个Kafka就是一个Broker，多个Brokder构成一个Kafka集群\n- Consumer：消费任何Topic的数据，多个Consume组成一个消费者组。\n\n通过定义producer和consumer类，启动实例和zk就可已启动kafka服务。\n\n\n\n## 负载均衡\n\n- Nginx\n- Zookeeper\n\n\n\n## 个人总结\n\n- 基本上离线任务用MySQL+redis的存储方案可以cover大部分场景，实时任务用kafka做。\n- 大厂会自己改造开源组件，字节有abase之类的\n- 上面这些组件基本感觉都会设置一个中心调度器来管理，类似zookeeper这种，框架的共通性。","slug":"编程开发/后端技术栈","published":1,"updated":"2022-09-15T03:46:43.368Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551p2003rjqrrzokhxqxv","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"微服务\"><a href=\"#微服务\" class=\"headerlink\" title=\"微服务\"></a>微服务</h2><p>一种将整个后端服务，按照领域、模块分解为若干独立小应用的一种架构方式。微服务有如下特点</p>\n<ul>\n<li>服务可以单独编写、发布、测试、部署，相比于所有功能集中于一体的单体服务，可维护性更强</li>\n<li>服务彼此之间<strong>依赖服务通信的方式松耦合</strong></li>\n<li>按照业务领域来组织服务，每个团队维护各自的服务</li>\n</ul>\n<p>引申出了RPC框架，比较有代表性的：</p>\n<ul>\n<li>Thrift - Facebook</li>\n<li>Dubbo - 阿里</li>\n<li>Spring Cloud</li>\n</ul>\n<p>为了更好地管理服务实例，负载均衡之类的，就需要服务注册中心：</p>\n<ul>\n<li>Zookeeper</li>\n<li>Consul</li>\n</ul>\n<h2 id=\"数据库\"><a href=\"#数据库\" class=\"headerlink\" title=\"数据库\"></a>数据库</h2><h4 id=\"关系型数据库-SQL\"><a href=\"#关系型数据库-SQL\" class=\"headerlink\" title=\"关系型数据库(SQL)\"></a>关系型数据库(SQL)</h4><p>代表就是MySQL，二维表结构，结构清晰</p>\n<ul>\n<li><p>优点：开源、体积小、成本低，支持复杂查询</p>\n</li>\n<li><p>缺点：高并发支持差，海量查询慢，横向拓展支持差</p>\n</li>\n</ul>\n<h4 id=\"非关系型数据库-NoSQL，not-only-SQL\"><a href=\"#非关系型数据库-NoSQL，not-only-SQL\" class=\"headerlink\" title=\"非关系型数据库(NoSQL，not only SQL)\"></a>非关系型数据库(NoSQL，not only SQL)</h4><ul>\n<li><p>Redis：KV存储，基于分布式缓存(目前一般都是基于proxy的集群化方案，zk+codis)，高性能，速度快。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkcyfsdenj31300ocwsl.jpg\" alt=\"image-20201015165936575\"></p>\n</li>\n<li><p>Hbase：海量数据存储，基于列式存储，row按照key - value存</p>\n</li>\n<li><p>Elastic Search：倒排索引，对于模糊查询，例如查询文档中的模糊词汇，MySQL -&gt; 文档分词 -&gt; 全量contains查询，ES则存储每个单词对应的文档。</p>\n</li>\n</ul>\n<h3 id=\"消息队列-MQ\"><a href=\"#消息队列-MQ\" class=\"headerlink\" title=\"消息队列(MQ)\"></a>消息队列(MQ)</h3><p>伴随着业务的复杂，我们往往会遇到这个场景，一个数据操作后，需要触发下游若干个子操作。例如外卖场景，用户下订单成功，要通知商家用户订单，要物流平台对订单进行调度和派单，要触发一些后置的风控逻辑对订单合法性进行校验等。如果是同步的设计，需要在订单完成后对后续的操作一一进行API调用，<strong>这样的做法让订单流程依赖更多外部服务，提升了业务复杂度，降低了服务的稳定性</strong>，所以我们需要消息中间件来解耦操作。依赖的服务依赖下单消息，而不是在下单结束后，通过接口调用的方式触发。</p>\n<p>我们可以把消息队列（MQ）比作是一个存放消息的容器，Producer 负责生产消息，将消息发送到MQ，Consumer取出消息<strong>供自己使用</strong>。如图所示：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkcymoo3yj311y0k4wig.jpg\" alt=\"image-20201015170419880\"></p>\n<h4 id=\"Kafka\"><a href=\"#Kafka\" class=\"headerlink\" title=\"Kafka\"></a>Kafka</h4><p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkcyppscvj31bg0oagv0.jpg\" alt=\"image-20201015170454563\"></p>\n<ul>\n<li>Producer：产生topic</li>\n<li>Parition：topic分成不同的partition处理，每个parition里保证有序</li>\n<li>Replica：每个分区都有一份完整topic副本</li>\n<li>Broker：启动一个Kafka就是一个Broker，多个Brokder构成一个Kafka集群</li>\n<li>Consumer：消费任何Topic的数据，多个Consume组成一个消费者组。</li>\n</ul>\n<p>通过定义producer和consumer类，启动实例和zk就可已启动kafka服务。</p>\n<h2 id=\"负载均衡\"><a href=\"#负载均衡\" class=\"headerlink\" title=\"负载均衡\"></a>负载均衡</h2><ul>\n<li>Nginx</li>\n<li>Zookeeper</li>\n</ul>\n<h2 id=\"个人总结\"><a href=\"#个人总结\" class=\"headerlink\" title=\"个人总结\"></a>个人总结</h2><ul>\n<li>基本上离线任务用MySQL+redis的存储方案可以cover大部分场景，实时任务用kafka做。</li>\n<li>大厂会自己改造开源组件，字节有abase之类的</li>\n<li>上面这些组件基本感觉都会设置一个中心调度器来管理，类似zookeeper这种，框架的共通性。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"微服务\"><a href=\"#微服务\" class=\"headerlink\" title=\"微服务\"></a>微服务</h2><p>一种将整个后端服务，按照领域、模块分解为若干独立小应用的一种架构方式。微服务有如下特点</p>\n<ul>\n<li>服务可以单独编写、发布、测试、部署，相比于所有功能集中于一体的单体服务，可维护性更强</li>\n<li>服务彼此之间<strong>依赖服务通信的方式松耦合</strong></li>\n<li>按照业务领域来组织服务，每个团队维护各自的服务</li>\n</ul>\n<p>引申出了RPC框架，比较有代表性的：</p>\n<ul>\n<li>Thrift - Facebook</li>\n<li>Dubbo - 阿里</li>\n<li>Spring Cloud</li>\n</ul>\n<p>为了更好地管理服务实例，负载均衡之类的，就需要服务注册中心：</p>\n<ul>\n<li>Zookeeper</li>\n<li>Consul</li>\n</ul>\n<h2 id=\"数据库\"><a href=\"#数据库\" class=\"headerlink\" title=\"数据库\"></a>数据库</h2><h4 id=\"关系型数据库-SQL\"><a href=\"#关系型数据库-SQL\" class=\"headerlink\" title=\"关系型数据库(SQL)\"></a>关系型数据库(SQL)</h4><p>代表就是MySQL，二维表结构，结构清晰</p>\n<ul>\n<li><p>优点：开源、体积小、成本低，支持复杂查询</p>\n</li>\n<li><p>缺点：高并发支持差，海量查询慢，横向拓展支持差</p>\n</li>\n</ul>\n<h4 id=\"非关系型数据库-NoSQL，not-only-SQL\"><a href=\"#非关系型数据库-NoSQL，not-only-SQL\" class=\"headerlink\" title=\"非关系型数据库(NoSQL，not only SQL)\"></a>非关系型数据库(NoSQL，not only SQL)</h4><ul>\n<li><p>Redis：KV存储，基于分布式缓存(目前一般都是基于proxy的集群化方案，zk+codis)，高性能，速度快。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkcyfsdenj31300ocwsl.jpg\" alt=\"image-20201015165936575\"></p>\n</li>\n<li><p>Hbase：海量数据存储，基于列式存储，row按照key - value存</p>\n</li>\n<li><p>Elastic Search：倒排索引，对于模糊查询，例如查询文档中的模糊词汇，MySQL -&gt; 文档分词 -&gt; 全量contains查询，ES则存储每个单词对应的文档。</p>\n</li>\n</ul>\n<h3 id=\"消息队列-MQ\"><a href=\"#消息队列-MQ\" class=\"headerlink\" title=\"消息队列(MQ)\"></a>消息队列(MQ)</h3><p>伴随着业务的复杂，我们往往会遇到这个场景，一个数据操作后，需要触发下游若干个子操作。例如外卖场景，用户下订单成功，要通知商家用户订单，要物流平台对订单进行调度和派单，要触发一些后置的风控逻辑对订单合法性进行校验等。如果是同步的设计，需要在订单完成后对后续的操作一一进行API调用，<strong>这样的做法让订单流程依赖更多外部服务，提升了业务复杂度，降低了服务的稳定性</strong>，所以我们需要消息中间件来解耦操作。依赖的服务依赖下单消息，而不是在下单结束后，通过接口调用的方式触发。</p>\n<p>我们可以把消息队列（MQ）比作是一个存放消息的容器，Producer 负责生产消息，将消息发送到MQ，Consumer取出消息<strong>供自己使用</strong>。如图所示：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkcymoo3yj311y0k4wig.jpg\" alt=\"image-20201015170419880\"></p>\n<h4 id=\"Kafka\"><a href=\"#Kafka\" class=\"headerlink\" title=\"Kafka\"></a>Kafka</h4><p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkcyppscvj31bg0oagv0.jpg\" alt=\"image-20201015170454563\"></p>\n<ul>\n<li>Producer：产生topic</li>\n<li>Parition：topic分成不同的partition处理，每个parition里保证有序</li>\n<li>Replica：每个分区都有一份完整topic副本</li>\n<li>Broker：启动一个Kafka就是一个Broker，多个Brokder构成一个Kafka集群</li>\n<li>Consumer：消费任何Topic的数据，多个Consume组成一个消费者组。</li>\n</ul>\n<p>通过定义producer和consumer类，启动实例和zk就可已启动kafka服务。</p>\n<h2 id=\"负载均衡\"><a href=\"#负载均衡\" class=\"headerlink\" title=\"负载均衡\"></a>负载均衡</h2><ul>\n<li>Nginx</li>\n<li>Zookeeper</li>\n</ul>\n<h2 id=\"个人总结\"><a href=\"#个人总结\" class=\"headerlink\" title=\"个人总结\"></a>个人总结</h2><ul>\n<li>基本上离线任务用MySQL+redis的存储方案可以cover大部分场景，实时任务用kafka做。</li>\n<li>大厂会自己改造开源组件，字节有abase之类的</li>\n<li>上面这些组件基本感觉都会设置一个中心调度器来管理，类似zookeeper这种，框架的共通性。</li>\n</ul>\n"},{"title":"word2vec详解","date":"2019-11-04T09:40:06.000Z","_content":"\n世界级解释博客：https://blog.csdn.net/a819825294/article/details/52438625\n\n \n\ncbow和skip-gram的原理解析，hierarchical softmax / negative sampling， gradient descent derivation for each one.\n\n \n\n1. ![image-20200605154521303](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgkg8d7vj30uc09nagn.jpg)\n\n \n\n\n\n2. ![image-20200605154543836](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhglv7e9hj30o10lqmyw.jpg)\n\n3. \n\n![image-20200605154601962](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhglw07lrj30rb07eab7.jpg)\n\n4. \n\n![image-20200605154622654](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgluc6b6j30qs0mj0uw.jpg)","source":"_posts/自然语言处理/word2vec详解.md","raw":"---\ntitle: word2vec详解\ndate: 2019-11-04 17:40:06\ntags: word2vec\ncategories: [自然语言处理]\n---\n\n世界级解释博客：https://blog.csdn.net/a819825294/article/details/52438625\n\n \n\ncbow和skip-gram的原理解析，hierarchical softmax / negative sampling， gradient descent derivation for each one.\n\n \n\n1. ![image-20200605154521303](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgkg8d7vj30uc09nagn.jpg)\n\n \n\n\n\n2. ![image-20200605154543836](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhglv7e9hj30o10lqmyw.jpg)\n\n3. \n\n![image-20200605154601962](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhglw07lrj30rb07eab7.jpg)\n\n4. \n\n![image-20200605154622654](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgluc6b6j30qs0mj0uw.jpg)","slug":"自然语言处理/word2vec详解","published":1,"updated":"2022-09-15T03:46:43.368Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551p3003tjqrr43qd30th","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>世界级解释博客：<a href=\"https://blog.csdn.net/a819825294/article/details/52438625\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/a819825294/article/details/52438625</a></p>\n<p>cbow和skip-gram的原理解析，hierarchical softmax / negative sampling， gradient descent derivation for each one.</p>\n<ol>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgkg8d7vj30uc09nagn.jpg\" alt=\"image-20200605154521303\"></li>\n</ol>\n<ol>\n<li><p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhglv7e9hj30o10lqmyw.jpg\" alt=\"image-20200605154543836\"></p>\n</li>\n<li></li>\n</ol>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhglw07lrj30rb07eab7.jpg\" alt=\"image-20200605154601962\"></p>\n<ol>\n<li><p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgluc6b6j30qs0mj0uw.jpg\" alt=\"image-20200605154622654\"></p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>世界级解释博客：<a href=\"https://blog.csdn.net/a819825294/article/details/52438625\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/a819825294/article/details/52438625</a></p>\n<p>cbow和skip-gram的原理解析，hierarchical softmax / negative sampling， gradient descent derivation for each one.</p>\n<ol>\n<li><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgkg8d7vj30uc09nagn.jpg\" alt=\"image-20200605154521303\"></li>\n</ol>\n<ol>\n<li><p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhglv7e9hj30o10lqmyw.jpg\" alt=\"image-20200605154543836\"></p>\n</li>\n<li></li>\n</ol>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhglw07lrj30rb07eab7.jpg\" alt=\"image-20200605154601962\"></p>\n<ol>\n<li><p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgluc6b6j30qs0mj0uw.jpg\" alt=\"image-20200605154622654\"></p>\n</li>\n</ol>\n"},{"title":"《自然语言处理入门》笔记","date":"2020-03-20T09:40:06.000Z","_content":"\n疫情期间看完了何晗老师的《自然语言处理入门》这本书，真的是学习了很多NLP的传统知识，本文是相关的笔记。\n\n何晗老师的博客：[码农场](https://www.hankcs.com/)\n\n\n\n### 一、新手上路\n\n#### NLP相关任务\n\n- 最基本的工具任务：词法分析：(中文)分词，词性标注和命名实体识别\n\n- 信息抽取\n\n- 文本分类与文本聚类\n\n- 句法分析\n\n- 语义分析与篇章分析\n\n- 更高级任务：机器翻译、问答系统等\n\n  \n\n#### 语料库\n\n- 中文分词语料库：\n  - 1998《人民日报》，PKU语料库\n  - 微软亚洲研究院，MSR语料库\n  - 香港城市大学，CITYU语料库-繁体中文\n  - 台湾中央研究院，AS语料库-繁体中文\n- 词性标注：\n  - 1998年《人民日报》，PKU标注集\n  - 国家语委语料库，863标注集\n  - CTB(中文树库)语料库，CTB标注集\n  - 《诛仙》语料库，CTB标注集\n- 命名实体识别：\n  - 1998年《人民日报》，实体：人名/地名/机构名\n  - 微软亚洲研究院，实体: 专有名词/时间表达式/数字表达式/度量表达式/地址表达式等5大类30个子类\n- 句法分析\n  - CTB语料库\n- 文本分类\n  - 搜狗文本分类语料库，8000篇新闻\n\n\n\n#### 开源工具\n\n- NLTK\n- 斯坦福大学CoreNLP\n- 哈工大LTP\n- HanLP\n\n\n\n### 二、词典分词\n\n#### 总体思想\n\n基于词典进行分词，分词算法包括：\n\n- 完全切分\n- 最大正向匹配\n- 最大逆向匹配\n- 双向最大匹配\n\n\n\n#### 存储和计算效率\n\n为了提升存储和计算效率，提出了词典的四种数据结构：\n\n- 字典树\n- 双数组字典树\n- AC自动机\n- 基于双数组字典树的AC自动机\n\n\n\n#### 其他应用\n\n- 停用词过滤\n- 简繁转换\n- 拼音转换\n\n\n\n总体而言，字典分词的缺点是无法解决歧义和OOV问题。\n\n\n\n### 三、二元语法与中文分词\n\n- 提出了语言模型，来解决歧义问题，例如分别计算“商品 和 服务” 与 “商品 和服 务”的概率，选择概率大的一种分词。\n- 如果用假设为一阶马尔科夫过程，则为二元语法模型。\n- 模型训练：统计词频，计算二元概率\n- 模型预测：\n  - 词语全切分\n  - 生成词网图\n  - 维特比译码，其实就是动态规划，每个上游节点都保存最短路径。\n- 缺点：还是无法解决OOV问题\n\n\n\n### 四、隐马尔科夫模型与序列标注\n\n- 正式提出了序列标注思想，对于分词任务而言，就是设置{B、M、E、S}标注集，作为隐状态，而字符就是显状态，也称观测状态。\n- HMM由{初始概率矩阵，状态转移矩阵，发射矩阵}三部分组成。\n- HMM是生成模型，因为计算的其实就是f(x,y)的联合概率，只是用马尔科夫过程简化为了初始概率矩阵 * 状态转移矩阵 * 发射矩阵。\n- 模型训练：\n  - 显状态和隐状态都已知，直接计算词频，统计概率。\n  - 显状态已知，隐状态未知，需要用EM算法。\n- 模型预测：\n  - 理论上是遍历所有y，计算最大概率的y，复杂度高。\n  - 维特比译码，即动态规划，每个时刻的每个状态保留最大概率路径。\n- 可以解决OOV，但是还是不够好，jieba分词就是用的HMM\n\n\n\n### 五、感知机分类与序列标注\n\n#### 感知机算法\n\n- 模型预测：公式为 $y = sign(wx + b)$\n\n- 模型训练：对于每一个训练样本：\n\n  - 如果预测$\\hat{y}$与真实$y$相等，则跳过\n  - 如果不相等，则$w = w + x * y$\n\n- 其实相当于损失函数为\n  $$\n  L = \\frac{1}{N}\\sum max(0, -y^{(i)}.w.x^{(i)})\n  $$\n\n- 每次迭代的感知机参数都保留，做集成：\n\n  - 投票感知机：每个感知机结果加权平均\n  - 平均感知机：每个感知机的参数直接求平均\n\n\n\n#### 结构化感知机算法\n\n- 属于结构化预测问题，例如机器翻译、序列标注等，预测结果诸如是一个序列、一颗树啊等等。此类算法往往在训练的时候，就需要做预测的工作。\n\n- 定义得分函数$score(x,y) = w.\\phi(x, y)$，其中$\\phi(x,y)$就是特征函数，则$\\hat{y} = argmax \\ {score(x,y)}$\n\n- 模型属于判别模型，因为最终归一化后，其实还是条件概率$p(y|x) = \\frac{exp(score(x,y))}{\\sum_{y}{exp(score{(x,y))}}}$，其Loss Function是\n  $$\n  L(w) = max_{y}(score(x,y)) - score(x, y) \\\\\n  \\frac{\\delta{L(w)}}{\\delta{w}} = \\phi(x,\\hat{y}) - \\phi(x, y)\n  $$\n  \n- 模型训练：对于每一个训练样本，先预测$\\hat{y} = argmax \\ w.\\phi(x, y)$，然后对于正确的y进行奖励，对于错误的预测$\\hat{y}$，进行惩罚，最终w的更新公式为\n\n  $$\n  w = w + \\phi(x, y) - \\phi(x, \\hat{y})\n  $$\n\n- 模型预测：同样是维特比译码。\n\n- 特征提取问题：\n\n  - 特征函数取值0或1 ，一般分为两类：\n\n    - 转移特征，$f(y_{t-1}, y_{t})$ ，只跟状态值有关，N种状态的话，取值就只有$ N * (N+1)$，因为包含了初始状态BOS。\n    - 状态特征，$f(y_{t}, x_{t})$，只跟当前隐状态值和显状态有关。\n\n  - 一般是基于特征模板生成所有特征，特征模块如：\n\n    - 转移特征模板，$y_{t-1}$\n\n    - 状态特征模板，$x_{t-1}, x_t, x_{t-2}/x_{t-1}, x_{t-1}/x_{t}$\n\n      \n\n### 六、条件随机场与序列标注\n\n- 首先阐述概率图模型，概率图分为两种：\n\n  - 有向概率图：联合概率密度$p(x,y) = \\prod{p(v | \\pi(v))}$，$\\pi(v)$表示v的所有前驱节点\n  - 无向概率图：联合概率密度可以分解为所有最大团的某种函数之乘积，所谓最大团，就是团内每个节点互相连接。还可以定义虚拟的因子节点，因子节点只连接两个相邻节点，组成最小的最大团，那么联合概率密度就是所有因子节点之积：\n\n  $$\n  p(x,y)=\\frac{1}{Z}\\prod_{a}{\\phi_{a}{(x_a, y_a})}\n  $$\n\n  这样的话，\n  $$\n  p(y|x)=\\frac{1}{Z(x)}\\prod_{a}{\\phi_{a}{(x_a, y_a})}\n  $$\n\n- 条件随机场，就是给定输入随机变量x，求解条件概率$p(y|x)$的概率无向图。用于序列标注时，就是线性链条件随机场：\n\n  ​     \t\t\t\t\t\t\t\t\t\t\t<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh3p0sm96tj30r20iptbs.jpg\" alt=\"image-20200726004025174\" style=\"zoom:50%;\" />\n\n- 如果用虚拟因子的话，显然就只有两类因子：\n\n  - 转移因子，发生在$y_t$和$y_{t-1}$之间，即转移特征函数\n  - 状态因子，发生在$y_t$和$x_t$之间，即状态特征函数\n\n- 如果某种函数定义为$w.\\phi(y_t,y_{t-1},x_t)$之后，其实就和结构化感知机一模一样了：\n  $$\n  p(y|x)=\\frac{1}{Z(x)}exp(\\sum{w.\\phi(y_t,y_{t-1},x_t)})\n  $$\n\n- 条件随机场的预测：\n\n  - 和结构化感知机一样，都是维特比译码\n\n- 条件随机场的训练：\n\n  - 训练和结构化感知机不一样，因为条件随机场的Loss Function为最大似然概率，即也相当于最大(相对)熵：\n    $$\n    L(w)=log(\\prod{p(y|x)^{\\hat{p}(x,y)}}) = \\sum_{x,y}{\\hat{p}(x,y)log(p(y|x))} = \\sum_{i=1}^{N}{p(y^{(i)}|x^{(i)})}\n    $$\n\n  - 利用梯度下降法求解的话，w参数更新公式(和结构化感知机最大的区别就在这里)：\n    $$\n    w = w + \\phi(x, y) - E_w[\\phi(x, y)]\n    $$\n    \n\n    - 感知机仅惩罚错得最厉害的哪一个$\\hat{y}$对应的特征函数$\\phi(x,\\hat{y})$\n    - 条件随机场惩罚所有答案，总惩罚量依然为1，但是所有答案分摊，而当特征函数的经验分布期望和模型期望一致的时候，梯度为0，不需要再更新。\n\n- 条件随机场其实就是最大熵模型的衍生~可以看我之前的有关最大熵模型的博文。\n\n\n\n### 七、词性标注\n\n本质上也是一个序列标注模型，标注方式有两种：\n\n- 独立模型：先进行分词任务，再进行词性标注任务，流水线。\n- 联合模型：将分词任务和词性任务联合，标注集例如{B-名词，M-名词}等。\n  - 优点：联合模型几乎在所有问题上优于独立模型。\n  - 缺点：很难有同时标注分词和词性的优秀语料库，一般而言中分分词语料库远多于词性标注语料库；还有就是，联合模型的标注集很大，导致特征数量也很大，参数爆炸。\n\n\n\n### 八、命名实体识别\n\n- 同样是个序列标注模型，标注集{BMES-实体，O}。但命名实体识别任务，往往可以统计为主、规则为辅。\n- 对于规则较强的命名实体，例如网址、E-mail、ISBN、商品编号等，完全可以通过正则表达式先进行预处理提取，再分词统计\n- 对于较短的命名实体，例如人名，完全可以通过先分词，再词性标注即可。\n- HanLP对于一些命名实体是用规则来做的：\n  - 音译人名\n  - 日本人名\n  - 数词英文实体：这个被称为原子分词，这个代码非常值得学习。\n- **自定义领域的命名实体识别任务**\n  - Step 1：收集生语料\n  - Step 2：可以先利用HanLP的词法分析器，得到分词和词性标注结果\n  - Step 3：基于词法分析结果，人工标注你想要的实体，生成熟语料\n  - Step 4：训练序列标注模型\n\n\n\n### 九、信息抽取\n\n所介绍的都是无监督算法。\n\n#### 新词提取\n\n从文章中发现新的词汇，信息熵算法：\n\n- 如果一个字符串左边和右边的搭配很丰富，并且字符串本身的字符搭配很固定，这大概率就是个词汇。\n- 信息熵：计算某个字符串左边和右边单个字符的信息熵，设定信息熵>=某个阈值\n- 互信息：计算该字符串内部的所有字符之间的互信息，互信息大，说明字符都是相关的，设定互信息>=某个阈值\n- 取符合上诉要求的词频Top N字符串。\n\n\n\n#### 短语提取\n\n与新词提取相同，只是需要先进行分词，然后把：\n\n- 字符串 -> 单词列表\n- 左右的单个字符 -> 单个单词\n\n\n\n#### 关键词提取\n\n- Top N词频\n- Top N TF-IDF ：单词在本文档的词频 / 单词出现在所有文档的次数\n- TextRank：类似pageRank，基于网站之间的链接生成图，然后每个节点的权重取决于指向该节点的所有子节点，但是其他子节点的权重计算的时候会因为它指向的节点个数而减少。权重逐步迭代，最终稳定。而文本的话，就是用滑动窗口，中间单词和附近单词产生链接。\n\n\n\n#### 关键句提取\n\n类似关键词提取，但有个TF-IDF的变种-BM25。\n\n\n\n### 十、文本聚类\n\n#### 生成文档向量\n\n- 词袋模型：说白了就类似one-hot，只是值换为词频。\n- 布尔词频：就是one-hot\n- TF-IDF：就值换为tf-idf值\n- 词向量：word2vec，然后所有词向量求和\n- 自编码器：输入时词袋，文档向量就是中间的隐层向量\n\n#### 聚类算法\n\nK-means算法，但是k-means有非常多的改进方法：\n\n- 朴素k-means: \n  - 随机选取k个初始质心 -> 分配簇 -> 重新计算质心 -> 重复\n  - 初始质心选取改进：先选取一个质心，然后再选取一个其他的点，如果其和最近质心的距离能够减小准则函数，再将其变为质心，以此类推，每一步都保证了准则函数的减小。\n- 更快的准则函数：将欧式距离改为余弦距离：\n  - 随机选取k个初始质心 -> 分配簇 -> 对每个点，计算将其移入另一个簇时准则函数的增量，找出最大量并移动 -> 重复\n- 层次聚类：刚开始一个簇，然后k-means分成两个，以此类推，保证二分后准则函数的gain增大，可以自动判断聚类个数。\n\n\n\n### 十一、文本分类\n\n大致思想也很简单：\n\n- 分词，提取单词；这一步并非必须，清华有个研究表明，直接提取所有相邻的n元字符，效果更好。\n\n- 提取特征：词袋向量。缺点是无法表征词语之间顺序，如“不 优秀” 和 “优秀 不”。\n- 特征筛选：利用卡方校验判断特征与类别之间的独立性，其实思想比较类似IV值。\n- 分类模型：朴素贝叶斯、SVM等\n\n\n\n### 十二、依存句法分析\n\n在词法分析之后，语法分析是NLP的重要一环，也是较为高级、较为复杂的一种任务。\n\n\n\n#### 短语结构树\n\n- 上下文无关语法/短语结构语法：句子通过语法结构生成。比如上海+名词短语 -> 上海 + 浦东 + 名词短语 -> 上海 + 浦东 + 机场 + 航站楼。\n\n- 短语结构树：短语结构语法描述如何自顶而下生成一个句子，句子也可以通过短语结构语法来递归分解，最终生成一颗树结构。\n\n- 英文树库：宾州树库PTB，中文树库：CTB。词性标注集：CTB。\n\n- 20世纪90年代大部分句法分析都集中在短语结构树，由于其较为复杂，准确率并不高\n\n  \n\n#### 依存句法树\n\n- 词与词之间存在主从关系，如果一个词修饰另一个词，那么称修饰词为从属词，被修饰词为支配词，两者之间的语法关系称为依存关系。比如 “大梦想”中 ，“大” 修饰 “梦想”，定中关系。\n- 依存句法树4个公理：\n  - 有且只有一个root虚拟根节点，不依存其他词语\n  - 除此外所有单词必须依存于其他单词\n  - 每个单词不能依存多个单词\n  - 如果单词A依存B，那么位置处于A和B之间的单词C只能依存于A、B或AB之间的单词\n- 开源自由的依存树库：UD(Universal Dependencies)，树库格式为CoNLL-U；CTB语料库，可以从短语结构树转化为依存句法树。\n- 输入是词语和词性，输出是一颗依存句法树，算法有两类：\n  - 基于图的依存句法分析：提取特征，为每条边是否属于句法树的可能性打分，然后用最大生成树作为依存句法树。缺点：开销很大\n  - 基于转移的依存句法分析：将树的构建过程拆分为一系列转移动作，所以只需利用自己的状态和输入单词来预测下一步要执行的转移动作，最后根据动作拼接依存句法树。\n    - Arc-Eager转移系统：定义状态集合和转移动作\n    - 训练：结构化感知机\n    - 预测：柱搜索。全局最优转移路径理论上可以通过一些动态规划(如维特比)一样来实行，但是路径过长、分支过多，在计算上不可行，因此用柱搜索：每个时刻仅仅维护分数最高的前k条子路径，k又称柱宽。\n\n\n\n### 十三、深度学习与自然语言处理\n\n#### 传统方法的局限\n\n- 数据稀疏，无穷多的单词，one-hot编码维度巨高且稀疏  -> 深度神经网络将其化为稠密向量，相似度也会体现出来\n- 特征模板，需要自己设计，且特征非常稀疏  ->  深度神经网络利用多层感知器特征交叉，自动提取特征表示。\n- 误差传播，例如情感分析任务：先分词、再词性标注、再SVM，多个模型的误差传播 -> 深度神经网络，直接输入字符的one-hot向量，输出分类结果，端到端\n\n\n\n#### Word2Vec\n\n- CBOW：输入：上下文，输出：中心词\n- Skip-Gram：输入：中心词，输出：上下文\n- 更详细的介绍，可以看我之前的博客[word2vec详解](https://levylv.github.io/2019/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/word2vec%E8%AF%A6%E8%A7%A3/)\n\n\n\n#### 自然语言处理进阶\n\n- 两个常用的特征提取器：RNN和CNN\n  - RNN，可以处理变长的输入，适合文本。特别是LSTM，可以记忆约200左右的单词。缺陷在于难以并行化。如果句子相对较短，所以在句子颗粒度上进行的基础NLP任务(中文分词、词性标注、命名实体识别和句法分析)经常用RNN\n  - CNN，可以捕捉文本中的n元语法，可以并行化，考虑到文档一般较长，许多文档分类模型都是用CNN。\n\n- 词向量的研究：\n  - Fackbook-fastText，可以得到任意词语的向量，不要求词语一定出现在语料库\n  - ELMO，解决一词多义，需要读入上文才才可以预测当前单词的词向量\n  - Google BERT模型通过一种高效的双向transformer网络同时对上下文建模\n  - 基于线性模型的标注器被BiLSTM-CRF等取代\n    - 其实BiILSTM+CRF模型的话，就是用BiLSTM来提取状态特征f(xi, yi)，用CRF只提取转移特征。\n  - 句法分析器-BiAffineAttention\n  - QA任务，归结为衡量问题和备选答案之前的文本相似度，恰好是具备注意力机制的神经网络擅长的。\n  - 文档摘要涉及的文本生成技术，恰好是RNN擅长的。\n  - 机器翻译领域，Google早已利用基于神经网络的机器翻译技术。学术界目前流行的趋势是Transformer和注意力机制提取特征。","source":"_posts/自然语言处理/《自然语言处理入门》笔记.md","raw":"---\ntitle: 《自然语言处理入门》笔记\ndate: 2020-03-20 17:40:06\ncategories: [自然语言处理]\ntags: 《自然语言处理入门》\n---\n\n疫情期间看完了何晗老师的《自然语言处理入门》这本书，真的是学习了很多NLP的传统知识，本文是相关的笔记。\n\n何晗老师的博客：[码农场](https://www.hankcs.com/)\n\n\n\n### 一、新手上路\n\n#### NLP相关任务\n\n- 最基本的工具任务：词法分析：(中文)分词，词性标注和命名实体识别\n\n- 信息抽取\n\n- 文本分类与文本聚类\n\n- 句法分析\n\n- 语义分析与篇章分析\n\n- 更高级任务：机器翻译、问答系统等\n\n  \n\n#### 语料库\n\n- 中文分词语料库：\n  - 1998《人民日报》，PKU语料库\n  - 微软亚洲研究院，MSR语料库\n  - 香港城市大学，CITYU语料库-繁体中文\n  - 台湾中央研究院，AS语料库-繁体中文\n- 词性标注：\n  - 1998年《人民日报》，PKU标注集\n  - 国家语委语料库，863标注集\n  - CTB(中文树库)语料库，CTB标注集\n  - 《诛仙》语料库，CTB标注集\n- 命名实体识别：\n  - 1998年《人民日报》，实体：人名/地名/机构名\n  - 微软亚洲研究院，实体: 专有名词/时间表达式/数字表达式/度量表达式/地址表达式等5大类30个子类\n- 句法分析\n  - CTB语料库\n- 文本分类\n  - 搜狗文本分类语料库，8000篇新闻\n\n\n\n#### 开源工具\n\n- NLTK\n- 斯坦福大学CoreNLP\n- 哈工大LTP\n- HanLP\n\n\n\n### 二、词典分词\n\n#### 总体思想\n\n基于词典进行分词，分词算法包括：\n\n- 完全切分\n- 最大正向匹配\n- 最大逆向匹配\n- 双向最大匹配\n\n\n\n#### 存储和计算效率\n\n为了提升存储和计算效率，提出了词典的四种数据结构：\n\n- 字典树\n- 双数组字典树\n- AC自动机\n- 基于双数组字典树的AC自动机\n\n\n\n#### 其他应用\n\n- 停用词过滤\n- 简繁转换\n- 拼音转换\n\n\n\n总体而言，字典分词的缺点是无法解决歧义和OOV问题。\n\n\n\n### 三、二元语法与中文分词\n\n- 提出了语言模型，来解决歧义问题，例如分别计算“商品 和 服务” 与 “商品 和服 务”的概率，选择概率大的一种分词。\n- 如果用假设为一阶马尔科夫过程，则为二元语法模型。\n- 模型训练：统计词频，计算二元概率\n- 模型预测：\n  - 词语全切分\n  - 生成词网图\n  - 维特比译码，其实就是动态规划，每个上游节点都保存最短路径。\n- 缺点：还是无法解决OOV问题\n\n\n\n### 四、隐马尔科夫模型与序列标注\n\n- 正式提出了序列标注思想，对于分词任务而言，就是设置{B、M、E、S}标注集，作为隐状态，而字符就是显状态，也称观测状态。\n- HMM由{初始概率矩阵，状态转移矩阵，发射矩阵}三部分组成。\n- HMM是生成模型，因为计算的其实就是f(x,y)的联合概率，只是用马尔科夫过程简化为了初始概率矩阵 * 状态转移矩阵 * 发射矩阵。\n- 模型训练：\n  - 显状态和隐状态都已知，直接计算词频，统计概率。\n  - 显状态已知，隐状态未知，需要用EM算法。\n- 模型预测：\n  - 理论上是遍历所有y，计算最大概率的y，复杂度高。\n  - 维特比译码，即动态规划，每个时刻的每个状态保留最大概率路径。\n- 可以解决OOV，但是还是不够好，jieba分词就是用的HMM\n\n\n\n### 五、感知机分类与序列标注\n\n#### 感知机算法\n\n- 模型预测：公式为 $y = sign(wx + b)$\n\n- 模型训练：对于每一个训练样本：\n\n  - 如果预测$\\hat{y}$与真实$y$相等，则跳过\n  - 如果不相等，则$w = w + x * y$\n\n- 其实相当于损失函数为\n  $$\n  L = \\frac{1}{N}\\sum max(0, -y^{(i)}.w.x^{(i)})\n  $$\n\n- 每次迭代的感知机参数都保留，做集成：\n\n  - 投票感知机：每个感知机结果加权平均\n  - 平均感知机：每个感知机的参数直接求平均\n\n\n\n#### 结构化感知机算法\n\n- 属于结构化预测问题，例如机器翻译、序列标注等，预测结果诸如是一个序列、一颗树啊等等。此类算法往往在训练的时候，就需要做预测的工作。\n\n- 定义得分函数$score(x,y) = w.\\phi(x, y)$，其中$\\phi(x,y)$就是特征函数，则$\\hat{y} = argmax \\ {score(x,y)}$\n\n- 模型属于判别模型，因为最终归一化后，其实还是条件概率$p(y|x) = \\frac{exp(score(x,y))}{\\sum_{y}{exp(score{(x,y))}}}$，其Loss Function是\n  $$\n  L(w) = max_{y}(score(x,y)) - score(x, y) \\\\\n  \\frac{\\delta{L(w)}}{\\delta{w}} = \\phi(x,\\hat{y}) - \\phi(x, y)\n  $$\n  \n- 模型训练：对于每一个训练样本，先预测$\\hat{y} = argmax \\ w.\\phi(x, y)$，然后对于正确的y进行奖励，对于错误的预测$\\hat{y}$，进行惩罚，最终w的更新公式为\n\n  $$\n  w = w + \\phi(x, y) - \\phi(x, \\hat{y})\n  $$\n\n- 模型预测：同样是维特比译码。\n\n- 特征提取问题：\n\n  - 特征函数取值0或1 ，一般分为两类：\n\n    - 转移特征，$f(y_{t-1}, y_{t})$ ，只跟状态值有关，N种状态的话，取值就只有$ N * (N+1)$，因为包含了初始状态BOS。\n    - 状态特征，$f(y_{t}, x_{t})$，只跟当前隐状态值和显状态有关。\n\n  - 一般是基于特征模板生成所有特征，特征模块如：\n\n    - 转移特征模板，$y_{t-1}$\n\n    - 状态特征模板，$x_{t-1}, x_t, x_{t-2}/x_{t-1}, x_{t-1}/x_{t}$\n\n      \n\n### 六、条件随机场与序列标注\n\n- 首先阐述概率图模型，概率图分为两种：\n\n  - 有向概率图：联合概率密度$p(x,y) = \\prod{p(v | \\pi(v))}$，$\\pi(v)$表示v的所有前驱节点\n  - 无向概率图：联合概率密度可以分解为所有最大团的某种函数之乘积，所谓最大团，就是团内每个节点互相连接。还可以定义虚拟的因子节点，因子节点只连接两个相邻节点，组成最小的最大团，那么联合概率密度就是所有因子节点之积：\n\n  $$\n  p(x,y)=\\frac{1}{Z}\\prod_{a}{\\phi_{a}{(x_a, y_a})}\n  $$\n\n  这样的话，\n  $$\n  p(y|x)=\\frac{1}{Z(x)}\\prod_{a}{\\phi_{a}{(x_a, y_a})}\n  $$\n\n- 条件随机场，就是给定输入随机变量x，求解条件概率$p(y|x)$的概率无向图。用于序列标注时，就是线性链条件随机场：\n\n  ​     \t\t\t\t\t\t\t\t\t\t\t<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh3p0sm96tj30r20iptbs.jpg\" alt=\"image-20200726004025174\" style=\"zoom:50%;\" />\n\n- 如果用虚拟因子的话，显然就只有两类因子：\n\n  - 转移因子，发生在$y_t$和$y_{t-1}$之间，即转移特征函数\n  - 状态因子，发生在$y_t$和$x_t$之间，即状态特征函数\n\n- 如果某种函数定义为$w.\\phi(y_t,y_{t-1},x_t)$之后，其实就和结构化感知机一模一样了：\n  $$\n  p(y|x)=\\frac{1}{Z(x)}exp(\\sum{w.\\phi(y_t,y_{t-1},x_t)})\n  $$\n\n- 条件随机场的预测：\n\n  - 和结构化感知机一样，都是维特比译码\n\n- 条件随机场的训练：\n\n  - 训练和结构化感知机不一样，因为条件随机场的Loss Function为最大似然概率，即也相当于最大(相对)熵：\n    $$\n    L(w)=log(\\prod{p(y|x)^{\\hat{p}(x,y)}}) = \\sum_{x,y}{\\hat{p}(x,y)log(p(y|x))} = \\sum_{i=1}^{N}{p(y^{(i)}|x^{(i)})}\n    $$\n\n  - 利用梯度下降法求解的话，w参数更新公式(和结构化感知机最大的区别就在这里)：\n    $$\n    w = w + \\phi(x, y) - E_w[\\phi(x, y)]\n    $$\n    \n\n    - 感知机仅惩罚错得最厉害的哪一个$\\hat{y}$对应的特征函数$\\phi(x,\\hat{y})$\n    - 条件随机场惩罚所有答案，总惩罚量依然为1，但是所有答案分摊，而当特征函数的经验分布期望和模型期望一致的时候，梯度为0，不需要再更新。\n\n- 条件随机场其实就是最大熵模型的衍生~可以看我之前的有关最大熵模型的博文。\n\n\n\n### 七、词性标注\n\n本质上也是一个序列标注模型，标注方式有两种：\n\n- 独立模型：先进行分词任务，再进行词性标注任务，流水线。\n- 联合模型：将分词任务和词性任务联合，标注集例如{B-名词，M-名词}等。\n  - 优点：联合模型几乎在所有问题上优于独立模型。\n  - 缺点：很难有同时标注分词和词性的优秀语料库，一般而言中分分词语料库远多于词性标注语料库；还有就是，联合模型的标注集很大，导致特征数量也很大，参数爆炸。\n\n\n\n### 八、命名实体识别\n\n- 同样是个序列标注模型，标注集{BMES-实体，O}。但命名实体识别任务，往往可以统计为主、规则为辅。\n- 对于规则较强的命名实体，例如网址、E-mail、ISBN、商品编号等，完全可以通过正则表达式先进行预处理提取，再分词统计\n- 对于较短的命名实体，例如人名，完全可以通过先分词，再词性标注即可。\n- HanLP对于一些命名实体是用规则来做的：\n  - 音译人名\n  - 日本人名\n  - 数词英文实体：这个被称为原子分词，这个代码非常值得学习。\n- **自定义领域的命名实体识别任务**\n  - Step 1：收集生语料\n  - Step 2：可以先利用HanLP的词法分析器，得到分词和词性标注结果\n  - Step 3：基于词法分析结果，人工标注你想要的实体，生成熟语料\n  - Step 4：训练序列标注模型\n\n\n\n### 九、信息抽取\n\n所介绍的都是无监督算法。\n\n#### 新词提取\n\n从文章中发现新的词汇，信息熵算法：\n\n- 如果一个字符串左边和右边的搭配很丰富，并且字符串本身的字符搭配很固定，这大概率就是个词汇。\n- 信息熵：计算某个字符串左边和右边单个字符的信息熵，设定信息熵>=某个阈值\n- 互信息：计算该字符串内部的所有字符之间的互信息，互信息大，说明字符都是相关的，设定互信息>=某个阈值\n- 取符合上诉要求的词频Top N字符串。\n\n\n\n#### 短语提取\n\n与新词提取相同，只是需要先进行分词，然后把：\n\n- 字符串 -> 单词列表\n- 左右的单个字符 -> 单个单词\n\n\n\n#### 关键词提取\n\n- Top N词频\n- Top N TF-IDF ：单词在本文档的词频 / 单词出现在所有文档的次数\n- TextRank：类似pageRank，基于网站之间的链接生成图，然后每个节点的权重取决于指向该节点的所有子节点，但是其他子节点的权重计算的时候会因为它指向的节点个数而减少。权重逐步迭代，最终稳定。而文本的话，就是用滑动窗口，中间单词和附近单词产生链接。\n\n\n\n#### 关键句提取\n\n类似关键词提取，但有个TF-IDF的变种-BM25。\n\n\n\n### 十、文本聚类\n\n#### 生成文档向量\n\n- 词袋模型：说白了就类似one-hot，只是值换为词频。\n- 布尔词频：就是one-hot\n- TF-IDF：就值换为tf-idf值\n- 词向量：word2vec，然后所有词向量求和\n- 自编码器：输入时词袋，文档向量就是中间的隐层向量\n\n#### 聚类算法\n\nK-means算法，但是k-means有非常多的改进方法：\n\n- 朴素k-means: \n  - 随机选取k个初始质心 -> 分配簇 -> 重新计算质心 -> 重复\n  - 初始质心选取改进：先选取一个质心，然后再选取一个其他的点，如果其和最近质心的距离能够减小准则函数，再将其变为质心，以此类推，每一步都保证了准则函数的减小。\n- 更快的准则函数：将欧式距离改为余弦距离：\n  - 随机选取k个初始质心 -> 分配簇 -> 对每个点，计算将其移入另一个簇时准则函数的增量，找出最大量并移动 -> 重复\n- 层次聚类：刚开始一个簇，然后k-means分成两个，以此类推，保证二分后准则函数的gain增大，可以自动判断聚类个数。\n\n\n\n### 十一、文本分类\n\n大致思想也很简单：\n\n- 分词，提取单词；这一步并非必须，清华有个研究表明，直接提取所有相邻的n元字符，效果更好。\n\n- 提取特征：词袋向量。缺点是无法表征词语之间顺序，如“不 优秀” 和 “优秀 不”。\n- 特征筛选：利用卡方校验判断特征与类别之间的独立性，其实思想比较类似IV值。\n- 分类模型：朴素贝叶斯、SVM等\n\n\n\n### 十二、依存句法分析\n\n在词法分析之后，语法分析是NLP的重要一环，也是较为高级、较为复杂的一种任务。\n\n\n\n#### 短语结构树\n\n- 上下文无关语法/短语结构语法：句子通过语法结构生成。比如上海+名词短语 -> 上海 + 浦东 + 名词短语 -> 上海 + 浦东 + 机场 + 航站楼。\n\n- 短语结构树：短语结构语法描述如何自顶而下生成一个句子，句子也可以通过短语结构语法来递归分解，最终生成一颗树结构。\n\n- 英文树库：宾州树库PTB，中文树库：CTB。词性标注集：CTB。\n\n- 20世纪90年代大部分句法分析都集中在短语结构树，由于其较为复杂，准确率并不高\n\n  \n\n#### 依存句法树\n\n- 词与词之间存在主从关系，如果一个词修饰另一个词，那么称修饰词为从属词，被修饰词为支配词，两者之间的语法关系称为依存关系。比如 “大梦想”中 ，“大” 修饰 “梦想”，定中关系。\n- 依存句法树4个公理：\n  - 有且只有一个root虚拟根节点，不依存其他词语\n  - 除此外所有单词必须依存于其他单词\n  - 每个单词不能依存多个单词\n  - 如果单词A依存B，那么位置处于A和B之间的单词C只能依存于A、B或AB之间的单词\n- 开源自由的依存树库：UD(Universal Dependencies)，树库格式为CoNLL-U；CTB语料库，可以从短语结构树转化为依存句法树。\n- 输入是词语和词性，输出是一颗依存句法树，算法有两类：\n  - 基于图的依存句法分析：提取特征，为每条边是否属于句法树的可能性打分，然后用最大生成树作为依存句法树。缺点：开销很大\n  - 基于转移的依存句法分析：将树的构建过程拆分为一系列转移动作，所以只需利用自己的状态和输入单词来预测下一步要执行的转移动作，最后根据动作拼接依存句法树。\n    - Arc-Eager转移系统：定义状态集合和转移动作\n    - 训练：结构化感知机\n    - 预测：柱搜索。全局最优转移路径理论上可以通过一些动态规划(如维特比)一样来实行，但是路径过长、分支过多，在计算上不可行，因此用柱搜索：每个时刻仅仅维护分数最高的前k条子路径，k又称柱宽。\n\n\n\n### 十三、深度学习与自然语言处理\n\n#### 传统方法的局限\n\n- 数据稀疏，无穷多的单词，one-hot编码维度巨高且稀疏  -> 深度神经网络将其化为稠密向量，相似度也会体现出来\n- 特征模板，需要自己设计，且特征非常稀疏  ->  深度神经网络利用多层感知器特征交叉，自动提取特征表示。\n- 误差传播，例如情感分析任务：先分词、再词性标注、再SVM，多个模型的误差传播 -> 深度神经网络，直接输入字符的one-hot向量，输出分类结果，端到端\n\n\n\n#### Word2Vec\n\n- CBOW：输入：上下文，输出：中心词\n- Skip-Gram：输入：中心词，输出：上下文\n- 更详细的介绍，可以看我之前的博客[word2vec详解](https://levylv.github.io/2019/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/word2vec%E8%AF%A6%E8%A7%A3/)\n\n\n\n#### 自然语言处理进阶\n\n- 两个常用的特征提取器：RNN和CNN\n  - RNN，可以处理变长的输入，适合文本。特别是LSTM，可以记忆约200左右的单词。缺陷在于难以并行化。如果句子相对较短，所以在句子颗粒度上进行的基础NLP任务(中文分词、词性标注、命名实体识别和句法分析)经常用RNN\n  - CNN，可以捕捉文本中的n元语法，可以并行化，考虑到文档一般较长，许多文档分类模型都是用CNN。\n\n- 词向量的研究：\n  - Fackbook-fastText，可以得到任意词语的向量，不要求词语一定出现在语料库\n  - ELMO，解决一词多义，需要读入上文才才可以预测当前单词的词向量\n  - Google BERT模型通过一种高效的双向transformer网络同时对上下文建模\n  - 基于线性模型的标注器被BiLSTM-CRF等取代\n    - 其实BiILSTM+CRF模型的话，就是用BiLSTM来提取状态特征f(xi, yi)，用CRF只提取转移特征。\n  - 句法分析器-BiAffineAttention\n  - QA任务，归结为衡量问题和备选答案之前的文本相似度，恰好是具备注意力机制的神经网络擅长的。\n  - 文档摘要涉及的文本生成技术，恰好是RNN擅长的。\n  - 机器翻译领域，Google早已利用基于神经网络的机器翻译技术。学术界目前流行的趋势是Transformer和注意力机制提取特征。","slug":"自然语言处理/《自然语言处理入门》笔记","published":1,"updated":"2022-09-15T03:46:43.368Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551p5003wjqrrjki0haa0","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>疫情期间看完了何晗老师的《自然语言处理入门》这本书，真的是学习了很多NLP的传统知识，本文是相关的笔记。</p>\n<p>何晗老师的博客：<a href=\"https://www.hankcs.com/\" target=\"_blank\" rel=\"noopener\">码农场</a></p>\n<h3 id=\"一、新手上路\"><a href=\"#一、新手上路\" class=\"headerlink\" title=\"一、新手上路\"></a>一、新手上路</h3><h4 id=\"NLP相关任务\"><a href=\"#NLP相关任务\" class=\"headerlink\" title=\"NLP相关任务\"></a>NLP相关任务</h4><ul>\n<li><p>最基本的工具任务：词法分析：(中文)分词，词性标注和命名实体识别</p>\n</li>\n<li><p>信息抽取</p>\n</li>\n<li><p>文本分类与文本聚类</p>\n</li>\n<li><p>句法分析</p>\n</li>\n<li><p>语义分析与篇章分析</p>\n</li>\n<li><p>更高级任务：机器翻译、问答系统等</p>\n</li>\n</ul>\n<h4 id=\"语料库\"><a href=\"#语料库\" class=\"headerlink\" title=\"语料库\"></a>语料库</h4><ul>\n<li>中文分词语料库：<ul>\n<li>1998《人民日报》，PKU语料库</li>\n<li>微软亚洲研究院，MSR语料库</li>\n<li>香港城市大学，CITYU语料库-繁体中文</li>\n<li>台湾中央研究院，AS语料库-繁体中文</li>\n</ul>\n</li>\n<li>词性标注：<ul>\n<li>1998年《人民日报》，PKU标注集</li>\n<li>国家语委语料库，863标注集</li>\n<li>CTB(中文树库)语料库，CTB标注集</li>\n<li>《诛仙》语料库，CTB标注集</li>\n</ul>\n</li>\n<li>命名实体识别：<ul>\n<li>1998年《人民日报》，实体：人名/地名/机构名</li>\n<li>微软亚洲研究院，实体: 专有名词/时间表达式/数字表达式/度量表达式/地址表达式等5大类30个子类</li>\n</ul>\n</li>\n<li>句法分析<ul>\n<li>CTB语料库</li>\n</ul>\n</li>\n<li>文本分类<ul>\n<li>搜狗文本分类语料库，8000篇新闻</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"开源工具\"><a href=\"#开源工具\" class=\"headerlink\" title=\"开源工具\"></a>开源工具</h4><ul>\n<li>NLTK</li>\n<li>斯坦福大学CoreNLP</li>\n<li>哈工大LTP</li>\n<li>HanLP</li>\n</ul>\n<h3 id=\"二、词典分词\"><a href=\"#二、词典分词\" class=\"headerlink\" title=\"二、词典分词\"></a>二、词典分词</h3><h4 id=\"总体思想\"><a href=\"#总体思想\" class=\"headerlink\" title=\"总体思想\"></a>总体思想</h4><p>基于词典进行分词，分词算法包括：</p>\n<ul>\n<li>完全切分</li>\n<li>最大正向匹配</li>\n<li>最大逆向匹配</li>\n<li>双向最大匹配</li>\n</ul>\n<h4 id=\"存储和计算效率\"><a href=\"#存储和计算效率\" class=\"headerlink\" title=\"存储和计算效率\"></a>存储和计算效率</h4><p>为了提升存储和计算效率，提出了词典的四种数据结构：</p>\n<ul>\n<li>字典树</li>\n<li>双数组字典树</li>\n<li>AC自动机</li>\n<li>基于双数组字典树的AC自动机</li>\n</ul>\n<h4 id=\"其他应用\"><a href=\"#其他应用\" class=\"headerlink\" title=\"其他应用\"></a>其他应用</h4><ul>\n<li>停用词过滤</li>\n<li>简繁转换</li>\n<li>拼音转换</li>\n</ul>\n<p>总体而言，字典分词的缺点是无法解决歧义和OOV问题。</p>\n<h3 id=\"三、二元语法与中文分词\"><a href=\"#三、二元语法与中文分词\" class=\"headerlink\" title=\"三、二元语法与中文分词\"></a>三、二元语法与中文分词</h3><ul>\n<li>提出了语言模型，来解决歧义问题，例如分别计算“商品 和 服务” 与 “商品 和服 务”的概率，选择概率大的一种分词。</li>\n<li>如果用假设为一阶马尔科夫过程，则为二元语法模型。</li>\n<li>模型训练：统计词频，计算二元概率</li>\n<li>模型预测：<ul>\n<li>词语全切分</li>\n<li>生成词网图</li>\n<li>维特比译码，其实就是动态规划，每个上游节点都保存最短路径。</li>\n</ul>\n</li>\n<li>缺点：还是无法解决OOV问题</li>\n</ul>\n<h3 id=\"四、隐马尔科夫模型与序列标注\"><a href=\"#四、隐马尔科夫模型与序列标注\" class=\"headerlink\" title=\"四、隐马尔科夫模型与序列标注\"></a>四、隐马尔科夫模型与序列标注</h3><ul>\n<li>正式提出了序列标注思想，对于分词任务而言，就是设置{B、M、E、S}标注集，作为隐状态，而字符就是显状态，也称观测状态。</li>\n<li>HMM由{初始概率矩阵，状态转移矩阵，发射矩阵}三部分组成。</li>\n<li>HMM是生成模型，因为计算的其实就是f(x,y)的联合概率，只是用马尔科夫过程简化为了初始概率矩阵 <em> 状态转移矩阵 </em> 发射矩阵。</li>\n<li>模型训练：<ul>\n<li>显状态和隐状态都已知，直接计算词频，统计概率。</li>\n<li>显状态已知，隐状态未知，需要用EM算法。</li>\n</ul>\n</li>\n<li>模型预测：<ul>\n<li>理论上是遍历所有y，计算最大概率的y，复杂度高。</li>\n<li>维特比译码，即动态规划，每个时刻的每个状态保留最大概率路径。</li>\n</ul>\n</li>\n<li>可以解决OOV，但是还是不够好，jieba分词就是用的HMM</li>\n</ul>\n<h3 id=\"五、感知机分类与序列标注\"><a href=\"#五、感知机分类与序列标注\" class=\"headerlink\" title=\"五、感知机分类与序列标注\"></a>五、感知机分类与序列标注</h3><h4 id=\"感知机算法\"><a href=\"#感知机算法\" class=\"headerlink\" title=\"感知机算法\"></a>感知机算法</h4><ul>\n<li><p>模型预测：公式为 $y = sign(wx + b)$</p>\n</li>\n<li><p>模型训练：对于每一个训练样本：</p>\n<ul>\n<li>如果预测$\\hat{y}$与真实$y$相等，则跳过</li>\n<li>如果不相等，则$w = w + x * y$</li>\n</ul>\n</li>\n<li><p>其实相当于损失函数为</p>\n<script type=\"math/tex; mode=display\">\nL = \\frac{1}{N}\\sum max(0, -y^{(i)}.w.x^{(i)})</script></li>\n<li><p>每次迭代的感知机参数都保留，做集成：</p>\n<ul>\n<li>投票感知机：每个感知机结果加权平均</li>\n<li>平均感知机：每个感知机的参数直接求平均</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"结构化感知机算法\"><a href=\"#结构化感知机算法\" class=\"headerlink\" title=\"结构化感知机算法\"></a>结构化感知机算法</h4><ul>\n<li><p>属于结构化预测问题，例如机器翻译、序列标注等，预测结果诸如是一个序列、一颗树啊等等。此类算法往往在训练的时候，就需要做预测的工作。</p>\n</li>\n<li><p>定义得分函数$score(x,y) = w.\\phi(x, y)$，其中$\\phi(x,y)$就是特征函数，则$\\hat{y} = argmax \\ {score(x,y)}$</p>\n</li>\n<li><p>模型属于判别模型，因为最终归一化后，其实还是条件概率$p(y|x) = \\frac{exp(score(x,y))}{\\sum_{y}{exp(score{(x,y))}}}$，其Loss Function是</p>\n<script type=\"math/tex; mode=display\">\nL(w) = max_{y}(score(x,y)) - score(x, y) \\\\\n\\frac{\\delta{L(w)}}{\\delta{w}} = \\phi(x,\\hat{y}) - \\phi(x, y)</script></li>\n<li><p>模型训练：对于每一个训练样本，先预测$\\hat{y} = argmax \\ w.\\phi(x, y)$，然后对于正确的y进行奖励，对于错误的预测$\\hat{y}$，进行惩罚，最终w的更新公式为</p>\n<script type=\"math/tex; mode=display\">\nw = w + \\phi(x, y) - \\phi(x, \\hat{y})</script></li>\n<li><p>模型预测：同样是维特比译码。</p>\n</li>\n<li><p>特征提取问题：</p>\n<ul>\n<li><p>特征函数取值0或1 ，一般分为两类：</p>\n<ul>\n<li>转移特征，$f(y<em>{t-1}, y</em>{t})$ ，只跟状态值有关，N种状态的话，取值就只有$ N * (N+1)$，因为包含了初始状态BOS。</li>\n<li>状态特征，$f(y<em>{t}, x</em>{t})$，只跟当前隐状态值和显状态有关。</li>\n</ul>\n</li>\n<li><p>一般是基于特征模板生成所有特征，特征模块如：</p>\n<ul>\n<li><p>转移特征模板，$y_{t-1}$</p>\n</li>\n<li><p>状态特征模板，$x<em>{t-1}, x_t, x</em>{t-2}/x<em>{t-1}, x</em>{t-1}/x_{t}$</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"六、条件随机场与序列标注\"><a href=\"#六、条件随机场与序列标注\" class=\"headerlink\" title=\"六、条件随机场与序列标注\"></a>六、条件随机场与序列标注</h3><ul>\n<li><p>首先阐述概率图模型，概率图分为两种：</p>\n<ul>\n<li>有向概率图：联合概率密度$p(x,y) = \\prod{p(v | \\pi(v))}$，$\\pi(v)$表示v的所有前驱节点</li>\n<li>无向概率图：联合概率密度可以分解为所有最大团的某种函数之乘积，所谓最大团，就是团内每个节点互相连接。还可以定义虚拟的因子节点，因子节点只连接两个相邻节点，组成最小的最大团，那么联合概率密度就是所有因子节点之积：</li>\n</ul>\n<script type=\"math/tex; mode=display\">\np(x,y)=\\frac{1}{Z}\\prod_{a}{\\phi_{a}{(x_a, y_a})}</script><p>这样的话，</p>\n<script type=\"math/tex; mode=display\">\np(y|x)=\\frac{1}{Z(x)}\\prod_{a}{\\phi_{a}{(x_a, y_a})}</script></li>\n<li><p>条件随机场，就是给定输入随机变量x，求解条件概率$p(y|x)$的概率无向图。用于序列标注时，就是线性链条件随机场：</p>\n<p>​                                                 <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh3p0sm96tj30r20iptbs.jpg\" alt=\"image-20200726004025174\" style=\"zoom:50%;\"></p>\n</li>\n<li><p>如果用虚拟因子的话，显然就只有两类因子：</p>\n<ul>\n<li>转移因子，发生在$y<em>t$和$y</em>{t-1}$之间，即转移特征函数</li>\n<li>状态因子，发生在$y_t$和$x_t$之间，即状态特征函数</li>\n</ul>\n</li>\n<li><p>如果某种函数定义为$w.\\phi(y<em>t,y</em>{t-1},x_t)$之后，其实就和结构化感知机一模一样了：</p>\n<script type=\"math/tex; mode=display\">\np(y|x)=\\frac{1}{Z(x)}exp(\\sum{w.\\phi(y_t,y_{t-1},x_t)})</script></li>\n<li><p>条件随机场的预测：</p>\n<ul>\n<li>和结构化感知机一样，都是维特比译码</li>\n</ul>\n</li>\n<li><p>条件随机场的训练：</p>\n<ul>\n<li><p>训练和结构化感知机不一样，因为条件随机场的Loss Function为最大似然概率，即也相当于最大(相对)熵：</p>\n<script type=\"math/tex; mode=display\">\nL(w)=log(\\prod{p(y|x)^{\\hat{p}(x,y)}}) = \\sum_{x,y}{\\hat{p}(x,y)log(p(y|x))} = \\sum_{i=1}^{N}{p(y^{(i)}|x^{(i)})}</script></li>\n<li><p>利用梯度下降法求解的话，w参数更新公式(和结构化感知机最大的区别就在这里)：</p>\n<script type=\"math/tex; mode=display\">\nw = w + \\phi(x, y) - E_w[\\phi(x, y)]</script></li>\n</ul>\n</li>\n</ul>\n<pre><code>- 感知机仅惩罚错得最厉害的哪一个$\\hat{y}$对应的特征函数$\\phi(x,\\hat{y})$\n- 条件随机场惩罚所有答案，总惩罚量依然为1，但是所有答案分摊，而当特征函数的经验分布期望和模型期望一致的时候，梯度为0，不需要再更新。\n</code></pre><ul>\n<li>条件随机场其实就是最大熵模型的衍生~可以看我之前的有关最大熵模型的博文。</li>\n</ul>\n<h3 id=\"七、词性标注\"><a href=\"#七、词性标注\" class=\"headerlink\" title=\"七、词性标注\"></a>七、词性标注</h3><p>本质上也是一个序列标注模型，标注方式有两种：</p>\n<ul>\n<li>独立模型：先进行分词任务，再进行词性标注任务，流水线。</li>\n<li>联合模型：将分词任务和词性任务联合，标注集例如{B-名词，M-名词}等。<ul>\n<li>优点：联合模型几乎在所有问题上优于独立模型。</li>\n<li>缺点：很难有同时标注分词和词性的优秀语料库，一般而言中分分词语料库远多于词性标注语料库；还有就是，联合模型的标注集很大，导致特征数量也很大，参数爆炸。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"八、命名实体识别\"><a href=\"#八、命名实体识别\" class=\"headerlink\" title=\"八、命名实体识别\"></a>八、命名实体识别</h3><ul>\n<li>同样是个序列标注模型，标注集{BMES-实体，O}。但命名实体识别任务，往往可以统计为主、规则为辅。</li>\n<li>对于规则较强的命名实体，例如网址、E-mail、ISBN、商品编号等，完全可以通过正则表达式先进行预处理提取，再分词统计</li>\n<li>对于较短的命名实体，例如人名，完全可以通过先分词，再词性标注即可。</li>\n<li>HanLP对于一些命名实体是用规则来做的：<ul>\n<li>音译人名</li>\n<li>日本人名</li>\n<li>数词英文实体：这个被称为原子分词，这个代码非常值得学习。</li>\n</ul>\n</li>\n<li><strong>自定义领域的命名实体识别任务</strong><ul>\n<li>Step 1：收集生语料</li>\n<li>Step 2：可以先利用HanLP的词法分析器，得到分词和词性标注结果</li>\n<li>Step 3：基于词法分析结果，人工标注你想要的实体，生成熟语料</li>\n<li>Step 4：训练序列标注模型</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"九、信息抽取\"><a href=\"#九、信息抽取\" class=\"headerlink\" title=\"九、信息抽取\"></a>九、信息抽取</h3><p>所介绍的都是无监督算法。</p>\n<h4 id=\"新词提取\"><a href=\"#新词提取\" class=\"headerlink\" title=\"新词提取\"></a>新词提取</h4><p>从文章中发现新的词汇，信息熵算法：</p>\n<ul>\n<li>如果一个字符串左边和右边的搭配很丰富，并且字符串本身的字符搭配很固定，这大概率就是个词汇。</li>\n<li>信息熵：计算某个字符串左边和右边单个字符的信息熵，设定信息熵&gt;=某个阈值</li>\n<li>互信息：计算该字符串内部的所有字符之间的互信息，互信息大，说明字符都是相关的，设定互信息&gt;=某个阈值</li>\n<li>取符合上诉要求的词频Top N字符串。</li>\n</ul>\n<h4 id=\"短语提取\"><a href=\"#短语提取\" class=\"headerlink\" title=\"短语提取\"></a>短语提取</h4><p>与新词提取相同，只是需要先进行分词，然后把：</p>\n<ul>\n<li>字符串 -&gt; 单词列表</li>\n<li>左右的单个字符 -&gt; 单个单词</li>\n</ul>\n<h4 id=\"关键词提取\"><a href=\"#关键词提取\" class=\"headerlink\" title=\"关键词提取\"></a>关键词提取</h4><ul>\n<li>Top N词频</li>\n<li>Top N TF-IDF ：单词在本文档的词频 / 单词出现在所有文档的次数</li>\n<li>TextRank：类似pageRank，基于网站之间的链接生成图，然后每个节点的权重取决于指向该节点的所有子节点，但是其他子节点的权重计算的时候会因为它指向的节点个数而减少。权重逐步迭代，最终稳定。而文本的话，就是用滑动窗口，中间单词和附近单词产生链接。</li>\n</ul>\n<h4 id=\"关键句提取\"><a href=\"#关键句提取\" class=\"headerlink\" title=\"关键句提取\"></a>关键句提取</h4><p>类似关键词提取，但有个TF-IDF的变种-BM25。</p>\n<h3 id=\"十、文本聚类\"><a href=\"#十、文本聚类\" class=\"headerlink\" title=\"十、文本聚类\"></a>十、文本聚类</h3><h4 id=\"生成文档向量\"><a href=\"#生成文档向量\" class=\"headerlink\" title=\"生成文档向量\"></a>生成文档向量</h4><ul>\n<li>词袋模型：说白了就类似one-hot，只是值换为词频。</li>\n<li>布尔词频：就是one-hot</li>\n<li>TF-IDF：就值换为tf-idf值</li>\n<li>词向量：word2vec，然后所有词向量求和</li>\n<li>自编码器：输入时词袋，文档向量就是中间的隐层向量</li>\n</ul>\n<h4 id=\"聚类算法\"><a href=\"#聚类算法\" class=\"headerlink\" title=\"聚类算法\"></a>聚类算法</h4><p>K-means算法，但是k-means有非常多的改进方法：</p>\n<ul>\n<li>朴素k-means: <ul>\n<li>随机选取k个初始质心 -&gt; 分配簇 -&gt; 重新计算质心 -&gt; 重复</li>\n<li>初始质心选取改进：先选取一个质心，然后再选取一个其他的点，如果其和最近质心的距离能够减小准则函数，再将其变为质心，以此类推，每一步都保证了准则函数的减小。</li>\n</ul>\n</li>\n<li>更快的准则函数：将欧式距离改为余弦距离：<ul>\n<li>随机选取k个初始质心 -&gt; 分配簇 -&gt; 对每个点，计算将其移入另一个簇时准则函数的增量，找出最大量并移动 -&gt; 重复</li>\n</ul>\n</li>\n<li>层次聚类：刚开始一个簇，然后k-means分成两个，以此类推，保证二分后准则函数的gain增大，可以自动判断聚类个数。</li>\n</ul>\n<h3 id=\"十一、文本分类\"><a href=\"#十一、文本分类\" class=\"headerlink\" title=\"十一、文本分类\"></a>十一、文本分类</h3><p>大致思想也很简单：</p>\n<ul>\n<li><p>分词，提取单词；这一步并非必须，清华有个研究表明，直接提取所有相邻的n元字符，效果更好。</p>\n</li>\n<li><p>提取特征：词袋向量。缺点是无法表征词语之间顺序，如“不 优秀” 和 “优秀 不”。</p>\n</li>\n<li>特征筛选：利用卡方校验判断特征与类别之间的独立性，其实思想比较类似IV值。</li>\n<li>分类模型：朴素贝叶斯、SVM等</li>\n</ul>\n<h3 id=\"十二、依存句法分析\"><a href=\"#十二、依存句法分析\" class=\"headerlink\" title=\"十二、依存句法分析\"></a>十二、依存句法分析</h3><p>在词法分析之后，语法分析是NLP的重要一环，也是较为高级、较为复杂的一种任务。</p>\n<h4 id=\"短语结构树\"><a href=\"#短语结构树\" class=\"headerlink\" title=\"短语结构树\"></a>短语结构树</h4><ul>\n<li><p>上下文无关语法/短语结构语法：句子通过语法结构生成。比如上海+名词短语 -&gt; 上海 + 浦东 + 名词短语 -&gt; 上海 + 浦东 + 机场 + 航站楼。</p>\n</li>\n<li><p>短语结构树：短语结构语法描述如何自顶而下生成一个句子，句子也可以通过短语结构语法来递归分解，最终生成一颗树结构。</p>\n</li>\n<li><p>英文树库：宾州树库PTB，中文树库：CTB。词性标注集：CTB。</p>\n</li>\n<li><p>20世纪90年代大部分句法分析都集中在短语结构树，由于其较为复杂，准确率并不高</p>\n</li>\n</ul>\n<h4 id=\"依存句法树\"><a href=\"#依存句法树\" class=\"headerlink\" title=\"依存句法树\"></a>依存句法树</h4><ul>\n<li>词与词之间存在主从关系，如果一个词修饰另一个词，那么称修饰词为从属词，被修饰词为支配词，两者之间的语法关系称为依存关系。比如 “大梦想”中 ，“大” 修饰 “梦想”，定中关系。</li>\n<li>依存句法树4个公理：<ul>\n<li>有且只有一个root虚拟根节点，不依存其他词语</li>\n<li>除此外所有单词必须依存于其他单词</li>\n<li>每个单词不能依存多个单词</li>\n<li>如果单词A依存B，那么位置处于A和B之间的单词C只能依存于A、B或AB之间的单词</li>\n</ul>\n</li>\n<li>开源自由的依存树库：UD(Universal Dependencies)，树库格式为CoNLL-U；CTB语料库，可以从短语结构树转化为依存句法树。</li>\n<li>输入是词语和词性，输出是一颗依存句法树，算法有两类：<ul>\n<li>基于图的依存句法分析：提取特征，为每条边是否属于句法树的可能性打分，然后用最大生成树作为依存句法树。缺点：开销很大</li>\n<li>基于转移的依存句法分析：将树的构建过程拆分为一系列转移动作，所以只需利用自己的状态和输入单词来预测下一步要执行的转移动作，最后根据动作拼接依存句法树。<ul>\n<li>Arc-Eager转移系统：定义状态集合和转移动作</li>\n<li>训练：结构化感知机</li>\n<li>预测：柱搜索。全局最优转移路径理论上可以通过一些动态规划(如维特比)一样来实行，但是路径过长、分支过多，在计算上不可行，因此用柱搜索：每个时刻仅仅维护分数最高的前k条子路径，k又称柱宽。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"十三、深度学习与自然语言处理\"><a href=\"#十三、深度学习与自然语言处理\" class=\"headerlink\" title=\"十三、深度学习与自然语言处理\"></a>十三、深度学习与自然语言处理</h3><h4 id=\"传统方法的局限\"><a href=\"#传统方法的局限\" class=\"headerlink\" title=\"传统方法的局限\"></a>传统方法的局限</h4><ul>\n<li>数据稀疏，无穷多的单词，one-hot编码维度巨高且稀疏  -&gt; 深度神经网络将其化为稠密向量，相似度也会体现出来</li>\n<li>特征模板，需要自己设计，且特征非常稀疏  -&gt;  深度神经网络利用多层感知器特征交叉，自动提取特征表示。</li>\n<li>误差传播，例如情感分析任务：先分词、再词性标注、再SVM，多个模型的误差传播 -&gt; 深度神经网络，直接输入字符的one-hot向量，输出分类结果，端到端</li>\n</ul>\n<h4 id=\"Word2Vec\"><a href=\"#Word2Vec\" class=\"headerlink\" title=\"Word2Vec\"></a>Word2Vec</h4><ul>\n<li>CBOW：输入：上下文，输出：中心词</li>\n<li>Skip-Gram：输入：中心词，输出：上下文</li>\n<li>更详细的介绍，可以看我之前的博客<a href=\"https://levylv.github.io/2019/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/word2vec%E8%AF%A6%E8%A7%A3/\" target=\"_blank\" rel=\"noopener\">word2vec详解</a></li>\n</ul>\n<h4 id=\"自然语言处理进阶\"><a href=\"#自然语言处理进阶\" class=\"headerlink\" title=\"自然语言处理进阶\"></a>自然语言处理进阶</h4><ul>\n<li><p>两个常用的特征提取器：RNN和CNN</p>\n<ul>\n<li>RNN，可以处理变长的输入，适合文本。特别是LSTM，可以记忆约200左右的单词。缺陷在于难以并行化。如果句子相对较短，所以在句子颗粒度上进行的基础NLP任务(中文分词、词性标注、命名实体识别和句法分析)经常用RNN</li>\n<li>CNN，可以捕捉文本中的n元语法，可以并行化，考虑到文档一般较长，许多文档分类模型都是用CNN。</li>\n</ul>\n</li>\n<li><p>词向量的研究：</p>\n<ul>\n<li>Fackbook-fastText，可以得到任意词语的向量，不要求词语一定出现在语料库</li>\n<li>ELMO，解决一词多义，需要读入上文才才可以预测当前单词的词向量</li>\n<li>Google BERT模型通过一种高效的双向transformer网络同时对上下文建模</li>\n<li>基于线性模型的标注器被BiLSTM-CRF等取代<ul>\n<li>其实BiILSTM+CRF模型的话，就是用BiLSTM来提取状态特征f(xi, yi)，用CRF只提取转移特征。</li>\n</ul>\n</li>\n<li>句法分析器-BiAffineAttention</li>\n<li>QA任务，归结为衡量问题和备选答案之前的文本相似度，恰好是具备注意力机制的神经网络擅长的。</li>\n<li>文档摘要涉及的文本生成技术，恰好是RNN擅长的。</li>\n<li>机器翻译领域，Google早已利用基于神经网络的机器翻译技术。学术界目前流行的趋势是Transformer和注意力机制提取特征。</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>疫情期间看完了何晗老师的《自然语言处理入门》这本书，真的是学习了很多NLP的传统知识，本文是相关的笔记。</p>\n<p>何晗老师的博客：<a href=\"https://www.hankcs.com/\" target=\"_blank\" rel=\"noopener\">码农场</a></p>\n<h3 id=\"一、新手上路\"><a href=\"#一、新手上路\" class=\"headerlink\" title=\"一、新手上路\"></a>一、新手上路</h3><h4 id=\"NLP相关任务\"><a href=\"#NLP相关任务\" class=\"headerlink\" title=\"NLP相关任务\"></a>NLP相关任务</h4><ul>\n<li><p>最基本的工具任务：词法分析：(中文)分词，词性标注和命名实体识别</p>\n</li>\n<li><p>信息抽取</p>\n</li>\n<li><p>文本分类与文本聚类</p>\n</li>\n<li><p>句法分析</p>\n</li>\n<li><p>语义分析与篇章分析</p>\n</li>\n<li><p>更高级任务：机器翻译、问答系统等</p>\n</li>\n</ul>\n<h4 id=\"语料库\"><a href=\"#语料库\" class=\"headerlink\" title=\"语料库\"></a>语料库</h4><ul>\n<li>中文分词语料库：<ul>\n<li>1998《人民日报》，PKU语料库</li>\n<li>微软亚洲研究院，MSR语料库</li>\n<li>香港城市大学，CITYU语料库-繁体中文</li>\n<li>台湾中央研究院，AS语料库-繁体中文</li>\n</ul>\n</li>\n<li>词性标注：<ul>\n<li>1998年《人民日报》，PKU标注集</li>\n<li>国家语委语料库，863标注集</li>\n<li>CTB(中文树库)语料库，CTB标注集</li>\n<li>《诛仙》语料库，CTB标注集</li>\n</ul>\n</li>\n<li>命名实体识别：<ul>\n<li>1998年《人民日报》，实体：人名/地名/机构名</li>\n<li>微软亚洲研究院，实体: 专有名词/时间表达式/数字表达式/度量表达式/地址表达式等5大类30个子类</li>\n</ul>\n</li>\n<li>句法分析<ul>\n<li>CTB语料库</li>\n</ul>\n</li>\n<li>文本分类<ul>\n<li>搜狗文本分类语料库，8000篇新闻</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"开源工具\"><a href=\"#开源工具\" class=\"headerlink\" title=\"开源工具\"></a>开源工具</h4><ul>\n<li>NLTK</li>\n<li>斯坦福大学CoreNLP</li>\n<li>哈工大LTP</li>\n<li>HanLP</li>\n</ul>\n<h3 id=\"二、词典分词\"><a href=\"#二、词典分词\" class=\"headerlink\" title=\"二、词典分词\"></a>二、词典分词</h3><h4 id=\"总体思想\"><a href=\"#总体思想\" class=\"headerlink\" title=\"总体思想\"></a>总体思想</h4><p>基于词典进行分词，分词算法包括：</p>\n<ul>\n<li>完全切分</li>\n<li>最大正向匹配</li>\n<li>最大逆向匹配</li>\n<li>双向最大匹配</li>\n</ul>\n<h4 id=\"存储和计算效率\"><a href=\"#存储和计算效率\" class=\"headerlink\" title=\"存储和计算效率\"></a>存储和计算效率</h4><p>为了提升存储和计算效率，提出了词典的四种数据结构：</p>\n<ul>\n<li>字典树</li>\n<li>双数组字典树</li>\n<li>AC自动机</li>\n<li>基于双数组字典树的AC自动机</li>\n</ul>\n<h4 id=\"其他应用\"><a href=\"#其他应用\" class=\"headerlink\" title=\"其他应用\"></a>其他应用</h4><ul>\n<li>停用词过滤</li>\n<li>简繁转换</li>\n<li>拼音转换</li>\n</ul>\n<p>总体而言，字典分词的缺点是无法解决歧义和OOV问题。</p>\n<h3 id=\"三、二元语法与中文分词\"><a href=\"#三、二元语法与中文分词\" class=\"headerlink\" title=\"三、二元语法与中文分词\"></a>三、二元语法与中文分词</h3><ul>\n<li>提出了语言模型，来解决歧义问题，例如分别计算“商品 和 服务” 与 “商品 和服 务”的概率，选择概率大的一种分词。</li>\n<li>如果用假设为一阶马尔科夫过程，则为二元语法模型。</li>\n<li>模型训练：统计词频，计算二元概率</li>\n<li>模型预测：<ul>\n<li>词语全切分</li>\n<li>生成词网图</li>\n<li>维特比译码，其实就是动态规划，每个上游节点都保存最短路径。</li>\n</ul>\n</li>\n<li>缺点：还是无法解决OOV问题</li>\n</ul>\n<h3 id=\"四、隐马尔科夫模型与序列标注\"><a href=\"#四、隐马尔科夫模型与序列标注\" class=\"headerlink\" title=\"四、隐马尔科夫模型与序列标注\"></a>四、隐马尔科夫模型与序列标注</h3><ul>\n<li>正式提出了序列标注思想，对于分词任务而言，就是设置{B、M、E、S}标注集，作为隐状态，而字符就是显状态，也称观测状态。</li>\n<li>HMM由{初始概率矩阵，状态转移矩阵，发射矩阵}三部分组成。</li>\n<li>HMM是生成模型，因为计算的其实就是f(x,y)的联合概率，只是用马尔科夫过程简化为了初始概率矩阵 <em> 状态转移矩阵 </em> 发射矩阵。</li>\n<li>模型训练：<ul>\n<li>显状态和隐状态都已知，直接计算词频，统计概率。</li>\n<li>显状态已知，隐状态未知，需要用EM算法。</li>\n</ul>\n</li>\n<li>模型预测：<ul>\n<li>理论上是遍历所有y，计算最大概率的y，复杂度高。</li>\n<li>维特比译码，即动态规划，每个时刻的每个状态保留最大概率路径。</li>\n</ul>\n</li>\n<li>可以解决OOV，但是还是不够好，jieba分词就是用的HMM</li>\n</ul>\n<h3 id=\"五、感知机分类与序列标注\"><a href=\"#五、感知机分类与序列标注\" class=\"headerlink\" title=\"五、感知机分类与序列标注\"></a>五、感知机分类与序列标注</h3><h4 id=\"感知机算法\"><a href=\"#感知机算法\" class=\"headerlink\" title=\"感知机算法\"></a>感知机算法</h4><ul>\n<li><p>模型预测：公式为 $y = sign(wx + b)$</p>\n</li>\n<li><p>模型训练：对于每一个训练样本：</p>\n<ul>\n<li>如果预测$\\hat{y}$与真实$y$相等，则跳过</li>\n<li>如果不相等，则$w = w + x * y$</li>\n</ul>\n</li>\n<li><p>其实相当于损失函数为</p>\n<script type=\"math/tex; mode=display\">\nL = \\frac{1}{N}\\sum max(0, -y^{(i)}.w.x^{(i)})</script></li>\n<li><p>每次迭代的感知机参数都保留，做集成：</p>\n<ul>\n<li>投票感知机：每个感知机结果加权平均</li>\n<li>平均感知机：每个感知机的参数直接求平均</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"结构化感知机算法\"><a href=\"#结构化感知机算法\" class=\"headerlink\" title=\"结构化感知机算法\"></a>结构化感知机算法</h4><ul>\n<li><p>属于结构化预测问题，例如机器翻译、序列标注等，预测结果诸如是一个序列、一颗树啊等等。此类算法往往在训练的时候，就需要做预测的工作。</p>\n</li>\n<li><p>定义得分函数$score(x,y) = w.\\phi(x, y)$，其中$\\phi(x,y)$就是特征函数，则$\\hat{y} = argmax \\ {score(x,y)}$</p>\n</li>\n<li><p>模型属于判别模型，因为最终归一化后，其实还是条件概率$p(y|x) = \\frac{exp(score(x,y))}{\\sum_{y}{exp(score{(x,y))}}}$，其Loss Function是</p>\n<script type=\"math/tex; mode=display\">\nL(w) = max_{y}(score(x,y)) - score(x, y) \\\\\n\\frac{\\delta{L(w)}}{\\delta{w}} = \\phi(x,\\hat{y}) - \\phi(x, y)</script></li>\n<li><p>模型训练：对于每一个训练样本，先预测$\\hat{y} = argmax \\ w.\\phi(x, y)$，然后对于正确的y进行奖励，对于错误的预测$\\hat{y}$，进行惩罚，最终w的更新公式为</p>\n<script type=\"math/tex; mode=display\">\nw = w + \\phi(x, y) - \\phi(x, \\hat{y})</script></li>\n<li><p>模型预测：同样是维特比译码。</p>\n</li>\n<li><p>特征提取问题：</p>\n<ul>\n<li><p>特征函数取值0或1 ，一般分为两类：</p>\n<ul>\n<li>转移特征，$f(y<em>{t-1}, y</em>{t})$ ，只跟状态值有关，N种状态的话，取值就只有$ N * (N+1)$，因为包含了初始状态BOS。</li>\n<li>状态特征，$f(y<em>{t}, x</em>{t})$，只跟当前隐状态值和显状态有关。</li>\n</ul>\n</li>\n<li><p>一般是基于特征模板生成所有特征，特征模块如：</p>\n<ul>\n<li><p>转移特征模板，$y_{t-1}$</p>\n</li>\n<li><p>状态特征模板，$x<em>{t-1}, x_t, x</em>{t-2}/x<em>{t-1}, x</em>{t-1}/x_{t}$</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"六、条件随机场与序列标注\"><a href=\"#六、条件随机场与序列标注\" class=\"headerlink\" title=\"六、条件随机场与序列标注\"></a>六、条件随机场与序列标注</h3><ul>\n<li><p>首先阐述概率图模型，概率图分为两种：</p>\n<ul>\n<li>有向概率图：联合概率密度$p(x,y) = \\prod{p(v | \\pi(v))}$，$\\pi(v)$表示v的所有前驱节点</li>\n<li>无向概率图：联合概率密度可以分解为所有最大团的某种函数之乘积，所谓最大团，就是团内每个节点互相连接。还可以定义虚拟的因子节点，因子节点只连接两个相邻节点，组成最小的最大团，那么联合概率密度就是所有因子节点之积：</li>\n</ul>\n<script type=\"math/tex; mode=display\">\np(x,y)=\\frac{1}{Z}\\prod_{a}{\\phi_{a}{(x_a, y_a})}</script><p>这样的话，</p>\n<script type=\"math/tex; mode=display\">\np(y|x)=\\frac{1}{Z(x)}\\prod_{a}{\\phi_{a}{(x_a, y_a})}</script></li>\n<li><p>条件随机场，就是给定输入随机变量x，求解条件概率$p(y|x)$的概率无向图。用于序列标注时，就是线性链条件随机场：</p>\n<p>​                                                 <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gh3p0sm96tj30r20iptbs.jpg\" alt=\"image-20200726004025174\" style=\"zoom:50%;\"></p>\n</li>\n<li><p>如果用虚拟因子的话，显然就只有两类因子：</p>\n<ul>\n<li>转移因子，发生在$y<em>t$和$y</em>{t-1}$之间，即转移特征函数</li>\n<li>状态因子，发生在$y_t$和$x_t$之间，即状态特征函数</li>\n</ul>\n</li>\n<li><p>如果某种函数定义为$w.\\phi(y<em>t,y</em>{t-1},x_t)$之后，其实就和结构化感知机一模一样了：</p>\n<script type=\"math/tex; mode=display\">\np(y|x)=\\frac{1}{Z(x)}exp(\\sum{w.\\phi(y_t,y_{t-1},x_t)})</script></li>\n<li><p>条件随机场的预测：</p>\n<ul>\n<li>和结构化感知机一样，都是维特比译码</li>\n</ul>\n</li>\n<li><p>条件随机场的训练：</p>\n<ul>\n<li><p>训练和结构化感知机不一样，因为条件随机场的Loss Function为最大似然概率，即也相当于最大(相对)熵：</p>\n<script type=\"math/tex; mode=display\">\nL(w)=log(\\prod{p(y|x)^{\\hat{p}(x,y)}}) = \\sum_{x,y}{\\hat{p}(x,y)log(p(y|x))} = \\sum_{i=1}^{N}{p(y^{(i)}|x^{(i)})}</script></li>\n<li><p>利用梯度下降法求解的话，w参数更新公式(和结构化感知机最大的区别就在这里)：</p>\n<script type=\"math/tex; mode=display\">\nw = w + \\phi(x, y) - E_w[\\phi(x, y)]</script></li>\n</ul>\n</li>\n</ul>\n<pre><code>- 感知机仅惩罚错得最厉害的哪一个$\\hat{y}$对应的特征函数$\\phi(x,\\hat{y})$\n- 条件随机场惩罚所有答案，总惩罚量依然为1，但是所有答案分摊，而当特征函数的经验分布期望和模型期望一致的时候，梯度为0，不需要再更新。\n</code></pre><ul>\n<li>条件随机场其实就是最大熵模型的衍生~可以看我之前的有关最大熵模型的博文。</li>\n</ul>\n<h3 id=\"七、词性标注\"><a href=\"#七、词性标注\" class=\"headerlink\" title=\"七、词性标注\"></a>七、词性标注</h3><p>本质上也是一个序列标注模型，标注方式有两种：</p>\n<ul>\n<li>独立模型：先进行分词任务，再进行词性标注任务，流水线。</li>\n<li>联合模型：将分词任务和词性任务联合，标注集例如{B-名词，M-名词}等。<ul>\n<li>优点：联合模型几乎在所有问题上优于独立模型。</li>\n<li>缺点：很难有同时标注分词和词性的优秀语料库，一般而言中分分词语料库远多于词性标注语料库；还有就是，联合模型的标注集很大，导致特征数量也很大，参数爆炸。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"八、命名实体识别\"><a href=\"#八、命名实体识别\" class=\"headerlink\" title=\"八、命名实体识别\"></a>八、命名实体识别</h3><ul>\n<li>同样是个序列标注模型，标注集{BMES-实体，O}。但命名实体识别任务，往往可以统计为主、规则为辅。</li>\n<li>对于规则较强的命名实体，例如网址、E-mail、ISBN、商品编号等，完全可以通过正则表达式先进行预处理提取，再分词统计</li>\n<li>对于较短的命名实体，例如人名，完全可以通过先分词，再词性标注即可。</li>\n<li>HanLP对于一些命名实体是用规则来做的：<ul>\n<li>音译人名</li>\n<li>日本人名</li>\n<li>数词英文实体：这个被称为原子分词，这个代码非常值得学习。</li>\n</ul>\n</li>\n<li><strong>自定义领域的命名实体识别任务</strong><ul>\n<li>Step 1：收集生语料</li>\n<li>Step 2：可以先利用HanLP的词法分析器，得到分词和词性标注结果</li>\n<li>Step 3：基于词法分析结果，人工标注你想要的实体，生成熟语料</li>\n<li>Step 4：训练序列标注模型</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"九、信息抽取\"><a href=\"#九、信息抽取\" class=\"headerlink\" title=\"九、信息抽取\"></a>九、信息抽取</h3><p>所介绍的都是无监督算法。</p>\n<h4 id=\"新词提取\"><a href=\"#新词提取\" class=\"headerlink\" title=\"新词提取\"></a>新词提取</h4><p>从文章中发现新的词汇，信息熵算法：</p>\n<ul>\n<li>如果一个字符串左边和右边的搭配很丰富，并且字符串本身的字符搭配很固定，这大概率就是个词汇。</li>\n<li>信息熵：计算某个字符串左边和右边单个字符的信息熵，设定信息熵&gt;=某个阈值</li>\n<li>互信息：计算该字符串内部的所有字符之间的互信息，互信息大，说明字符都是相关的，设定互信息&gt;=某个阈值</li>\n<li>取符合上诉要求的词频Top N字符串。</li>\n</ul>\n<h4 id=\"短语提取\"><a href=\"#短语提取\" class=\"headerlink\" title=\"短语提取\"></a>短语提取</h4><p>与新词提取相同，只是需要先进行分词，然后把：</p>\n<ul>\n<li>字符串 -&gt; 单词列表</li>\n<li>左右的单个字符 -&gt; 单个单词</li>\n</ul>\n<h4 id=\"关键词提取\"><a href=\"#关键词提取\" class=\"headerlink\" title=\"关键词提取\"></a>关键词提取</h4><ul>\n<li>Top N词频</li>\n<li>Top N TF-IDF ：单词在本文档的词频 / 单词出现在所有文档的次数</li>\n<li>TextRank：类似pageRank，基于网站之间的链接生成图，然后每个节点的权重取决于指向该节点的所有子节点，但是其他子节点的权重计算的时候会因为它指向的节点个数而减少。权重逐步迭代，最终稳定。而文本的话，就是用滑动窗口，中间单词和附近单词产生链接。</li>\n</ul>\n<h4 id=\"关键句提取\"><a href=\"#关键句提取\" class=\"headerlink\" title=\"关键句提取\"></a>关键句提取</h4><p>类似关键词提取，但有个TF-IDF的变种-BM25。</p>\n<h3 id=\"十、文本聚类\"><a href=\"#十、文本聚类\" class=\"headerlink\" title=\"十、文本聚类\"></a>十、文本聚类</h3><h4 id=\"生成文档向量\"><a href=\"#生成文档向量\" class=\"headerlink\" title=\"生成文档向量\"></a>生成文档向量</h4><ul>\n<li>词袋模型：说白了就类似one-hot，只是值换为词频。</li>\n<li>布尔词频：就是one-hot</li>\n<li>TF-IDF：就值换为tf-idf值</li>\n<li>词向量：word2vec，然后所有词向量求和</li>\n<li>自编码器：输入时词袋，文档向量就是中间的隐层向量</li>\n</ul>\n<h4 id=\"聚类算法\"><a href=\"#聚类算法\" class=\"headerlink\" title=\"聚类算法\"></a>聚类算法</h4><p>K-means算法，但是k-means有非常多的改进方法：</p>\n<ul>\n<li>朴素k-means: <ul>\n<li>随机选取k个初始质心 -&gt; 分配簇 -&gt; 重新计算质心 -&gt; 重复</li>\n<li>初始质心选取改进：先选取一个质心，然后再选取一个其他的点，如果其和最近质心的距离能够减小准则函数，再将其变为质心，以此类推，每一步都保证了准则函数的减小。</li>\n</ul>\n</li>\n<li>更快的准则函数：将欧式距离改为余弦距离：<ul>\n<li>随机选取k个初始质心 -&gt; 分配簇 -&gt; 对每个点，计算将其移入另一个簇时准则函数的增量，找出最大量并移动 -&gt; 重复</li>\n</ul>\n</li>\n<li>层次聚类：刚开始一个簇，然后k-means分成两个，以此类推，保证二分后准则函数的gain增大，可以自动判断聚类个数。</li>\n</ul>\n<h3 id=\"十一、文本分类\"><a href=\"#十一、文本分类\" class=\"headerlink\" title=\"十一、文本分类\"></a>十一、文本分类</h3><p>大致思想也很简单：</p>\n<ul>\n<li><p>分词，提取单词；这一步并非必须，清华有个研究表明，直接提取所有相邻的n元字符，效果更好。</p>\n</li>\n<li><p>提取特征：词袋向量。缺点是无法表征词语之间顺序，如“不 优秀” 和 “优秀 不”。</p>\n</li>\n<li>特征筛选：利用卡方校验判断特征与类别之间的独立性，其实思想比较类似IV值。</li>\n<li>分类模型：朴素贝叶斯、SVM等</li>\n</ul>\n<h3 id=\"十二、依存句法分析\"><a href=\"#十二、依存句法分析\" class=\"headerlink\" title=\"十二、依存句法分析\"></a>十二、依存句法分析</h3><p>在词法分析之后，语法分析是NLP的重要一环，也是较为高级、较为复杂的一种任务。</p>\n<h4 id=\"短语结构树\"><a href=\"#短语结构树\" class=\"headerlink\" title=\"短语结构树\"></a>短语结构树</h4><ul>\n<li><p>上下文无关语法/短语结构语法：句子通过语法结构生成。比如上海+名词短语 -&gt; 上海 + 浦东 + 名词短语 -&gt; 上海 + 浦东 + 机场 + 航站楼。</p>\n</li>\n<li><p>短语结构树：短语结构语法描述如何自顶而下生成一个句子，句子也可以通过短语结构语法来递归分解，最终生成一颗树结构。</p>\n</li>\n<li><p>英文树库：宾州树库PTB，中文树库：CTB。词性标注集：CTB。</p>\n</li>\n<li><p>20世纪90年代大部分句法分析都集中在短语结构树，由于其较为复杂，准确率并不高</p>\n</li>\n</ul>\n<h4 id=\"依存句法树\"><a href=\"#依存句法树\" class=\"headerlink\" title=\"依存句法树\"></a>依存句法树</h4><ul>\n<li>词与词之间存在主从关系，如果一个词修饰另一个词，那么称修饰词为从属词，被修饰词为支配词，两者之间的语法关系称为依存关系。比如 “大梦想”中 ，“大” 修饰 “梦想”，定中关系。</li>\n<li>依存句法树4个公理：<ul>\n<li>有且只有一个root虚拟根节点，不依存其他词语</li>\n<li>除此外所有单词必须依存于其他单词</li>\n<li>每个单词不能依存多个单词</li>\n<li>如果单词A依存B，那么位置处于A和B之间的单词C只能依存于A、B或AB之间的单词</li>\n</ul>\n</li>\n<li>开源自由的依存树库：UD(Universal Dependencies)，树库格式为CoNLL-U；CTB语料库，可以从短语结构树转化为依存句法树。</li>\n<li>输入是词语和词性，输出是一颗依存句法树，算法有两类：<ul>\n<li>基于图的依存句法分析：提取特征，为每条边是否属于句法树的可能性打分，然后用最大生成树作为依存句法树。缺点：开销很大</li>\n<li>基于转移的依存句法分析：将树的构建过程拆分为一系列转移动作，所以只需利用自己的状态和输入单词来预测下一步要执行的转移动作，最后根据动作拼接依存句法树。<ul>\n<li>Arc-Eager转移系统：定义状态集合和转移动作</li>\n<li>训练：结构化感知机</li>\n<li>预测：柱搜索。全局最优转移路径理论上可以通过一些动态规划(如维特比)一样来实行，但是路径过长、分支过多，在计算上不可行，因此用柱搜索：每个时刻仅仅维护分数最高的前k条子路径，k又称柱宽。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"十三、深度学习与自然语言处理\"><a href=\"#十三、深度学习与自然语言处理\" class=\"headerlink\" title=\"十三、深度学习与自然语言处理\"></a>十三、深度学习与自然语言处理</h3><h4 id=\"传统方法的局限\"><a href=\"#传统方法的局限\" class=\"headerlink\" title=\"传统方法的局限\"></a>传统方法的局限</h4><ul>\n<li>数据稀疏，无穷多的单词，one-hot编码维度巨高且稀疏  -&gt; 深度神经网络将其化为稠密向量，相似度也会体现出来</li>\n<li>特征模板，需要自己设计，且特征非常稀疏  -&gt;  深度神经网络利用多层感知器特征交叉，自动提取特征表示。</li>\n<li>误差传播，例如情感分析任务：先分词、再词性标注、再SVM，多个模型的误差传播 -&gt; 深度神经网络，直接输入字符的one-hot向量，输出分类结果，端到端</li>\n</ul>\n<h4 id=\"Word2Vec\"><a href=\"#Word2Vec\" class=\"headerlink\" title=\"Word2Vec\"></a>Word2Vec</h4><ul>\n<li>CBOW：输入：上下文，输出：中心词</li>\n<li>Skip-Gram：输入：中心词，输出：上下文</li>\n<li>更详细的介绍，可以看我之前的博客<a href=\"https://levylv.github.io/2019/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/word2vec%E8%AF%A6%E8%A7%A3/\" target=\"_blank\" rel=\"noopener\">word2vec详解</a></li>\n</ul>\n<h4 id=\"自然语言处理进阶\"><a href=\"#自然语言处理进阶\" class=\"headerlink\" title=\"自然语言处理进阶\"></a>自然语言处理进阶</h4><ul>\n<li><p>两个常用的特征提取器：RNN和CNN</p>\n<ul>\n<li>RNN，可以处理变长的输入，适合文本。特别是LSTM，可以记忆约200左右的单词。缺陷在于难以并行化。如果句子相对较短，所以在句子颗粒度上进行的基础NLP任务(中文分词、词性标注、命名实体识别和句法分析)经常用RNN</li>\n<li>CNN，可以捕捉文本中的n元语法，可以并行化，考虑到文档一般较长，许多文档分类模型都是用CNN。</li>\n</ul>\n</li>\n<li><p>词向量的研究：</p>\n<ul>\n<li>Fackbook-fastText，可以得到任意词语的向量，不要求词语一定出现在语料库</li>\n<li>ELMO，解决一词多义，需要读入上文才才可以预测当前单词的词向量</li>\n<li>Google BERT模型通过一种高效的双向transformer网络同时对上下文建模</li>\n<li>基于线性模型的标注器被BiLSTM-CRF等取代<ul>\n<li>其实BiILSTM+CRF模型的话，就是用BiLSTM来提取状态特征f(xi, yi)，用CRF只提取转移特征。</li>\n</ul>\n</li>\n<li>句法分析器-BiAffineAttention</li>\n<li>QA任务，归结为衡量问题和备选答案之前的文本相似度，恰好是具备注意力机制的神经网络擅长的。</li>\n<li>文档摘要涉及的文本生成技术，恰好是RNN擅长的。</li>\n<li>机器翻译领域，Google早已利用基于神经网络的机器翻译技术。学术界目前流行的趋势是Transformer和注意力机制提取特征。</li>\n</ul>\n</li>\n</ul>\n"},{"title":"理解LSI、PLSI、LDA和LFM","date":"2020-04-24T16:00:00.000Z","_content":"\n","source":"_posts/自然语言处理/理解LSI、PLSI、LDA和LFM.md","raw":"---\ntitle: 理解LSI、PLSI、LDA和LFM\ndate: 2020-04-25 \ntags: word2vec\ncategories: [自然语言处理]\n---\n\n","slug":"自然语言处理/理解LSI、PLSI、LDA和LFM","published":1,"updated":"2022-09-15T03:46:43.368Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551p5003yjqrrdecgl277","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script>","site":{"data":{}},"excerpt":"","more":""},{"title":"Databus学习笔记","date":"2020-11-09T16:00:00.000Z","_content":"\n\n\nDatabus是一个低延迟、可靠的、支持事务的、保持一致性的数据变更抓取系统。\n\n\n\n这块我也只是大概了解了一下，本质上想要解决的问题是：如果有一个mysql存储和一个redis缓存，mysql的变更要同步到redis里，为了保持数据的一致性，中间就加了一个databus。\n\n\n\n图片解释：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkeg24rtjj30ju0fu0tu.jpg\" alt=\"image-20201110213021835\" style=\"zoom:50%;\" />\n\n变为：\n\n​              \t\t\t\t\t\t\t\t\t\t\t<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkeh2sv7ej30jy0ug3z9.jpg\" alt=\"image-20201110213058927\" style=\"zoom:50%;\"                  />\n\n​       ","source":"_posts/大数据/Databus/Databus学习笔记.md","raw":"---\ntitle: Databus学习笔记\ndate: 2020-11-10\ncategories: [大数据,Databus]\n\n---\n\n\n\nDatabus是一个低延迟、可靠的、支持事务的、保持一致性的数据变更抓取系统。\n\n\n\n这块我也只是大概了解了一下，本质上想要解决的问题是：如果有一个mysql存储和一个redis缓存，mysql的变更要同步到redis里，为了保持数据的一致性，中间就加了一个databus。\n\n\n\n图片解释：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkeg24rtjj30ju0fu0tu.jpg\" alt=\"image-20201110213021835\" style=\"zoom:50%;\" />\n\n变为：\n\n​              \t\t\t\t\t\t\t\t\t\t\t<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkeh2sv7ej30jy0ug3z9.jpg\" alt=\"image-20201110213058927\" style=\"zoom:50%;\"                  />\n\n​       ","slug":"大数据/Databus/Databus学习笔记","published":1,"updated":"2022-09-15T03:46:43.359Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qa005kjqrrvbomas32","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>Databus是一个低延迟、可靠的、支持事务的、保持一致性的数据变更抓取系统。</p>\n<p>这块我也只是大概了解了一下，本质上想要解决的问题是：如果有一个mysql存储和一个redis缓存，mysql的变更要同步到redis里，为了保持数据的一致性，中间就加了一个databus。</p>\n<p>图片解释：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkeg24rtjj30ju0fu0tu.jpg\" alt=\"image-20201110213021835\" style=\"zoom:50%;\"></p>\n<p>变为：</p>\n<p>​                                                          <img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkeh2sv7ej30jy0ug3z9.jpg\" alt=\"image-20201110213058927\" style=\"zoom:50%;\"></p>\n<p>​       </p>\n","site":{"data":{}},"excerpt":"","more":"<p>Databus是一个低延迟、可靠的、支持事务的、保持一致性的数据变更抓取系统。</p>\n<p>这块我也只是大概了解了一下，本质上想要解决的问题是：如果有一个mysql存储和一个redis缓存，mysql的变更要同步到redis里，为了保持数据的一致性，中间就加了一个databus。</p>\n<p>图片解释：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkeg24rtjj30ju0fu0tu.jpg\" alt=\"image-20201110213021835\" style=\"zoom:50%;\"></p>\n<p>变为：</p>\n<p>​                                                          <img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkeh2sv7ej30jy0ug3z9.jpg\" alt=\"image-20201110213058927\" style=\"zoom:50%;\"></p>\n<p>​       </p>\n"},{"title":"hdfs文件理解","date":"2020-11-09T16:00:00.000Z","_content":"\n\n\nHDFS是一个分布式的文件系统，利用集群来存储海量数据。hdfs路径是一个虚拟节点，下面的多个文件可能放在多台机器上，具体放在哪台机器等信息由name node节点维护。\n\n","source":"_posts/大数据/Hive/hdfs文件理解.md","raw":"---\ntitle: hdfs文件理解\ndate: 2020-11-10\ncategories: [大数据,Hive]\n---\n\n\n\nHDFS是一个分布式的文件系统，利用集群来存储海量数据。hdfs路径是一个虚拟节点，下面的多个文件可能放在多台机器上，具体放在哪台机器等信息由name node节点维护。\n\n","slug":"大数据/Hive/hdfs文件理解","published":1,"updated":"2022-09-15T03:46:43.359Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qb005ljqrrj3otbs91","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>HDFS是一个分布式的文件系统，利用集群来存储海量数据。hdfs路径是一个虚拟节点，下面的多个文件可能放在多台机器上，具体放在哪台机器等信息由name node节点维护。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>HDFS是一个分布式的文件系统，利用集群来存储海量数据。hdfs路径是一个虚拟节点，下面的多个文件可能放在多台机器上，具体放在哪台机器等信息由name node节点维护。</p>\n"},{"title":"hive建表时的format","date":"2018-05-30T10:13:30.000Z","_content":"\nhive建表时有三种指定，举例如下：\n\n- ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.orc.OrcSerde'\n- STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat'\n- OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat'\n\n \n\n对于第一种指定row format delimited，是指hive读取数据文件时的分隔符，用来划分字段，默认分隔符是'\\001'。加入serde的话，是指定序列化和反序列化的一些规则，这个我就不深究了。。\n\n \n\n对于第二种指定store as inputformat，就是hive加载数据时，对数据文件的处理，这里可以自定义一些方法，比如原来的数据文本分隔符是'|'，我的表指定的是'\\t'，那么可以自定义方法进行正则化处理。\n\n \n\n同理对于第三种指定output，就是hive输出数据时，对数据文件的处理，也可以自定义一些方法。这里注意，输入和输出的数据文件是统一的。\n\n \n\n值得注意的是，无论指定何种分隔符，hive -e \"select * from table \" > x，x文件的分隔符都是'\\t'(因为hive环境中的字段是以\\t分割的，hive环境和数据文件类似于映射的关系，如果是beeline那就是|)，在excel中打开都是一格（excel需要以逗号分割csv）。如果想要以指定分隔符生成x，那么可以\n\n```sql\ninsert overwirt local directory x\n\nrow format delimited fields terminated by '分隔符'\n\nselect * from *\n```\n\n\n\n﻿**那么对于上述举例中的三种指定，含义就是将数据文件转化为了一种更高效，压缩更好的orc文件，这个数据文件我用cat查看了一下是乱码的。。**\n\n \n\n最后总结一下 平时建表的一些规范：\n\n- 如果这个表纯粹是各个数据表之间的处理，那么建议写成举例形式，orc文件毕竟高效。\n- 如果这个表是从外部生成数据导入，例如python处理后生成数据导入，那么生成表是要指定分隔符： ROW FORMAT DELIMITED FIELDS TERMINATED BY '分隔符'，下面两种指定不加。\n\n ","source":"_posts/大数据/Hive/hive建表时的format.md","raw":"---\ntitle: hive建表时的format\ndate: 2018-05-30 18:13:30\ncategories: [大数据,Hive]\n---\n\nhive建表时有三种指定，举例如下：\n\n- ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.orc.OrcSerde'\n- STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat'\n- OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat'\n\n \n\n对于第一种指定row format delimited，是指hive读取数据文件时的分隔符，用来划分字段，默认分隔符是'\\001'。加入serde的话，是指定序列化和反序列化的一些规则，这个我就不深究了。。\n\n \n\n对于第二种指定store as inputformat，就是hive加载数据时，对数据文件的处理，这里可以自定义一些方法，比如原来的数据文本分隔符是'|'，我的表指定的是'\\t'，那么可以自定义方法进行正则化处理。\n\n \n\n同理对于第三种指定output，就是hive输出数据时，对数据文件的处理，也可以自定义一些方法。这里注意，输入和输出的数据文件是统一的。\n\n \n\n值得注意的是，无论指定何种分隔符，hive -e \"select * from table \" > x，x文件的分隔符都是'\\t'(因为hive环境中的字段是以\\t分割的，hive环境和数据文件类似于映射的关系，如果是beeline那就是|)，在excel中打开都是一格（excel需要以逗号分割csv）。如果想要以指定分隔符生成x，那么可以\n\n```sql\ninsert overwirt local directory x\n\nrow format delimited fields terminated by '分隔符'\n\nselect * from *\n```\n\n\n\n﻿**那么对于上述举例中的三种指定，含义就是将数据文件转化为了一种更高效，压缩更好的orc文件，这个数据文件我用cat查看了一下是乱码的。。**\n\n \n\n最后总结一下 平时建表的一些规范：\n\n- 如果这个表纯粹是各个数据表之间的处理，那么建议写成举例形式，orc文件毕竟高效。\n- 如果这个表是从外部生成数据导入，例如python处理后生成数据导入，那么生成表是要指定分隔符： ROW FORMAT DELIMITED FIELDS TERMINATED BY '分隔符'，下面两种指定不加。\n\n ","slug":"大数据/Hive/hive建表时的format","published":1,"updated":"2022-09-15T03:46:43.359Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qd005njqrrdlbkjz7u","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>hive建表时有三种指定，举例如下：</p>\n<ul>\n<li>ROW FORMAT SERDE ‘org.apache.hadoop.hive.ql.io.orc.OrcSerde’</li>\n<li>STORED AS INPUTFORMAT ‘org.apache.hadoop.hive.ql.io.orc.OrcInputFormat’</li>\n<li>OUTPUTFORMAT ‘org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat’</li>\n</ul>\n<p>对于第一种指定row format delimited，是指hive读取数据文件时的分隔符，用来划分字段，默认分隔符是’\\001’。加入serde的话，是指定序列化和反序列化的一些规则，这个我就不深究了。。</p>\n<p>对于第二种指定store as inputformat，就是hive加载数据时，对数据文件的处理，这里可以自定义一些方法，比如原来的数据文本分隔符是’|’，我的表指定的是’\\t’，那么可以自定义方法进行正则化处理。</p>\n<p>同理对于第三种指定output，就是hive输出数据时，对数据文件的处理，也可以自定义一些方法。这里注意，输入和输出的数据文件是统一的。</p>\n<p>值得注意的是，无论指定何种分隔符，hive -e “select * from table “ &gt; x，x文件的分隔符都是’\\t’(因为hive环境中的字段是以\\t分割的，hive环境和数据文件类似于映射的关系，如果是beeline那就是|)，在excel中打开都是一格（excel需要以逗号分割csv）。如果想要以指定分隔符生成x，那么可以</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">insert</span> overwirt <span class=\"keyword\">local</span> <span class=\"keyword\">directory</span> x</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">row</span> <span class=\"keyword\">format</span> <span class=\"keyword\">delimited</span> <span class=\"keyword\">fields</span> <span class=\"keyword\">terminated</span> <span class=\"keyword\">by</span> <span class=\"string\">'分隔符'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> *</span><br></pre></td></tr></table></figure>\n<p>﻿<strong>那么对于上述举例中的三种指定，含义就是将数据文件转化为了一种更高效，压缩更好的orc文件，这个数据文件我用cat查看了一下是乱码的。。</strong></p>\n<p>最后总结一下 平时建表的一些规范：</p>\n<ul>\n<li>如果这个表纯粹是各个数据表之间的处理，那么建议写成举例形式，orc文件毕竟高效。</li>\n<li>如果这个表是从外部生成数据导入，例如python处理后生成数据导入，那么生成表是要指定分隔符： ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘分隔符’，下面两种指定不加。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>hive建表时有三种指定，举例如下：</p>\n<ul>\n<li>ROW FORMAT SERDE ‘org.apache.hadoop.hive.ql.io.orc.OrcSerde’</li>\n<li>STORED AS INPUTFORMAT ‘org.apache.hadoop.hive.ql.io.orc.OrcInputFormat’</li>\n<li>OUTPUTFORMAT ‘org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat’</li>\n</ul>\n<p>对于第一种指定row format delimited，是指hive读取数据文件时的分隔符，用来划分字段，默认分隔符是’\\001’。加入serde的话，是指定序列化和反序列化的一些规则，这个我就不深究了。。</p>\n<p>对于第二种指定store as inputformat，就是hive加载数据时，对数据文件的处理，这里可以自定义一些方法，比如原来的数据文本分隔符是’|’，我的表指定的是’\\t’，那么可以自定义方法进行正则化处理。</p>\n<p>同理对于第三种指定output，就是hive输出数据时，对数据文件的处理，也可以自定义一些方法。这里注意，输入和输出的数据文件是统一的。</p>\n<p>值得注意的是，无论指定何种分隔符，hive -e “select * from table “ &gt; x，x文件的分隔符都是’\\t’(因为hive环境中的字段是以\\t分割的，hive环境和数据文件类似于映射的关系，如果是beeline那就是|)，在excel中打开都是一格（excel需要以逗号分割csv）。如果想要以指定分隔符生成x，那么可以</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">insert</span> overwirt <span class=\"keyword\">local</span> <span class=\"keyword\">directory</span> x</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">row</span> <span class=\"keyword\">format</span> <span class=\"keyword\">delimited</span> <span class=\"keyword\">fields</span> <span class=\"keyword\">terminated</span> <span class=\"keyword\">by</span> <span class=\"string\">'分隔符'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> *</span><br></pre></td></tr></table></figure>\n<p>﻿<strong>那么对于上述举例中的三种指定，含义就是将数据文件转化为了一种更高效，压缩更好的orc文件，这个数据文件我用cat查看了一下是乱码的。。</strong></p>\n<p>最后总结一下 平时建表的一些规范：</p>\n<ul>\n<li>如果这个表纯粹是各个数据表之间的处理，那么建议写成举例形式，orc文件毕竟高效。</li>\n<li>如果这个表是从外部生成数据导入，例如python处理后生成数据导入，那么生成表是要指定分隔符： ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘分隔符’，下面两种指定不加。</li>\n</ul>\n"},{"title":"Flink学习笔记","date":"2020-11-09T16:00:00.000Z","_content":"\n\n\n### 基本概念\n\nFlink是一个分布式的流式数据处理框架，目前很多公司都开始用flink来处理流式任务（对，说的就是我司）。在Flink之前，其实我们已经有spark streaming和storm来处理流式任务，为何还要flink？下面就说吞吐量和时延上说下flink的优势，主要讲一下基本原理和容错机制。\n\n\n\n### 流框架\n\n- Naive streaming： storm和flink都是naive streaming处理，这类引擎中所有的data在到来的时候就会被立即处理，一条接着一条（HINT： 狭隘的来说是一条接着一条，但流引擎有时会为提高性能缓存一小部分data然后一次性处理）。\n- Micro-batch：spark streaming是批处理的。数据流被切分为一个一个小的批次， 然后再逐个被引擎处理。这些batch一般是以时间为单位进行切分，单位一般是‘秒‘。\n\n显然， storm和flink因为是naive streaming，他们的时延性能要远远优于spark streaming。\n\n- spark streaming：秒级别\n- storm：几十毫秒级别\n- flink：百毫秒级别\n\n但相对的，吞吐量上spark streaming是最大的。\n\n\n\n### 容错机制（Fault Tolerance）\n\n先讲下三个性质：\n\n- **at-most-once**：就是说数据只发一次，成不成功都有可能。所以这种分发方式成本最低，吞吐量和时延都很好，但是数据可能丢失，可靠性不高。\n- **at-least-once**：数据如果不发送成功，就会多次重发尝试，需要发送端做处理，且接收端有ack机制。这种方式可能会造成数据的重复问题。\n- **exactly-once**： 保证数据有且只有一次，接收端要做数据的去重。\n\n####  Spark streaming\n\nspark依赖checkpoint机制来进行容错，只要batch执行到doCheckpoint操作前挂了，那么该batch就会被完整的重新计算。spark可以保证计算过程的exactly once（不包含sink的exactly once）。\t\n\n\n\n#### Storm\n\nstorm的容错通过ack机制实现，每个bolt或spout处理完成一条data后会发送一条ack消息给acker bolt。当该条data被所有节点都处理过后，它会收到来自所有节点ack， 这样一条data处理就是成功的。storm可以保证数据不丢失，但是只能达到at least once语义。此外，因为需要每条data都做ack，所以容错的开销很大。\n\n\n\n#### Flink\n\nflink使用Chandy-Chandy-Lamport Algorithm 来做Asynchronous Distributed Snapshots（异步分布式快照），其本质也是checkpoint。如下图，flink定时往流里插入一个barrier（隔栏），这些barriers把数据分割成若干个小的部分，当barrier流到某个operator时，operator立即会对barrier对应的一小部分数据做checkpoint并且把barrier传给下游（checkpoint操作是异步的，并不会打断数据的处理），直到所有的sink operator做完自己checkpoint后，一个完整的checkpoint才算完成。当出现failure时，flink会从最新完整的checkpoint点开始恢复。\n\nflink的checkpoint机制非常轻量，barrier不会打断streaming的流动，而且做checkpoint操作也是异步的。其次，相比storm需要ack每条data，flink做的是small batch的checkpoint，容错的代价相对要低很多。最重要的是flink的checkpoint机制能保证exactly once。\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkffelsbkj30y20cwgrm.jpg\" alt=\"image-20201110220420631\" style=\"zoom:50%;\" />\n\n\n\n\n\n显然，storm的容错机制需要对每条data进行ack，因此容错开销对throughputs影响巨大，throughputs下降甚至可以达到70%。\n\nflink的容错机制更加轻量，处理开销少，因此相比于storm来说，flink可以达到更大的吞吐量。\n\n\n\n### 最终性能\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkflbaoxyj30wu0f2qch.jpg\" alt=\"image-20201110221000926\" style=\"zoom:50%;\" />\n\n从吞吐量和时延性能的综合来看，flink是最好的。","source":"_posts/大数据/Flink/Flink学习笔记.md","raw":"---\ntitle: Flink学习笔记\ndate: 2020-11-10\ncategories: [大数据,Flink]\n---\n\n\n\n### 基本概念\n\nFlink是一个分布式的流式数据处理框架，目前很多公司都开始用flink来处理流式任务（对，说的就是我司）。在Flink之前，其实我们已经有spark streaming和storm来处理流式任务，为何还要flink？下面就说吞吐量和时延上说下flink的优势，主要讲一下基本原理和容错机制。\n\n\n\n### 流框架\n\n- Naive streaming： storm和flink都是naive streaming处理，这类引擎中所有的data在到来的时候就会被立即处理，一条接着一条（HINT： 狭隘的来说是一条接着一条，但流引擎有时会为提高性能缓存一小部分data然后一次性处理）。\n- Micro-batch：spark streaming是批处理的。数据流被切分为一个一个小的批次， 然后再逐个被引擎处理。这些batch一般是以时间为单位进行切分，单位一般是‘秒‘。\n\n显然， storm和flink因为是naive streaming，他们的时延性能要远远优于spark streaming。\n\n- spark streaming：秒级别\n- storm：几十毫秒级别\n- flink：百毫秒级别\n\n但相对的，吞吐量上spark streaming是最大的。\n\n\n\n### 容错机制（Fault Tolerance）\n\n先讲下三个性质：\n\n- **at-most-once**：就是说数据只发一次，成不成功都有可能。所以这种分发方式成本最低，吞吐量和时延都很好，但是数据可能丢失，可靠性不高。\n- **at-least-once**：数据如果不发送成功，就会多次重发尝试，需要发送端做处理，且接收端有ack机制。这种方式可能会造成数据的重复问题。\n- **exactly-once**： 保证数据有且只有一次，接收端要做数据的去重。\n\n####  Spark streaming\n\nspark依赖checkpoint机制来进行容错，只要batch执行到doCheckpoint操作前挂了，那么该batch就会被完整的重新计算。spark可以保证计算过程的exactly once（不包含sink的exactly once）。\t\n\n\n\n#### Storm\n\nstorm的容错通过ack机制实现，每个bolt或spout处理完成一条data后会发送一条ack消息给acker bolt。当该条data被所有节点都处理过后，它会收到来自所有节点ack， 这样一条data处理就是成功的。storm可以保证数据不丢失，但是只能达到at least once语义。此外，因为需要每条data都做ack，所以容错的开销很大。\n\n\n\n#### Flink\n\nflink使用Chandy-Chandy-Lamport Algorithm 来做Asynchronous Distributed Snapshots（异步分布式快照），其本质也是checkpoint。如下图，flink定时往流里插入一个barrier（隔栏），这些barriers把数据分割成若干个小的部分，当barrier流到某个operator时，operator立即会对barrier对应的一小部分数据做checkpoint并且把barrier传给下游（checkpoint操作是异步的，并不会打断数据的处理），直到所有的sink operator做完自己checkpoint后，一个完整的checkpoint才算完成。当出现failure时，flink会从最新完整的checkpoint点开始恢复。\n\nflink的checkpoint机制非常轻量，barrier不会打断streaming的流动，而且做checkpoint操作也是异步的。其次，相比storm需要ack每条data，flink做的是small batch的checkpoint，容错的代价相对要低很多。最重要的是flink的checkpoint机制能保证exactly once。\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkffelsbkj30y20cwgrm.jpg\" alt=\"image-20201110220420631\" style=\"zoom:50%;\" />\n\n\n\n\n\n显然，storm的容错机制需要对每条data进行ack，因此容错开销对throughputs影响巨大，throughputs下降甚至可以达到70%。\n\nflink的容错机制更加轻量，处理开销少，因此相比于storm来说，flink可以达到更大的吞吐量。\n\n\n\n### 最终性能\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkflbaoxyj30wu0f2qch.jpg\" alt=\"image-20201110221000926\" style=\"zoom:50%;\" />\n\n从吞吐量和时延性能的综合来看，flink是最好的。","slug":"大数据/Flink/Flink学习笔记","published":1,"updated":"2022-09-15T03:46:43.359Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qe005ojqrrhnsd7ttm","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h3><p>Flink是一个分布式的流式数据处理框架，目前很多公司都开始用flink来处理流式任务（对，说的就是我司）。在Flink之前，其实我们已经有spark streaming和storm来处理流式任务，为何还要flink？下面就说吞吐量和时延上说下flink的优势，主要讲一下基本原理和容错机制。</p>\n<h3 id=\"流框架\"><a href=\"#流框架\" class=\"headerlink\" title=\"流框架\"></a>流框架</h3><ul>\n<li>Naive streaming： storm和flink都是naive streaming处理，这类引擎中所有的data在到来的时候就会被立即处理，一条接着一条（HINT： 狭隘的来说是一条接着一条，但流引擎有时会为提高性能缓存一小部分data然后一次性处理）。</li>\n<li>Micro-batch：spark streaming是批处理的。数据流被切分为一个一个小的批次， 然后再逐个被引擎处理。这些batch一般是以时间为单位进行切分，单位一般是‘秒‘。</li>\n</ul>\n<p>显然， storm和flink因为是naive streaming，他们的时延性能要远远优于spark streaming。</p>\n<ul>\n<li>spark streaming：秒级别</li>\n<li>storm：几十毫秒级别</li>\n<li>flink：百毫秒级别</li>\n</ul>\n<p>但相对的，吞吐量上spark streaming是最大的。</p>\n<h3 id=\"容错机制（Fault-Tolerance）\"><a href=\"#容错机制（Fault-Tolerance）\" class=\"headerlink\" title=\"容错机制（Fault Tolerance）\"></a>容错机制（Fault Tolerance）</h3><p>先讲下三个性质：</p>\n<ul>\n<li><strong>at-most-once</strong>：就是说数据只发一次，成不成功都有可能。所以这种分发方式成本最低，吞吐量和时延都很好，但是数据可能丢失，可靠性不高。</li>\n<li><strong>at-least-once</strong>：数据如果不发送成功，就会多次重发尝试，需要发送端做处理，且接收端有ack机制。这种方式可能会造成数据的重复问题。</li>\n<li><strong>exactly-once</strong>： 保证数据有且只有一次，接收端要做数据的去重。</li>\n</ul>\n<h4 id=\"Spark-streaming\"><a href=\"#Spark-streaming\" class=\"headerlink\" title=\"Spark streaming\"></a>Spark streaming</h4><p>spark依赖checkpoint机制来进行容错，只要batch执行到doCheckpoint操作前挂了，那么该batch就会被完整的重新计算。spark可以保证计算过程的exactly once（不包含sink的exactly once）。    </p>\n<h4 id=\"Storm\"><a href=\"#Storm\" class=\"headerlink\" title=\"Storm\"></a>Storm</h4><p>storm的容错通过ack机制实现，每个bolt或spout处理完成一条data后会发送一条ack消息给acker bolt。当该条data被所有节点都处理过后，它会收到来自所有节点ack， 这样一条data处理就是成功的。storm可以保证数据不丢失，但是只能达到at least once语义。此外，因为需要每条data都做ack，所以容错的开销很大。</p>\n<h4 id=\"Flink\"><a href=\"#Flink\" class=\"headerlink\" title=\"Flink\"></a>Flink</h4><p>flink使用Chandy-Chandy-Lamport Algorithm 来做Asynchronous Distributed Snapshots（异步分布式快照），其本质也是checkpoint。如下图，flink定时往流里插入一个barrier（隔栏），这些barriers把数据分割成若干个小的部分，当barrier流到某个operator时，operator立即会对barrier对应的一小部分数据做checkpoint并且把barrier传给下游（checkpoint操作是异步的，并不会打断数据的处理），直到所有的sink operator做完自己checkpoint后，一个完整的checkpoint才算完成。当出现failure时，flink会从最新完整的checkpoint点开始恢复。</p>\n<p>flink的checkpoint机制非常轻量，barrier不会打断streaming的流动，而且做checkpoint操作也是异步的。其次，相比storm需要ack每条data，flink做的是small batch的checkpoint，容错的代价相对要低很多。最重要的是flink的checkpoint机制能保证exactly once。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkffelsbkj30y20cwgrm.jpg\" alt=\"image-20201110220420631\" style=\"zoom:50%;\"></p>\n<p>显然，storm的容错机制需要对每条data进行ack，因此容错开销对throughputs影响巨大，throughputs下降甚至可以达到70%。</p>\n<p>flink的容错机制更加轻量，处理开销少，因此相比于storm来说，flink可以达到更大的吞吐量。</p>\n<h3 id=\"最终性能\"><a href=\"#最终性能\" class=\"headerlink\" title=\"最终性能\"></a>最终性能</h3><p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkflbaoxyj30wu0f2qch.jpg\" alt=\"image-20201110221000926\" style=\"zoom:50%;\"></p>\n<p>从吞吐量和时延性能的综合来看，flink是最好的。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h3><p>Flink是一个分布式的流式数据处理框架，目前很多公司都开始用flink来处理流式任务（对，说的就是我司）。在Flink之前，其实我们已经有spark streaming和storm来处理流式任务，为何还要flink？下面就说吞吐量和时延上说下flink的优势，主要讲一下基本原理和容错机制。</p>\n<h3 id=\"流框架\"><a href=\"#流框架\" class=\"headerlink\" title=\"流框架\"></a>流框架</h3><ul>\n<li>Naive streaming： storm和flink都是naive streaming处理，这类引擎中所有的data在到来的时候就会被立即处理，一条接着一条（HINT： 狭隘的来说是一条接着一条，但流引擎有时会为提高性能缓存一小部分data然后一次性处理）。</li>\n<li>Micro-batch：spark streaming是批处理的。数据流被切分为一个一个小的批次， 然后再逐个被引擎处理。这些batch一般是以时间为单位进行切分，单位一般是‘秒‘。</li>\n</ul>\n<p>显然， storm和flink因为是naive streaming，他们的时延性能要远远优于spark streaming。</p>\n<ul>\n<li>spark streaming：秒级别</li>\n<li>storm：几十毫秒级别</li>\n<li>flink：百毫秒级别</li>\n</ul>\n<p>但相对的，吞吐量上spark streaming是最大的。</p>\n<h3 id=\"容错机制（Fault-Tolerance）\"><a href=\"#容错机制（Fault-Tolerance）\" class=\"headerlink\" title=\"容错机制（Fault Tolerance）\"></a>容错机制（Fault Tolerance）</h3><p>先讲下三个性质：</p>\n<ul>\n<li><strong>at-most-once</strong>：就是说数据只发一次，成不成功都有可能。所以这种分发方式成本最低，吞吐量和时延都很好，但是数据可能丢失，可靠性不高。</li>\n<li><strong>at-least-once</strong>：数据如果不发送成功，就会多次重发尝试，需要发送端做处理，且接收端有ack机制。这种方式可能会造成数据的重复问题。</li>\n<li><strong>exactly-once</strong>： 保证数据有且只有一次，接收端要做数据的去重。</li>\n</ul>\n<h4 id=\"Spark-streaming\"><a href=\"#Spark-streaming\" class=\"headerlink\" title=\"Spark streaming\"></a>Spark streaming</h4><p>spark依赖checkpoint机制来进行容错，只要batch执行到doCheckpoint操作前挂了，那么该batch就会被完整的重新计算。spark可以保证计算过程的exactly once（不包含sink的exactly once）。    </p>\n<h4 id=\"Storm\"><a href=\"#Storm\" class=\"headerlink\" title=\"Storm\"></a>Storm</h4><p>storm的容错通过ack机制实现，每个bolt或spout处理完成一条data后会发送一条ack消息给acker bolt。当该条data被所有节点都处理过后，它会收到来自所有节点ack， 这样一条data处理就是成功的。storm可以保证数据不丢失，但是只能达到at least once语义。此外，因为需要每条data都做ack，所以容错的开销很大。</p>\n<h4 id=\"Flink\"><a href=\"#Flink\" class=\"headerlink\" title=\"Flink\"></a>Flink</h4><p>flink使用Chandy-Chandy-Lamport Algorithm 来做Asynchronous Distributed Snapshots（异步分布式快照），其本质也是checkpoint。如下图，flink定时往流里插入一个barrier（隔栏），这些barriers把数据分割成若干个小的部分，当barrier流到某个operator时，operator立即会对barrier对应的一小部分数据做checkpoint并且把barrier传给下游（checkpoint操作是异步的，并不会打断数据的处理），直到所有的sink operator做完自己checkpoint后，一个完整的checkpoint才算完成。当出现failure时，flink会从最新完整的checkpoint点开始恢复。</p>\n<p>flink的checkpoint机制非常轻量，barrier不会打断streaming的流动，而且做checkpoint操作也是异步的。其次，相比storm需要ack每条data，flink做的是small batch的checkpoint，容错的代价相对要低很多。最重要的是flink的checkpoint机制能保证exactly once。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkffelsbkj30y20cwgrm.jpg\" alt=\"image-20201110220420631\" style=\"zoom:50%;\"></p>\n<p>显然，storm的容错机制需要对每条data进行ack，因此容错开销对throughputs影响巨大，throughputs下降甚至可以达到70%。</p>\n<p>flink的容错机制更加轻量，处理开销少，因此相比于storm来说，flink可以达到更大的吞吐量。</p>\n<h3 id=\"最终性能\"><a href=\"#最终性能\" class=\"headerlink\" title=\"最终性能\"></a>最终性能</h3><p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkflbaoxyj30wu0f2qch.jpg\" alt=\"image-20201110221000926\" style=\"zoom:50%;\"></p>\n<p>从吞吐量和时延性能的综合来看，flink是最好的。</p>\n"},{"title":"Spark学习笔记","date":"2020-11-09T16:00:00.000Z","_content":"\n\n\n### 基本概念\n\nKafka是一个分布式的发布-订阅消息传递系统，其实本质就是一个分布式的日志系统，是实时任务依赖的主流数据源。注意，数据本身同样是存储在hdfs上的。\n\n\n\n### 原理\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkdxkxgi1j30wg0ion7f.jpg\" alt=\"image-20201110211236165\" style=\"zoom:50%;\" />\n\n\n\n1、话题（Topic）：是特定类型的消息流。消息是字节的有效负载（Payload），话题是消息的分类名或种子（Feed）名；\n\n2、生产者（Producer）：是能够发布消息到话题的任何对象；\n\n3、服务代理（Broker）：一个broker就是一台机器，多台broker组成集群。\n\n4、消费者（Consumer）：可以订阅一个或多个话题，并从Broker拉数据，从而消费这些已发布的消息；\n\n\n\n### 存储\n\n理解存储最主要是理解partition的概念。其实Apache体系里partition的概念都比较类似（比如spark中的partition），都是将数据进行分片，一般分片的逻辑就比如是按照key值来划分，同一个key值分到同一个partition。\n\n\n\nKafka里也是将topic数据进行partition，当然每个partition的数据还是按照顺序写入的，然后将parition分配到不同broker上，partition数目一般设置成broker的倍数，这样能够让每个broker的partition均匀一点。\n\n\n\nkafka的partition还会备份，leader作为主要的，follower partition放在其他broker上。\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkke5hzvbgj30yw0j8jt4.jpg\" alt=\"image-20201110212007002\" style=\"zoom:50%;\" /> \n\n\n\n具体存储的日志文件形式是这样的：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkke6gpqcfj310i0j8djz.jpg\" alt=\"image-20201110212109581\" style=\"zoom:50%;\" />\n\n- 每个topic下的partition都有一个文件夹。文件夹中的文件类型有.log数据文件，.index偏移量索引文件和.timeindex时间索引文件。\n\n- 日志文件会被分为多个LogSegment文件，一般分段文件是1G。文件名字按照基准偏移量命名。\n\n  \n\n介绍下具体的三个文件：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkke9uac8cj30u00uzn7g.jpg\" alt=\"image-20201110212424025\" style=\"zoom:50%;\" />\n\n- log文件：真实的日志数据文件，存放消息payload\n- index文件：偏移量索引文件，重要的稀疏索引文件。因为如果直接去log文件里顺序查找的话，效率太低。所以现在index文件里做粗筛，定位到大致范围，然后再去log文件里找，大大提升了效率。\n- timeindex文件：时间戳索引文件的时间戳类型与日志数据文件中的时间类型是一致的，索引条目中的时间戳值及偏移量与日志数据文件中对应的字段值相同，Kafka也提供了通过时间戳索引来访问消息的方法。","source":"_posts/大数据/Kafka/Kafka学习笔记.md","raw":"---\ntitle: Spark学习笔记\ndate: 2020-11-10\ncategories: [大数据,Kafka]\n---\n\n\n\n### 基本概念\n\nKafka是一个分布式的发布-订阅消息传递系统，其实本质就是一个分布式的日志系统，是实时任务依赖的主流数据源。注意，数据本身同样是存储在hdfs上的。\n\n\n\n### 原理\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkdxkxgi1j30wg0ion7f.jpg\" alt=\"image-20201110211236165\" style=\"zoom:50%;\" />\n\n\n\n1、话题（Topic）：是特定类型的消息流。消息是字节的有效负载（Payload），话题是消息的分类名或种子（Feed）名；\n\n2、生产者（Producer）：是能够发布消息到话题的任何对象；\n\n3、服务代理（Broker）：一个broker就是一台机器，多台broker组成集群。\n\n4、消费者（Consumer）：可以订阅一个或多个话题，并从Broker拉数据，从而消费这些已发布的消息；\n\n\n\n### 存储\n\n理解存储最主要是理解partition的概念。其实Apache体系里partition的概念都比较类似（比如spark中的partition），都是将数据进行分片，一般分片的逻辑就比如是按照key值来划分，同一个key值分到同一个partition。\n\n\n\nKafka里也是将topic数据进行partition，当然每个partition的数据还是按照顺序写入的，然后将parition分配到不同broker上，partition数目一般设置成broker的倍数，这样能够让每个broker的partition均匀一点。\n\n\n\nkafka的partition还会备份，leader作为主要的，follower partition放在其他broker上。\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkke5hzvbgj30yw0j8jt4.jpg\" alt=\"image-20201110212007002\" style=\"zoom:50%;\" /> \n\n\n\n具体存储的日志文件形式是这样的：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkke6gpqcfj310i0j8djz.jpg\" alt=\"image-20201110212109581\" style=\"zoom:50%;\" />\n\n- 每个topic下的partition都有一个文件夹。文件夹中的文件类型有.log数据文件，.index偏移量索引文件和.timeindex时间索引文件。\n\n- 日志文件会被分为多个LogSegment文件，一般分段文件是1G。文件名字按照基准偏移量命名。\n\n  \n\n介绍下具体的三个文件：\n\n<img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkke9uac8cj30u00uzn7g.jpg\" alt=\"image-20201110212424025\" style=\"zoom:50%;\" />\n\n- log文件：真实的日志数据文件，存放消息payload\n- index文件：偏移量索引文件，重要的稀疏索引文件。因为如果直接去log文件里顺序查找的话，效率太低。所以现在index文件里做粗筛，定位到大致范围，然后再去log文件里找，大大提升了效率。\n- timeindex文件：时间戳索引文件的时间戳类型与日志数据文件中的时间类型是一致的，索引条目中的时间戳值及偏移量与日志数据文件中对应的字段值相同，Kafka也提供了通过时间戳索引来访问消息的方法。","slug":"大数据/Kafka/Kafka学习笔记","published":1,"updated":"2022-09-15T03:46:43.359Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qf005pjqrrja9fecpt","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h3><p>Kafka是一个分布式的发布-订阅消息传递系统，其实本质就是一个分布式的日志系统，是实时任务依赖的主流数据源。注意，数据本身同样是存储在hdfs上的。</p>\n<h3 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h3><p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkdxkxgi1j30wg0ion7f.jpg\" alt=\"image-20201110211236165\" style=\"zoom:50%;\"></p>\n<p>1、话题（Topic）：是特定类型的消息流。消息是字节的有效负载（Payload），话题是消息的分类名或种子（Feed）名；</p>\n<p>2、生产者（Producer）：是能够发布消息到话题的任何对象；</p>\n<p>3、服务代理（Broker）：一个broker就是一台机器，多台broker组成集群。</p>\n<p>4、消费者（Consumer）：可以订阅一个或多个话题，并从Broker拉数据，从而消费这些已发布的消息；</p>\n<h3 id=\"存储\"><a href=\"#存储\" class=\"headerlink\" title=\"存储\"></a>存储</h3><p>理解存储最主要是理解partition的概念。其实Apache体系里partition的概念都比较类似（比如spark中的partition），都是将数据进行分片，一般分片的逻辑就比如是按照key值来划分，同一个key值分到同一个partition。</p>\n<p>Kafka里也是将topic数据进行partition，当然每个partition的数据还是按照顺序写入的，然后将parition分配到不同broker上，partition数目一般设置成broker的倍数，这样能够让每个broker的partition均匀一点。</p>\n<p>kafka的partition还会备份，leader作为主要的，follower partition放在其他broker上。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkke5hzvbgj30yw0j8jt4.jpg\" alt=\"image-20201110212007002\" style=\"zoom:50%;\"> </p>\n<p>具体存储的日志文件形式是这样的：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkke6gpqcfj310i0j8djz.jpg\" alt=\"image-20201110212109581\" style=\"zoom:50%;\"></p>\n<ul>\n<li><p>每个topic下的partition都有一个文件夹。文件夹中的文件类型有.log数据文件，.index偏移量索引文件和.timeindex时间索引文件。</p>\n</li>\n<li><p>日志文件会被分为多个LogSegment文件，一般分段文件是1G。文件名字按照基准偏移量命名。</p>\n</li>\n</ul>\n<p>介绍下具体的三个文件：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkke9uac8cj30u00uzn7g.jpg\" alt=\"image-20201110212424025\" style=\"zoom:50%;\"></p>\n<ul>\n<li>log文件：真实的日志数据文件，存放消息payload</li>\n<li>index文件：偏移量索引文件，重要的稀疏索引文件。因为如果直接去log文件里顺序查找的话，效率太低。所以现在index文件里做粗筛，定位到大致范围，然后再去log文件里找，大大提升了效率。</li>\n<li>timeindex文件：时间戳索引文件的时间戳类型与日志数据文件中的时间类型是一致的，索引条目中的时间戳值及偏移量与日志数据文件中对应的字段值相同，Kafka也提供了通过时间戳索引来访问消息的方法。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h3><p>Kafka是一个分布式的发布-订阅消息传递系统，其实本质就是一个分布式的日志系统，是实时任务依赖的主流数据源。注意，数据本身同样是存储在hdfs上的。</p>\n<h3 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h3><p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkkdxkxgi1j30wg0ion7f.jpg\" alt=\"image-20201110211236165\" style=\"zoom:50%;\"></p>\n<p>1、话题（Topic）：是特定类型的消息流。消息是字节的有效负载（Payload），话题是消息的分类名或种子（Feed）名；</p>\n<p>2、生产者（Producer）：是能够发布消息到话题的任何对象；</p>\n<p>3、服务代理（Broker）：一个broker就是一台机器，多台broker组成集群。</p>\n<p>4、消费者（Consumer）：可以订阅一个或多个话题，并从Broker拉数据，从而消费这些已发布的消息；</p>\n<h3 id=\"存储\"><a href=\"#存储\" class=\"headerlink\" title=\"存储\"></a>存储</h3><p>理解存储最主要是理解partition的概念。其实Apache体系里partition的概念都比较类似（比如spark中的partition），都是将数据进行分片，一般分片的逻辑就比如是按照key值来划分，同一个key值分到同一个partition。</p>\n<p>Kafka里也是将topic数据进行partition，当然每个partition的数据还是按照顺序写入的，然后将parition分配到不同broker上，partition数目一般设置成broker的倍数，这样能够让每个broker的partition均匀一点。</p>\n<p>kafka的partition还会备份，leader作为主要的，follower partition放在其他broker上。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkke5hzvbgj30yw0j8jt4.jpg\" alt=\"image-20201110212007002\" style=\"zoom:50%;\"> </p>\n<p>具体存储的日志文件形式是这样的：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkke6gpqcfj310i0j8djz.jpg\" alt=\"image-20201110212109581\" style=\"zoom:50%;\"></p>\n<ul>\n<li><p>每个topic下的partition都有一个文件夹。文件夹中的文件类型有.log数据文件，.index偏移量索引文件和.timeindex时间索引文件。</p>\n</li>\n<li><p>日志文件会被分为多个LogSegment文件，一般分段文件是1G。文件名字按照基准偏移量命名。</p>\n</li>\n</ul>\n<p>介绍下具体的三个文件：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/0081Kckwly1gkke9uac8cj30u00uzn7g.jpg\" alt=\"image-20201110212424025\" style=\"zoom:50%;\"></p>\n<ul>\n<li>log文件：真实的日志数据文件，存放消息payload</li>\n<li>index文件：偏移量索引文件，重要的稀疏索引文件。因为如果直接去log文件里顺序查找的话，效率太低。所以现在index文件里做粗筛，定位到大致范围，然后再去log文件里找，大大提升了效率。</li>\n<li>timeindex文件：时间戳索引文件的时间戳类型与日志数据文件中的时间类型是一致的，索引条目中的时间戳值及偏移量与日志数据文件中对应的字段值相同，Kafka也提供了通过时间戳索引来访问消息的方法。</li>\n</ul>\n"},{"title":"Spark中的UDF","date":"2020-08-12T16:00:00.000Z","_content":"\n\n\n我们做模型想要上线，很多时候都会借助spark的udf来实现，最近在摸索这个东西，有了一点心得记录一下。\n\n\n\n### Hive/Spark SQL中的UDF\n\n这种上线方式是经常会用到的，UDF分为三种：\n\n- UDF：一进对应一出\n- UDTF：一进对应多出，经常遇到的就是比如一行数组数据分为多行，类似explode lateral view\n- UDAF：多进对应一出，就是聚合函数，类似sum()，count()\n\n\n\nUDF写完后直接在SQL中使用即可，一般写法又分为java和python两种：\n\n- Java：这种方式比较常见，引用hadoop/spark接口即可，最终形成一个jar包，可以包含多个模块，容易管理，借助maven工具也容易进行依赖管理。\n- Python：transform(..)  using(..)的方式py的好处是线下代码直接迁移，不用大改(一般模型也是用python开发巨多)，但坏处也有：\n  - 依赖py文件的问题：**py文件无法打包**，模块之间不能复用，不太容易管理。依赖的py文件需要手动add file上去。\n  - 依赖lib的问题：如果依赖第三方包，需要**自定义python环境**，然后打包上传，运行时选择自定义python环境。http://heloowird.com/2018/01/29/hive_python_udf/\n\n\n\n### Spark中的UDF\n\n对于复杂的模型，例如需要特征工程之类的，我们可能就需要直接写spark代码来实现。如果核心算法有现成的spark包，例如xgboost这种还好说，如果是自己手写实现的算法，则需要将其包装成udf来实现分布式处理。\n\nUDF也是支持是三种（这个我是基于pyspark的pandas udf来的）：\n\n- 一对一的scalar\n\n- 多对多的Grouped Map\n\n- 多对一的Grouped Aggregate\n\n  \n\n同样的，这种方式也有java(确切来讲是scala)和python两种方式：\n\n- Scala(Spark)：spark.udf.register(*)，基本原理是实现一个function，然后注册成udf。function里的计算就是普通的计算。\n- Python(Pyspark)：原理也是类似，有udf功能。更进一步的，spark 2.4.0之后提出了pandas udf，基于apache arrow，借助pandas向量计算的能力大幅提升计算性能，同时省去了py4j的序列化流程。https://www.jianshu.com/p/17117574a86b。python的坏处也和sql udf里一样，依赖问题比较蛋疼。\n\n\n\n##### 注意事项\n\n- UDF里的变量都是普通变量，不能是rdd，因为rdd是不能嵌套的，每个executor都在做udf计算，再来一个rdd，executor又得分发，这是不对的。\n- 如果想要从hdfs里获取某个文件分发给executor做udf计算，则需要在driver里先获取该文件，然后将其变为普通变量，用sc.broadcast将其分发到每个executor上。","source":"_posts/大数据/Spark/Spark中的UDF.md","raw":"---\ntitle: Spark中的UDF\ndate: 2020-08-13\ncategories: [大数据,Spark]\ntags: 模型上线\n---\n\n\n\n我们做模型想要上线，很多时候都会借助spark的udf来实现，最近在摸索这个东西，有了一点心得记录一下。\n\n\n\n### Hive/Spark SQL中的UDF\n\n这种上线方式是经常会用到的，UDF分为三种：\n\n- UDF：一进对应一出\n- UDTF：一进对应多出，经常遇到的就是比如一行数组数据分为多行，类似explode lateral view\n- UDAF：多进对应一出，就是聚合函数，类似sum()，count()\n\n\n\nUDF写完后直接在SQL中使用即可，一般写法又分为java和python两种：\n\n- Java：这种方式比较常见，引用hadoop/spark接口即可，最终形成一个jar包，可以包含多个模块，容易管理，借助maven工具也容易进行依赖管理。\n- Python：transform(..)  using(..)的方式py的好处是线下代码直接迁移，不用大改(一般模型也是用python开发巨多)，但坏处也有：\n  - 依赖py文件的问题：**py文件无法打包**，模块之间不能复用，不太容易管理。依赖的py文件需要手动add file上去。\n  - 依赖lib的问题：如果依赖第三方包，需要**自定义python环境**，然后打包上传，运行时选择自定义python环境。http://heloowird.com/2018/01/29/hive_python_udf/\n\n\n\n### Spark中的UDF\n\n对于复杂的模型，例如需要特征工程之类的，我们可能就需要直接写spark代码来实现。如果核心算法有现成的spark包，例如xgboost这种还好说，如果是自己手写实现的算法，则需要将其包装成udf来实现分布式处理。\n\nUDF也是支持是三种（这个我是基于pyspark的pandas udf来的）：\n\n- 一对一的scalar\n\n- 多对多的Grouped Map\n\n- 多对一的Grouped Aggregate\n\n  \n\n同样的，这种方式也有java(确切来讲是scala)和python两种方式：\n\n- Scala(Spark)：spark.udf.register(*)，基本原理是实现一个function，然后注册成udf。function里的计算就是普通的计算。\n- Python(Pyspark)：原理也是类似，有udf功能。更进一步的，spark 2.4.0之后提出了pandas udf，基于apache arrow，借助pandas向量计算的能力大幅提升计算性能，同时省去了py4j的序列化流程。https://www.jianshu.com/p/17117574a86b。python的坏处也和sql udf里一样，依赖问题比较蛋疼。\n\n\n\n##### 注意事项\n\n- UDF里的变量都是普通变量，不能是rdd，因为rdd是不能嵌套的，每个executor都在做udf计算，再来一个rdd，executor又得分发，这是不对的。\n- 如果想要从hdfs里获取某个文件分发给executor做udf计算，则需要在driver里先获取该文件，然后将其变为普通变量，用sc.broadcast将其分发到每个executor上。","slug":"大数据/Spark/Spark中的UDF","published":1,"updated":"2022-09-15T03:46:43.359Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qf005rjqrrhcvt63fm","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>我们做模型想要上线，很多时候都会借助spark的udf来实现，最近在摸索这个东西，有了一点心得记录一下。</p>\n<h3 id=\"Hive-Spark-SQL中的UDF\"><a href=\"#Hive-Spark-SQL中的UDF\" class=\"headerlink\" title=\"Hive/Spark SQL中的UDF\"></a>Hive/Spark SQL中的UDF</h3><p>这种上线方式是经常会用到的，UDF分为三种：</p>\n<ul>\n<li>UDF：一进对应一出</li>\n<li>UDTF：一进对应多出，经常遇到的就是比如一行数组数据分为多行，类似explode lateral view</li>\n<li>UDAF：多进对应一出，就是聚合函数，类似sum()，count()</li>\n</ul>\n<p>UDF写完后直接在SQL中使用即可，一般写法又分为java和python两种：</p>\n<ul>\n<li>Java：这种方式比较常见，引用hadoop/spark接口即可，最终形成一个jar包，可以包含多个模块，容易管理，借助maven工具也容易进行依赖管理。</li>\n<li>Python：transform(..)  using(..)的方式py的好处是线下代码直接迁移，不用大改(一般模型也是用python开发巨多)，但坏处也有：<ul>\n<li>依赖py文件的问题：<strong>py文件无法打包</strong>，模块之间不能复用，不太容易管理。依赖的py文件需要手动add file上去。</li>\n<li>依赖lib的问题：如果依赖第三方包，需要<strong>自定义python环境</strong>，然后打包上传，运行时选择自定义python环境。<a href=\"http://heloowird.com/2018/01/29/hive_python_udf/\" target=\"_blank\" rel=\"noopener\">http://heloowird.com/2018/01/29/hive_python_udf/</a></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Spark中的UDF\"><a href=\"#Spark中的UDF\" class=\"headerlink\" title=\"Spark中的UDF\"></a>Spark中的UDF</h3><p>对于复杂的模型，例如需要特征工程之类的，我们可能就需要直接写spark代码来实现。如果核心算法有现成的spark包，例如xgboost这种还好说，如果是自己手写实现的算法，则需要将其包装成udf来实现分布式处理。</p>\n<p>UDF也是支持是三种（这个我是基于pyspark的pandas udf来的）：</p>\n<ul>\n<li><p>一对一的scalar</p>\n</li>\n<li><p>多对多的Grouped Map</p>\n</li>\n<li><p>多对一的Grouped Aggregate</p>\n</li>\n</ul>\n<p>同样的，这种方式也有java(确切来讲是scala)和python两种方式：</p>\n<ul>\n<li>Scala(Spark)：spark.udf.register(*)，基本原理是实现一个function，然后注册成udf。function里的计算就是普通的计算。</li>\n<li>Python(Pyspark)：原理也是类似，有udf功能。更进一步的，spark 2.4.0之后提出了pandas udf，基于apache arrow，借助pandas向量计算的能力大幅提升计算性能，同时省去了py4j的序列化流程。<a href=\"https://www.jianshu.com/p/17117574a86b。python的坏处也和sql\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/17117574a86b。python的坏处也和sql</a> udf里一样，依赖问题比较蛋疼。</li>\n</ul>\n<h5 id=\"注意事项\"><a href=\"#注意事项\" class=\"headerlink\" title=\"注意事项\"></a>注意事项</h5><ul>\n<li>UDF里的变量都是普通变量，不能是rdd，因为rdd是不能嵌套的，每个executor都在做udf计算，再来一个rdd，executor又得分发，这是不对的。</li>\n<li>如果想要从hdfs里获取某个文件分发给executor做udf计算，则需要在driver里先获取该文件，然后将其变为普通变量，用sc.broadcast将其分发到每个executor上。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>我们做模型想要上线，很多时候都会借助spark的udf来实现，最近在摸索这个东西，有了一点心得记录一下。</p>\n<h3 id=\"Hive-Spark-SQL中的UDF\"><a href=\"#Hive-Spark-SQL中的UDF\" class=\"headerlink\" title=\"Hive/Spark SQL中的UDF\"></a>Hive/Spark SQL中的UDF</h3><p>这种上线方式是经常会用到的，UDF分为三种：</p>\n<ul>\n<li>UDF：一进对应一出</li>\n<li>UDTF：一进对应多出，经常遇到的就是比如一行数组数据分为多行，类似explode lateral view</li>\n<li>UDAF：多进对应一出，就是聚合函数，类似sum()，count()</li>\n</ul>\n<p>UDF写完后直接在SQL中使用即可，一般写法又分为java和python两种：</p>\n<ul>\n<li>Java：这种方式比较常见，引用hadoop/spark接口即可，最终形成一个jar包，可以包含多个模块，容易管理，借助maven工具也容易进行依赖管理。</li>\n<li>Python：transform(..)  using(..)的方式py的好处是线下代码直接迁移，不用大改(一般模型也是用python开发巨多)，但坏处也有：<ul>\n<li>依赖py文件的问题：<strong>py文件无法打包</strong>，模块之间不能复用，不太容易管理。依赖的py文件需要手动add file上去。</li>\n<li>依赖lib的问题：如果依赖第三方包，需要<strong>自定义python环境</strong>，然后打包上传，运行时选择自定义python环境。<a href=\"http://heloowird.com/2018/01/29/hive_python_udf/\" target=\"_blank\" rel=\"noopener\">http://heloowird.com/2018/01/29/hive_python_udf/</a></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Spark中的UDF\"><a href=\"#Spark中的UDF\" class=\"headerlink\" title=\"Spark中的UDF\"></a>Spark中的UDF</h3><p>对于复杂的模型，例如需要特征工程之类的，我们可能就需要直接写spark代码来实现。如果核心算法有现成的spark包，例如xgboost这种还好说，如果是自己手写实现的算法，则需要将其包装成udf来实现分布式处理。</p>\n<p>UDF也是支持是三种（这个我是基于pyspark的pandas udf来的）：</p>\n<ul>\n<li><p>一对一的scalar</p>\n</li>\n<li><p>多对多的Grouped Map</p>\n</li>\n<li><p>多对一的Grouped Aggregate</p>\n</li>\n</ul>\n<p>同样的，这种方式也有java(确切来讲是scala)和python两种方式：</p>\n<ul>\n<li>Scala(Spark)：spark.udf.register(*)，基本原理是实现一个function，然后注册成udf。function里的计算就是普通的计算。</li>\n<li>Python(Pyspark)：原理也是类似，有udf功能。更进一步的，spark 2.4.0之后提出了pandas udf，基于apache arrow，借助pandas向量计算的能力大幅提升计算性能，同时省去了py4j的序列化流程。<a href=\"https://www.jianshu.com/p/17117574a86b。python的坏处也和sql\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/17117574a86b。python的坏处也和sql</a> udf里一样，依赖问题比较蛋疼。</li>\n</ul>\n<h5 id=\"注意事项\"><a href=\"#注意事项\" class=\"headerlink\" title=\"注意事项\"></a>注意事项</h5><ul>\n<li>UDF里的变量都是普通变量，不能是rdd，因为rdd是不能嵌套的，每个executor都在做udf计算，再来一个rdd，executor又得分发，这是不对的。</li>\n<li>如果想要从hdfs里获取某个文件分发给executor做udf计算，则需要在driver里先获取该文件，然后将其变为普通变量，用sc.broadcast将其分发到每个executor上。</li>\n</ul>\n"},{"title":"Spark名词相关理解","date":"2020-03-05T14:06:02.000Z","_content":"\n## 关于partition和task\npartition是spark RDD的操作单元，通常会把一个数据集切分成若干个partition，实现并行处理。我把它称之为需求。\n\ntask则是机器能提供的操作单元，一个core对应一个task，一个task处理一个partition。我把它称之为供给。\n\n**所以，如果stage还是只有2个partition，无论怎么调节executors的资源数目，都是没有用的，active task也只有2个而已！**\n\n关于调节partition，又分为两类：\n#### 非spark sql操作\n\n- *spark.default.parallelism* 集团没有默认值\n这个参数控制RDD的partition数目，但是只对于Spark SQL以外的所有Spark的stage生效，无法控制spark sql生成的分区。Spark SQL的并行度不允许用户自己指定，Spark SQL自己会默认根据hive表对应的HDFS文件的split个数自动设置Spark SQL所在的那个stage的并行度。\n**然而，我们平时用到的大部分操作都是spark sql的操作，为方便后续的复杂逻辑处理，最后sql取数之后repartition处理成多个分区**。\n\n\n#### spark sql操作\n\n##### a. 普通的操作可以用repartition来做。\n##### b. 对于shuffle操作，也是最常见的操作，例如join， group等。\n\n- *spark.sql.shuffle.partitions* 集团默认是1000个\n控制的是每个mapper端写出的partition个数，其实也就是reducer的个数，并不是mapper的个数。例如group by a,那么在每个mapper里按照a的值分成1000个partition数，写到磁盘，启动1000个reducer，每个reducer从每个mapper端拉取对应索引的partition。\n- *spark.sql.adaptive.enabled*\n是否开启调整partition功能，如果开启，spark.sql.shuffle.partitions设置的partition可能会被合并到一个reducer里运行。默认开启，同时强烈建议开启。理由：更好利用单个executor的性能，还能缓解小文件问题。\n- *spark.sql.adaptive.shuffle.targetPostShuffleInputSize*\n和spark.sql.adaptive.enabled配合使用，当开启调整partition功能后，当mapper端两个partition的数据合并后数据量小于targetPostShuffleInputSize时，Spark会将两个partition进行合并到一个reducer端进行处理。\n- *spark.sql.adaptive.minNumPostShufflePartitions*\n当spark.sql.adaptive.enabled参数开启后，有时会导致很多分区被合并，为了防止分区过少，可以设置spark.sql.adaptive.minNumPostShufflePartitions参数，防止分区过少而影响性能。\n\n\n\n\n## 调优例子\n\n我明明设置了minNumPostShufflePartitions参数，但是我发现某个涉及shuffle操作stage(A join B 得到C， C join D)的始终只有2个parition!\n\n解决方案：这个问题原因应该是shuffle后的C导致，因为A join B的关联key值过少，远远小于minNumPostShufflePartitions这个值，导致reduce后C的partition只有2个，从而使得后面C join D的时候，mapper数也只有2个。**只加了一句C.repartition(200)后问题就解决了。。**\n\n\n\n## 关于MapReduce的shuffle过程和Spark的shuffle算子\n\nHadoop是MapReduce框架，任何一个MapReduce过程都分为Mapper(程序员编写), Shuffle和Reduce(程序员编写)过程。最影响性能的就是shuffle，因为涉及到key值排序，网络传输等。\n\n![image-20200605112750651](https://tva1.sinaimg.cn/large/007S8ZIlly1gfh9nktybqj30k508xq5u.jpg)\n\n对于spark而言，只有两类操作，包括transform操作(从一个RDD到另一个RDD)和action操作(RDD变为结果值返回)，任何操作都是由partition构成，以典型的shuffle算子为例，其实也类似与mapper(mapper数即为partition数)和reduce(reduce数即为partiton数)过程。但是更吊的是，在mapper task里直接进行了partition，后续reduce只要按照索引从每个mapper里取对应索引的partition就好了。\n\n![image-20200605115037216](https://tva1.sinaimg.cn/large/007S8ZIlly1gfh9s51wzjj30lq07i0u3.jpg)","source":"_posts/大数据/Spark/Spark名词相关理解.md","raw":"---\ntitle: Spark名词相关理解\ndate: 2020-03-05 22:06:02\ncategories: [大数据,Spark]\n---\n\n## 关于partition和task\npartition是spark RDD的操作单元，通常会把一个数据集切分成若干个partition，实现并行处理。我把它称之为需求。\n\ntask则是机器能提供的操作单元，一个core对应一个task，一个task处理一个partition。我把它称之为供给。\n\n**所以，如果stage还是只有2个partition，无论怎么调节executors的资源数目，都是没有用的，active task也只有2个而已！**\n\n关于调节partition，又分为两类：\n#### 非spark sql操作\n\n- *spark.default.parallelism* 集团没有默认值\n这个参数控制RDD的partition数目，但是只对于Spark SQL以外的所有Spark的stage生效，无法控制spark sql生成的分区。Spark SQL的并行度不允许用户自己指定，Spark SQL自己会默认根据hive表对应的HDFS文件的split个数自动设置Spark SQL所在的那个stage的并行度。\n**然而，我们平时用到的大部分操作都是spark sql的操作，为方便后续的复杂逻辑处理，最后sql取数之后repartition处理成多个分区**。\n\n\n#### spark sql操作\n\n##### a. 普通的操作可以用repartition来做。\n##### b. 对于shuffle操作，也是最常见的操作，例如join， group等。\n\n- *spark.sql.shuffle.partitions* 集团默认是1000个\n控制的是每个mapper端写出的partition个数，其实也就是reducer的个数，并不是mapper的个数。例如group by a,那么在每个mapper里按照a的值分成1000个partition数，写到磁盘，启动1000个reducer，每个reducer从每个mapper端拉取对应索引的partition。\n- *spark.sql.adaptive.enabled*\n是否开启调整partition功能，如果开启，spark.sql.shuffle.partitions设置的partition可能会被合并到一个reducer里运行。默认开启，同时强烈建议开启。理由：更好利用单个executor的性能，还能缓解小文件问题。\n- *spark.sql.adaptive.shuffle.targetPostShuffleInputSize*\n和spark.sql.adaptive.enabled配合使用，当开启调整partition功能后，当mapper端两个partition的数据合并后数据量小于targetPostShuffleInputSize时，Spark会将两个partition进行合并到一个reducer端进行处理。\n- *spark.sql.adaptive.minNumPostShufflePartitions*\n当spark.sql.adaptive.enabled参数开启后，有时会导致很多分区被合并，为了防止分区过少，可以设置spark.sql.adaptive.minNumPostShufflePartitions参数，防止分区过少而影响性能。\n\n\n\n\n## 调优例子\n\n我明明设置了minNumPostShufflePartitions参数，但是我发现某个涉及shuffle操作stage(A join B 得到C， C join D)的始终只有2个parition!\n\n解决方案：这个问题原因应该是shuffle后的C导致，因为A join B的关联key值过少，远远小于minNumPostShufflePartitions这个值，导致reduce后C的partition只有2个，从而使得后面C join D的时候，mapper数也只有2个。**只加了一句C.repartition(200)后问题就解决了。。**\n\n\n\n## 关于MapReduce的shuffle过程和Spark的shuffle算子\n\nHadoop是MapReduce框架，任何一个MapReduce过程都分为Mapper(程序员编写), Shuffle和Reduce(程序员编写)过程。最影响性能的就是shuffle，因为涉及到key值排序，网络传输等。\n\n![image-20200605112750651](https://tva1.sinaimg.cn/large/007S8ZIlly1gfh9nktybqj30k508xq5u.jpg)\n\n对于spark而言，只有两类操作，包括transform操作(从一个RDD到另一个RDD)和action操作(RDD变为结果值返回)，任何操作都是由partition构成，以典型的shuffle算子为例，其实也类似与mapper(mapper数即为partition数)和reduce(reduce数即为partiton数)过程。但是更吊的是，在mapper task里直接进行了partition，后续reduce只要按照索引从每个mapper里取对应索引的partition就好了。\n\n![image-20200605115037216](https://tva1.sinaimg.cn/large/007S8ZIlly1gfh9s51wzjj30lq07i0u3.jpg)","slug":"大数据/Spark/Spark名词相关理解","published":1,"updated":"2022-09-15T03:46:43.359Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qg005sjqrr47jkkz1s","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"关于partition和task\"><a href=\"#关于partition和task\" class=\"headerlink\" title=\"关于partition和task\"></a>关于partition和task</h2><p>partition是spark RDD的操作单元，通常会把一个数据集切分成若干个partition，实现并行处理。我把它称之为需求。</p>\n<p>task则是机器能提供的操作单元，一个core对应一个task，一个task处理一个partition。我把它称之为供给。</p>\n<p><strong>所以，如果stage还是只有2个partition，无论怎么调节executors的资源数目，都是没有用的，active task也只有2个而已！</strong></p>\n<p>关于调节partition，又分为两类：</p>\n<h4 id=\"非spark-sql操作\"><a href=\"#非spark-sql操作\" class=\"headerlink\" title=\"非spark sql操作\"></a>非spark sql操作</h4><ul>\n<li><em>spark.default.parallelism</em> 集团没有默认值<br>这个参数控制RDD的partition数目，但是只对于Spark SQL以外的所有Spark的stage生效，无法控制spark sql生成的分区。Spark SQL的并行度不允许用户自己指定，Spark SQL自己会默认根据hive表对应的HDFS文件的split个数自动设置Spark SQL所在的那个stage的并行度。<br><strong>然而，我们平时用到的大部分操作都是spark sql的操作，为方便后续的复杂逻辑处理，最后sql取数之后repartition处理成多个分区</strong>。</li>\n</ul>\n<h4 id=\"spark-sql操作\"><a href=\"#spark-sql操作\" class=\"headerlink\" title=\"spark sql操作\"></a>spark sql操作</h4><h5 id=\"a-普通的操作可以用repartition来做。\"><a href=\"#a-普通的操作可以用repartition来做。\" class=\"headerlink\" title=\"a. 普通的操作可以用repartition来做。\"></a>a. 普通的操作可以用repartition来做。</h5><h5 id=\"b-对于shuffle操作，也是最常见的操作，例如join，-group等。\"><a href=\"#b-对于shuffle操作，也是最常见的操作，例如join，-group等。\" class=\"headerlink\" title=\"b. 对于shuffle操作，也是最常见的操作，例如join， group等。\"></a>b. 对于shuffle操作，也是最常见的操作，例如join， group等。</h5><ul>\n<li><em>spark.sql.shuffle.partitions</em> 集团默认是1000个<br>控制的是每个mapper端写出的partition个数，其实也就是reducer的个数，并不是mapper的个数。例如group by a,那么在每个mapper里按照a的值分成1000个partition数，写到磁盘，启动1000个reducer，每个reducer从每个mapper端拉取对应索引的partition。</li>\n<li><em>spark.sql.adaptive.enabled</em><br>是否开启调整partition功能，如果开启，spark.sql.shuffle.partitions设置的partition可能会被合并到一个reducer里运行。默认开启，同时强烈建议开启。理由：更好利用单个executor的性能，还能缓解小文件问题。</li>\n<li><em>spark.sql.adaptive.shuffle.targetPostShuffleInputSize</em><br>和spark.sql.adaptive.enabled配合使用，当开启调整partition功能后，当mapper端两个partition的数据合并后数据量小于targetPostShuffleInputSize时，Spark会将两个partition进行合并到一个reducer端进行处理。</li>\n<li><em>spark.sql.adaptive.minNumPostShufflePartitions</em><br>当spark.sql.adaptive.enabled参数开启后，有时会导致很多分区被合并，为了防止分区过少，可以设置spark.sql.adaptive.minNumPostShufflePartitions参数，防止分区过少而影响性能。</li>\n</ul>\n<h2 id=\"调优例子\"><a href=\"#调优例子\" class=\"headerlink\" title=\"调优例子\"></a>调优例子</h2><p>我明明设置了minNumPostShufflePartitions参数，但是我发现某个涉及shuffle操作stage(A join B 得到C， C join D)的始终只有2个parition!</p>\n<p>解决方案：这个问题原因应该是shuffle后的C导致，因为A join B的关联key值过少，远远小于minNumPostShufflePartitions这个值，导致reduce后C的partition只有2个，从而使得后面C join D的时候，mapper数也只有2个。<strong>只加了一句C.repartition(200)后问题就解决了。。</strong></p>\n<h2 id=\"关于MapReduce的shuffle过程和Spark的shuffle算子\"><a href=\"#关于MapReduce的shuffle过程和Spark的shuffle算子\" class=\"headerlink\" title=\"关于MapReduce的shuffle过程和Spark的shuffle算子\"></a>关于MapReduce的shuffle过程和Spark的shuffle算子</h2><p>Hadoop是MapReduce框架，任何一个MapReduce过程都分为Mapper(程序员编写), Shuffle和Reduce(程序员编写)过程。最影响性能的就是shuffle，因为涉及到key值排序，网络传输等。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfh9nktybqj30k508xq5u.jpg\" alt=\"image-20200605112750651\"></p>\n<p>对于spark而言，只有两类操作，包括transform操作(从一个RDD到另一个RDD)和action操作(RDD变为结果值返回)，任何操作都是由partition构成，以典型的shuffle算子为例，其实也类似与mapper(mapper数即为partition数)和reduce(reduce数即为partiton数)过程。但是更吊的是，在mapper task里直接进行了partition，后续reduce只要按照索引从每个mapper里取对应索引的partition就好了。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfh9s51wzjj30lq07i0u3.jpg\" alt=\"image-20200605115037216\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"关于partition和task\"><a href=\"#关于partition和task\" class=\"headerlink\" title=\"关于partition和task\"></a>关于partition和task</h2><p>partition是spark RDD的操作单元，通常会把一个数据集切分成若干个partition，实现并行处理。我把它称之为需求。</p>\n<p>task则是机器能提供的操作单元，一个core对应一个task，一个task处理一个partition。我把它称之为供给。</p>\n<p><strong>所以，如果stage还是只有2个partition，无论怎么调节executors的资源数目，都是没有用的，active task也只有2个而已！</strong></p>\n<p>关于调节partition，又分为两类：</p>\n<h4 id=\"非spark-sql操作\"><a href=\"#非spark-sql操作\" class=\"headerlink\" title=\"非spark sql操作\"></a>非spark sql操作</h4><ul>\n<li><em>spark.default.parallelism</em> 集团没有默认值<br>这个参数控制RDD的partition数目，但是只对于Spark SQL以外的所有Spark的stage生效，无法控制spark sql生成的分区。Spark SQL的并行度不允许用户自己指定，Spark SQL自己会默认根据hive表对应的HDFS文件的split个数自动设置Spark SQL所在的那个stage的并行度。<br><strong>然而，我们平时用到的大部分操作都是spark sql的操作，为方便后续的复杂逻辑处理，最后sql取数之后repartition处理成多个分区</strong>。</li>\n</ul>\n<h4 id=\"spark-sql操作\"><a href=\"#spark-sql操作\" class=\"headerlink\" title=\"spark sql操作\"></a>spark sql操作</h4><h5 id=\"a-普通的操作可以用repartition来做。\"><a href=\"#a-普通的操作可以用repartition来做。\" class=\"headerlink\" title=\"a. 普通的操作可以用repartition来做。\"></a>a. 普通的操作可以用repartition来做。</h5><h5 id=\"b-对于shuffle操作，也是最常见的操作，例如join，-group等。\"><a href=\"#b-对于shuffle操作，也是最常见的操作，例如join，-group等。\" class=\"headerlink\" title=\"b. 对于shuffle操作，也是最常见的操作，例如join， group等。\"></a>b. 对于shuffle操作，也是最常见的操作，例如join， group等。</h5><ul>\n<li><em>spark.sql.shuffle.partitions</em> 集团默认是1000个<br>控制的是每个mapper端写出的partition个数，其实也就是reducer的个数，并不是mapper的个数。例如group by a,那么在每个mapper里按照a的值分成1000个partition数，写到磁盘，启动1000个reducer，每个reducer从每个mapper端拉取对应索引的partition。</li>\n<li><em>spark.sql.adaptive.enabled</em><br>是否开启调整partition功能，如果开启，spark.sql.shuffle.partitions设置的partition可能会被合并到一个reducer里运行。默认开启，同时强烈建议开启。理由：更好利用单个executor的性能，还能缓解小文件问题。</li>\n<li><em>spark.sql.adaptive.shuffle.targetPostShuffleInputSize</em><br>和spark.sql.adaptive.enabled配合使用，当开启调整partition功能后，当mapper端两个partition的数据合并后数据量小于targetPostShuffleInputSize时，Spark会将两个partition进行合并到一个reducer端进行处理。</li>\n<li><em>spark.sql.adaptive.minNumPostShufflePartitions</em><br>当spark.sql.adaptive.enabled参数开启后，有时会导致很多分区被合并，为了防止分区过少，可以设置spark.sql.adaptive.minNumPostShufflePartitions参数，防止分区过少而影响性能。</li>\n</ul>\n<h2 id=\"调优例子\"><a href=\"#调优例子\" class=\"headerlink\" title=\"调优例子\"></a>调优例子</h2><p>我明明设置了minNumPostShufflePartitions参数，但是我发现某个涉及shuffle操作stage(A join B 得到C， C join D)的始终只有2个parition!</p>\n<p>解决方案：这个问题原因应该是shuffle后的C导致，因为A join B的关联key值过少，远远小于minNumPostShufflePartitions这个值，导致reduce后C的partition只有2个，从而使得后面C join D的时候，mapper数也只有2个。<strong>只加了一句C.repartition(200)后问题就解决了。。</strong></p>\n<h2 id=\"关于MapReduce的shuffle过程和Spark的shuffle算子\"><a href=\"#关于MapReduce的shuffle过程和Spark的shuffle算子\" class=\"headerlink\" title=\"关于MapReduce的shuffle过程和Spark的shuffle算子\"></a>关于MapReduce的shuffle过程和Spark的shuffle算子</h2><p>Hadoop是MapReduce框架，任何一个MapReduce过程都分为Mapper(程序员编写), Shuffle和Reduce(程序员编写)过程。最影响性能的就是shuffle，因为涉及到key值排序，网络传输等。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfh9nktybqj30k508xq5u.jpg\" alt=\"image-20200605112750651\"></p>\n<p>对于spark而言，只有两类操作，包括transform操作(从一个RDD到另一个RDD)和action操作(RDD变为结果值返回)，任何操作都是由partition构成，以典型的shuffle算子为例，其实也类似与mapper(mapper数即为partition数)和reduce(reduce数即为partiton数)过程。但是更吊的是，在mapper task里直接进行了partition，后续reduce只要按照索引从每个mapper里取对应索引的partition就好了。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfh9s51wzjj30lq07i0u3.jpg\" alt=\"image-20200605115037216\"></p>\n"},{"title":"Spark笔记","date":"2018-10-18T14:06:02.000Z","_content":"\n\n\n- 如何手动分区：\n  分两种情况，创建 RDD 时和通过转换操作得到新 RDD 时。\n\n  对于前者，在调用 textFile 和 parallelize 方法时候手动指定分区个数即可。例如 sc.parallelize(Array(1, 2, 3, 5, 6), 2) 指定创建得到的 RDD 分区个数为 2。\n\n  对于后者，直接调用 repartition 方法即可。实际上分区的个数是根据转换操作对应多个 RDD 之间的依赖关系来确定，窄依赖子 RDD 由父 RDD 分区个数决定，例如 map 操作，父 RDD 和子 RDD 分区个数一致；Shuffle 依赖则由分区器（Partitioner）决定，例如 groupByKey(new HashPartitioner(2)) 或者直接 groupByKey(2) 得到的新 RDD 分区个数等于 2。\n\n\n\n- 集团的hadoop，hive，spark环境：\n  - 集群在线上环境中，线下环境与之没有打通，无法连接。\n  - hive有个hivejdbc接口，jdbc:hive2://10.83.16.36:8083，线下环境可以访问该ip，由此访问线上hive。\n  - 想要客户端访问集群，只能通过客户端，也就是各类中转机，堡垒机，D++等，同样需要装上hadoop，hive，spark等环境，并且做相关配置，例如hadoop的core-site，yarn-site，mapred-site.xml，以及spark的hive-site等。\n\n \n\n- 关于版本问题：\n  - maven的pom指定了编译打包版本(spark,java)，也是本地调试运行时的版本，此时甚至不需要本地安装java或者spark，因为pom会自动拉取该程序文件到仓库。\n  - 打成jar包后我们可能会到处部署，放到不同机器环境中，此时运行版本最好与编译版本保持一致，或者高于编译版本(java向下兼容)\n  - 对于hadoop/spark集群，无论master/slave所有机器上都要安装hadoop/spark，并且保持配置一致。\n  - 所以为了统一，maven的pom指定版本要与集群上安装版本一致。\n  - maven clean package只是将编译产生的类打包，单独部署可能无法运行，适合作为工具包被导入；maven clean assembly:assemby还将所有依赖等文件全部打包，可以单独部署运行，最终jar包也很大，要执行这一操作需要在pom里加入assembly插件。\n\n \n\n \n\n- spark优化相关\n  - spark的设置：程序代码 > spark-submit指定 > spark-default.xml\n  - shuffle.partition最好设置成自动调整，使每个分区的数据尽量平均\n  - 数据倾斜是难以避免的，即使设置partition也没用，此时可以用map/broadcast join来避免shuffle操作，同时还有其他的一些手段例如随机前缀以及采用倾斜key等。\n\n \n\n- spark基础操作：\n  - transformation: rdd -> rdd， 注意：reduceByKey, sortByKey等都是该类操作。\n  - action： rdd 返回结果给drive problem， 注意：foreach， collect, show, count, countByKey,createOrReplaceTempView是该类操作\n\n \n\n- spark rdd处理不能嵌套！例如在对一个rdd做操作的时候，不能引入另一个rdd的操作。所以citys(Dataframe类型).foreach(func(_, data(也是Dataframe类型)))这种想法是不行的。 直观来说，就是对有分区的数据的处理时，不能再传有分区的数据。但如果单纯想要传rdd的话(不对这个rdd再做操作)，也是可以的，用broadcast变量。\n\n \n\n \n\n- rdd.foreach(x => func(x, y)) 对于这类操作，func和y都需要支持序列化和反序列化。\n  - 变量y可以定义成broadcast变量，从而省去每个task序列化和反序列化的过程中，对变量y的序列化和反序列化，直接广播到了每个executor上。\n  - 还要注意的是，这里的func也要支持序列化，如果是自定义的func，建立放在一个支持序列化的类中。也可以直接将func写在foreach中。\n  - 如果func，y是引用了某个类的成员函数或变量，那么这整个类都要支持序列化，所以最好放在当前函数中。\n\n \n\n- 出现“org.apache.spark.SparkException: Task not serializable\"这个错误，一般是因为在map、filter等的参数使用了外部的变量，但是这个变量不能序列化。特别是当引用了某个类（经常是当前类）的成员函数或变量时，会导致这个类的所有成员（整个类）都需要支持序列化。解决这个问题最常用的方法有：\n\n1. 1. 如果可以，将依赖的变量放到map、filter等的参数内部定义。这样就可以使用不支持序列化的类；\n   2. 如果可以，将依赖的变量独立放到一个小的class中，让这个class支持序列化；这样做可以减少网络传输量，提高效率；\n   3. 如果可以，将被依赖的类中不能序列化的部分使用transient关键字修饰，告诉编译器它不需要序列化。\n   4. 将引用的类做成可序列化的。\n\n \n\n- spark的worker, executor, core的概念：\n  - worker就是集群里可执行的机器，一个worker可以有多个executor。\n  - 一个executor就是CPU，一个CPU可以有多个核。\n  - 一个core(核)对应一个线程，也就是一个task，一个核同时只能执行一个task。注意，这个的core不是指物理核，是虚拟核。\n  - 一般来讲几个物理核就是几个线程，但是通过超线程技术，一个物理核可以分成多个虚拟核，从而使得一个核可以有多个线程。但是，一个核同时只能执行一个线程。\n  - 并发：多个线程在单个核心运行，同一时间一个线程运行，系统不停切换线程，看起来像同时运行，实际上是线程不停切换。\n  - 并行：多个线程在多个核心运行，线程同时运行。\n\n \n\n \n\n \n\n ","source":"_posts/大数据/Spark/Spark笔记.md","raw":"---\ntitle: Spark笔记\ndate: 2018-10-18 22:06:02\ncategories: [大数据,Spark]\n---\n\n\n\n- 如何手动分区：\n  分两种情况，创建 RDD 时和通过转换操作得到新 RDD 时。\n\n  对于前者，在调用 textFile 和 parallelize 方法时候手动指定分区个数即可。例如 sc.parallelize(Array(1, 2, 3, 5, 6), 2) 指定创建得到的 RDD 分区个数为 2。\n\n  对于后者，直接调用 repartition 方法即可。实际上分区的个数是根据转换操作对应多个 RDD 之间的依赖关系来确定，窄依赖子 RDD 由父 RDD 分区个数决定，例如 map 操作，父 RDD 和子 RDD 分区个数一致；Shuffle 依赖则由分区器（Partitioner）决定，例如 groupByKey(new HashPartitioner(2)) 或者直接 groupByKey(2) 得到的新 RDD 分区个数等于 2。\n\n\n\n- 集团的hadoop，hive，spark环境：\n  - 集群在线上环境中，线下环境与之没有打通，无法连接。\n  - hive有个hivejdbc接口，jdbc:hive2://10.83.16.36:8083，线下环境可以访问该ip，由此访问线上hive。\n  - 想要客户端访问集群，只能通过客户端，也就是各类中转机，堡垒机，D++等，同样需要装上hadoop，hive，spark等环境，并且做相关配置，例如hadoop的core-site，yarn-site，mapred-site.xml，以及spark的hive-site等。\n\n \n\n- 关于版本问题：\n  - maven的pom指定了编译打包版本(spark,java)，也是本地调试运行时的版本，此时甚至不需要本地安装java或者spark，因为pom会自动拉取该程序文件到仓库。\n  - 打成jar包后我们可能会到处部署，放到不同机器环境中，此时运行版本最好与编译版本保持一致，或者高于编译版本(java向下兼容)\n  - 对于hadoop/spark集群，无论master/slave所有机器上都要安装hadoop/spark，并且保持配置一致。\n  - 所以为了统一，maven的pom指定版本要与集群上安装版本一致。\n  - maven clean package只是将编译产生的类打包，单独部署可能无法运行，适合作为工具包被导入；maven clean assembly:assemby还将所有依赖等文件全部打包，可以单独部署运行，最终jar包也很大，要执行这一操作需要在pom里加入assembly插件。\n\n \n\n \n\n- spark优化相关\n  - spark的设置：程序代码 > spark-submit指定 > spark-default.xml\n  - shuffle.partition最好设置成自动调整，使每个分区的数据尽量平均\n  - 数据倾斜是难以避免的，即使设置partition也没用，此时可以用map/broadcast join来避免shuffle操作，同时还有其他的一些手段例如随机前缀以及采用倾斜key等。\n\n \n\n- spark基础操作：\n  - transformation: rdd -> rdd， 注意：reduceByKey, sortByKey等都是该类操作。\n  - action： rdd 返回结果给drive problem， 注意：foreach， collect, show, count, countByKey,createOrReplaceTempView是该类操作\n\n \n\n- spark rdd处理不能嵌套！例如在对一个rdd做操作的时候，不能引入另一个rdd的操作。所以citys(Dataframe类型).foreach(func(_, data(也是Dataframe类型)))这种想法是不行的。 直观来说，就是对有分区的数据的处理时，不能再传有分区的数据。但如果单纯想要传rdd的话(不对这个rdd再做操作)，也是可以的，用broadcast变量。\n\n \n\n \n\n- rdd.foreach(x => func(x, y)) 对于这类操作，func和y都需要支持序列化和反序列化。\n  - 变量y可以定义成broadcast变量，从而省去每个task序列化和反序列化的过程中，对变量y的序列化和反序列化，直接广播到了每个executor上。\n  - 还要注意的是，这里的func也要支持序列化，如果是自定义的func，建立放在一个支持序列化的类中。也可以直接将func写在foreach中。\n  - 如果func，y是引用了某个类的成员函数或变量，那么这整个类都要支持序列化，所以最好放在当前函数中。\n\n \n\n- 出现“org.apache.spark.SparkException: Task not serializable\"这个错误，一般是因为在map、filter等的参数使用了外部的变量，但是这个变量不能序列化。特别是当引用了某个类（经常是当前类）的成员函数或变量时，会导致这个类的所有成员（整个类）都需要支持序列化。解决这个问题最常用的方法有：\n\n1. 1. 如果可以，将依赖的变量放到map、filter等的参数内部定义。这样就可以使用不支持序列化的类；\n   2. 如果可以，将依赖的变量独立放到一个小的class中，让这个class支持序列化；这样做可以减少网络传输量，提高效率；\n   3. 如果可以，将被依赖的类中不能序列化的部分使用transient关键字修饰，告诉编译器它不需要序列化。\n   4. 将引用的类做成可序列化的。\n\n \n\n- spark的worker, executor, core的概念：\n  - worker就是集群里可执行的机器，一个worker可以有多个executor。\n  - 一个executor就是CPU，一个CPU可以有多个核。\n  - 一个core(核)对应一个线程，也就是一个task，一个核同时只能执行一个task。注意，这个的core不是指物理核，是虚拟核。\n  - 一般来讲几个物理核就是几个线程，但是通过超线程技术，一个物理核可以分成多个虚拟核，从而使得一个核可以有多个线程。但是，一个核同时只能执行一个线程。\n  - 并发：多个线程在单个核心运行，同一时间一个线程运行，系统不停切换线程，看起来像同时运行，实际上是线程不停切换。\n  - 并行：多个线程在多个核心运行，线程同时运行。\n\n \n\n \n\n \n\n ","slug":"大数据/Spark/Spark笔记","published":1,"updated":"2022-09-15T03:46:43.360Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qh005vjqrrpiup3ldm","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><ul>\n<li><p>如何手动分区：<br>分两种情况，创建 RDD 时和通过转换操作得到新 RDD 时。</p>\n<p>对于前者，在调用 textFile 和 parallelize 方法时候手动指定分区个数即可。例如 sc.parallelize(Array(1, 2, 3, 5, 6), 2) 指定创建得到的 RDD 分区个数为 2。</p>\n<p>对于后者，直接调用 repartition 方法即可。实际上分区的个数是根据转换操作对应多个 RDD 之间的依赖关系来确定，窄依赖子 RDD 由父 RDD 分区个数决定，例如 map 操作，父 RDD 和子 RDD 分区个数一致；Shuffle 依赖则由分区器（Partitioner）决定，例如 groupByKey(new HashPartitioner(2)) 或者直接 groupByKey(2) 得到的新 RDD 分区个数等于 2。</p>\n</li>\n</ul>\n<ul>\n<li>集团的hadoop，hive，spark环境：<ul>\n<li>集群在线上环境中，线下环境与之没有打通，无法连接。</li>\n<li>hive有个hivejdbc接口，jdbc:hive2://10.83.16.36:8083，线下环境可以访问该ip，由此访问线上hive。</li>\n<li>想要客户端访问集群，只能通过客户端，也就是各类中转机，堡垒机，D++等，同样需要装上hadoop，hive，spark等环境，并且做相关配置，例如hadoop的core-site，yarn-site，mapred-site.xml，以及spark的hive-site等。</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>关于版本问题：<ul>\n<li>maven的pom指定了编译打包版本(spark,java)，也是本地调试运行时的版本，此时甚至不需要本地安装java或者spark，因为pom会自动拉取该程序文件到仓库。</li>\n<li>打成jar包后我们可能会到处部署，放到不同机器环境中，此时运行版本最好与编译版本保持一致，或者高于编译版本(java向下兼容)</li>\n<li>对于hadoop/spark集群，无论master/slave所有机器上都要安装hadoop/spark，并且保持配置一致。</li>\n<li>所以为了统一，maven的pom指定版本要与集群上安装版本一致。</li>\n<li>maven clean package只是将编译产生的类打包，单独部署可能无法运行，适合作为工具包被导入；maven clean assembly:assemby还将所有依赖等文件全部打包，可以单独部署运行，最终jar包也很大，要执行这一操作需要在pom里加入assembly插件。</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>spark优化相关<ul>\n<li>spark的设置：程序代码 &gt; spark-submit指定 &gt; spark-default.xml</li>\n<li>shuffle.partition最好设置成自动调整，使每个分区的数据尽量平均</li>\n<li>数据倾斜是难以避免的，即使设置partition也没用，此时可以用map/broadcast join来避免shuffle操作，同时还有其他的一些手段例如随机前缀以及采用倾斜key等。</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>spark基础操作：<ul>\n<li>transformation: rdd -&gt; rdd， 注意：reduceByKey, sortByKey等都是该类操作。</li>\n<li>action： rdd 返回结果给drive problem， 注意：foreach， collect, show, count, countByKey,createOrReplaceTempView是该类操作</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>spark rdd处理不能嵌套！例如在对一个rdd做操作的时候，不能引入另一个rdd的操作。所以citys(Dataframe类型).foreach(func(_, data(也是Dataframe类型)))这种想法是不行的。 直观来说，就是对有分区的数据的处理时，不能再传有分区的数据。但如果单纯想要传rdd的话(不对这个rdd再做操作)，也是可以的，用broadcast变量。</li>\n</ul>\n<ul>\n<li>rdd.foreach(x =&gt; func(x, y)) 对于这类操作，func和y都需要支持序列化和反序列化。<ul>\n<li>变量y可以定义成broadcast变量，从而省去每个task序列化和反序列化的过程中，对变量y的序列化和反序列化，直接广播到了每个executor上。</li>\n<li>还要注意的是，这里的func也要支持序列化，如果是自定义的func，建立放在一个支持序列化的类中。也可以直接将func写在foreach中。</li>\n<li>如果func，y是引用了某个类的成员函数或变量，那么这整个类都要支持序列化，所以最好放在当前函数中。</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>出现“org.apache.spark.SparkException: Task not serializable”这个错误，一般是因为在map、filter等的参数使用了外部的变量，但是这个变量不能序列化。特别是当引用了某个类（经常是当前类）的成员函数或变量时，会导致这个类的所有成员（整个类）都需要支持序列化。解决这个问题最常用的方法有：</li>\n</ul>\n<ol>\n<li><ol>\n<li>如果可以，将依赖的变量放到map、filter等的参数内部定义。这样就可以使用不支持序列化的类；</li>\n<li>如果可以，将依赖的变量独立放到一个小的class中，让这个class支持序列化；这样做可以减少网络传输量，提高效率；</li>\n<li>如果可以，将被依赖的类中不能序列化的部分使用transient关键字修饰，告诉编译器它不需要序列化。</li>\n<li>将引用的类做成可序列化的。</li>\n</ol>\n</li>\n</ol>\n<ul>\n<li>spark的worker, executor, core的概念：<ul>\n<li>worker就是集群里可执行的机器，一个worker可以有多个executor。</li>\n<li>一个executor就是CPU，一个CPU可以有多个核。</li>\n<li>一个core(核)对应一个线程，也就是一个task，一个核同时只能执行一个task。注意，这个的core不是指物理核，是虚拟核。</li>\n<li>一般来讲几个物理核就是几个线程，但是通过超线程技术，一个物理核可以分成多个虚拟核，从而使得一个核可以有多个线程。但是，一个核同时只能执行一个线程。</li>\n<li>并发：多个线程在单个核心运行，同一时间一个线程运行，系统不停切换线程，看起来像同时运行，实际上是线程不停切换。</li>\n<li>并行：多个线程在多个核心运行，线程同时运行。</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li><p>如何手动分区：<br>分两种情况，创建 RDD 时和通过转换操作得到新 RDD 时。</p>\n<p>对于前者，在调用 textFile 和 parallelize 方法时候手动指定分区个数即可。例如 sc.parallelize(Array(1, 2, 3, 5, 6), 2) 指定创建得到的 RDD 分区个数为 2。</p>\n<p>对于后者，直接调用 repartition 方法即可。实际上分区的个数是根据转换操作对应多个 RDD 之间的依赖关系来确定，窄依赖子 RDD 由父 RDD 分区个数决定，例如 map 操作，父 RDD 和子 RDD 分区个数一致；Shuffle 依赖则由分区器（Partitioner）决定，例如 groupByKey(new HashPartitioner(2)) 或者直接 groupByKey(2) 得到的新 RDD 分区个数等于 2。</p>\n</li>\n</ul>\n<ul>\n<li>集团的hadoop，hive，spark环境：<ul>\n<li>集群在线上环境中，线下环境与之没有打通，无法连接。</li>\n<li>hive有个hivejdbc接口，jdbc:hive2://10.83.16.36:8083，线下环境可以访问该ip，由此访问线上hive。</li>\n<li>想要客户端访问集群，只能通过客户端，也就是各类中转机，堡垒机，D++等，同样需要装上hadoop，hive，spark等环境，并且做相关配置，例如hadoop的core-site，yarn-site，mapred-site.xml，以及spark的hive-site等。</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>关于版本问题：<ul>\n<li>maven的pom指定了编译打包版本(spark,java)，也是本地调试运行时的版本，此时甚至不需要本地安装java或者spark，因为pom会自动拉取该程序文件到仓库。</li>\n<li>打成jar包后我们可能会到处部署，放到不同机器环境中，此时运行版本最好与编译版本保持一致，或者高于编译版本(java向下兼容)</li>\n<li>对于hadoop/spark集群，无论master/slave所有机器上都要安装hadoop/spark，并且保持配置一致。</li>\n<li>所以为了统一，maven的pom指定版本要与集群上安装版本一致。</li>\n<li>maven clean package只是将编译产生的类打包，单独部署可能无法运行，适合作为工具包被导入；maven clean assembly:assemby还将所有依赖等文件全部打包，可以单独部署运行，最终jar包也很大，要执行这一操作需要在pom里加入assembly插件。</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>spark优化相关<ul>\n<li>spark的设置：程序代码 &gt; spark-submit指定 &gt; spark-default.xml</li>\n<li>shuffle.partition最好设置成自动调整，使每个分区的数据尽量平均</li>\n<li>数据倾斜是难以避免的，即使设置partition也没用，此时可以用map/broadcast join来避免shuffle操作，同时还有其他的一些手段例如随机前缀以及采用倾斜key等。</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>spark基础操作：<ul>\n<li>transformation: rdd -&gt; rdd， 注意：reduceByKey, sortByKey等都是该类操作。</li>\n<li>action： rdd 返回结果给drive problem， 注意：foreach， collect, show, count, countByKey,createOrReplaceTempView是该类操作</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>spark rdd处理不能嵌套！例如在对一个rdd做操作的时候，不能引入另一个rdd的操作。所以citys(Dataframe类型).foreach(func(_, data(也是Dataframe类型)))这种想法是不行的。 直观来说，就是对有分区的数据的处理时，不能再传有分区的数据。但如果单纯想要传rdd的话(不对这个rdd再做操作)，也是可以的，用broadcast变量。</li>\n</ul>\n<ul>\n<li>rdd.foreach(x =&gt; func(x, y)) 对于这类操作，func和y都需要支持序列化和反序列化。<ul>\n<li>变量y可以定义成broadcast变量，从而省去每个task序列化和反序列化的过程中，对变量y的序列化和反序列化，直接广播到了每个executor上。</li>\n<li>还要注意的是，这里的func也要支持序列化，如果是自定义的func，建立放在一个支持序列化的类中。也可以直接将func写在foreach中。</li>\n<li>如果func，y是引用了某个类的成员函数或变量，那么这整个类都要支持序列化，所以最好放在当前函数中。</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>出现“org.apache.spark.SparkException: Task not serializable”这个错误，一般是因为在map、filter等的参数使用了外部的变量，但是这个变量不能序列化。特别是当引用了某个类（经常是当前类）的成员函数或变量时，会导致这个类的所有成员（整个类）都需要支持序列化。解决这个问题最常用的方法有：</li>\n</ul>\n<ol>\n<li><ol>\n<li>如果可以，将依赖的变量放到map、filter等的参数内部定义。这样就可以使用不支持序列化的类；</li>\n<li>如果可以，将依赖的变量独立放到一个小的class中，让这个class支持序列化；这样做可以减少网络传输量，提高效率；</li>\n<li>如果可以，将被依赖的类中不能序列化的部分使用transient关键字修饰，告诉编译器它不需要序列化。</li>\n<li>将引用的类做成可序列化的。</li>\n</ol>\n</li>\n</ol>\n<ul>\n<li>spark的worker, executor, core的概念：<ul>\n<li>worker就是集群里可执行的机器，一个worker可以有多个executor。</li>\n<li>一个executor就是CPU，一个CPU可以有多个核。</li>\n<li>一个core(核)对应一个线程，也就是一个task，一个核同时只能执行一个task。注意，这个的core不是指物理核，是虚拟核。</li>\n<li>一般来讲几个物理核就是几个线程，但是通过超线程技术，一个物理核可以分成多个虚拟核，从而使得一个核可以有多个线程。但是，一个核同时只能执行一个线程。</li>\n<li>并发：多个线程在单个核心运行，同一时间一个线程运行，系统不停切换线程，看起来像同时运行，实际上是线程不停切换。</li>\n<li>并行：多个线程在多个核心运行，线程同时运行。</li>\n</ul>\n</li>\n</ul>\n"},{"title":"Spark调优以及各名词深刻理解","date":"2018-11-28T14:06:02.000Z","_content":"\n### **Spark资源优化：**\n\n队列是根据Fair调度分配资源的。\n\n静态资源分配方式的问题： \n\n- stage非对称\n- Task非对称-数据倾斜\n- 执行时间随意性\n\n \n\n所以需要根据任务动态分配资源。例如：\n\nExecutor资源量相关：\n\nspark.dynamicAllocation.minExecutors\n\nspark.dynamicAllocation.maxExecutors\n\n这个就会让任务根据资源需求而自动调整executors。\n\n \n\n遗留参数\n\nspark.executor.instances -- 这个参数是老版本的，静态资源分配，不要用了。\n\n \n\n### **Spark内存优化：**\n\n内存模型（heap就是工作用的可用内存，超过了就OOM，滴滴NodeManager指定了不超过15G，超过了就被yarn killed）\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfheqfmzdsj30nm0gkjxu.jpg\" alt=\"image-20200605144153817\" style=\"zoom:67%;\" />\n\n \n\n统一内存模型：(可用内存 = 统一内存+其他，统一内存= 存储内存+计算内存)\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfheri64lbj30ux0i9dr5.jpg\" alt=\"image-20200605144258996\" style=\"zoom:67%;\" />\n\n​      <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhes1vdxuj30uz0i8k3o.jpg\" alt=\"image-20200605144331698\" style=\"zoom:67%;\" /> \n\nacutal used大于heap memory：因为还有overhead的开销\n\n \n\n常见异常1：\n\n- Executor OOM（具体其实是executor中的task超出了heap内存）\n  - heap内存不够，TASK需要更多内存(task是在这个executor上的任务，最低保障是 1/2n)\n- 解决思路\n  - 增加单位Task的内存可用量\n    - 增加heap的值：spark.executor.memory (java -Xmx)\n    - 减少单个executor的task数，即减少n，spark.executor.cores\n  - 减少单位Task的内存消耗量\n    - 增加partition，降低Task处理的数据，增加spark.default.parallism或者spark.sql.shuffle.partition(sql应用)\n    - 调整应用逻辑，降低内存使用\n      - groupByKey -> reduceByKey\n      - 数据预处理，降低倾斜\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhet710nmj30wb0h2k0u.jpg\" alt=\"image-20200605144437338\" style=\"zoom:50%;\" />\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhetjtbomj30sj0hwdql.jpg\" alt=\"image-20200605144456476\" style=\"zoom: 60%;\" />\n\n \n\n常见异常2：\n\n- killed by yarn\n  - Executor不存在子进程\n    - yarn监控到的container的内存为JVM内存\n    - 此时，killed by yarn为JVM非堆内存不足所致，也就是超过了overhead设置的内存\n  - 调整方案\n    - 增加overhead量\n      - spark.yarn.executor.memoryOverHead\n      - scala或者java应用，默认2G能满足需求\n    - 减少cores,也就是减少n\n  - Executor存在子进程\n    - container监控内存=executor内存(E) + 子进程内存（S）\n    - 子进程对内存资源的占用会压缩E\n  - 典型场景\n    - PySpark, JVM + PVM\n  - 调整方案，增加overhead量\n\n \n\n### **Spark Shuffle优化：** \n\nshuffle挑战：\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhex22uzmj30ux0hcdmw.jpg\" alt=\"image-20200605144817474\" style=\"zoom:60%;\" />\n\nI/O优化：\n\n![image-20200605144842117](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhexwmo8hj30g50820wh.jpg)\n\n \n\n避免shuffle的broadcast hash join\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhexxv824j30th0fydmf.jpg\" alt=\"image-20200605144901134\" style=\"zoom:60%;\" />\n\n缺点：很耗driver内存，例如16M的broadcast的数据，耗费100M的driver内存。\n\n \n\nCBO是优化join时候的build表的，从而达到各种broadcast join / shuffle hash join(先shuffle，再broadcast)的目的， sort merge join就是我们目前经常用的。\n\n​                          <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfheyd8nopj30n00exjw0.jpg\" alt=\"image-20200605144936196\" style=\"zoom:67%;\" />\n\n默认不开启是为了driver内存考虑，下次可以尝试开启试一下。\n\n \n\n \n\n \n\n ","source":"_posts/大数据/Spark/Spark性能调优.md","raw":"---\ntitle: Spark调优以及各名词深刻理解\ndate: 2018-11-28 22:06:02\ncategories: [大数据,Spark]\n---\n\n### **Spark资源优化：**\n\n队列是根据Fair调度分配资源的。\n\n静态资源分配方式的问题： \n\n- stage非对称\n- Task非对称-数据倾斜\n- 执行时间随意性\n\n \n\n所以需要根据任务动态分配资源。例如：\n\nExecutor资源量相关：\n\nspark.dynamicAllocation.minExecutors\n\nspark.dynamicAllocation.maxExecutors\n\n这个就会让任务根据资源需求而自动调整executors。\n\n \n\n遗留参数\n\nspark.executor.instances -- 这个参数是老版本的，静态资源分配，不要用了。\n\n \n\n### **Spark内存优化：**\n\n内存模型（heap就是工作用的可用内存，超过了就OOM，滴滴NodeManager指定了不超过15G，超过了就被yarn killed）\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfheqfmzdsj30nm0gkjxu.jpg\" alt=\"image-20200605144153817\" style=\"zoom:67%;\" />\n\n \n\n统一内存模型：(可用内存 = 统一内存+其他，统一内存= 存储内存+计算内存)\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfheri64lbj30ux0i9dr5.jpg\" alt=\"image-20200605144258996\" style=\"zoom:67%;\" />\n\n​      <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhes1vdxuj30uz0i8k3o.jpg\" alt=\"image-20200605144331698\" style=\"zoom:67%;\" /> \n\nacutal used大于heap memory：因为还有overhead的开销\n\n \n\n常见异常1：\n\n- Executor OOM（具体其实是executor中的task超出了heap内存）\n  - heap内存不够，TASK需要更多内存(task是在这个executor上的任务，最低保障是 1/2n)\n- 解决思路\n  - 增加单位Task的内存可用量\n    - 增加heap的值：spark.executor.memory (java -Xmx)\n    - 减少单个executor的task数，即减少n，spark.executor.cores\n  - 减少单位Task的内存消耗量\n    - 增加partition，降低Task处理的数据，增加spark.default.parallism或者spark.sql.shuffle.partition(sql应用)\n    - 调整应用逻辑，降低内存使用\n      - groupByKey -> reduceByKey\n      - 数据预处理，降低倾斜\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhet710nmj30wb0h2k0u.jpg\" alt=\"image-20200605144437338\" style=\"zoom:50%;\" />\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhetjtbomj30sj0hwdql.jpg\" alt=\"image-20200605144456476\" style=\"zoom: 60%;\" />\n\n \n\n常见异常2：\n\n- killed by yarn\n  - Executor不存在子进程\n    - yarn监控到的container的内存为JVM内存\n    - 此时，killed by yarn为JVM非堆内存不足所致，也就是超过了overhead设置的内存\n  - 调整方案\n    - 增加overhead量\n      - spark.yarn.executor.memoryOverHead\n      - scala或者java应用，默认2G能满足需求\n    - 减少cores,也就是减少n\n  - Executor存在子进程\n    - container监控内存=executor内存(E) + 子进程内存（S）\n    - 子进程对内存资源的占用会压缩E\n  - 典型场景\n    - PySpark, JVM + PVM\n  - 调整方案，增加overhead量\n\n \n\n### **Spark Shuffle优化：** \n\nshuffle挑战：\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhex22uzmj30ux0hcdmw.jpg\" alt=\"image-20200605144817474\" style=\"zoom:60%;\" />\n\nI/O优化：\n\n![image-20200605144842117](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhexwmo8hj30g50820wh.jpg)\n\n \n\n避免shuffle的broadcast hash join\n\n<img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhexxv824j30th0fydmf.jpg\" alt=\"image-20200605144901134\" style=\"zoom:60%;\" />\n\n缺点：很耗driver内存，例如16M的broadcast的数据，耗费100M的driver内存。\n\n \n\nCBO是优化join时候的build表的，从而达到各种broadcast join / shuffle hash join(先shuffle，再broadcast)的目的， sort merge join就是我们目前经常用的。\n\n​                          <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfheyd8nopj30n00exjw0.jpg\" alt=\"image-20200605144936196\" style=\"zoom:67%;\" />\n\n默认不开启是为了driver内存考虑，下次可以尝试开启试一下。\n\n \n\n \n\n \n\n ","slug":"大数据/Spark/Spark性能调优","published":1,"updated":"2022-09-15T03:46:43.360Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qh005wjqrrztfpybeb","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"Spark资源优化：\"><a href=\"#Spark资源优化：\" class=\"headerlink\" title=\"Spark资源优化：\"></a><strong>Spark资源优化：</strong></h3><p>队列是根据Fair调度分配资源的。</p>\n<p>静态资源分配方式的问题： </p>\n<ul>\n<li>stage非对称</li>\n<li>Task非对称-数据倾斜</li>\n<li>执行时间随意性</li>\n</ul>\n<p>所以需要根据任务动态分配资源。例如：</p>\n<p>Executor资源量相关：</p>\n<p>spark.dynamicAllocation.minExecutors</p>\n<p>spark.dynamicAllocation.maxExecutors</p>\n<p>这个就会让任务根据资源需求而自动调整executors。</p>\n<p>遗留参数</p>\n<p>spark.executor.instances — 这个参数是老版本的，静态资源分配，不要用了。</p>\n<h3 id=\"Spark内存优化：\"><a href=\"#Spark内存优化：\" class=\"headerlink\" title=\"Spark内存优化：\"></a><strong>Spark内存优化：</strong></h3><p>内存模型（heap就是工作用的可用内存，超过了就OOM，滴滴NodeManager指定了不超过15G，超过了就被yarn killed）</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfheqfmzdsj30nm0gkjxu.jpg\" alt=\"image-20200605144153817\" style=\"zoom:67%;\"></p>\n<p>统一内存模型：(可用内存 = 统一内存+其他，统一内存= 存储内存+计算内存)</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfheri64lbj30ux0i9dr5.jpg\" alt=\"image-20200605144258996\" style=\"zoom:67%;\"></p>\n<p>​      <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhes1vdxuj30uz0i8k3o.jpg\" alt=\"image-20200605144331698\" style=\"zoom:67%;\"> </p>\n<p>acutal used大于heap memory：因为还有overhead的开销</p>\n<p>常见异常1：</p>\n<ul>\n<li>Executor OOM（具体其实是executor中的task超出了heap内存）<ul>\n<li>heap内存不够，TASK需要更多内存(task是在这个executor上的任务，最低保障是 1/2n)</li>\n</ul>\n</li>\n<li>解决思路<ul>\n<li>增加单位Task的内存可用量<ul>\n<li>增加heap的值：spark.executor.memory (java -Xmx)</li>\n<li>减少单个executor的task数，即减少n，spark.executor.cores</li>\n</ul>\n</li>\n<li>减少单位Task的内存消耗量<ul>\n<li>增加partition，降低Task处理的数据，增加spark.default.parallism或者spark.sql.shuffle.partition(sql应用)</li>\n<li>调整应用逻辑，降低内存使用<ul>\n<li>groupByKey -&gt; reduceByKey</li>\n<li>数据预处理，降低倾斜</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhet710nmj30wb0h2k0u.jpg\" alt=\"image-20200605144437338\" style=\"zoom:50%;\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhetjtbomj30sj0hwdql.jpg\" alt=\"image-20200605144456476\" style=\"zoom: 60%;\"></p>\n<p>常见异常2：</p>\n<ul>\n<li>killed by yarn<ul>\n<li>Executor不存在子进程<ul>\n<li>yarn监控到的container的内存为JVM内存</li>\n<li>此时，killed by yarn为JVM非堆内存不足所致，也就是超过了overhead设置的内存</li>\n</ul>\n</li>\n<li>调整方案<ul>\n<li>增加overhead量<ul>\n<li>spark.yarn.executor.memoryOverHead</li>\n<li>scala或者java应用，默认2G能满足需求</li>\n</ul>\n</li>\n<li>减少cores,也就是减少n</li>\n</ul>\n</li>\n<li>Executor存在子进程<ul>\n<li>container监控内存=executor内存(E) + 子进程内存（S）</li>\n<li>子进程对内存资源的占用会压缩E</li>\n</ul>\n</li>\n<li>典型场景<ul>\n<li>PySpark, JVM + PVM</li>\n</ul>\n</li>\n<li>调整方案，增加overhead量</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Spark-Shuffle优化：\"><a href=\"#Spark-Shuffle优化：\" class=\"headerlink\" title=\"Spark Shuffle优化：\"></a><strong>Spark Shuffle优化：</strong></h3><p>shuffle挑战：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhex22uzmj30ux0hcdmw.jpg\" alt=\"image-20200605144817474\" style=\"zoom:60%;\"></p>\n<p>I/O优化：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhexwmo8hj30g50820wh.jpg\" alt=\"image-20200605144842117\"></p>\n<p>避免shuffle的broadcast hash join</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhexxv824j30th0fydmf.jpg\" alt=\"image-20200605144901134\" style=\"zoom:60%;\"></p>\n<p>缺点：很耗driver内存，例如16M的broadcast的数据，耗费100M的driver内存。</p>\n<p>CBO是优化join时候的build表的，从而达到各种broadcast join / shuffle hash join(先shuffle，再broadcast)的目的， sort merge join就是我们目前经常用的。</p>\n<p>​                          <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfheyd8nopj30n00exjw0.jpg\" alt=\"image-20200605144936196\" style=\"zoom:67%;\"></p>\n<p>默认不开启是为了driver内存考虑，下次可以尝试开启试一下。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Spark资源优化：\"><a href=\"#Spark资源优化：\" class=\"headerlink\" title=\"Spark资源优化：\"></a><strong>Spark资源优化：</strong></h3><p>队列是根据Fair调度分配资源的。</p>\n<p>静态资源分配方式的问题： </p>\n<ul>\n<li>stage非对称</li>\n<li>Task非对称-数据倾斜</li>\n<li>执行时间随意性</li>\n</ul>\n<p>所以需要根据任务动态分配资源。例如：</p>\n<p>Executor资源量相关：</p>\n<p>spark.dynamicAllocation.minExecutors</p>\n<p>spark.dynamicAllocation.maxExecutors</p>\n<p>这个就会让任务根据资源需求而自动调整executors。</p>\n<p>遗留参数</p>\n<p>spark.executor.instances — 这个参数是老版本的，静态资源分配，不要用了。</p>\n<h3 id=\"Spark内存优化：\"><a href=\"#Spark内存优化：\" class=\"headerlink\" title=\"Spark内存优化：\"></a><strong>Spark内存优化：</strong></h3><p>内存模型（heap就是工作用的可用内存，超过了就OOM，滴滴NodeManager指定了不超过15G，超过了就被yarn killed）</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfheqfmzdsj30nm0gkjxu.jpg\" alt=\"image-20200605144153817\" style=\"zoom:67%;\"></p>\n<p>统一内存模型：(可用内存 = 统一内存+其他，统一内存= 存储内存+计算内存)</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfheri64lbj30ux0i9dr5.jpg\" alt=\"image-20200605144258996\" style=\"zoom:67%;\"></p>\n<p>​      <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhes1vdxuj30uz0i8k3o.jpg\" alt=\"image-20200605144331698\" style=\"zoom:67%;\"> </p>\n<p>acutal used大于heap memory：因为还有overhead的开销</p>\n<p>常见异常1：</p>\n<ul>\n<li>Executor OOM（具体其实是executor中的task超出了heap内存）<ul>\n<li>heap内存不够，TASK需要更多内存(task是在这个executor上的任务，最低保障是 1/2n)</li>\n</ul>\n</li>\n<li>解决思路<ul>\n<li>增加单位Task的内存可用量<ul>\n<li>增加heap的值：spark.executor.memory (java -Xmx)</li>\n<li>减少单个executor的task数，即减少n，spark.executor.cores</li>\n</ul>\n</li>\n<li>减少单位Task的内存消耗量<ul>\n<li>增加partition，降低Task处理的数据，增加spark.default.parallism或者spark.sql.shuffle.partition(sql应用)</li>\n<li>调整应用逻辑，降低内存使用<ul>\n<li>groupByKey -&gt; reduceByKey</li>\n<li>数据预处理，降低倾斜</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhet710nmj30wb0h2k0u.jpg\" alt=\"image-20200605144437338\" style=\"zoom:50%;\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhetjtbomj30sj0hwdql.jpg\" alt=\"image-20200605144456476\" style=\"zoom: 60%;\"></p>\n<p>常见异常2：</p>\n<ul>\n<li>killed by yarn<ul>\n<li>Executor不存在子进程<ul>\n<li>yarn监控到的container的内存为JVM内存</li>\n<li>此时，killed by yarn为JVM非堆内存不足所致，也就是超过了overhead设置的内存</li>\n</ul>\n</li>\n<li>调整方案<ul>\n<li>增加overhead量<ul>\n<li>spark.yarn.executor.memoryOverHead</li>\n<li>scala或者java应用，默认2G能满足需求</li>\n</ul>\n</li>\n<li>减少cores,也就是减少n</li>\n</ul>\n</li>\n<li>Executor存在子进程<ul>\n<li>container监控内存=executor内存(E) + 子进程内存（S）</li>\n<li>子进程对内存资源的占用会压缩E</li>\n</ul>\n</li>\n<li>典型场景<ul>\n<li>PySpark, JVM + PVM</li>\n</ul>\n</li>\n<li>调整方案，增加overhead量</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Spark-Shuffle优化：\"><a href=\"#Spark-Shuffle优化：\" class=\"headerlink\" title=\"Spark Shuffle优化：\"></a><strong>Spark Shuffle优化：</strong></h3><p>shuffle挑战：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhex22uzmj30ux0hcdmw.jpg\" alt=\"image-20200605144817474\" style=\"zoom:60%;\"></p>\n<p>I/O优化：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhexwmo8hj30g50820wh.jpg\" alt=\"image-20200605144842117\"></p>\n<p>避免shuffle的broadcast hash join</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhexxv824j30th0fydmf.jpg\" alt=\"image-20200605144901134\" style=\"zoom:60%;\"></p>\n<p>缺点：很耗driver内存，例如16M的broadcast的数据，耗费100M的driver内存。</p>\n<p>CBO是优化join时候的build表的，从而达到各种broadcast join / shuffle hash join(先shuffle，再broadcast)的目的， sort merge join就是我们目前经常用的。</p>\n<p>​                          <img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfheyd8nopj30n00exjw0.jpg\" alt=\"image-20200605144936196\" style=\"zoom:67%;\"></p>\n<p>默认不开启是为了driver内存考虑，下次可以尝试开启试一下。</p>\n"},{"title":"关于线程/进程的理解","date":"2020-12-15T16:00:00.000Z","_content":"\n\n\n最近对线程有了一些的新的理解，再整理一下知识点：\n\n- 线程的执行单位是core，一个cpu可以有多个core，所以为啥现在计算就主打多核cpu..\n- 但实际上即使是一个core，也可以实现并发，因为线程之间可以随时切换，因为有thread context这个信息，下面会提。\n- 我们实现一个服务/进程，有多时候都会用多线程来并发处理，那么来看下线程的共享资源单位：\n  - 代码区：毫无疑问，就是二进制的代码文件\n  - 动态链接库地址：就是依赖的外部库，c/c++在window是ddl，在linux是so\n  - 堆区：就是对象，c/c++里是new、malloc的对象，java也是new出来的对象。\n  - 栈区：\n    - 局部变量\n    - thread context，包含函数栈指针、程序计数器等，简单理解就是这个函数可能会调用多个其他函数，比如递归，那么就有个栈指针来记录这个上下文信息\n    - 原则上栈区是每个thread独有的，但是依旧是可以被其他thread修改，所以就有多进程里的各种线程锁之类的处理。\n- Spark中，一个executor可以有多个core，但是内存是按照executor来分配的，也就是core越多，多进程的话，就越吃机器的内存。内存分为memory和memoryOverHead，前者应该就是放工作数据的堆区，后者是栈区。\n\n","source":"_posts/大数据/Spark/关于线程进程的理解.md","raw":"---\ntitle: 关于线程/进程的理解\ndate: 2020-12-16\ntags: 并发\ncategories: [大数据,Spark]\n---\n\n\n\n最近对线程有了一些的新的理解，再整理一下知识点：\n\n- 线程的执行单位是core，一个cpu可以有多个core，所以为啥现在计算就主打多核cpu..\n- 但实际上即使是一个core，也可以实现并发，因为线程之间可以随时切换，因为有thread context这个信息，下面会提。\n- 我们实现一个服务/进程，有多时候都会用多线程来并发处理，那么来看下线程的共享资源单位：\n  - 代码区：毫无疑问，就是二进制的代码文件\n  - 动态链接库地址：就是依赖的外部库，c/c++在window是ddl，在linux是so\n  - 堆区：就是对象，c/c++里是new、malloc的对象，java也是new出来的对象。\n  - 栈区：\n    - 局部变量\n    - thread context，包含函数栈指针、程序计数器等，简单理解就是这个函数可能会调用多个其他函数，比如递归，那么就有个栈指针来记录这个上下文信息\n    - 原则上栈区是每个thread独有的，但是依旧是可以被其他thread修改，所以就有多进程里的各种线程锁之类的处理。\n- Spark中，一个executor可以有多个core，但是内存是按照executor来分配的，也就是core越多，多进程的话，就越吃机器的内存。内存分为memory和memoryOverHead，前者应该就是放工作数据的堆区，后者是栈区。\n\n","slug":"大数据/Spark/关于线程进程的理解","published":1,"updated":"2022-09-15T03:46:43.360Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qh005yjqrr2ayicpci","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>最近对线程有了一些的新的理解，再整理一下知识点：</p>\n<ul>\n<li>线程的执行单位是core，一个cpu可以有多个core，所以为啥现在计算就主打多核cpu..</li>\n<li>但实际上即使是一个core，也可以实现并发，因为线程之间可以随时切换，因为有thread context这个信息，下面会提。</li>\n<li>我们实现一个服务/进程，有多时候都会用多线程来并发处理，那么来看下线程的共享资源单位：<ul>\n<li>代码区：毫无疑问，就是二进制的代码文件</li>\n<li>动态链接库地址：就是依赖的外部库，c/c++在window是ddl，在linux是so</li>\n<li>堆区：就是对象，c/c++里是new、malloc的对象，java也是new出来的对象。</li>\n<li>栈区：<ul>\n<li>局部变量</li>\n<li>thread context，包含函数栈指针、程序计数器等，简单理解就是这个函数可能会调用多个其他函数，比如递归，那么就有个栈指针来记录这个上下文信息</li>\n<li>原则上栈区是每个thread独有的，但是依旧是可以被其他thread修改，所以就有多进程里的各种线程锁之类的处理。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Spark中，一个executor可以有多个core，但是内存是按照executor来分配的，也就是core越多，多进程的话，就越吃机器的内存。内存分为memory和memoryOverHead，前者应该就是放工作数据的堆区，后者是栈区。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>最近对线程有了一些的新的理解，再整理一下知识点：</p>\n<ul>\n<li>线程的执行单位是core，一个cpu可以有多个core，所以为啥现在计算就主打多核cpu..</li>\n<li>但实际上即使是一个core，也可以实现并发，因为线程之间可以随时切换，因为有thread context这个信息，下面会提。</li>\n<li>我们实现一个服务/进程，有多时候都会用多线程来并发处理，那么来看下线程的共享资源单位：<ul>\n<li>代码区：毫无疑问，就是二进制的代码文件</li>\n<li>动态链接库地址：就是依赖的外部库，c/c++在window是ddl，在linux是so</li>\n<li>堆区：就是对象，c/c++里是new、malloc的对象，java也是new出来的对象。</li>\n<li>栈区：<ul>\n<li>局部变量</li>\n<li>thread context，包含函数栈指针、程序计数器等，简单理解就是这个函数可能会调用多个其他函数，比如递归，那么就有个栈指针来记录这个上下文信息</li>\n<li>原则上栈区是每个thread独有的，但是依旧是可以被其他thread修改，所以就有多进程里的各种线程锁之类的处理。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Spark中，一个executor可以有多个core，但是内存是按照executor来分配的，也就是core越多，多进程的话，就越吃机器的内存。内存分为memory和memoryOverHead，前者应该就是放工作数据的堆区，后者是栈区。</li>\n</ul>\n"},{"title":"多进程，多线程以及spark的executor等概念","date":"2018-11-07T14:06:02.000Z","_content":"\n在spark中，\n\n- worker就是集群里可执行的机器，一个worker可以有多个executor。\n- 一个executor就是CPU，一个CPU可以有多个核。\n- 一个core(核)对应一个线程，也就是一个task，一个核同时只能执行一个task。注意，这个的core不是指物理核，是虚拟核。\n\n \n\n关于CPU和核：\n\n- CPU有单核CPU和多核CPU。\n- 一般来讲几个物理核就是几个线程，但是通过超线程技术，一个物理核可以分成多个虚拟核，从而使得一个核可以有多个线程。但是，一个核同时只能执行一个线程。\n- 并发：多个线程在单个核心运行，同一时间一个线程运行，系统不停切换线程，看起来像同时运行，实际上是线程不停切换。\n- 并行：多个线程在多个核心运行，线程同时运行。\n- 串行和并发的区别：虽然都是同时运行一个线程，但是串行就只能一个一个线程串行处理，就是一个结束了再起另一个线程，而并发本质上还是可以处理多个线程。\n\n \n\n选择多个单核CPU和单个多核CPU？\n\n- 多核CPU共享数据是通过CPU内部的总线，多个单核CPU共享数据是通过主板的总线，通信开销更大。\n- 多核CPU只需要一套芯片组，一套存储，而多个单核CPU，每一个CPU都需要有较为独立的电路支持，有自己的Cache。如果要多个耗内存的大型程序，还是需要多个单核CPU。\n\n \n\n多进程和多线程：\n\n- 进程是分配资源(包括了CPU、内存、磁盘IO等)的最小单位，线程是CPU分配和调度的单位。一个进程是由多个线程组成的。其实我理解无论线程和进程都是要分配资源的，但是进程涉及的资源分配更多，而线程只涉及CPU里的资源分配，进程更加宏观，线程更加精细。\n- 同一个进程内的多线程是共享资源的，因此数据共享非常方便，占用内存少，切换速度快，CPU利用率高，但是缺点就是编程较为复杂，涉及到锁之类的，同时一个线程挂导致整个进程挂，鲁棒性比较差。\n- 进程之间的通信是通过管道，信号之类的，数据要共享的话涉及到共享内存，比较复杂，同时占用内存多，切换复杂，CPU利用率低，但优点就是变成简单，且进程间不受影响，鲁棒性高。\n\n![image-20200605145655675](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhf5zn73gj30sm0ajq97.jpg)\n\n \n\n ","source":"_posts/大数据/Spark/多进程，多线程以及spark的executor等概念.md","raw":"---\ntitle: 多进程，多线程以及spark的executor等概念\ndate: 2018-11-07 22:06:02\ntags: 并发\ncategories: [大数据,Spark]\n---\n\n在spark中，\n\n- worker就是集群里可执行的机器，一个worker可以有多个executor。\n- 一个executor就是CPU，一个CPU可以有多个核。\n- 一个core(核)对应一个线程，也就是一个task，一个核同时只能执行一个task。注意，这个的core不是指物理核，是虚拟核。\n\n \n\n关于CPU和核：\n\n- CPU有单核CPU和多核CPU。\n- 一般来讲几个物理核就是几个线程，但是通过超线程技术，一个物理核可以分成多个虚拟核，从而使得一个核可以有多个线程。但是，一个核同时只能执行一个线程。\n- 并发：多个线程在单个核心运行，同一时间一个线程运行，系统不停切换线程，看起来像同时运行，实际上是线程不停切换。\n- 并行：多个线程在多个核心运行，线程同时运行。\n- 串行和并发的区别：虽然都是同时运行一个线程，但是串行就只能一个一个线程串行处理，就是一个结束了再起另一个线程，而并发本质上还是可以处理多个线程。\n\n \n\n选择多个单核CPU和单个多核CPU？\n\n- 多核CPU共享数据是通过CPU内部的总线，多个单核CPU共享数据是通过主板的总线，通信开销更大。\n- 多核CPU只需要一套芯片组，一套存储，而多个单核CPU，每一个CPU都需要有较为独立的电路支持，有自己的Cache。如果要多个耗内存的大型程序，还是需要多个单核CPU。\n\n \n\n多进程和多线程：\n\n- 进程是分配资源(包括了CPU、内存、磁盘IO等)的最小单位，线程是CPU分配和调度的单位。一个进程是由多个线程组成的。其实我理解无论线程和进程都是要分配资源的，但是进程涉及的资源分配更多，而线程只涉及CPU里的资源分配，进程更加宏观，线程更加精细。\n- 同一个进程内的多线程是共享资源的，因此数据共享非常方便，占用内存少，切换速度快，CPU利用率高，但是缺点就是编程较为复杂，涉及到锁之类的，同时一个线程挂导致整个进程挂，鲁棒性比较差。\n- 进程之间的通信是通过管道，信号之类的，数据要共享的话涉及到共享内存，比较复杂，同时占用内存多，切换复杂，CPU利用率低，但优点就是变成简单，且进程间不受影响，鲁棒性高。\n\n![image-20200605145655675](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhf5zn73gj30sm0ajq97.jpg)\n\n \n\n ","slug":"大数据/Spark/多进程，多线程以及spark的executor等概念","published":1,"updated":"2022-09-15T03:46:43.360Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qi0060jqrrk1dk1mq0","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>在spark中，</p>\n<ul>\n<li>worker就是集群里可执行的机器，一个worker可以有多个executor。</li>\n<li>一个executor就是CPU，一个CPU可以有多个核。</li>\n<li>一个core(核)对应一个线程，也就是一个task，一个核同时只能执行一个task。注意，这个的core不是指物理核，是虚拟核。</li>\n</ul>\n<p>关于CPU和核：</p>\n<ul>\n<li>CPU有单核CPU和多核CPU。</li>\n<li>一般来讲几个物理核就是几个线程，但是通过超线程技术，一个物理核可以分成多个虚拟核，从而使得一个核可以有多个线程。但是，一个核同时只能执行一个线程。</li>\n<li>并发：多个线程在单个核心运行，同一时间一个线程运行，系统不停切换线程，看起来像同时运行，实际上是线程不停切换。</li>\n<li>并行：多个线程在多个核心运行，线程同时运行。</li>\n<li>串行和并发的区别：虽然都是同时运行一个线程，但是串行就只能一个一个线程串行处理，就是一个结束了再起另一个线程，而并发本质上还是可以处理多个线程。</li>\n</ul>\n<p>选择多个单核CPU和单个多核CPU？</p>\n<ul>\n<li>多核CPU共享数据是通过CPU内部的总线，多个单核CPU共享数据是通过主板的总线，通信开销更大。</li>\n<li>多核CPU只需要一套芯片组，一套存储，而多个单核CPU，每一个CPU都需要有较为独立的电路支持，有自己的Cache。如果要多个耗内存的大型程序，还是需要多个单核CPU。</li>\n</ul>\n<p>多进程和多线程：</p>\n<ul>\n<li>进程是分配资源(包括了CPU、内存、磁盘IO等)的最小单位，线程是CPU分配和调度的单位。一个进程是由多个线程组成的。其实我理解无论线程和进程都是要分配资源的，但是进程涉及的资源分配更多，而线程只涉及CPU里的资源分配，进程更加宏观，线程更加精细。</li>\n<li>同一个进程内的多线程是共享资源的，因此数据共享非常方便，占用内存少，切换速度快，CPU利用率高，但是缺点就是编程较为复杂，涉及到锁之类的，同时一个线程挂导致整个进程挂，鲁棒性比较差。</li>\n<li>进程之间的通信是通过管道，信号之类的，数据要共享的话涉及到共享内存，比较复杂，同时占用内存多，切换复杂，CPU利用率低，但优点就是变成简单，且进程间不受影响，鲁棒性高。</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhf5zn73gj30sm0ajq97.jpg\" alt=\"image-20200605145655675\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>在spark中，</p>\n<ul>\n<li>worker就是集群里可执行的机器，一个worker可以有多个executor。</li>\n<li>一个executor就是CPU，一个CPU可以有多个核。</li>\n<li>一个core(核)对应一个线程，也就是一个task，一个核同时只能执行一个task。注意，这个的core不是指物理核，是虚拟核。</li>\n</ul>\n<p>关于CPU和核：</p>\n<ul>\n<li>CPU有单核CPU和多核CPU。</li>\n<li>一般来讲几个物理核就是几个线程，但是通过超线程技术，一个物理核可以分成多个虚拟核，从而使得一个核可以有多个线程。但是，一个核同时只能执行一个线程。</li>\n<li>并发：多个线程在单个核心运行，同一时间一个线程运行，系统不停切换线程，看起来像同时运行，实际上是线程不停切换。</li>\n<li>并行：多个线程在多个核心运行，线程同时运行。</li>\n<li>串行和并发的区别：虽然都是同时运行一个线程，但是串行就只能一个一个线程串行处理，就是一个结束了再起另一个线程，而并发本质上还是可以处理多个线程。</li>\n</ul>\n<p>选择多个单核CPU和单个多核CPU？</p>\n<ul>\n<li>多核CPU共享数据是通过CPU内部的总线，多个单核CPU共享数据是通过主板的总线，通信开销更大。</li>\n<li>多核CPU只需要一套芯片组，一套存储，而多个单核CPU，每一个CPU都需要有较为独立的电路支持，有自己的Cache。如果要多个耗内存的大型程序，还是需要多个单核CPU。</li>\n</ul>\n<p>多进程和多线程：</p>\n<ul>\n<li>进程是分配资源(包括了CPU、内存、磁盘IO等)的最小单位，线程是CPU分配和调度的单位。一个进程是由多个线程组成的。其实我理解无论线程和进程都是要分配资源的，但是进程涉及的资源分配更多，而线程只涉及CPU里的资源分配，进程更加宏观，线程更加精细。</li>\n<li>同一个进程内的多线程是共享资源的，因此数据共享非常方便，占用内存少，切换速度快，CPU利用率高，但是缺点就是编程较为复杂，涉及到锁之类的，同时一个线程挂导致整个进程挂，鲁棒性比较差。</li>\n<li>进程之间的通信是通过管道，信号之类的，数据要共享的话涉及到共享内存，比较复杂，同时占用内存多，切换复杂，CPU利用率低，但优点就是变成简单，且进程间不受影响，鲁棒性高。</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhf5zn73gj30sm0ajq97.jpg\" alt=\"image-20200605145655675\"></p>\n"},{"title":"Ubuntu与Windows之间的远程连接","date":"2017-06-13T07:34:47.000Z","_content":"\n之前使用Ubuntu 14.04时其实一直没有很好得解决远程桌面连接的问题，每次用到实验室的Windows服务器时，我都会切换到windows系统去使用。。可以说非常不方便了。这回重装Ubuntu16.04，总算是解决了这个问题，并且还解决了Windows连接Ubuntu的问题。\n\n# Ubuntu连接Windows服务器\n其实Ubuntu下也有类似Windows远程连接的很方便的自带软件，那就是remmina，remmina支持很多协议，包括rdp，vnc等等，我们这里选用rdp协议来连接windows服务器。\n\n<!-- more -->\nRemmina有着简单易懂的图形界面，建立连接很简单。事实上，之前用Ubuntu 14.04时我就用过remmina，但当时碰到了一个很棘手的问题，那就是只能建立远程连接，而无法传输文件。在设置中有一个共享文件夹的选项，但是即使勾选后在windows中依然无法显示（windows服务器版本为sever 2012R）。所幸经过一番搜索，我发现了问题的解决办法，只需要利用第三方软件源将remmina进行版本更新。\n```\nsudo apt-add-repository ppa:remmina-ppa-team/remmina-next\nsudo apt-get update\nsudo apt-get install remmina remmina-plugin-rdp libfreerdp-plugins-standard\n```\n然后再重启remmina，就可以使用共享文件夹了。\n\n# Windows连接Ubuntu\n实验室的工作电脑我装的是Ubuntu，但是笔记本我装的是Windows系统，并且平时笔记本一般放在寝室。为了能在寝室用笔记本连接实验室的Ubuntu(就是爱学习！),我尝试了一些办法，我觉得最好的办法就是用teamviewer!\n\n## Teamviewer安装\n从[官网](https://www.teamviewer.com/en/download/linux/)下载deb文件（非商业用途的个人版本是免费的），然后执行命令（建议使用apt-get安装以解决依赖问题）\n```\nsudo apt-get install ./teamviewer*.deb\n```\n\n## Teamviewer使用\n\n在Ubuntu中打开teamviewer后会生成了一个ID和密码，我们只要在windows段也打开teamviewer，输入该ID和密码就可以连接到Ubuntu了。注意，这种连接方式是需要联网的。\n\n如果想要不联网，在内网中直接使用的话，我们需要设置`Extras->Options->General->Incoming LAN connections`选择accept exclusively,这样的话，就只会通过局域网连接了，ID也会显示为你的局域网中的ID。经过测试，我觉得teamviewer的连接速度也是挺给力的！赞！\n","source":"_posts/操作系统/Linux/Ubuntu与Windows之间的远程连接.md","raw":"---\ntitle: Ubuntu与Windows之间的远程连接\ndate: 2017-06-13 15:34:47\ncategories: [操作系统,Linux]\n---\n\n之前使用Ubuntu 14.04时其实一直没有很好得解决远程桌面连接的问题，每次用到实验室的Windows服务器时，我都会切换到windows系统去使用。。可以说非常不方便了。这回重装Ubuntu16.04，总算是解决了这个问题，并且还解决了Windows连接Ubuntu的问题。\n\n# Ubuntu连接Windows服务器\n其实Ubuntu下也有类似Windows远程连接的很方便的自带软件，那就是remmina，remmina支持很多协议，包括rdp，vnc等等，我们这里选用rdp协议来连接windows服务器。\n\n<!-- more -->\nRemmina有着简单易懂的图形界面，建立连接很简单。事实上，之前用Ubuntu 14.04时我就用过remmina，但当时碰到了一个很棘手的问题，那就是只能建立远程连接，而无法传输文件。在设置中有一个共享文件夹的选项，但是即使勾选后在windows中依然无法显示（windows服务器版本为sever 2012R）。所幸经过一番搜索，我发现了问题的解决办法，只需要利用第三方软件源将remmina进行版本更新。\n```\nsudo apt-add-repository ppa:remmina-ppa-team/remmina-next\nsudo apt-get update\nsudo apt-get install remmina remmina-plugin-rdp libfreerdp-plugins-standard\n```\n然后再重启remmina，就可以使用共享文件夹了。\n\n# Windows连接Ubuntu\n实验室的工作电脑我装的是Ubuntu，但是笔记本我装的是Windows系统，并且平时笔记本一般放在寝室。为了能在寝室用笔记本连接实验室的Ubuntu(就是爱学习！),我尝试了一些办法，我觉得最好的办法就是用teamviewer!\n\n## Teamviewer安装\n从[官网](https://www.teamviewer.com/en/download/linux/)下载deb文件（非商业用途的个人版本是免费的），然后执行命令（建议使用apt-get安装以解决依赖问题）\n```\nsudo apt-get install ./teamviewer*.deb\n```\n\n## Teamviewer使用\n\n在Ubuntu中打开teamviewer后会生成了一个ID和密码，我们只要在windows段也打开teamviewer，输入该ID和密码就可以连接到Ubuntu了。注意，这种连接方式是需要联网的。\n\n如果想要不联网，在内网中直接使用的话，我们需要设置`Extras->Options->General->Incoming LAN connections`选择accept exclusively,这样的话，就只会通过局域网连接了，ID也会显示为你的局域网中的ID。经过测试，我觉得teamviewer的连接速度也是挺给力的！赞！\n","slug":"操作系统/Linux/Ubuntu与Windows之间的远程连接","published":1,"updated":"2022-09-15T03:46:43.360Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qj0063jqrrw5ekwuym","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>之前使用Ubuntu 14.04时其实一直没有很好得解决远程桌面连接的问题，每次用到实验室的Windows服务器时，我都会切换到windows系统去使用。。可以说非常不方便了。这回重装Ubuntu16.04，总算是解决了这个问题，并且还解决了Windows连接Ubuntu的问题。</p>\n<h1 id=\"Ubuntu连接Windows服务器\"><a href=\"#Ubuntu连接Windows服务器\" class=\"headerlink\" title=\"Ubuntu连接Windows服务器\"></a>Ubuntu连接Windows服务器</h1><p>其实Ubuntu下也有类似Windows远程连接的很方便的自带软件，那就是remmina，remmina支持很多协议，包括rdp，vnc等等，我们这里选用rdp协议来连接windows服务器。</p>\n<a id=\"more\"></a>\n<p>Remmina有着简单易懂的图形界面，建立连接很简单。事实上，之前用Ubuntu 14.04时我就用过remmina，但当时碰到了一个很棘手的问题，那就是只能建立远程连接，而无法传输文件。在设置中有一个共享文件夹的选项，但是即使勾选后在windows中依然无法显示（windows服务器版本为sever 2012R）。所幸经过一番搜索，我发现了问题的解决办法，只需要利用第三方软件源将remmina进行版本更新。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-add-repository ppa:remmina-ppa-team/remmina-next</span><br><span class=\"line\">sudo apt-get update</span><br><span class=\"line\">sudo apt-get install remmina remmina-plugin-rdp libfreerdp-plugins-standard</span><br></pre></td></tr></table></figure></p>\n<p>然后再重启remmina，就可以使用共享文件夹了。</p>\n<h1 id=\"Windows连接Ubuntu\"><a href=\"#Windows连接Ubuntu\" class=\"headerlink\" title=\"Windows连接Ubuntu\"></a>Windows连接Ubuntu</h1><p>实验室的工作电脑我装的是Ubuntu，但是笔记本我装的是Windows系统，并且平时笔记本一般放在寝室。为了能在寝室用笔记本连接实验室的Ubuntu(就是爱学习！),我尝试了一些办法，我觉得最好的办法就是用teamviewer!</p>\n<h2 id=\"Teamviewer安装\"><a href=\"#Teamviewer安装\" class=\"headerlink\" title=\"Teamviewer安装\"></a>Teamviewer安装</h2><p>从<a href=\"https://www.teamviewer.com/en/download/linux/\" target=\"_blank\" rel=\"noopener\">官网</a>下载deb文件（非商业用途的个人版本是免费的），然后执行命令（建议使用apt-get安装以解决依赖问题）<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install ./teamviewer*.deb</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"Teamviewer使用\"><a href=\"#Teamviewer使用\" class=\"headerlink\" title=\"Teamviewer使用\"></a>Teamviewer使用</h2><p>在Ubuntu中打开teamviewer后会生成了一个ID和密码，我们只要在windows段也打开teamviewer，输入该ID和密码就可以连接到Ubuntu了。注意，这种连接方式是需要联网的。</p>\n<p>如果想要不联网，在内网中直接使用的话，我们需要设置<code>Extras-&gt;Options-&gt;General-&gt;Incoming LAN connections</code>选择accept exclusively,这样的话，就只会通过局域网连接了，ID也会显示为你的局域网中的ID。经过测试，我觉得teamviewer的连接速度也是挺给力的！赞！</p>\n","site":{"data":{}},"excerpt":"<p>之前使用Ubuntu 14.04时其实一直没有很好得解决远程桌面连接的问题，每次用到实验室的Windows服务器时，我都会切换到windows系统去使用。。可以说非常不方便了。这回重装Ubuntu16.04，总算是解决了这个问题，并且还解决了Windows连接Ubuntu的问题。</p>\n<h1 id=\"Ubuntu连接Windows服务器\"><a href=\"#Ubuntu连接Windows服务器\" class=\"headerlink\" title=\"Ubuntu连接Windows服务器\"></a>Ubuntu连接Windows服务器</h1><p>其实Ubuntu下也有类似Windows远程连接的很方便的自带软件，那就是remmina，remmina支持很多协议，包括rdp，vnc等等，我们这里选用rdp协议来连接windows服务器。</p>","more":"<p>Remmina有着简单易懂的图形界面，建立连接很简单。事实上，之前用Ubuntu 14.04时我就用过remmina，但当时碰到了一个很棘手的问题，那就是只能建立远程连接，而无法传输文件。在设置中有一个共享文件夹的选项，但是即使勾选后在windows中依然无法显示（windows服务器版本为sever 2012R）。所幸经过一番搜索，我发现了问题的解决办法，只需要利用第三方软件源将remmina进行版本更新。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-add-repository ppa:remmina-ppa-team/remmina-next</span><br><span class=\"line\">sudo apt-get update</span><br><span class=\"line\">sudo apt-get install remmina remmina-plugin-rdp libfreerdp-plugins-standard</span><br></pre></td></tr></table></figure></p>\n<p>然后再重启remmina，就可以使用共享文件夹了。</p>\n<h1 id=\"Windows连接Ubuntu\"><a href=\"#Windows连接Ubuntu\" class=\"headerlink\" title=\"Windows连接Ubuntu\"></a>Windows连接Ubuntu</h1><p>实验室的工作电脑我装的是Ubuntu，但是笔记本我装的是Windows系统，并且平时笔记本一般放在寝室。为了能在寝室用笔记本连接实验室的Ubuntu(就是爱学习！),我尝试了一些办法，我觉得最好的办法就是用teamviewer!</p>\n<h2 id=\"Teamviewer安装\"><a href=\"#Teamviewer安装\" class=\"headerlink\" title=\"Teamviewer安装\"></a>Teamviewer安装</h2><p>从<a href=\"https://www.teamviewer.com/en/download/linux/\" target=\"_blank\" rel=\"noopener\">官网</a>下载deb文件（非商业用途的个人版本是免费的），然后执行命令（建议使用apt-get安装以解决依赖问题）<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install ./teamviewer*.deb</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"Teamviewer使用\"><a href=\"#Teamviewer使用\" class=\"headerlink\" title=\"Teamviewer使用\"></a>Teamviewer使用</h2><p>在Ubuntu中打开teamviewer后会生成了一个ID和密码，我们只要在windows段也打开teamviewer，输入该ID和密码就可以连接到Ubuntu了。注意，这种连接方式是需要联网的。</p>\n<p>如果想要不联网，在内网中直接使用的话，我们需要设置<code>Extras-&gt;Options-&gt;General-&gt;Incoming LAN connections</code>选择accept exclusively,这样的话，就只会通过局域网连接了，ID也会显示为你的局域网中的ID。经过测试，我觉得teamviewer的连接速度也是挺给力的！赞！</p>"},{"title":"开始使用Ubuntu","date":"2016-04-19T12:41:51.000Z","_content":"对linux的向往由来已久，加上前阵子在win7下用vim总是感觉很不舒服，用gcc编译还要专门去下载MinGW(minmalist GNU for Windows),这么想还不如直接去用linux，GNU下的那些工具就直接能用了！在linux下打造一个IDE吧！\n> GNU's Not Unix!\n\n哈哈哈，其实以前也装过一阵Ubuntu,但是那会啥都不会，四处碰壁，没用多久就泄气了。可是看了各种大牛的书后，发现windows这种操作系统都是给大牛们摸透了计算机后想办法降低门槛给小白用的，所以要是不会Linux，永远进不了真正的程序员世界。\n\n<!-- more -->\n\n对于linux的众多发行版中，我选择了Ubuntu 14.04 LTS，毕竟Ubuntu有不错的GUI环境（X window的gnome），我既不是忠实的GUI党也不是忠实的CLI党，我觉得选择自己最好用的才是最重要的，该GUI的时候还是得GUI（用命令行去找分区里的文件太痛苦了。。），哈哈当然CLI是超强大的！\n\n大概花了两周左右的时间，将[《鸟叔的Linux私房菜之基础学习篇》](http://linux.vbird.org/)看了一半（实在好长。。剩下的慢慢看），然后将Ubuntu下的工作环境都部署了一遍，感觉以后大部分的工作都可以完成了。\n\n这部署的过程相当纠结，当然主要还是因为我的强迫症，比如一个字体好不好看我要纠结半天，各种换啊换，每次强迫症犯的时候都好想打死自己啊！所以部署的效率实在是有点低诶。好了，话不多说，下面贴上我的配置。\n\n\n# 分区\n\n装ubuntu的时候要给系统分区，我参考了鸟叔的书以及网络上的一些博客后，最后我分区如下:\n![Ubuntu 分区](/images/my/1.png)\n\n因为我装了双系统，我把sda1,sda2,sda3三个主分区都分给了windows，sda4扩展分区分成了好多逻辑分区，分别给/boot，/，/home，/var，/usr，总共大概给Ubuntu650G左右^0^\n\n\n# VPN\n\n由于用的是校园网，学校有专门的VPN客户端，我就去学校的论坛那里下了个Ubuntu下的vpn客户端，配置简单，没费什么事就能上网了（当然，前提要设置好IP地址和DNS，连上校内网）。\n\n# 换源\n\n虽然进入系统后，软件更新源里默认的是中国的服务器，但我还是按照[Ubuntu中文](http://wiki.ubuntu.org.cn/%E6%BA%90%E5%88%97%E8%A1%A8)的推荐换了网易，搜狐，阿里云及我们自己学校的源。\n\n```\n#网易\ndeb http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse\ndeb http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse\ndeb http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse\ndeb http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse\ndeb-src http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse\ndeb-src http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse\ndeb-src http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse\ndeb-src http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb-src http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse\n\n#搜狐\ndeb http://mirrors.sohu.com/ubuntu/ trusty main restricted universe multiverse\ndeb http://mirrors.sohu.com/ubuntu/ trusty-security main restricted universe multiverse\ndeb http://mirrors.sohu.com/ubuntu/ trusty-updates main restricted universe multiverse\ndeb http://mirrors.sohu.com/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb http://mirrors.sohu.com/ubuntu/ trusty-backports main restricted universe multiverse\ndeb-src http://mirrors.sohu.com/ubuntu/ trusty main restricted universe multiverse\ndeb-src http://mirrors.sohu.com/ubuntu/ trusty-security main restricted universe multiverse\ndeb-src http://mirrors.sohu.com/ubuntu/ trusty-updates main restricted universe multiverse\ndeb-src http://mirrors.sohu.com/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb-src http://mirrors.sohu.com/ubuntu/ trusty-backports main restricted universe multiverse\n\n#学校\ndeb http://mirrors.zju.edu.cn/ubuntu/ trusty main restricted universe multiverse\ndeb http://mirrors.zju.edu.cn/ubuntu/ trusty-backports restricted universe multiverse\ndeb http://mirrors.zju.edu.cn/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb http://mirrors.zju.edu.cn/ubuntu/ trusty-security main restricted universe multiverse\ndeb http://mirrors.zju.edu.cn/ubuntu/ trusty-updates main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ trusty main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ trusty-backports main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ trusty-security main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ trusty-updates main restricted universe multiverse\n\n#阿里云\ndeb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse\n```\n\n# 输入法\n\nUbuntu下自带的ibus输入法用起来还是不舒服，不像搜狗输入法那样将模糊语义，关键词之类的做得符合日常生活习惯，所以我还是装了搜狗输入法。\n\n可以直接去[官网](http://pinyin.sogou.com/linux/)下载deb包，然后`sudo dpkg -i *.deb` 像搜狗输入法是需要fcitx做输入法框架的，所以安装完后需要在语言设置里将默认输入法设置为fcitx.\n\n\n# 浏览器\n\nUbuntu自带浏览器为firefox，但我以前用的一直都是Chrome，书签什么的同步也会方便一点的，所以毫不犹豫的换成了Chrome,`sudo apt-get install google-chrome-stable`\n\nflash插件问题:Chrome用的谷歌自己的flash插件，而firefox默认是没装flash插件的，所以我去abode flash player的[官网](https://get.adobe.com/cn/flashplayer/)手动下载了插件，教程可以看[Ubuntu中文里的介绍](http://wiki.ubuntu.org.cn/Flash)，Ubuntu软件中心装flash插件太坑了！安装的时候等半天根本就不动！\n\n\n# 词典\n看论文及查资料的时候少不了查英文单词，由于在windows里一直用有道词典，所以我先去有道官网看了一下，一看，还真有linux版本，马上下载deb包后用了一下，刚开始觉得还不错，因为有道的鼠标取词（不用划词）这个功能我实在喜欢，虽然取词反应貌似有点慢。但后来我突然发现单词无法**发音**！！查了各种资料还是无法解决，无奈我只能忍痛割爱。\n\n然后我还是用了公认好用的星际译王，不得不说，自己可以自由添加词典，离线也能查单词确实比较强大（*然而现在工作基本都是联网的*）。具体安装及下载词典教程[看这里](http://wiki.ubuntu.org.cn/index.php?title=Stardict&variant=zh-cn)。 \n\n发音我没有装，感觉文件比较大，离线发音没必要，因为我还在Chrome下载了一个插件，我个人觉得非常好用，推荐一下，[ChaZD](https://chrome.google.com/webstore/detail/chazd/nkiipedegbhbjmajlhpegcpcaacbfggp?hl=zh-CN)。\n\n# Matlab\n下载matlab估计是最让我蛋疼的事了，在windows直接找个破解版就好了，而找个linux下的破解版真是不容易，虽然好多博客都有贴下载地址，但我试了试总是下载不了，有的就是下到1G左右就不能继续下了，特别折腾，为此我还下了个BT客户端deluge(系统自带的transmission其实也挺好的)。\n\n后来终于找到了一个靠谱的matlab 2010a,用wget后台下载了一天终于下好了，具体教程看[这里](ftp://wcmc.csu.edu.cn/software/%E7%A8%8B%E5%BA%8F%E8%BD%AF%E4%BB%B6/matlab/install%20matlab%20in%20linux.pdf)～\n\nmatlab下载好之后还有[中文乱码的问题](http://forum.ubuntu.org.cn/viewtopic.php?t=373776)还有[常见的一些安装问题](https://forum.ubuntu.org.cn/viewtopic.php?f=122&t=443586)这两篇帖子都解决了。\n\n\n# 办公套件\nLibreOffice以及WPC For Linux 都试过,感觉还是不行,格式会乱,所以决定还是office文件老老实实回到windows下编辑,平时自己写文档还是用markdown生成pdf,或者latex都行。\n\n# 工程绘图\n\n由于论文的需要，我需要一个类似MS下visio的工程绘图软件，这里我选的替代品是Dia，这个绘图软件基本能替代visio~安装很简单，也是直接`sudo apt-get install dia`，这里有个地方要注意的是，默认情况下进入dia是intergrated模式，中文显示会有问题，需要做如下修改\n\n    sudo gedit /usr/bin/dia\n    #dia-normal --integrated \"$@\"\n    dia-normal \"$@\"\n\n# 图片处理\n\nImagemagick！这个图片处理软件真的超棒！可以用import截图，用convert转换图片格式，大小，清晰，可以加滤镜等，非常好用，我直接把它当做默认图片打开方式了。安装同样`sudo apt-get install imagemagick`。\n\n# 视频，音频播放器\n\nMplayer！这是号称目前这个星球上支持多媒体文件格式最多的软件！哈哈哈，反正目前我电脑里的视频音频格式它都支持，而且gnome版的界面都还不错。详细介绍及安装可以看[这里](http://wiki.ubuntu.com.cn/MPlayer)\n\n# Git\nGit的安装很方便，直接`sudo apt-get install git`，因为git本来就是linus在linux下开发的嘛～具体git的使用方法，建议看[廖老师的这篇教程](http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000)！\n\n# 终端\n我这里直接就用ubuntu自带的gnome-terminal来使用Bash（Bourne again shell），作为一个强迫症患者，我觉得终端自带的紫底白字配色太伤眼睛了，于是上Github寻找好看的配色方案。\n\n刚开始我选了solarized，想把终端配色和vim的配色都弄成solarized。\n\n* 终端的solarized配色文件显示，[github下载](https://github.com/seebi/dircolors-solarized)\n* 终端的solarized配色，[github下载](https://github.com/Anthony25/gnome-terminal-colors-solarized)\n\n然而solarized配完后，总觉得看得不舒服，一时切换不过来，强迫症发作的我又去寻找其他配色。最后用了这个[Git](https://github.com/chriskempson/base16-gnome-terminal).\n![Ocean Light](/images/my/2.png)\n\n","source":"_posts/操作系统/Linux/开始使用Ubuntu.markdown","raw":"---\ntitle: 开始使用Ubuntu\ndate: 2016-04-19 20:41:51\ncategories: [操作系统,Linux]\n---\n对linux的向往由来已久，加上前阵子在win7下用vim总是感觉很不舒服，用gcc编译还要专门去下载MinGW(minmalist GNU for Windows),这么想还不如直接去用linux，GNU下的那些工具就直接能用了！在linux下打造一个IDE吧！\n> GNU's Not Unix!\n\n哈哈哈，其实以前也装过一阵Ubuntu,但是那会啥都不会，四处碰壁，没用多久就泄气了。可是看了各种大牛的书后，发现windows这种操作系统都是给大牛们摸透了计算机后想办法降低门槛给小白用的，所以要是不会Linux，永远进不了真正的程序员世界。\n\n<!-- more -->\n\n对于linux的众多发行版中，我选择了Ubuntu 14.04 LTS，毕竟Ubuntu有不错的GUI环境（X window的gnome），我既不是忠实的GUI党也不是忠实的CLI党，我觉得选择自己最好用的才是最重要的，该GUI的时候还是得GUI（用命令行去找分区里的文件太痛苦了。。），哈哈当然CLI是超强大的！\n\n大概花了两周左右的时间，将[《鸟叔的Linux私房菜之基础学习篇》](http://linux.vbird.org/)看了一半（实在好长。。剩下的慢慢看），然后将Ubuntu下的工作环境都部署了一遍，感觉以后大部分的工作都可以完成了。\n\n这部署的过程相当纠结，当然主要还是因为我的强迫症，比如一个字体好不好看我要纠结半天，各种换啊换，每次强迫症犯的时候都好想打死自己啊！所以部署的效率实在是有点低诶。好了，话不多说，下面贴上我的配置。\n\n\n# 分区\n\n装ubuntu的时候要给系统分区，我参考了鸟叔的书以及网络上的一些博客后，最后我分区如下:\n![Ubuntu 分区](/images/my/1.png)\n\n因为我装了双系统，我把sda1,sda2,sda3三个主分区都分给了windows，sda4扩展分区分成了好多逻辑分区，分别给/boot，/，/home，/var，/usr，总共大概给Ubuntu650G左右^0^\n\n\n# VPN\n\n由于用的是校园网，学校有专门的VPN客户端，我就去学校的论坛那里下了个Ubuntu下的vpn客户端，配置简单，没费什么事就能上网了（当然，前提要设置好IP地址和DNS，连上校内网）。\n\n# 换源\n\n虽然进入系统后，软件更新源里默认的是中国的服务器，但我还是按照[Ubuntu中文](http://wiki.ubuntu.org.cn/%E6%BA%90%E5%88%97%E8%A1%A8)的推荐换了网易，搜狐，阿里云及我们自己学校的源。\n\n```\n#网易\ndeb http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse\ndeb http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse\ndeb http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse\ndeb http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse\ndeb-src http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse\ndeb-src http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse\ndeb-src http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse\ndeb-src http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb-src http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse\n\n#搜狐\ndeb http://mirrors.sohu.com/ubuntu/ trusty main restricted universe multiverse\ndeb http://mirrors.sohu.com/ubuntu/ trusty-security main restricted universe multiverse\ndeb http://mirrors.sohu.com/ubuntu/ trusty-updates main restricted universe multiverse\ndeb http://mirrors.sohu.com/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb http://mirrors.sohu.com/ubuntu/ trusty-backports main restricted universe multiverse\ndeb-src http://mirrors.sohu.com/ubuntu/ trusty main restricted universe multiverse\ndeb-src http://mirrors.sohu.com/ubuntu/ trusty-security main restricted universe multiverse\ndeb-src http://mirrors.sohu.com/ubuntu/ trusty-updates main restricted universe multiverse\ndeb-src http://mirrors.sohu.com/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb-src http://mirrors.sohu.com/ubuntu/ trusty-backports main restricted universe multiverse\n\n#学校\ndeb http://mirrors.zju.edu.cn/ubuntu/ trusty main restricted universe multiverse\ndeb http://mirrors.zju.edu.cn/ubuntu/ trusty-backports restricted universe multiverse\ndeb http://mirrors.zju.edu.cn/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb http://mirrors.zju.edu.cn/ubuntu/ trusty-security main restricted universe multiverse\ndeb http://mirrors.zju.edu.cn/ubuntu/ trusty-updates main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ trusty main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ trusty-backports main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ trusty-security main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ trusty-updates main restricted universe multiverse\n\n#阿里云\ndeb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse\n```\n\n# 输入法\n\nUbuntu下自带的ibus输入法用起来还是不舒服，不像搜狗输入法那样将模糊语义，关键词之类的做得符合日常生活习惯，所以我还是装了搜狗输入法。\n\n可以直接去[官网](http://pinyin.sogou.com/linux/)下载deb包，然后`sudo dpkg -i *.deb` 像搜狗输入法是需要fcitx做输入法框架的，所以安装完后需要在语言设置里将默认输入法设置为fcitx.\n\n\n# 浏览器\n\nUbuntu自带浏览器为firefox，但我以前用的一直都是Chrome，书签什么的同步也会方便一点的，所以毫不犹豫的换成了Chrome,`sudo apt-get install google-chrome-stable`\n\nflash插件问题:Chrome用的谷歌自己的flash插件，而firefox默认是没装flash插件的，所以我去abode flash player的[官网](https://get.adobe.com/cn/flashplayer/)手动下载了插件，教程可以看[Ubuntu中文里的介绍](http://wiki.ubuntu.org.cn/Flash)，Ubuntu软件中心装flash插件太坑了！安装的时候等半天根本就不动！\n\n\n# 词典\n看论文及查资料的时候少不了查英文单词，由于在windows里一直用有道词典，所以我先去有道官网看了一下，一看，还真有linux版本，马上下载deb包后用了一下，刚开始觉得还不错，因为有道的鼠标取词（不用划词）这个功能我实在喜欢，虽然取词反应貌似有点慢。但后来我突然发现单词无法**发音**！！查了各种资料还是无法解决，无奈我只能忍痛割爱。\n\n然后我还是用了公认好用的星际译王，不得不说，自己可以自由添加词典，离线也能查单词确实比较强大（*然而现在工作基本都是联网的*）。具体安装及下载词典教程[看这里](http://wiki.ubuntu.org.cn/index.php?title=Stardict&variant=zh-cn)。 \n\n发音我没有装，感觉文件比较大，离线发音没必要，因为我还在Chrome下载了一个插件，我个人觉得非常好用，推荐一下，[ChaZD](https://chrome.google.com/webstore/detail/chazd/nkiipedegbhbjmajlhpegcpcaacbfggp?hl=zh-CN)。\n\n# Matlab\n下载matlab估计是最让我蛋疼的事了，在windows直接找个破解版就好了，而找个linux下的破解版真是不容易，虽然好多博客都有贴下载地址，但我试了试总是下载不了，有的就是下到1G左右就不能继续下了，特别折腾，为此我还下了个BT客户端deluge(系统自带的transmission其实也挺好的)。\n\n后来终于找到了一个靠谱的matlab 2010a,用wget后台下载了一天终于下好了，具体教程看[这里](ftp://wcmc.csu.edu.cn/software/%E7%A8%8B%E5%BA%8F%E8%BD%AF%E4%BB%B6/matlab/install%20matlab%20in%20linux.pdf)～\n\nmatlab下载好之后还有[中文乱码的问题](http://forum.ubuntu.org.cn/viewtopic.php?t=373776)还有[常见的一些安装问题](https://forum.ubuntu.org.cn/viewtopic.php?f=122&t=443586)这两篇帖子都解决了。\n\n\n# 办公套件\nLibreOffice以及WPC For Linux 都试过,感觉还是不行,格式会乱,所以决定还是office文件老老实实回到windows下编辑,平时自己写文档还是用markdown生成pdf,或者latex都行。\n\n# 工程绘图\n\n由于论文的需要，我需要一个类似MS下visio的工程绘图软件，这里我选的替代品是Dia，这个绘图软件基本能替代visio~安装很简单，也是直接`sudo apt-get install dia`，这里有个地方要注意的是，默认情况下进入dia是intergrated模式，中文显示会有问题，需要做如下修改\n\n    sudo gedit /usr/bin/dia\n    #dia-normal --integrated \"$@\"\n    dia-normal \"$@\"\n\n# 图片处理\n\nImagemagick！这个图片处理软件真的超棒！可以用import截图，用convert转换图片格式，大小，清晰，可以加滤镜等，非常好用，我直接把它当做默认图片打开方式了。安装同样`sudo apt-get install imagemagick`。\n\n# 视频，音频播放器\n\nMplayer！这是号称目前这个星球上支持多媒体文件格式最多的软件！哈哈哈，反正目前我电脑里的视频音频格式它都支持，而且gnome版的界面都还不错。详细介绍及安装可以看[这里](http://wiki.ubuntu.com.cn/MPlayer)\n\n# Git\nGit的安装很方便，直接`sudo apt-get install git`，因为git本来就是linus在linux下开发的嘛～具体git的使用方法，建议看[廖老师的这篇教程](http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000)！\n\n# 终端\n我这里直接就用ubuntu自带的gnome-terminal来使用Bash（Bourne again shell），作为一个强迫症患者，我觉得终端自带的紫底白字配色太伤眼睛了，于是上Github寻找好看的配色方案。\n\n刚开始我选了solarized，想把终端配色和vim的配色都弄成solarized。\n\n* 终端的solarized配色文件显示，[github下载](https://github.com/seebi/dircolors-solarized)\n* 终端的solarized配色，[github下载](https://github.com/Anthony25/gnome-terminal-colors-solarized)\n\n然而solarized配完后，总觉得看得不舒服，一时切换不过来，强迫症发作的我又去寻找其他配色。最后用了这个[Git](https://github.com/chriskempson/base16-gnome-terminal).\n![Ocean Light](/images/my/2.png)\n\n","slug":"操作系统/Linux/开始使用Ubuntu","published":1,"updated":"2022-09-15T03:46:43.360Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qj0064jqrrch26x58k","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>对linux的向往由来已久，加上前阵子在win7下用vim总是感觉很不舒服，用gcc编译还要专门去下载MinGW(minmalist GNU for Windows),这么想还不如直接去用linux，GNU下的那些工具就直接能用了！在linux下打造一个IDE吧！</p>\n<blockquote>\n<p>GNU’s Not Unix!</p>\n</blockquote>\n<p>哈哈哈，其实以前也装过一阵Ubuntu,但是那会啥都不会，四处碰壁，没用多久就泄气了。可是看了各种大牛的书后，发现windows这种操作系统都是给大牛们摸透了计算机后想办法降低门槛给小白用的，所以要是不会Linux，永远进不了真正的程序员世界。</p>\n<a id=\"more\"></a>\n<p>对于linux的众多发行版中，我选择了Ubuntu 14.04 LTS，毕竟Ubuntu有不错的GUI环境（X window的gnome），我既不是忠实的GUI党也不是忠实的CLI党，我觉得选择自己最好用的才是最重要的，该GUI的时候还是得GUI（用命令行去找分区里的文件太痛苦了。。），哈哈当然CLI是超强大的！</p>\n<p>大概花了两周左右的时间，将<a href=\"http://linux.vbird.org/\" target=\"_blank\" rel=\"noopener\">《鸟叔的Linux私房菜之基础学习篇》</a>看了一半（实在好长。。剩下的慢慢看），然后将Ubuntu下的工作环境都部署了一遍，感觉以后大部分的工作都可以完成了。</p>\n<p>这部署的过程相当纠结，当然主要还是因为我的强迫症，比如一个字体好不好看我要纠结半天，各种换啊换，每次强迫症犯的时候都好想打死自己啊！所以部署的效率实在是有点低诶。好了，话不多说，下面贴上我的配置。</p>\n<h1 id=\"分区\"><a href=\"#分区\" class=\"headerlink\" title=\"分区\"></a>分区</h1><p>装ubuntu的时候要给系统分区，我参考了鸟叔的书以及网络上的一些博客后，最后我分区如下:<br><img src=\"/images/my/1.png\" alt=\"Ubuntu 分区\"></p>\n<p>因为我装了双系统，我把sda1,sda2,sda3三个主分区都分给了windows，sda4扩展分区分成了好多逻辑分区，分别给/boot，/，/home，/var，/usr，总共大概给Ubuntu650G左右^0^</p>\n<h1 id=\"VPN\"><a href=\"#VPN\" class=\"headerlink\" title=\"VPN\"></a>VPN</h1><p>由于用的是校园网，学校有专门的VPN客户端，我就去学校的论坛那里下了个Ubuntu下的vpn客户端，配置简单，没费什么事就能上网了（当然，前提要设置好IP地址和DNS，连上校内网）。</p>\n<h1 id=\"换源\"><a href=\"#换源\" class=\"headerlink\" title=\"换源\"></a>换源</h1><p>虽然进入系统后，软件更新源里默认的是中国的服务器，但我还是按照<a href=\"http://wiki.ubuntu.org.cn/%E6%BA%90%E5%88%97%E8%A1%A8\" target=\"_blank\" rel=\"noopener\">Ubuntu中文</a>的推荐换了网易，搜狐，阿里云及我们自己学校的源。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#网易</span><br><span class=\"line\">deb http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class=\"line\"></span><br><span class=\"line\">#搜狐</span><br><span class=\"line\">deb http://mirrors.sohu.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.sohu.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.sohu.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.sohu.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.sohu.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.sohu.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.sohu.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.sohu.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.sohu.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.sohu.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class=\"line\"></span><br><span class=\"line\">#学校</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ trusty main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ trusty-backports restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ trusty main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class=\"line\"></span><br><span class=\"line\">#阿里云</span><br><span class=\"line\">deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br></pre></td></tr></table></figure>\n<h1 id=\"输入法\"><a href=\"#输入法\" class=\"headerlink\" title=\"输入法\"></a>输入法</h1><p>Ubuntu下自带的ibus输入法用起来还是不舒服，不像搜狗输入法那样将模糊语义，关键词之类的做得符合日常生活习惯，所以我还是装了搜狗输入法。</p>\n<p>可以直接去<a href=\"http://pinyin.sogou.com/linux/\" target=\"_blank\" rel=\"noopener\">官网</a>下载deb包，然后<code>sudo dpkg -i *.deb</code> 像搜狗输入法是需要fcitx做输入法框架的，所以安装完后需要在语言设置里将默认输入法设置为fcitx.</p>\n<h1 id=\"浏览器\"><a href=\"#浏览器\" class=\"headerlink\" title=\"浏览器\"></a>浏览器</h1><p>Ubuntu自带浏览器为firefox，但我以前用的一直都是Chrome，书签什么的同步也会方便一点的，所以毫不犹豫的换成了Chrome,<code>sudo apt-get install google-chrome-stable</code></p>\n<p>flash插件问题:Chrome用的谷歌自己的flash插件，而firefox默认是没装flash插件的，所以我去abode flash player的<a href=\"https://get.adobe.com/cn/flashplayer/\" target=\"_blank\" rel=\"noopener\">官网</a>手动下载了插件，教程可以看<a href=\"http://wiki.ubuntu.org.cn/Flash\" target=\"_blank\" rel=\"noopener\">Ubuntu中文里的介绍</a>，Ubuntu软件中心装flash插件太坑了！安装的时候等半天根本就不动！</p>\n<h1 id=\"词典\"><a href=\"#词典\" class=\"headerlink\" title=\"词典\"></a>词典</h1><p>看论文及查资料的时候少不了查英文单词，由于在windows里一直用有道词典，所以我先去有道官网看了一下，一看，还真有linux版本，马上下载deb包后用了一下，刚开始觉得还不错，因为有道的鼠标取词（不用划词）这个功能我实在喜欢，虽然取词反应貌似有点慢。但后来我突然发现单词无法<strong>发音</strong>！！查了各种资料还是无法解决，无奈我只能忍痛割爱。</p>\n<p>然后我还是用了公认好用的星际译王，不得不说，自己可以自由添加词典，离线也能查单词确实比较强大（<em>然而现在工作基本都是联网的</em>）。具体安装及下载词典教程<a href=\"http://wiki.ubuntu.org.cn/index.php?title=Stardict&amp;variant=zh-cn\" target=\"_blank\" rel=\"noopener\">看这里</a>。 </p>\n<p>发音我没有装，感觉文件比较大，离线发音没必要，因为我还在Chrome下载了一个插件，我个人觉得非常好用，推荐一下，<a href=\"https://chrome.google.com/webstore/detail/chazd/nkiipedegbhbjmajlhpegcpcaacbfggp?hl=zh-CN\" target=\"_blank\" rel=\"noopener\">ChaZD</a>。</p>\n<h1 id=\"Matlab\"><a href=\"#Matlab\" class=\"headerlink\" title=\"Matlab\"></a>Matlab</h1><p>下载matlab估计是最让我蛋疼的事了，在windows直接找个破解版就好了，而找个linux下的破解版真是不容易，虽然好多博客都有贴下载地址，但我试了试总是下载不了，有的就是下到1G左右就不能继续下了，特别折腾，为此我还下了个BT客户端deluge(系统自带的transmission其实也挺好的)。</p>\n<p>后来终于找到了一个靠谱的matlab 2010a,用wget后台下载了一天终于下好了，具体教程看<a href=\"ftp://wcmc.csu.edu.cn/software/%E7%A8%8B%E5%BA%8F%E8%BD%AF%E4%BB%B6/matlab/install%20matlab%20in%20linux.pdf\" target=\"_blank\" rel=\"noopener\">这里</a>～</p>\n<p>matlab下载好之后还有<a href=\"http://forum.ubuntu.org.cn/viewtopic.php?t=373776\" target=\"_blank\" rel=\"noopener\">中文乱码的问题</a>还有<a href=\"https://forum.ubuntu.org.cn/viewtopic.php?f=122&amp;t=443586\" target=\"_blank\" rel=\"noopener\">常见的一些安装问题</a>这两篇帖子都解决了。</p>\n<h1 id=\"办公套件\"><a href=\"#办公套件\" class=\"headerlink\" title=\"办公套件\"></a>办公套件</h1><p>LibreOffice以及WPC For Linux 都试过,感觉还是不行,格式会乱,所以决定还是office文件老老实实回到windows下编辑,平时自己写文档还是用markdown生成pdf,或者latex都行。</p>\n<h1 id=\"工程绘图\"><a href=\"#工程绘图\" class=\"headerlink\" title=\"工程绘图\"></a>工程绘图</h1><p>由于论文的需要，我需要一个类似MS下visio的工程绘图软件，这里我选的替代品是Dia，这个绘图软件基本能替代visio~安装很简单，也是直接<code>sudo apt-get install dia</code>，这里有个地方要注意的是，默认情况下进入dia是intergrated模式，中文显示会有问题，需要做如下修改</p>\n<pre><code>sudo gedit /usr/bin/dia\n#dia-normal --integrated &quot;$@&quot;\ndia-normal &quot;$@&quot;\n</code></pre><h1 id=\"图片处理\"><a href=\"#图片处理\" class=\"headerlink\" title=\"图片处理\"></a>图片处理</h1><p>Imagemagick！这个图片处理软件真的超棒！可以用import截图，用convert转换图片格式，大小，清晰，可以加滤镜等，非常好用，我直接把它当做默认图片打开方式了。安装同样<code>sudo apt-get install imagemagick</code>。</p>\n<h1 id=\"视频，音频播放器\"><a href=\"#视频，音频播放器\" class=\"headerlink\" title=\"视频，音频播放器\"></a>视频，音频播放器</h1><p>Mplayer！这是号称目前这个星球上支持多媒体文件格式最多的软件！哈哈哈，反正目前我电脑里的视频音频格式它都支持，而且gnome版的界面都还不错。详细介绍及安装可以看<a href=\"http://wiki.ubuntu.com.cn/MPlayer\" target=\"_blank\" rel=\"noopener\">这里</a></p>\n<h1 id=\"Git\"><a href=\"#Git\" class=\"headerlink\" title=\"Git\"></a>Git</h1><p>Git的安装很方便，直接<code>sudo apt-get install git</code>，因为git本来就是linus在linux下开发的嘛～具体git的使用方法，建议看<a href=\"http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000\" target=\"_blank\" rel=\"noopener\">廖老师的这篇教程</a>！</p>\n<h1 id=\"终端\"><a href=\"#终端\" class=\"headerlink\" title=\"终端\"></a>终端</h1><p>我这里直接就用ubuntu自带的gnome-terminal来使用Bash（Bourne again shell），作为一个强迫症患者，我觉得终端自带的紫底白字配色太伤眼睛了，于是上Github寻找好看的配色方案。</p>\n<p>刚开始我选了solarized，想把终端配色和vim的配色都弄成solarized。</p>\n<ul>\n<li>终端的solarized配色文件显示，<a href=\"https://github.com/seebi/dircolors-solarized\" target=\"_blank\" rel=\"noopener\">github下载</a></li>\n<li>终端的solarized配色，<a href=\"https://github.com/Anthony25/gnome-terminal-colors-solarized\" target=\"_blank\" rel=\"noopener\">github下载</a></li>\n</ul>\n<p>然而solarized配完后，总觉得看得不舒服，一时切换不过来，强迫症发作的我又去寻找其他配色。最后用了这个<a href=\"https://github.com/chriskempson/base16-gnome-terminal\" target=\"_blank\" rel=\"noopener\">Git</a>.<br><img src=\"/images/my/2.png\" alt=\"Ocean Light\"></p>\n","site":{"data":{}},"excerpt":"<p>对linux的向往由来已久，加上前阵子在win7下用vim总是感觉很不舒服，用gcc编译还要专门去下载MinGW(minmalist GNU for Windows),这么想还不如直接去用linux，GNU下的那些工具就直接能用了！在linux下打造一个IDE吧！</p>\n<blockquote>\n<p>GNU’s Not Unix!</p>\n</blockquote>\n<p>哈哈哈，其实以前也装过一阵Ubuntu,但是那会啥都不会，四处碰壁，没用多久就泄气了。可是看了各种大牛的书后，发现windows这种操作系统都是给大牛们摸透了计算机后想办法降低门槛给小白用的，所以要是不会Linux，永远进不了真正的程序员世界。</p>","more":"<p>对于linux的众多发行版中，我选择了Ubuntu 14.04 LTS，毕竟Ubuntu有不错的GUI环境（X window的gnome），我既不是忠实的GUI党也不是忠实的CLI党，我觉得选择自己最好用的才是最重要的，该GUI的时候还是得GUI（用命令行去找分区里的文件太痛苦了。。），哈哈当然CLI是超强大的！</p>\n<p>大概花了两周左右的时间，将<a href=\"http://linux.vbird.org/\" target=\"_blank\" rel=\"noopener\">《鸟叔的Linux私房菜之基础学习篇》</a>看了一半（实在好长。。剩下的慢慢看），然后将Ubuntu下的工作环境都部署了一遍，感觉以后大部分的工作都可以完成了。</p>\n<p>这部署的过程相当纠结，当然主要还是因为我的强迫症，比如一个字体好不好看我要纠结半天，各种换啊换，每次强迫症犯的时候都好想打死自己啊！所以部署的效率实在是有点低诶。好了，话不多说，下面贴上我的配置。</p>\n<h1 id=\"分区\"><a href=\"#分区\" class=\"headerlink\" title=\"分区\"></a>分区</h1><p>装ubuntu的时候要给系统分区，我参考了鸟叔的书以及网络上的一些博客后，最后我分区如下:<br><img src=\"/images/my/1.png\" alt=\"Ubuntu 分区\"></p>\n<p>因为我装了双系统，我把sda1,sda2,sda3三个主分区都分给了windows，sda4扩展分区分成了好多逻辑分区，分别给/boot，/，/home，/var，/usr，总共大概给Ubuntu650G左右^0^</p>\n<h1 id=\"VPN\"><a href=\"#VPN\" class=\"headerlink\" title=\"VPN\"></a>VPN</h1><p>由于用的是校园网，学校有专门的VPN客户端，我就去学校的论坛那里下了个Ubuntu下的vpn客户端，配置简单，没费什么事就能上网了（当然，前提要设置好IP地址和DNS，连上校内网）。</p>\n<h1 id=\"换源\"><a href=\"#换源\" class=\"headerlink\" title=\"换源\"></a>换源</h1><p>虽然进入系统后，软件更新源里默认的是中国的服务器，但我还是按照<a href=\"http://wiki.ubuntu.org.cn/%E6%BA%90%E5%88%97%E8%A1%A8\" target=\"_blank\" rel=\"noopener\">Ubuntu中文</a>的推荐换了网易，搜狐，阿里云及我们自己学校的源。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#网易</span><br><span class=\"line\">deb http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class=\"line\"></span><br><span class=\"line\">#搜狐</span><br><span class=\"line\">deb http://mirrors.sohu.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.sohu.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.sohu.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.sohu.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.sohu.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.sohu.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.sohu.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.sohu.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.sohu.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.sohu.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class=\"line\"></span><br><span class=\"line\">#学校</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ trusty main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ trusty-backports restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ trusty main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class=\"line\"></span><br><span class=\"line\">#阿里云</span><br><span class=\"line\">deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br></pre></td></tr></table></figure>\n<h1 id=\"输入法\"><a href=\"#输入法\" class=\"headerlink\" title=\"输入法\"></a>输入法</h1><p>Ubuntu下自带的ibus输入法用起来还是不舒服，不像搜狗输入法那样将模糊语义，关键词之类的做得符合日常生活习惯，所以我还是装了搜狗输入法。</p>\n<p>可以直接去<a href=\"http://pinyin.sogou.com/linux/\" target=\"_blank\" rel=\"noopener\">官网</a>下载deb包，然后<code>sudo dpkg -i *.deb</code> 像搜狗输入法是需要fcitx做输入法框架的，所以安装完后需要在语言设置里将默认输入法设置为fcitx.</p>\n<h1 id=\"浏览器\"><a href=\"#浏览器\" class=\"headerlink\" title=\"浏览器\"></a>浏览器</h1><p>Ubuntu自带浏览器为firefox，但我以前用的一直都是Chrome，书签什么的同步也会方便一点的，所以毫不犹豫的换成了Chrome,<code>sudo apt-get install google-chrome-stable</code></p>\n<p>flash插件问题:Chrome用的谷歌自己的flash插件，而firefox默认是没装flash插件的，所以我去abode flash player的<a href=\"https://get.adobe.com/cn/flashplayer/\" target=\"_blank\" rel=\"noopener\">官网</a>手动下载了插件，教程可以看<a href=\"http://wiki.ubuntu.org.cn/Flash\" target=\"_blank\" rel=\"noopener\">Ubuntu中文里的介绍</a>，Ubuntu软件中心装flash插件太坑了！安装的时候等半天根本就不动！</p>\n<h1 id=\"词典\"><a href=\"#词典\" class=\"headerlink\" title=\"词典\"></a>词典</h1><p>看论文及查资料的时候少不了查英文单词，由于在windows里一直用有道词典，所以我先去有道官网看了一下，一看，还真有linux版本，马上下载deb包后用了一下，刚开始觉得还不错，因为有道的鼠标取词（不用划词）这个功能我实在喜欢，虽然取词反应貌似有点慢。但后来我突然发现单词无法<strong>发音</strong>！！查了各种资料还是无法解决，无奈我只能忍痛割爱。</p>\n<p>然后我还是用了公认好用的星际译王，不得不说，自己可以自由添加词典，离线也能查单词确实比较强大（<em>然而现在工作基本都是联网的</em>）。具体安装及下载词典教程<a href=\"http://wiki.ubuntu.org.cn/index.php?title=Stardict&amp;variant=zh-cn\" target=\"_blank\" rel=\"noopener\">看这里</a>。 </p>\n<p>发音我没有装，感觉文件比较大，离线发音没必要，因为我还在Chrome下载了一个插件，我个人觉得非常好用，推荐一下，<a href=\"https://chrome.google.com/webstore/detail/chazd/nkiipedegbhbjmajlhpegcpcaacbfggp?hl=zh-CN\" target=\"_blank\" rel=\"noopener\">ChaZD</a>。</p>\n<h1 id=\"Matlab\"><a href=\"#Matlab\" class=\"headerlink\" title=\"Matlab\"></a>Matlab</h1><p>下载matlab估计是最让我蛋疼的事了，在windows直接找个破解版就好了，而找个linux下的破解版真是不容易，虽然好多博客都有贴下载地址，但我试了试总是下载不了，有的就是下到1G左右就不能继续下了，特别折腾，为此我还下了个BT客户端deluge(系统自带的transmission其实也挺好的)。</p>\n<p>后来终于找到了一个靠谱的matlab 2010a,用wget后台下载了一天终于下好了，具体教程看<a href=\"ftp://wcmc.csu.edu.cn/software/%E7%A8%8B%E5%BA%8F%E8%BD%AF%E4%BB%B6/matlab/install%20matlab%20in%20linux.pdf\" target=\"_blank\" rel=\"noopener\">这里</a>～</p>\n<p>matlab下载好之后还有<a href=\"http://forum.ubuntu.org.cn/viewtopic.php?t=373776\" target=\"_blank\" rel=\"noopener\">中文乱码的问题</a>还有<a href=\"https://forum.ubuntu.org.cn/viewtopic.php?f=122&amp;t=443586\" target=\"_blank\" rel=\"noopener\">常见的一些安装问题</a>这两篇帖子都解决了。</p>\n<h1 id=\"办公套件\"><a href=\"#办公套件\" class=\"headerlink\" title=\"办公套件\"></a>办公套件</h1><p>LibreOffice以及WPC For Linux 都试过,感觉还是不行,格式会乱,所以决定还是office文件老老实实回到windows下编辑,平时自己写文档还是用markdown生成pdf,或者latex都行。</p>\n<h1 id=\"工程绘图\"><a href=\"#工程绘图\" class=\"headerlink\" title=\"工程绘图\"></a>工程绘图</h1><p>由于论文的需要，我需要一个类似MS下visio的工程绘图软件，这里我选的替代品是Dia，这个绘图软件基本能替代visio~安装很简单，也是直接<code>sudo apt-get install dia</code>，这里有个地方要注意的是，默认情况下进入dia是intergrated模式，中文显示会有问题，需要做如下修改</p>\n<pre><code>sudo gedit /usr/bin/dia\n#dia-normal --integrated &quot;$@&quot;\ndia-normal &quot;$@&quot;\n</code></pre><h1 id=\"图片处理\"><a href=\"#图片处理\" class=\"headerlink\" title=\"图片处理\"></a>图片处理</h1><p>Imagemagick！这个图片处理软件真的超棒！可以用import截图，用convert转换图片格式，大小，清晰，可以加滤镜等，非常好用，我直接把它当做默认图片打开方式了。安装同样<code>sudo apt-get install imagemagick</code>。</p>\n<h1 id=\"视频，音频播放器\"><a href=\"#视频，音频播放器\" class=\"headerlink\" title=\"视频，音频播放器\"></a>视频，音频播放器</h1><p>Mplayer！这是号称目前这个星球上支持多媒体文件格式最多的软件！哈哈哈，反正目前我电脑里的视频音频格式它都支持，而且gnome版的界面都还不错。详细介绍及安装可以看<a href=\"http://wiki.ubuntu.com.cn/MPlayer\" target=\"_blank\" rel=\"noopener\">这里</a></p>\n<h1 id=\"Git\"><a href=\"#Git\" class=\"headerlink\" title=\"Git\"></a>Git</h1><p>Git的安装很方便，直接<code>sudo apt-get install git</code>，因为git本来就是linus在linux下开发的嘛～具体git的使用方法，建议看<a href=\"http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000\" target=\"_blank\" rel=\"noopener\">廖老师的这篇教程</a>！</p>\n<h1 id=\"终端\"><a href=\"#终端\" class=\"headerlink\" title=\"终端\"></a>终端</h1><p>我这里直接就用ubuntu自带的gnome-terminal来使用Bash（Bourne again shell），作为一个强迫症患者，我觉得终端自带的紫底白字配色太伤眼睛了，于是上Github寻找好看的配色方案。</p>\n<p>刚开始我选了solarized，想把终端配色和vim的配色都弄成solarized。</p>\n<ul>\n<li>终端的solarized配色文件显示，<a href=\"https://github.com/seebi/dircolors-solarized\" target=\"_blank\" rel=\"noopener\">github下载</a></li>\n<li>终端的solarized配色，<a href=\"https://github.com/Anthony25/gnome-terminal-colors-solarized\" target=\"_blank\" rel=\"noopener\">github下载</a></li>\n</ul>\n<p>然而solarized配完后，总觉得看得不舒服，一时切换不过来，强迫症发作的我又去寻找其他配色。最后用了这个<a href=\"https://github.com/chriskempson/base16-gnome-terminal\" target=\"_blank\" rel=\"noopener\">Git</a>.<br><img src=\"/images/my/2.png\" alt=\"Ocean Light\"></p>"},{"title":"重装Ubuntu16.04","date":"2017-06-12T09:55:56.000Z","_content":"\n之前的Ubuntu14.04用了快两年了，中途经过升级之类各种事，感觉系统里的一些依赖什么都被我折腾坏了，右上角总是有个软件更新冲突提示，所以决定重装Ubuntu16.04。值得一提的是，之前装完Ubuntu14.04写了一篇博客发布在简书上，博客名叫[《开始使用Ubuntu》](http://www.jianshu.com/p/4b9271bba240)(这篇博客也迁移到本站点中了)，至今已被阅读908次，喜欢30次，加入了一些Ubuntu专题，感觉还挺有成就感的。\n\n\n# 分区\n有了之前使用Ubuntu14.04的经验，这次我的分区就简单了许多，主分区1,2,3给windows系统，第四个主分区变成拓展分区，拓展为`/boot:500M`(由于经常更新内核，还是需要多一点空间); `/:400G`;`/home:250G`(个人文件夹要放很多文件，所以最好单独分出来);`/swap:8G(大小和内存相似)`。\n\n# VPN\n我发现之前从校内网下载的deb包在Ubuntu16.04里无法使用，原因是因为该deb包依赖iproute，然而在我还未联网更新的Ubuntu16.04中没有iproute,iproute2取代了iproute，所以我解压了该deb包，修改了依赖项，并重新打包，然后安装完就ok了。\n```\nsudo dpkg -X xl2tpd_1.1.12-zju2_am64_new.deb test/ //解压文件\nsudo dpkg -e xl2tpd_1.1.12-zju2_am64_new.deb test/ //解压控制文件\n修改control文件\nsudo dpkg-deb -b test/ new.deb //重新打包\nsudo dpkg -i new.deb //安装\n```\n\n# 换源\n在software&Updates里面可以进行测速，系统会自动选择一个速度最好的源，系统给我选了`http://ubuntu.cn99.com/ubuntu`这个源，保险起见我又添加了一个自己学校的源。\n```\n# ZJU\ndeb http://mirrors.zju.edu.cn/ubuntu/ xenial main restricted universe multiverse\ndeb http://mirrors.zju.edu.cn/ubuntu/ xenial-security main restricted universe multiverse\ndeb http://mirrors.zju.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse\ndeb http://mirrors.zju.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse\ndeb http://mirrors.zju.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ xenial main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ xenial-security main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse\n```\n换好之后更新源：`sudo apt-get update`\n\n# 搜狗输入法\n官网下载deb文件安装即可，`sudo apt-get install -f`解决依赖问题，并且在系统语言设置出选择fcitx,添加sogo pinyin.\n\n# Chrome浏览器\n添加第三方源并安装。\n```\nsudo wget https://repo.fdzh.org/chrome/google-chrome.list -P /etc/apt/sources.list.d/ \nwget -q -O - https://dl.google.com/linux/linux_signing_key.pub  | sudo apt-key add -\nsudo apt-get update\nsudo apt-get install google-chrome-stable\n```\n\n# Shadowsocks\n不用多说，翻墙是必备的。为了方便起见，我选择安装图形界面的shadowsocks,即shadowsocks-qt5,详细的ss说明可参照[这里](https://github.com/shadowsocks/shadowsocks/wiki),虽然代码已删，但是wiki还在。\n```\nsudo add-apt-repository ppa:hzwhuang/ss-qt5 //ppa即personal package archives\nsudo apt-get update\nsudo apt-get install shadowsocks-qt5\n```\n下载完成后再配置ip地址等等，我买的服务器是包年100元，感觉还凑合。此外，配置好SS后，只是打开了sock5代理端口，如何让chrome用ss代理还是另一码事。\n\n接下来，我们需要在chrome里安装一个插件:SwitchyOmega，插件安装后需要进行配置。首先，新建一个情景模式，然后修改为sock5协议以及配置端口。\n![新建SS情景模式](http://upload-images.jianshu.io/upload_images/825093-708ebfa92c818de0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/800)\n\n然后，我们再在自动切换这个情景模式下进行修改，首先添加一个给GFW墙掉的地址链接，该链接为` https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt`,由[github的一个项目](https://github.com/gfwlist/gfwlist)维护。然后，我们设置该地址里的url,我们用ss代理，其他url全部直接连接，这就相当于一个pac了。\n![自动切换情景模式](http://upload-images.jianshu.io/upload_images/825093-90aab2477f7c436f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/800)\n\n最后保存之后，就可以翻墙了。\n\n# Git\n安装很简单，`sudo apt-get install git`,下载好之后，配置一下该电脑下的公私钥。\n\n# Latex\n不用多说，写论文必备，当做平时写文章也还行，markdown转pdf我一直都觉得挺麻烦的。。装latex无非就是编译环境和编辑器两方面，编译环境在linux下一般都用texlive，为了方便，我直接安装了全套texlive...整整3G多..`sudo apt-get install texlive-full`。\n\n对于编辑器选择，我直接用的是texmaker,虽然整体来说用得不错，但我还是有点嫌弃它界面有点丑。。我查阅了其他一些流行的编辑器，如sublime,lyX等，最终还是选择了texmaker的fork版texstudio，界面之类的改进了很多，加上之前texmaker习惯大部分都适用，我觉得还是不错的。至于为什么不用vim来编辑latex，我觉得这就像我不用vim编辑markdown一样，我觉得latex及markdown都是需要实时预览，编辑起来才爽的语言，虽然vim也可以搞些插件来预览，但是一方面太麻烦，一方面vim提倡的是解放双手，远离鼠标，一旦有实时预览，双手必然会回归鼠标，我觉得这样就没有必要了，因此对于markdown和latex我都选择了其他编辑器。下图是texstudio界面：\n![image.png](http://upload-images.jianshu.io/upload_images/825093-185e4118d7e48ae9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/800)\n\n## 中文支持\n其实latex支持中文很简单，只需在头文件处加入`\\usepackage{ctex}`或者`\\usepackage{xeCJK}`,然后用xelatex编译即可，中文字体也可以通过`\\setCJKmainfont{中文字体}`自己设置。\n\n## 字体包问题\n我在编译一个文件时用到了`\\usapage{uarial}`,但是编译失败，message显示`File 'uarial.sty' not found`，该包没有默认安装，经过google之后，我起初以为是ubuntu没有该uarial字体，于是将windows下的字体都安装到了Ubuntu中，并且还装了文泉译微米黑字体(为了好看)..\n```\nsudo apt-get install ttf-wqy-microhei \nsudo apt-get install ttf-mscorefonts-installer \nsudo fc-cache -f -v //更新\n```\n这么做之后并无乱用，因为问题其实是latex缺少包，而非系统缺少字体。。\n\n正确做法是从CTAN下载non free fonts,也就是这些字体包不是免费的(怪不得不默认安装在latex)。。\n```\nwget -q http://tug.org/fonts/getnonfreefonts/install-getnonfreefonts\nsudo texlua ./install-getnonfreefonts\nsudo getnonfreefonts --sys -a\n```\n\n---\n\n# Matlab R2016a\n我分享的iso下载地址及crack破解文件:[百度网盘](http://pan.baidu.com/s/1nuHAUCh)\n\n## 1. 挂载安装\n```linux\nsudo mkdir /media/matlab\nsudo mount -o loop ~/Downloads/R2016a_glnxa64.iso /media/matlab/ //挂载iso到/matlab文件夹\ncd /media/matlab\nsudo ./install\n```\n\n## 2.破解激活\n- 安装过程中选择不联网安装,输入产品密钥(crack文件中的FIK).\n- 等待安装完成, 默认安装位置为/usr/local/MATLAB/R2016a.\n- 安装结束后,打开matlab应用程序.\n```linux\ncd /usr/local/MATLAB/R2016a/bin/glnxa64/\nsudo MATLAB\n```\n选择离线激活,并添加crack中的Matlab_R2016a_glnxa64.lic.\n\n- 将crack中的另外两个文件复制到matlab安装目录下.\n```linux\nsudo cp ~/Downloads/crack/libcufft.so.7.5.18 /usr/local/MATLAB/R2016a/bin/glnxa64/\n sudo cp ~/Downloads/crack/libmwservices.so /usr/local/MATLAB/R2016a/bin/glnxa64/\n```\n\n## 3. 创建快捷方式\n- 由于默认PATH里不包含/usr/local/MATLAB,所以终端直接输入matlab是不行的,可以创建一个软链接\n`sudo ln -s /usr/local/MATLAB/R2016a/bin/glnxa64/MATLAB /usr/local/bin/matlab\n`\n- 为了更加方便,我们可以创建一个桌面快捷方式,在/usr/share/applications/下面创建一个Matlab.desktop,并添加内容如下\n\n        [Desktop Entry]\n        Type = Application\n        Name = Matlab\n        GenericName = Matlab R2016a\n        Comment = Matlab R2016a: The Language of the Technical Computing\n        Exec = /usr/local/MATLAB/R2016a/bin/glnxa64/MATLAB -desktop //路径需自己修改\n        Icon = /usr/local/MATLAB/matlab.png // 网上下载一个快捷方式图标\n        StartupNotify = true\n        Terminal = false\n        Categories = Development;Matlab;\n接着加上权限`sudo chmod a+x Matlab.desktop`.\n[我的快捷方式图标](http://upload-images.jianshu.io/upload_images/825093-3a8333c910981276.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/120)可供下载.\n![Matlab](http://upload-images.jianshu.io/upload_images/825093-3a8333c910981276.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/120)\n\n- 为了避免每次打开matlab后存在权限问题无法读取~/.matab文件的问题，通过`sudo chown [your ubuntu username] -R ~/.matlab`改变权限。\n\n## 4. 字体和快捷键\n- 字体美化:进入Matlab，从菜单打开Preferences，打开Fonts页，把右边最下面的复选框Use antialising to smooth desktop fonts选中.\n- 中文字体显示问题:可以不用很麻烦,同样打开Preferences->Fonts,挑选一个支持中文的字体就ok了,我选择的是AR PL Ukai CN(楷体)．\n- 默认的快捷键是Emacs的，有点不习惯，可以Preferences->Keyboard->Shortcuts->Active settings选Windows Default set.\n\n---\n# Hexo\n之前在Ubuntu14.04里我用octopress搭建了个人博客，重装之后我原本也是想装回octopress的，但是偶然间发现了hexo，一个更加快速、简洁且高效的博客框架！而且支持octopress的完美迁移，看了用hexo搭建的几个demo之后，我立马就决定这回使用hexo搭建个人博客了。\n\n## 安装与使用说明\nhexo的安装和使用可以说相当得简单了，看完[官网的介绍文档](https://hexo.io/zh-cn/docs/index.html)我相信就立马入门了。\n\n## 主题更换\n当然了，安装hexo后最重要当然是选一个自己最心仪的主题（其实官网提供的landscape主题其实也还可以。。），经过一番搜索，我选择了github上hexo主题star数排名第一的next主题，附上github[传送门](https://github.com/iissnan/hexo-theme-next)，以及next作者的[demo](http://notes.iissnan.com/)。\n\nNext的主题安装和使用也有着详细的说明文档，附上[传送门](http://theme-next.iissnan.com/getting-started.html),官网的介绍已经很详细了，我也就不在这里赘述了。\n\n最后，我总结一下自己用到的hexo模块：\n\n- 选择Pisces主题（hexo又分为Muse, Mist, Pisces三个主题）。\n- 阅读次数统计（LeanCloud）。\n- 添加「标签」页面。\n- 设置night bright代码高亮主题。\n- 侧边栏社交链接添加微博，知乎。\n- 开启打赏功能。\n- 添加disqus评论系统。\n- 添加local search。\n- 开启MathJax，这里要注意的是，我在使用分段函数时，分段用的latex代码`\\\\`只被识别前一个`\\`,所以要分段必须使用三个`\\`。。\n\n---\n# Tensorflow\n机器学习将是我的以后工作及学习重心，tensorflow这个平台我必须快速熟悉起来。Tensorflow的安装分为无GPU(只支持CPU)和有GPU的安装，前者安装相当简单，后者的话会很麻烦，还需要对显卡驱动的各种配置。。。由于实验室的工作电脑只是集成显卡而已，所以我就选择了无GPU的安装，当然之后要是有独显了，再研究一下如何支持GPU。\n\n建议使用pip直接进行安装(当然也可以通过docker，Anaconda等第三方环境安装),确保安装了python3及pip3，`sudo apt-get install python3-pip python3-dev`,然后再利用pip3就可以直接安装tensorflow无GPU支持版了，`pip3 install tensorflow`。\n\n## Python安装numpy,scipy,matplotlib库\n作为python中重要的科学计算库，numpy，scipy，matplotlib库一定要正确安装。\n- NumPy是一个定义了数值数组和矩阵类型和它们的基本运算的语言扩展。 \n- SciPy是一种使用NumPy来做高等数学、信号处理、优化、统计和许多其它科学任务的语言扩展。 \n- Matplotlib则可能是Python 2D绘图领域使用最广泛的套件。\n\n之前在windows下用pip安装scipy时，总会遇到依赖问题，我只能通过[这篇知乎上的方法](https://www.zhihu.com/question/30188492)，从非官方维护的第三方库安装scipy。然而在ubuntu下，不需要用pip, 直接利用`apt-get`安装，它会将依赖项自动安装，非常简单有效。\n```\nsudo apt-get install python-numpy\nsudo apt-get install python-scipy\nsudo apt-get install python-matplotlib\n```\n## pip换源\n\n由于连接国外官方pypi很慢，我的电脑大概是70kb/s左右的速度，所以最好将pip源更换为国内的镜像源，我使用的是清华大学的pip源。\n\n新建`~/.pip/pip.conf`,创建内容如下:\n> \n[global]\nindex-url = https://pypi.tuna.tsinghua.edu.cn/simple\n\n","source":"_posts/操作系统/Linux/重装Ubuntu16.04.md","raw":"---\ntitle: 重装Ubuntu16.04\ndate: 2017-06-12 17:55:56\ncategories: [操作系统,Linux]\n---\n\n之前的Ubuntu14.04用了快两年了，中途经过升级之类各种事，感觉系统里的一些依赖什么都被我折腾坏了，右上角总是有个软件更新冲突提示，所以决定重装Ubuntu16.04。值得一提的是，之前装完Ubuntu14.04写了一篇博客发布在简书上，博客名叫[《开始使用Ubuntu》](http://www.jianshu.com/p/4b9271bba240)(这篇博客也迁移到本站点中了)，至今已被阅读908次，喜欢30次，加入了一些Ubuntu专题，感觉还挺有成就感的。\n\n\n# 分区\n有了之前使用Ubuntu14.04的经验，这次我的分区就简单了许多，主分区1,2,3给windows系统，第四个主分区变成拓展分区，拓展为`/boot:500M`(由于经常更新内核，还是需要多一点空间); `/:400G`;`/home:250G`(个人文件夹要放很多文件，所以最好单独分出来);`/swap:8G(大小和内存相似)`。\n\n# VPN\n我发现之前从校内网下载的deb包在Ubuntu16.04里无法使用，原因是因为该deb包依赖iproute，然而在我还未联网更新的Ubuntu16.04中没有iproute,iproute2取代了iproute，所以我解压了该deb包，修改了依赖项，并重新打包，然后安装完就ok了。\n```\nsudo dpkg -X xl2tpd_1.1.12-zju2_am64_new.deb test/ //解压文件\nsudo dpkg -e xl2tpd_1.1.12-zju2_am64_new.deb test/ //解压控制文件\n修改control文件\nsudo dpkg-deb -b test/ new.deb //重新打包\nsudo dpkg -i new.deb //安装\n```\n\n# 换源\n在software&Updates里面可以进行测速，系统会自动选择一个速度最好的源，系统给我选了`http://ubuntu.cn99.com/ubuntu`这个源，保险起见我又添加了一个自己学校的源。\n```\n# ZJU\ndeb http://mirrors.zju.edu.cn/ubuntu/ xenial main restricted universe multiverse\ndeb http://mirrors.zju.edu.cn/ubuntu/ xenial-security main restricted universe multiverse\ndeb http://mirrors.zju.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse\ndeb http://mirrors.zju.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse\ndeb http://mirrors.zju.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ xenial main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ xenial-security main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse\ndeb-src http://mirrors.zju.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse\n```\n换好之后更新源：`sudo apt-get update`\n\n# 搜狗输入法\n官网下载deb文件安装即可，`sudo apt-get install -f`解决依赖问题，并且在系统语言设置出选择fcitx,添加sogo pinyin.\n\n# Chrome浏览器\n添加第三方源并安装。\n```\nsudo wget https://repo.fdzh.org/chrome/google-chrome.list -P /etc/apt/sources.list.d/ \nwget -q -O - https://dl.google.com/linux/linux_signing_key.pub  | sudo apt-key add -\nsudo apt-get update\nsudo apt-get install google-chrome-stable\n```\n\n# Shadowsocks\n不用多说，翻墙是必备的。为了方便起见，我选择安装图形界面的shadowsocks,即shadowsocks-qt5,详细的ss说明可参照[这里](https://github.com/shadowsocks/shadowsocks/wiki),虽然代码已删，但是wiki还在。\n```\nsudo add-apt-repository ppa:hzwhuang/ss-qt5 //ppa即personal package archives\nsudo apt-get update\nsudo apt-get install shadowsocks-qt5\n```\n下载完成后再配置ip地址等等，我买的服务器是包年100元，感觉还凑合。此外，配置好SS后，只是打开了sock5代理端口，如何让chrome用ss代理还是另一码事。\n\n接下来，我们需要在chrome里安装一个插件:SwitchyOmega，插件安装后需要进行配置。首先，新建一个情景模式，然后修改为sock5协议以及配置端口。\n![新建SS情景模式](http://upload-images.jianshu.io/upload_images/825093-708ebfa92c818de0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/800)\n\n然后，我们再在自动切换这个情景模式下进行修改，首先添加一个给GFW墙掉的地址链接，该链接为` https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt`,由[github的一个项目](https://github.com/gfwlist/gfwlist)维护。然后，我们设置该地址里的url,我们用ss代理，其他url全部直接连接，这就相当于一个pac了。\n![自动切换情景模式](http://upload-images.jianshu.io/upload_images/825093-90aab2477f7c436f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/800)\n\n最后保存之后，就可以翻墙了。\n\n# Git\n安装很简单，`sudo apt-get install git`,下载好之后，配置一下该电脑下的公私钥。\n\n# Latex\n不用多说，写论文必备，当做平时写文章也还行，markdown转pdf我一直都觉得挺麻烦的。。装latex无非就是编译环境和编辑器两方面，编译环境在linux下一般都用texlive，为了方便，我直接安装了全套texlive...整整3G多..`sudo apt-get install texlive-full`。\n\n对于编辑器选择，我直接用的是texmaker,虽然整体来说用得不错，但我还是有点嫌弃它界面有点丑。。我查阅了其他一些流行的编辑器，如sublime,lyX等，最终还是选择了texmaker的fork版texstudio，界面之类的改进了很多，加上之前texmaker习惯大部分都适用，我觉得还是不错的。至于为什么不用vim来编辑latex，我觉得这就像我不用vim编辑markdown一样，我觉得latex及markdown都是需要实时预览，编辑起来才爽的语言，虽然vim也可以搞些插件来预览，但是一方面太麻烦，一方面vim提倡的是解放双手，远离鼠标，一旦有实时预览，双手必然会回归鼠标，我觉得这样就没有必要了，因此对于markdown和latex我都选择了其他编辑器。下图是texstudio界面：\n![image.png](http://upload-images.jianshu.io/upload_images/825093-185e4118d7e48ae9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/800)\n\n## 中文支持\n其实latex支持中文很简单，只需在头文件处加入`\\usepackage{ctex}`或者`\\usepackage{xeCJK}`,然后用xelatex编译即可，中文字体也可以通过`\\setCJKmainfont{中文字体}`自己设置。\n\n## 字体包问题\n我在编译一个文件时用到了`\\usapage{uarial}`,但是编译失败，message显示`File 'uarial.sty' not found`，该包没有默认安装，经过google之后，我起初以为是ubuntu没有该uarial字体，于是将windows下的字体都安装到了Ubuntu中，并且还装了文泉译微米黑字体(为了好看)..\n```\nsudo apt-get install ttf-wqy-microhei \nsudo apt-get install ttf-mscorefonts-installer \nsudo fc-cache -f -v //更新\n```\n这么做之后并无乱用，因为问题其实是latex缺少包，而非系统缺少字体。。\n\n正确做法是从CTAN下载non free fonts,也就是这些字体包不是免费的(怪不得不默认安装在latex)。。\n```\nwget -q http://tug.org/fonts/getnonfreefonts/install-getnonfreefonts\nsudo texlua ./install-getnonfreefonts\nsudo getnonfreefonts --sys -a\n```\n\n---\n\n# Matlab R2016a\n我分享的iso下载地址及crack破解文件:[百度网盘](http://pan.baidu.com/s/1nuHAUCh)\n\n## 1. 挂载安装\n```linux\nsudo mkdir /media/matlab\nsudo mount -o loop ~/Downloads/R2016a_glnxa64.iso /media/matlab/ //挂载iso到/matlab文件夹\ncd /media/matlab\nsudo ./install\n```\n\n## 2.破解激活\n- 安装过程中选择不联网安装,输入产品密钥(crack文件中的FIK).\n- 等待安装完成, 默认安装位置为/usr/local/MATLAB/R2016a.\n- 安装结束后,打开matlab应用程序.\n```linux\ncd /usr/local/MATLAB/R2016a/bin/glnxa64/\nsudo MATLAB\n```\n选择离线激活,并添加crack中的Matlab_R2016a_glnxa64.lic.\n\n- 将crack中的另外两个文件复制到matlab安装目录下.\n```linux\nsudo cp ~/Downloads/crack/libcufft.so.7.5.18 /usr/local/MATLAB/R2016a/bin/glnxa64/\n sudo cp ~/Downloads/crack/libmwservices.so /usr/local/MATLAB/R2016a/bin/glnxa64/\n```\n\n## 3. 创建快捷方式\n- 由于默认PATH里不包含/usr/local/MATLAB,所以终端直接输入matlab是不行的,可以创建一个软链接\n`sudo ln -s /usr/local/MATLAB/R2016a/bin/glnxa64/MATLAB /usr/local/bin/matlab\n`\n- 为了更加方便,我们可以创建一个桌面快捷方式,在/usr/share/applications/下面创建一个Matlab.desktop,并添加内容如下\n\n        [Desktop Entry]\n        Type = Application\n        Name = Matlab\n        GenericName = Matlab R2016a\n        Comment = Matlab R2016a: The Language of the Technical Computing\n        Exec = /usr/local/MATLAB/R2016a/bin/glnxa64/MATLAB -desktop //路径需自己修改\n        Icon = /usr/local/MATLAB/matlab.png // 网上下载一个快捷方式图标\n        StartupNotify = true\n        Terminal = false\n        Categories = Development;Matlab;\n接着加上权限`sudo chmod a+x Matlab.desktop`.\n[我的快捷方式图标](http://upload-images.jianshu.io/upload_images/825093-3a8333c910981276.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/120)可供下载.\n![Matlab](http://upload-images.jianshu.io/upload_images/825093-3a8333c910981276.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/120)\n\n- 为了避免每次打开matlab后存在权限问题无法读取~/.matab文件的问题，通过`sudo chown [your ubuntu username] -R ~/.matlab`改变权限。\n\n## 4. 字体和快捷键\n- 字体美化:进入Matlab，从菜单打开Preferences，打开Fonts页，把右边最下面的复选框Use antialising to smooth desktop fonts选中.\n- 中文字体显示问题:可以不用很麻烦,同样打开Preferences->Fonts,挑选一个支持中文的字体就ok了,我选择的是AR PL Ukai CN(楷体)．\n- 默认的快捷键是Emacs的，有点不习惯，可以Preferences->Keyboard->Shortcuts->Active settings选Windows Default set.\n\n---\n# Hexo\n之前在Ubuntu14.04里我用octopress搭建了个人博客，重装之后我原本也是想装回octopress的，但是偶然间发现了hexo，一个更加快速、简洁且高效的博客框架！而且支持octopress的完美迁移，看了用hexo搭建的几个demo之后，我立马就决定这回使用hexo搭建个人博客了。\n\n## 安装与使用说明\nhexo的安装和使用可以说相当得简单了，看完[官网的介绍文档](https://hexo.io/zh-cn/docs/index.html)我相信就立马入门了。\n\n## 主题更换\n当然了，安装hexo后最重要当然是选一个自己最心仪的主题（其实官网提供的landscape主题其实也还可以。。），经过一番搜索，我选择了github上hexo主题star数排名第一的next主题，附上github[传送门](https://github.com/iissnan/hexo-theme-next)，以及next作者的[demo](http://notes.iissnan.com/)。\n\nNext的主题安装和使用也有着详细的说明文档，附上[传送门](http://theme-next.iissnan.com/getting-started.html),官网的介绍已经很详细了，我也就不在这里赘述了。\n\n最后，我总结一下自己用到的hexo模块：\n\n- 选择Pisces主题（hexo又分为Muse, Mist, Pisces三个主题）。\n- 阅读次数统计（LeanCloud）。\n- 添加「标签」页面。\n- 设置night bright代码高亮主题。\n- 侧边栏社交链接添加微博，知乎。\n- 开启打赏功能。\n- 添加disqus评论系统。\n- 添加local search。\n- 开启MathJax，这里要注意的是，我在使用分段函数时，分段用的latex代码`\\\\`只被识别前一个`\\`,所以要分段必须使用三个`\\`。。\n\n---\n# Tensorflow\n机器学习将是我的以后工作及学习重心，tensorflow这个平台我必须快速熟悉起来。Tensorflow的安装分为无GPU(只支持CPU)和有GPU的安装，前者安装相当简单，后者的话会很麻烦，还需要对显卡驱动的各种配置。。。由于实验室的工作电脑只是集成显卡而已，所以我就选择了无GPU的安装，当然之后要是有独显了，再研究一下如何支持GPU。\n\n建议使用pip直接进行安装(当然也可以通过docker，Anaconda等第三方环境安装),确保安装了python3及pip3，`sudo apt-get install python3-pip python3-dev`,然后再利用pip3就可以直接安装tensorflow无GPU支持版了，`pip3 install tensorflow`。\n\n## Python安装numpy,scipy,matplotlib库\n作为python中重要的科学计算库，numpy，scipy，matplotlib库一定要正确安装。\n- NumPy是一个定义了数值数组和矩阵类型和它们的基本运算的语言扩展。 \n- SciPy是一种使用NumPy来做高等数学、信号处理、优化、统计和许多其它科学任务的语言扩展。 \n- Matplotlib则可能是Python 2D绘图领域使用最广泛的套件。\n\n之前在windows下用pip安装scipy时，总会遇到依赖问题，我只能通过[这篇知乎上的方法](https://www.zhihu.com/question/30188492)，从非官方维护的第三方库安装scipy。然而在ubuntu下，不需要用pip, 直接利用`apt-get`安装，它会将依赖项自动安装，非常简单有效。\n```\nsudo apt-get install python-numpy\nsudo apt-get install python-scipy\nsudo apt-get install python-matplotlib\n```\n## pip换源\n\n由于连接国外官方pypi很慢，我的电脑大概是70kb/s左右的速度，所以最好将pip源更换为国内的镜像源，我使用的是清华大学的pip源。\n\n新建`~/.pip/pip.conf`,创建内容如下:\n> \n[global]\nindex-url = https://pypi.tuna.tsinghua.edu.cn/simple\n\n","slug":"操作系统/Linux/重装Ubuntu16.04","published":1,"updated":"2022-09-15T03:46:43.360Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551ql0067jqrrga2902zq","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>之前的Ubuntu14.04用了快两年了，中途经过升级之类各种事，感觉系统里的一些依赖什么都被我折腾坏了，右上角总是有个软件更新冲突提示，所以决定重装Ubuntu16.04。值得一提的是，之前装完Ubuntu14.04写了一篇博客发布在简书上，博客名叫<a href=\"http://www.jianshu.com/p/4b9271bba240\" target=\"_blank\" rel=\"noopener\">《开始使用Ubuntu》</a>(这篇博客也迁移到本站点中了)，至今已被阅读908次，喜欢30次，加入了一些Ubuntu专题，感觉还挺有成就感的。</p>\n<h1 id=\"分区\"><a href=\"#分区\" class=\"headerlink\" title=\"分区\"></a>分区</h1><p>有了之前使用Ubuntu14.04的经验，这次我的分区就简单了许多，主分区1,2,3给windows系统，第四个主分区变成拓展分区，拓展为<code>/boot:500M</code>(由于经常更新内核，还是需要多一点空间); <code>/:400G</code>;<code>/home:250G</code>(个人文件夹要放很多文件，所以最好单独分出来);<code>/swap:8G(大小和内存相似)</code>。</p>\n<h1 id=\"VPN\"><a href=\"#VPN\" class=\"headerlink\" title=\"VPN\"></a>VPN</h1><p>我发现之前从校内网下载的deb包在Ubuntu16.04里无法使用，原因是因为该deb包依赖iproute，然而在我还未联网更新的Ubuntu16.04中没有iproute,iproute2取代了iproute，所以我解压了该deb包，修改了依赖项，并重新打包，然后安装完就ok了。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dpkg -X xl2tpd_1.1.12-zju2_am64_new.deb test/ //解压文件</span><br><span class=\"line\">sudo dpkg -e xl2tpd_1.1.12-zju2_am64_new.deb test/ //解压控制文件</span><br><span class=\"line\">修改control文件</span><br><span class=\"line\">sudo dpkg-deb -b test/ new.deb //重新打包</span><br><span class=\"line\">sudo dpkg -i new.deb //安装</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"换源\"><a href=\"#换源\" class=\"headerlink\" title=\"换源\"></a>换源</h1><p>在software&amp;Updates里面可以进行测速，系统会自动选择一个速度最好的源，系统给我选了<code>http://ubuntu.cn99.com/ubuntu</code>这个源，保险起见我又添加了一个自己学校的源。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># ZJU</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ xenial main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ xenial-security main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ xenial main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ xenial-security main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse</span><br></pre></td></tr></table></figure></p>\n<p>换好之后更新源：<code>sudo apt-get update</code></p>\n<h1 id=\"搜狗输入法\"><a href=\"#搜狗输入法\" class=\"headerlink\" title=\"搜狗输入法\"></a>搜狗输入法</h1><p>官网下载deb文件安装即可，<code>sudo apt-get install -f</code>解决依赖问题，并且在系统语言设置出选择fcitx,添加sogo pinyin.</p>\n<h1 id=\"Chrome浏览器\"><a href=\"#Chrome浏览器\" class=\"headerlink\" title=\"Chrome浏览器\"></a>Chrome浏览器</h1><p>添加第三方源并安装。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo wget https://repo.fdzh.org/chrome/google-chrome.list -P /etc/apt/sources.list.d/ </span><br><span class=\"line\">wget -q -O - https://dl.google.com/linux/linux_signing_key.pub  | sudo apt-key add -</span><br><span class=\"line\">sudo apt-get update</span><br><span class=\"line\">sudo apt-get install google-chrome-stable</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"Shadowsocks\"><a href=\"#Shadowsocks\" class=\"headerlink\" title=\"Shadowsocks\"></a>Shadowsocks</h1><p>不用多说，翻墙是必备的。为了方便起见，我选择安装图形界面的shadowsocks,即shadowsocks-qt5,详细的ss说明可参照<a href=\"https://github.com/shadowsocks/shadowsocks/wiki\" target=\"_blank\" rel=\"noopener\">这里</a>,虽然代码已删，但是wiki还在。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo add-apt-repository ppa:hzwhuang/ss-qt5 //ppa即personal package archives</span><br><span class=\"line\">sudo apt-get update</span><br><span class=\"line\">sudo apt-get install shadowsocks-qt5</span><br></pre></td></tr></table></figure></p>\n<p>下载完成后再配置ip地址等等，我买的服务器是包年100元，感觉还凑合。此外，配置好SS后，只是打开了sock5代理端口，如何让chrome用ss代理还是另一码事。</p>\n<p>接下来，我们需要在chrome里安装一个插件:SwitchyOmega，插件安装后需要进行配置。首先，新建一个情景模式，然后修改为sock5协议以及配置端口。<br><img src=\"http://upload-images.jianshu.io/upload_images/825093-708ebfa92c818de0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/800\" alt=\"新建SS情景模式\"></p>\n<p>然后，我们再在自动切换这个情景模式下进行修改，首先添加一个给GFW墙掉的地址链接，该链接为<code>https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt</code>,由<a href=\"https://github.com/gfwlist/gfwlist\" target=\"_blank\" rel=\"noopener\">github的一个项目</a>维护。然后，我们设置该地址里的url,我们用ss代理，其他url全部直接连接，这就相当于一个pac了。<br><img src=\"http://upload-images.jianshu.io/upload_images/825093-90aab2477f7c436f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/800\" alt=\"自动切换情景模式\"></p>\n<p>最后保存之后，就可以翻墙了。</p>\n<h1 id=\"Git\"><a href=\"#Git\" class=\"headerlink\" title=\"Git\"></a>Git</h1><p>安装很简单，<code>sudo apt-get install git</code>,下载好之后，配置一下该电脑下的公私钥。</p>\n<h1 id=\"Latex\"><a href=\"#Latex\" class=\"headerlink\" title=\"Latex\"></a>Latex</h1><p>不用多说，写论文必备，当做平时写文章也还行，markdown转pdf我一直都觉得挺麻烦的。。装latex无非就是编译环境和编辑器两方面，编译环境在linux下一般都用texlive，为了方便，我直接安装了全套texlive…整整3G多..<code>sudo apt-get install texlive-full</code>。</p>\n<p>对于编辑器选择，我直接用的是texmaker,虽然整体来说用得不错，但我还是有点嫌弃它界面有点丑。。我查阅了其他一些流行的编辑器，如sublime,lyX等，最终还是选择了texmaker的fork版texstudio，界面之类的改进了很多，加上之前texmaker习惯大部分都适用，我觉得还是不错的。至于为什么不用vim来编辑latex，我觉得这就像我不用vim编辑markdown一样，我觉得latex及markdown都是需要实时预览，编辑起来才爽的语言，虽然vim也可以搞些插件来预览，但是一方面太麻烦，一方面vim提倡的是解放双手，远离鼠标，一旦有实时预览，双手必然会回归鼠标，我觉得这样就没有必要了，因此对于markdown和latex我都选择了其他编辑器。下图是texstudio界面：<br><img src=\"http://upload-images.jianshu.io/upload_images/825093-185e4118d7e48ae9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/800\" alt=\"image.png\"></p>\n<h2 id=\"中文支持\"><a href=\"#中文支持\" class=\"headerlink\" title=\"中文支持\"></a>中文支持</h2><p>其实latex支持中文很简单，只需在头文件处加入<code>\\usepackage{ctex}</code>或者<code>\\usepackage{xeCJK}</code>,然后用xelatex编译即可，中文字体也可以通过<code>\\setCJKmainfont{中文字体}</code>自己设置。</p>\n<h2 id=\"字体包问题\"><a href=\"#字体包问题\" class=\"headerlink\" title=\"字体包问题\"></a>字体包问题</h2><p>我在编译一个文件时用到了<code>\\usapage{uarial}</code>,但是编译失败，message显示<code>File &#39;uarial.sty&#39; not found</code>，该包没有默认安装，经过google之后，我起初以为是ubuntu没有该uarial字体，于是将windows下的字体都安装到了Ubuntu中，并且还装了文泉译微米黑字体(为了好看)..<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install ttf-wqy-microhei </span><br><span class=\"line\">sudo apt-get install ttf-mscorefonts-installer </span><br><span class=\"line\">sudo fc-cache -f -v //更新</span><br></pre></td></tr></table></figure></p>\n<p>这么做之后并无乱用，因为问题其实是latex缺少包，而非系统缺少字体。。</p>\n<p>正确做法是从CTAN下载non free fonts,也就是这些字体包不是免费的(怪不得不默认安装在latex)。。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget -q http://tug.org/fonts/getnonfreefonts/install-getnonfreefonts</span><br><span class=\"line\">sudo texlua ./install-getnonfreefonts</span><br><span class=\"line\">sudo getnonfreefonts --sys -a</span><br></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"Matlab-R2016a\"><a href=\"#Matlab-R2016a\" class=\"headerlink\" title=\"Matlab R2016a\"></a>Matlab R2016a</h1><p>我分享的iso下载地址及crack破解文件:<a href=\"http://pan.baidu.com/s/1nuHAUCh\" target=\"_blank\" rel=\"noopener\">百度网盘</a></p>\n<h2 id=\"1-挂载安装\"><a href=\"#1-挂载安装\" class=\"headerlink\" title=\"1. 挂载安装\"></a>1. 挂载安装</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mkdir /media/matlab</span><br><span class=\"line\">sudo mount -o loop ~/Downloads/R2016a_glnxa64.iso /media/matlab/ //挂载iso到/matlab文件夹</span><br><span class=\"line\">cd /media/matlab</span><br><span class=\"line\">sudo ./install</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-破解激活\"><a href=\"#2-破解激活\" class=\"headerlink\" title=\"2.破解激活\"></a>2.破解激活</h2><ul>\n<li>安装过程中选择不联网安装,输入产品密钥(crack文件中的FIK).</li>\n<li>等待安装完成, 默认安装位置为/usr/local/MATLAB/R2016a.</li>\n<li>安装结束后,打开matlab应用程序.<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /usr/local/MATLAB/R2016a/bin/glnxa64/</span><br><span class=\"line\">sudo MATLAB</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>选择离线激活,并添加crack中的Matlab_R2016a_glnxa64.lic.</p>\n<ul>\n<li>将crack中的另外两个文件复制到matlab安装目录下.<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo cp ~/Downloads/crack/libcufft.so.7.5.18 /usr/local/MATLAB/R2016a/bin/glnxa64/</span><br><span class=\"line\"> sudo cp ~/Downloads/crack/libmwservices.so /usr/local/MATLAB/R2016a/bin/glnxa64/</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"3-创建快捷方式\"><a href=\"#3-创建快捷方式\" class=\"headerlink\" title=\"3. 创建快捷方式\"></a>3. 创建快捷方式</h2><ul>\n<li>由于默认PATH里不包含/usr/local/MATLAB,所以终端直接输入matlab是不行的,可以创建一个软链接<br><code>sudo ln -s /usr/local/MATLAB/R2016a/bin/glnxa64/MATLAB /usr/local/bin/matlab</code></li>\n<li><p>为了更加方便,我们可以创建一个桌面快捷方式,在/usr/share/applications/下面创建一个Matlab.desktop,并添加内容如下</p>\n<pre><code>  [Desktop Entry]\n  Type = Application\n  Name = Matlab\n  GenericName = Matlab R2016a\n  Comment = Matlab R2016a: The Language of the Technical Computing\n  Exec = /usr/local/MATLAB/R2016a/bin/glnxa64/MATLAB -desktop //路径需自己修改\n  Icon = /usr/local/MATLAB/matlab.png // 网上下载一个快捷方式图标\n  StartupNotify = true\n  Terminal = false\n  Categories = Development;Matlab;\n</code></pre><p>接着加上权限<code>sudo chmod a+x Matlab.desktop</code>.<br><a href=\"http://upload-images.jianshu.io/upload_images/825093-3a8333c910981276.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/120\" target=\"_blank\" rel=\"noopener\">我的快捷方式图标</a>可供下载.<br><img src=\"http://upload-images.jianshu.io/upload_images/825093-3a8333c910981276.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/120\" alt=\"Matlab\"></p>\n</li>\n<li><p>为了避免每次打开matlab后存在权限问题无法读取~/.matab文件的问题，通过<code>sudo chown [your ubuntu username] -R ~/.matlab</code>改变权限。</p>\n</li>\n</ul>\n<h2 id=\"4-字体和快捷键\"><a href=\"#4-字体和快捷键\" class=\"headerlink\" title=\"4. 字体和快捷键\"></a>4. 字体和快捷键</h2><ul>\n<li>字体美化:进入Matlab，从菜单打开Preferences，打开Fonts页，把右边最下面的复选框Use antialising to smooth desktop fonts选中.</li>\n<li>中文字体显示问题:可以不用很麻烦,同样打开Preferences-&gt;Fonts,挑选一个支持中文的字体就ok了,我选择的是AR PL Ukai CN(楷体)．</li>\n<li>默认的快捷键是Emacs的，有点不习惯，可以Preferences-&gt;Keyboard-&gt;Shortcuts-&gt;Active settings选Windows Default set.</li>\n</ul>\n<hr>\n<h1 id=\"Hexo\"><a href=\"#Hexo\" class=\"headerlink\" title=\"Hexo\"></a>Hexo</h1><p>之前在Ubuntu14.04里我用octopress搭建了个人博客，重装之后我原本也是想装回octopress的，但是偶然间发现了hexo，一个更加快速、简洁且高效的博客框架！而且支持octopress的完美迁移，看了用hexo搭建的几个demo之后，我立马就决定这回使用hexo搭建个人博客了。</p>\n<h2 id=\"安装与使用说明\"><a href=\"#安装与使用说明\" class=\"headerlink\" title=\"安装与使用说明\"></a>安装与使用说明</h2><p>hexo的安装和使用可以说相当得简单了，看完<a href=\"https://hexo.io/zh-cn/docs/index.html\" target=\"_blank\" rel=\"noopener\">官网的介绍文档</a>我相信就立马入门了。</p>\n<h2 id=\"主题更换\"><a href=\"#主题更换\" class=\"headerlink\" title=\"主题更换\"></a>主题更换</h2><p>当然了，安装hexo后最重要当然是选一个自己最心仪的主题（其实官网提供的landscape主题其实也还可以。。），经过一番搜索，我选择了github上hexo主题star数排名第一的next主题，附上github<a href=\"https://github.com/iissnan/hexo-theme-next\" target=\"_blank\" rel=\"noopener\">传送门</a>，以及next作者的<a href=\"http://notes.iissnan.com/\" target=\"_blank\" rel=\"noopener\">demo</a>。</p>\n<p>Next的主题安装和使用也有着详细的说明文档，附上<a href=\"http://theme-next.iissnan.com/getting-started.html\" target=\"_blank\" rel=\"noopener\">传送门</a>,官网的介绍已经很详细了，我也就不在这里赘述了。</p>\n<p>最后，我总结一下自己用到的hexo模块：</p>\n<ul>\n<li>选择Pisces主题（hexo又分为Muse, Mist, Pisces三个主题）。</li>\n<li>阅读次数统计（LeanCloud）。</li>\n<li>添加「标签」页面。</li>\n<li>设置night bright代码高亮主题。</li>\n<li>侧边栏社交链接添加微博，知乎。</li>\n<li>开启打赏功能。</li>\n<li>添加disqus评论系统。</li>\n<li>添加local search。</li>\n<li>开启MathJax，这里要注意的是，我在使用分段函数时，分段用的latex代码<code>\\\\</code>只被识别前一个<code>\\</code>,所以要分段必须使用三个<code>\\</code>。。</li>\n</ul>\n<hr>\n<h1 id=\"Tensorflow\"><a href=\"#Tensorflow\" class=\"headerlink\" title=\"Tensorflow\"></a>Tensorflow</h1><p>机器学习将是我的以后工作及学习重心，tensorflow这个平台我必须快速熟悉起来。Tensorflow的安装分为无GPU(只支持CPU)和有GPU的安装，前者安装相当简单，后者的话会很麻烦，还需要对显卡驱动的各种配置。。。由于实验室的工作电脑只是集成显卡而已，所以我就选择了无GPU的安装，当然之后要是有独显了，再研究一下如何支持GPU。</p>\n<p>建议使用pip直接进行安装(当然也可以通过docker，Anaconda等第三方环境安装),确保安装了python3及pip3，<code>sudo apt-get install python3-pip python3-dev</code>,然后再利用pip3就可以直接安装tensorflow无GPU支持版了，<code>pip3 install tensorflow</code>。</p>\n<h2 id=\"Python安装numpy-scipy-matplotlib库\"><a href=\"#Python安装numpy-scipy-matplotlib库\" class=\"headerlink\" title=\"Python安装numpy,scipy,matplotlib库\"></a>Python安装numpy,scipy,matplotlib库</h2><p>作为python中重要的科学计算库，numpy，scipy，matplotlib库一定要正确安装。</p>\n<ul>\n<li>NumPy是一个定义了数值数组和矩阵类型和它们的基本运算的语言扩展。 </li>\n<li>SciPy是一种使用NumPy来做高等数学、信号处理、优化、统计和许多其它科学任务的语言扩展。 </li>\n<li>Matplotlib则可能是Python 2D绘图领域使用最广泛的套件。</li>\n</ul>\n<p>之前在windows下用pip安装scipy时，总会遇到依赖问题，我只能通过<a href=\"https://www.zhihu.com/question/30188492\" target=\"_blank\" rel=\"noopener\">这篇知乎上的方法</a>，从非官方维护的第三方库安装scipy。然而在ubuntu下，不需要用pip, 直接利用<code>apt-get</code>安装，它会将依赖项自动安装，非常简单有效。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install python-numpy</span><br><span class=\"line\">sudo apt-get install python-scipy</span><br><span class=\"line\">sudo apt-get install python-matplotlib</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"pip换源\"><a href=\"#pip换源\" class=\"headerlink\" title=\"pip换源\"></a>pip换源</h2><p>由于连接国外官方pypi很慢，我的电脑大概是70kb/s左右的速度，所以最好将pip源更换为国内的镜像源，我使用的是清华大学的pip源。</p>\n<p>新建<code>~/.pip/pip.conf</code>,创建内容如下:</p>\n<blockquote>\n<p>[global]<br>index-url = <a href=\"https://pypi.tuna.tsinghua.edu.cn/simple\" target=\"_blank\" rel=\"noopener\">https://pypi.tuna.tsinghua.edu.cn/simple</a></p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<p>之前的Ubuntu14.04用了快两年了，中途经过升级之类各种事，感觉系统里的一些依赖什么都被我折腾坏了，右上角总是有个软件更新冲突提示，所以决定重装Ubuntu16.04。值得一提的是，之前装完Ubuntu14.04写了一篇博客发布在简书上，博客名叫<a href=\"http://www.jianshu.com/p/4b9271bba240\" target=\"_blank\" rel=\"noopener\">《开始使用Ubuntu》</a>(这篇博客也迁移到本站点中了)，至今已被阅读908次，喜欢30次，加入了一些Ubuntu专题，感觉还挺有成就感的。</p>\n<h1 id=\"分区\"><a href=\"#分区\" class=\"headerlink\" title=\"分区\"></a>分区</h1><p>有了之前使用Ubuntu14.04的经验，这次我的分区就简单了许多，主分区1,2,3给windows系统，第四个主分区变成拓展分区，拓展为<code>/boot:500M</code>(由于经常更新内核，还是需要多一点空间); <code>/:400G</code>;<code>/home:250G</code>(个人文件夹要放很多文件，所以最好单独分出来);<code>/swap:8G(大小和内存相似)</code>。</p>\n<h1 id=\"VPN\"><a href=\"#VPN\" class=\"headerlink\" title=\"VPN\"></a>VPN</h1><p>我发现之前从校内网下载的deb包在Ubuntu16.04里无法使用，原因是因为该deb包依赖iproute，然而在我还未联网更新的Ubuntu16.04中没有iproute,iproute2取代了iproute，所以我解压了该deb包，修改了依赖项，并重新打包，然后安装完就ok了。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo dpkg -X xl2tpd_1.1.12-zju2_am64_new.deb test/ //解压文件</span><br><span class=\"line\">sudo dpkg -e xl2tpd_1.1.12-zju2_am64_new.deb test/ //解压控制文件</span><br><span class=\"line\">修改control文件</span><br><span class=\"line\">sudo dpkg-deb -b test/ new.deb //重新打包</span><br><span class=\"line\">sudo dpkg -i new.deb //安装</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"换源\"><a href=\"#换源\" class=\"headerlink\" title=\"换源\"></a>换源</h1><p>在software&amp;Updates里面可以进行测速，系统会自动选择一个速度最好的源，系统给我选了<code>http://ubuntu.cn99.com/ubuntu</code>这个源，保险起见我又添加了一个自己学校的源。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># ZJU</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ xenial main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ xenial-security main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse</span><br><span class=\"line\">deb http://mirrors.zju.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ xenial main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ xenial-security main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse</span><br><span class=\"line\">deb-src http://mirrors.zju.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse</span><br></pre></td></tr></table></figure></p>\n<p>换好之后更新源：<code>sudo apt-get update</code></p>\n<h1 id=\"搜狗输入法\"><a href=\"#搜狗输入法\" class=\"headerlink\" title=\"搜狗输入法\"></a>搜狗输入法</h1><p>官网下载deb文件安装即可，<code>sudo apt-get install -f</code>解决依赖问题，并且在系统语言设置出选择fcitx,添加sogo pinyin.</p>\n<h1 id=\"Chrome浏览器\"><a href=\"#Chrome浏览器\" class=\"headerlink\" title=\"Chrome浏览器\"></a>Chrome浏览器</h1><p>添加第三方源并安装。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo wget https://repo.fdzh.org/chrome/google-chrome.list -P /etc/apt/sources.list.d/ </span><br><span class=\"line\">wget -q -O - https://dl.google.com/linux/linux_signing_key.pub  | sudo apt-key add -</span><br><span class=\"line\">sudo apt-get update</span><br><span class=\"line\">sudo apt-get install google-chrome-stable</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"Shadowsocks\"><a href=\"#Shadowsocks\" class=\"headerlink\" title=\"Shadowsocks\"></a>Shadowsocks</h1><p>不用多说，翻墙是必备的。为了方便起见，我选择安装图形界面的shadowsocks,即shadowsocks-qt5,详细的ss说明可参照<a href=\"https://github.com/shadowsocks/shadowsocks/wiki\" target=\"_blank\" rel=\"noopener\">这里</a>,虽然代码已删，但是wiki还在。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo add-apt-repository ppa:hzwhuang/ss-qt5 //ppa即personal package archives</span><br><span class=\"line\">sudo apt-get update</span><br><span class=\"line\">sudo apt-get install shadowsocks-qt5</span><br></pre></td></tr></table></figure></p>\n<p>下载完成后再配置ip地址等等，我买的服务器是包年100元，感觉还凑合。此外，配置好SS后，只是打开了sock5代理端口，如何让chrome用ss代理还是另一码事。</p>\n<p>接下来，我们需要在chrome里安装一个插件:SwitchyOmega，插件安装后需要进行配置。首先，新建一个情景模式，然后修改为sock5协议以及配置端口。<br><img src=\"http://upload-images.jianshu.io/upload_images/825093-708ebfa92c818de0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/800\" alt=\"新建SS情景模式\"></p>\n<p>然后，我们再在自动切换这个情景模式下进行修改，首先添加一个给GFW墙掉的地址链接，该链接为<code>https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt</code>,由<a href=\"https://github.com/gfwlist/gfwlist\" target=\"_blank\" rel=\"noopener\">github的一个项目</a>维护。然后，我们设置该地址里的url,我们用ss代理，其他url全部直接连接，这就相当于一个pac了。<br><img src=\"http://upload-images.jianshu.io/upload_images/825093-90aab2477f7c436f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/800\" alt=\"自动切换情景模式\"></p>\n<p>最后保存之后，就可以翻墙了。</p>\n<h1 id=\"Git\"><a href=\"#Git\" class=\"headerlink\" title=\"Git\"></a>Git</h1><p>安装很简单，<code>sudo apt-get install git</code>,下载好之后，配置一下该电脑下的公私钥。</p>\n<h1 id=\"Latex\"><a href=\"#Latex\" class=\"headerlink\" title=\"Latex\"></a>Latex</h1><p>不用多说，写论文必备，当做平时写文章也还行，markdown转pdf我一直都觉得挺麻烦的。。装latex无非就是编译环境和编辑器两方面，编译环境在linux下一般都用texlive，为了方便，我直接安装了全套texlive…整整3G多..<code>sudo apt-get install texlive-full</code>。</p>\n<p>对于编辑器选择，我直接用的是texmaker,虽然整体来说用得不错，但我还是有点嫌弃它界面有点丑。。我查阅了其他一些流行的编辑器，如sublime,lyX等，最终还是选择了texmaker的fork版texstudio，界面之类的改进了很多，加上之前texmaker习惯大部分都适用，我觉得还是不错的。至于为什么不用vim来编辑latex，我觉得这就像我不用vim编辑markdown一样，我觉得latex及markdown都是需要实时预览，编辑起来才爽的语言，虽然vim也可以搞些插件来预览，但是一方面太麻烦，一方面vim提倡的是解放双手，远离鼠标，一旦有实时预览，双手必然会回归鼠标，我觉得这样就没有必要了，因此对于markdown和latex我都选择了其他编辑器。下图是texstudio界面：<br><img src=\"http://upload-images.jianshu.io/upload_images/825093-185e4118d7e48ae9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/800\" alt=\"image.png\"></p>\n<h2 id=\"中文支持\"><a href=\"#中文支持\" class=\"headerlink\" title=\"中文支持\"></a>中文支持</h2><p>其实latex支持中文很简单，只需在头文件处加入<code>\\usepackage{ctex}</code>或者<code>\\usepackage{xeCJK}</code>,然后用xelatex编译即可，中文字体也可以通过<code>\\setCJKmainfont{中文字体}</code>自己设置。</p>\n<h2 id=\"字体包问题\"><a href=\"#字体包问题\" class=\"headerlink\" title=\"字体包问题\"></a>字体包问题</h2><p>我在编译一个文件时用到了<code>\\usapage{uarial}</code>,但是编译失败，message显示<code>File &#39;uarial.sty&#39; not found</code>，该包没有默认安装，经过google之后，我起初以为是ubuntu没有该uarial字体，于是将windows下的字体都安装到了Ubuntu中，并且还装了文泉译微米黑字体(为了好看)..<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install ttf-wqy-microhei </span><br><span class=\"line\">sudo apt-get install ttf-mscorefonts-installer </span><br><span class=\"line\">sudo fc-cache -f -v //更新</span><br></pre></td></tr></table></figure></p>\n<p>这么做之后并无乱用，因为问题其实是latex缺少包，而非系统缺少字体。。</p>\n<p>正确做法是从CTAN下载non free fonts,也就是这些字体包不是免费的(怪不得不默认安装在latex)。。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget -q http://tug.org/fonts/getnonfreefonts/install-getnonfreefonts</span><br><span class=\"line\">sudo texlua ./install-getnonfreefonts</span><br><span class=\"line\">sudo getnonfreefonts --sys -a</span><br></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"Matlab-R2016a\"><a href=\"#Matlab-R2016a\" class=\"headerlink\" title=\"Matlab R2016a\"></a>Matlab R2016a</h1><p>我分享的iso下载地址及crack破解文件:<a href=\"http://pan.baidu.com/s/1nuHAUCh\" target=\"_blank\" rel=\"noopener\">百度网盘</a></p>\n<h2 id=\"1-挂载安装\"><a href=\"#1-挂载安装\" class=\"headerlink\" title=\"1. 挂载安装\"></a>1. 挂载安装</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mkdir /media/matlab</span><br><span class=\"line\">sudo mount -o loop ~/Downloads/R2016a_glnxa64.iso /media/matlab/ //挂载iso到/matlab文件夹</span><br><span class=\"line\">cd /media/matlab</span><br><span class=\"line\">sudo ./install</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-破解激活\"><a href=\"#2-破解激活\" class=\"headerlink\" title=\"2.破解激活\"></a>2.破解激活</h2><ul>\n<li>安装过程中选择不联网安装,输入产品密钥(crack文件中的FIK).</li>\n<li>等待安装完成, 默认安装位置为/usr/local/MATLAB/R2016a.</li>\n<li>安装结束后,打开matlab应用程序.<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /usr/local/MATLAB/R2016a/bin/glnxa64/</span><br><span class=\"line\">sudo MATLAB</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>选择离线激活,并添加crack中的Matlab_R2016a_glnxa64.lic.</p>\n<ul>\n<li>将crack中的另外两个文件复制到matlab安装目录下.<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo cp ~/Downloads/crack/libcufft.so.7.5.18 /usr/local/MATLAB/R2016a/bin/glnxa64/</span><br><span class=\"line\"> sudo cp ~/Downloads/crack/libmwservices.so /usr/local/MATLAB/R2016a/bin/glnxa64/</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"3-创建快捷方式\"><a href=\"#3-创建快捷方式\" class=\"headerlink\" title=\"3. 创建快捷方式\"></a>3. 创建快捷方式</h2><ul>\n<li>由于默认PATH里不包含/usr/local/MATLAB,所以终端直接输入matlab是不行的,可以创建一个软链接<br><code>sudo ln -s /usr/local/MATLAB/R2016a/bin/glnxa64/MATLAB /usr/local/bin/matlab</code></li>\n<li><p>为了更加方便,我们可以创建一个桌面快捷方式,在/usr/share/applications/下面创建一个Matlab.desktop,并添加内容如下</p>\n<pre><code>  [Desktop Entry]\n  Type = Application\n  Name = Matlab\n  GenericName = Matlab R2016a\n  Comment = Matlab R2016a: The Language of the Technical Computing\n  Exec = /usr/local/MATLAB/R2016a/bin/glnxa64/MATLAB -desktop //路径需自己修改\n  Icon = /usr/local/MATLAB/matlab.png // 网上下载一个快捷方式图标\n  StartupNotify = true\n  Terminal = false\n  Categories = Development;Matlab;\n</code></pre><p>接着加上权限<code>sudo chmod a+x Matlab.desktop</code>.<br><a href=\"http://upload-images.jianshu.io/upload_images/825093-3a8333c910981276.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/120\" target=\"_blank\" rel=\"noopener\">我的快捷方式图标</a>可供下载.<br><img src=\"http://upload-images.jianshu.io/upload_images/825093-3a8333c910981276.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/120\" alt=\"Matlab\"></p>\n</li>\n<li><p>为了避免每次打开matlab后存在权限问题无法读取~/.matab文件的问题，通过<code>sudo chown [your ubuntu username] -R ~/.matlab</code>改变权限。</p>\n</li>\n</ul>\n<h2 id=\"4-字体和快捷键\"><a href=\"#4-字体和快捷键\" class=\"headerlink\" title=\"4. 字体和快捷键\"></a>4. 字体和快捷键</h2><ul>\n<li>字体美化:进入Matlab，从菜单打开Preferences，打开Fonts页，把右边最下面的复选框Use antialising to smooth desktop fonts选中.</li>\n<li>中文字体显示问题:可以不用很麻烦,同样打开Preferences-&gt;Fonts,挑选一个支持中文的字体就ok了,我选择的是AR PL Ukai CN(楷体)．</li>\n<li>默认的快捷键是Emacs的，有点不习惯，可以Preferences-&gt;Keyboard-&gt;Shortcuts-&gt;Active settings选Windows Default set.</li>\n</ul>\n<hr>\n<h1 id=\"Hexo\"><a href=\"#Hexo\" class=\"headerlink\" title=\"Hexo\"></a>Hexo</h1><p>之前在Ubuntu14.04里我用octopress搭建了个人博客，重装之后我原本也是想装回octopress的，但是偶然间发现了hexo，一个更加快速、简洁且高效的博客框架！而且支持octopress的完美迁移，看了用hexo搭建的几个demo之后，我立马就决定这回使用hexo搭建个人博客了。</p>\n<h2 id=\"安装与使用说明\"><a href=\"#安装与使用说明\" class=\"headerlink\" title=\"安装与使用说明\"></a>安装与使用说明</h2><p>hexo的安装和使用可以说相当得简单了，看完<a href=\"https://hexo.io/zh-cn/docs/index.html\" target=\"_blank\" rel=\"noopener\">官网的介绍文档</a>我相信就立马入门了。</p>\n<h2 id=\"主题更换\"><a href=\"#主题更换\" class=\"headerlink\" title=\"主题更换\"></a>主题更换</h2><p>当然了，安装hexo后最重要当然是选一个自己最心仪的主题（其实官网提供的landscape主题其实也还可以。。），经过一番搜索，我选择了github上hexo主题star数排名第一的next主题，附上github<a href=\"https://github.com/iissnan/hexo-theme-next\" target=\"_blank\" rel=\"noopener\">传送门</a>，以及next作者的<a href=\"http://notes.iissnan.com/\" target=\"_blank\" rel=\"noopener\">demo</a>。</p>\n<p>Next的主题安装和使用也有着详细的说明文档，附上<a href=\"http://theme-next.iissnan.com/getting-started.html\" target=\"_blank\" rel=\"noopener\">传送门</a>,官网的介绍已经很详细了，我也就不在这里赘述了。</p>\n<p>最后，我总结一下自己用到的hexo模块：</p>\n<ul>\n<li>选择Pisces主题（hexo又分为Muse, Mist, Pisces三个主题）。</li>\n<li>阅读次数统计（LeanCloud）。</li>\n<li>添加「标签」页面。</li>\n<li>设置night bright代码高亮主题。</li>\n<li>侧边栏社交链接添加微博，知乎。</li>\n<li>开启打赏功能。</li>\n<li>添加disqus评论系统。</li>\n<li>添加local search。</li>\n<li>开启MathJax，这里要注意的是，我在使用分段函数时，分段用的latex代码<code>\\\\</code>只被识别前一个<code>\\</code>,所以要分段必须使用三个<code>\\</code>。。</li>\n</ul>\n<hr>\n<h1 id=\"Tensorflow\"><a href=\"#Tensorflow\" class=\"headerlink\" title=\"Tensorflow\"></a>Tensorflow</h1><p>机器学习将是我的以后工作及学习重心，tensorflow这个平台我必须快速熟悉起来。Tensorflow的安装分为无GPU(只支持CPU)和有GPU的安装，前者安装相当简单，后者的话会很麻烦，还需要对显卡驱动的各种配置。。。由于实验室的工作电脑只是集成显卡而已，所以我就选择了无GPU的安装，当然之后要是有独显了，再研究一下如何支持GPU。</p>\n<p>建议使用pip直接进行安装(当然也可以通过docker，Anaconda等第三方环境安装),确保安装了python3及pip3，<code>sudo apt-get install python3-pip python3-dev</code>,然后再利用pip3就可以直接安装tensorflow无GPU支持版了，<code>pip3 install tensorflow</code>。</p>\n<h2 id=\"Python安装numpy-scipy-matplotlib库\"><a href=\"#Python安装numpy-scipy-matplotlib库\" class=\"headerlink\" title=\"Python安装numpy,scipy,matplotlib库\"></a>Python安装numpy,scipy,matplotlib库</h2><p>作为python中重要的科学计算库，numpy，scipy，matplotlib库一定要正确安装。</p>\n<ul>\n<li>NumPy是一个定义了数值数组和矩阵类型和它们的基本运算的语言扩展。 </li>\n<li>SciPy是一种使用NumPy来做高等数学、信号处理、优化、统计和许多其它科学任务的语言扩展。 </li>\n<li>Matplotlib则可能是Python 2D绘图领域使用最广泛的套件。</li>\n</ul>\n<p>之前在windows下用pip安装scipy时，总会遇到依赖问题，我只能通过<a href=\"https://www.zhihu.com/question/30188492\" target=\"_blank\" rel=\"noopener\">这篇知乎上的方法</a>，从非官方维护的第三方库安装scipy。然而在ubuntu下，不需要用pip, 直接利用<code>apt-get</code>安装，它会将依赖项自动安装，非常简单有效。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install python-numpy</span><br><span class=\"line\">sudo apt-get install python-scipy</span><br><span class=\"line\">sudo apt-get install python-matplotlib</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"pip换源\"><a href=\"#pip换源\" class=\"headerlink\" title=\"pip换源\"></a>pip换源</h2><p>由于连接国外官方pypi很慢，我的电脑大概是70kb/s左右的速度，所以最好将pip源更换为国内的镜像源，我使用的是清华大学的pip源。</p>\n<p>新建<code>~/.pip/pip.conf</code>,创建内容如下:</p>\n<blockquote>\n<p>[global]<br>index-url = <a href=\"https://pypi.tuna.tsinghua.edu.cn/simple\" target=\"_blank\" rel=\"noopener\">https://pypi.tuna.tsinghua.edu.cn/simple</a></p>\n</blockquote>\n"},{"title":"从零搭建Mac开发环境","date":"2020-06-19T16:00:00.000Z","_content":"\n前阵子电脑mac进水，搞了台备机，重新安装了各类软件搭建开发环境，特此记录...以防万一...\n\n###  软件包\n\n1. Chrome\n\n2. 搜狗输入法\n\n3. pycharm（2020.1）\n\n   - 模板：Editor -> File and code Templates  -> Python Script：\n\n     ```python\n      #!/usr/bin/env python\n      # -*- coding: utf-8 -*-\n      # @Author: levylv\n      # @Date  : ${DATE}\n     ```\n\n   - 激活 方法同idea\n\n4. Idea （2020.1）\n\n   - 模板：Editor -> File and code Templates  -> File Header:\n\n     ```java\n     /**\n      * Created by levylv on ${YEAR}/${MONTH}/${DAY}.\n      */\n     ```\n\n   - 激活 2020.1.2破解 https://www.jianshu.com/p/46f00b2ce3ce\n\n   - 插件 leetcode-editor https://github.com/shuzijun/leetcode-question , lombok 官网下载\n\n   - 插件 easycode\n\n5. 钉钉\n\n6. dchat\n\n7. 微信\n\n8. 网易云音乐\n\n9. typora\n\n   - ipic图床\n\n\n\n### 开发环境：\n\n1. Anaconda（4.8.2）\n\n   - 新版conda自己会配置环境变量，以及激活base环境\n\n2. jdk 8\n\n   - 配置java_home：~/.bash_profile。完整的~/.bash_profile配置看后面\n\n3. iterm2\n\n   - 颜色配置：~/.bash_profile\n\n4. homebrew https://zhuanlan.zhihu.com/p/90508170\n\n5. macvim\n\n   - brew install macvim\n\n   - 配置文件~/.vimrc，我的祖传配置：\n\n     ```sh\n     \"Wei Lyu\n     \"levy_lv@hotmail.com\n     \"levylv.github.io\n     \n     \"====================\"\n     \"        通用        \"\n     \"====================\"\n     set nocompatible              \" be iMproved \n     filetype plugin indent on\n     set nobackup \"不备份 \n     set autochdir \"自动切换当前目录\n     \n     \"启动，语法高亮，配色\n     winpos 400 200\n     set lines=100 columns=150\n     set laststatus=2   \"总是显示状态栏\n     set hlsearch  \"搜索高亮\n     set ignorecase \"搜索忽略大小写\n     syntax enable\n     syntax on\n     set t_Co=256\n     set cursorline \"高亮光标行\n     set ruler   \"显示光标位置状态栏\n     set number\n     set guifont=Monaco:h15\n     colorscheme molokai\n     let g:molokai_original = 1\n     let g:rehash256 = 1\n     \n     \n     \"Tab相关\n     set tabstop=4 \"制表符占用空格数\n     set softtabstop=4 \"将连续数量的空格视为一个制表符\n     set shiftwidth=4 \"格式化时制表符占用空格数\n     set expandtab \"制表符扩展为空格\n     set cindent\n     set autoindent\n     \n     \"编码相关\n     set encoding=utf-8\n     set fileencodings=ucs-bom,utf-8,cp936,gb18030,big5,euc-jp,euc-kr,latin1\n     \n     \"使用箭头导航buffer\"\n     \"map <right> :bn<cr>\n     \"map <left> :bp<cr>\n     \"set autowrite \"在切换buffer时自动保存当前的文件\n     \n     \n     \"====================\"\n     \"Vundle Configuration\"\n     \"====================\"\n     filetype off                  \" required\n     \n     \" set the runtime path to include Vundle and initialize\n     set rtp+=~/.vim/bundle/Vundle.vim\n     call vundle#begin()\n     \" alternatively, pass a path where Vundle should install plugins\n     \"call vundle#begin('~/some/path/here')\n     \n     \" let Vundle manage Vundle, required\n     Plugin 'VundleVim/Vundle.vim'\n     \n     \" My Plugin here:\n     \" Plugin 'Valloric/YouCompleteMe'\n     \" Plugin 'majutsushi/tagbar'\n     \" Plugin 'fholgado/minibufexpl.vim'\n     Plugin 'scrooloose/nerdtree'\n     \n     \n     \n     \" All of your Plugins must be added before the following line\n     call vundle#end()            \" required\n     filetype plugin indent on    \" required\n     \n     \n     \"===========================\"\n     \"Vundle Plugin Configuration\"\n     \"===========================\"\n     \n     \"minibufexpl\n     \"let g:miniBufExplMapWindowNavVim = 1 \"可以用<C-h,j,k,l>切换到上下左右的窗口 \n     \"let g:miniBufExplMapCTabSwitchBufs = 1 \"<C-Tab>,<C-S-Tab>切换\n     \"let g:miniBufExplModSelTarget = 1 \n     \n     \"NERDTree\n     nnoremap <Tab> :NERDTreeToggle<CR>\n     \n     ```\n\n   - 主题molokai\n\n   - vundle插件\n\n6. Maven（3.6.3） https://www.runoob.com/maven/maven-setup.html\n\n7. ClashX 翻墙：https://github.com/yichengchen/clashX/releases\n\n8. git\n\n   - ~/.gitconfig配置，祖传alias配置：\n\n     ```shell\n     [user]\n     \tname = lvwei\n     \temail = ***\n     \n     [alias]\n     \ta \t = !git add . && git status\n     \taa       = !git add . && git add -u . && git status\n     \tac       = !git add . && git commit\n     \tacm      = !git add . && git commit -m\n     \talias    = !git config --list | grep 'alias'\n     \tau       = !git add -u . && git status\n     \tc        = commit\n     \tca       = commit --amend\n     \tcm       = commit -m\n     \td        = diff\n     \tl        = log --graph --all --pretty=format:'%C(yellow)%h%C(cyan)%d%Creset %s %C(white)- %an, %ar%Creset'\n     \tlg       = log --color --graph --pretty=format:'%C(bold white)%h%Creset -%C(bold green)%d%Creset %s %C(bold green)(%cr)%Creset %C(bold blue)<%an>%Creset' --abbrev-commit --date=relative\n     \tll       = log --stat --abbrev-commit\n     \tllg      = log --color --graph --pretty=format:'%C(bold white)%H %d%Creset%n%s%n%+b%C(bold blue)%an <%ae>%Creset %C(bold green)%cr (%ci)' --abbrev-commit\n     \tmaster   = checkout master\n     \ts        = status\n     \tspull    = svn rebase\n     \tspush    = svn dcommit\n     \n     [credential]\n     \thelper = store\n     [core]\n     \texcludesfile = /Users/didi/.gitignore_global\n     ```\n\n   - .gitignore_global配置，祖传全局ignore配置：\n\n     ```shell\n     # Compiled source #\n     ###################\n     *.com\n     *.class\n     *.dll\n     *.exe\n     *.o\n     *.so\n      \n     # Packages #\n     ############\n     # it's better to unpack these files and commit the raw source\n     # git has its own built in compression methods\n     *.7z\n     *.dmg\n     *.gz\n     *.iso\n     *.jar\n     *.rar\n     *.tar\n     *.zip\n     # Logs and databases #\n     ######################\n     *.log\n     *.sql\n     *.sqlite\n     # OS generated files #\n     ######################\n     .DS_Store\n     .DS_Store?\n     .idea\n     ._*\n     .Spotlight-V100\n     .Trashes\n     Icon?\n     ehthumbs.db\n     Thumbs.db\n     ```\n\n     \n\n9. ~/.bash_profile配置:\n\n   ```shell\n   # alias\n   alias ll='ls -lF'\n   alias vi='mvim'\n   \n   # iterm2\n   export CLICOLOR=1\n   export LSCOLOR=Gxfxaxdxcxegedabagacad\n   export PS1='\\[\\e[01;33m\\][\\[\\e[01;36m\\]\\u\\[\\e[01;33m\\]@\\[\\e[01;35m\\]\\h\\[\\e[01;33m\\]] \\[\\e[01;36m\\]\\w \\[\\e[01;32m\\]\\$\\[\\033[00m\\] ' #显示全部路径名\n   \n   # JAVAHOME\n   export JAVA_HOME=$(/usr/libexec/java_home)\n   export PATH=$JAVA_HOME/bin:$PATH\n   \n   # Maven\n   export MAVEN_HOME=/usr/local/apache-maven-3.6.3\n   export PATH=$PATH:$MAVEN_HOME/bin\n   \n   # bash shell\n   export BASH_SILENCE_DEPRECATION_WARNING=1\n   \n   # >>> conda initialize >>>\n   # !! Contents within this block are managed by 'conda init' !!\n   __conda_setup=\"$('/opt/anaconda3/bin/conda' 'shell.bash' 'hook' 2> /dev/null)\"\n   if [ $? -eq 0 ]; then\n       eval \"$__conda_setup\"\n   else\n       if [ -f \"/opt/anaconda3/etc/profile.d/conda.sh\" ]; then\n           . \"/opt/anaconda3/etc/profile.d/conda.sh\"\n       else\n           export PATH=\"/opt/anaconda3/bin:$PATH\"\n       fi\n   fi\n   unset __conda_setup\n   # <<< conda initialize <<<\n   export PATH=/opt/anaconda3/bin:$PATH\n   \n   ```\n\n10. tmux配置, ~/.tmux.conf\n\n    ```shell\n    setw -g mode-keys vi\n    new-session -n $HOST\n    set-option -g status-interval 1\n    set-option -g automatic-rename on\n    #set-option -g automatic-rename-format '#(basename \"#{pane_current_path}\")'\n    \n    #select last window\n    bind-key C-l select-window -l\n    \n    #up\n    bind-key k select-pane -U\n    #down\n    bind-key j select-pane -D\n    #left\n    bind-key h select-pane -L\n    #right\n    bind-key l select-pane -R\n    \n    # resize pane\n    bind -r ^k resizep -U 1 # upward (prefix Ctrl+k)\n    bind -r ^j resizep -D 1 # downward (prefix Ctrl+j)\n    bind -r ^h resizep -L 1 # to the left (prefix Ctrl+h)\n    bind -r ^l resizep -R 1 # to the right (prefix Ctrl+l)\n    bind % split-window -h -c \"#{pane_current_path}\"\n    ```\n\n    ","source":"_posts/操作系统/Mac/从零搭建Mac开发环境.md","raw":"---\ntitle: 从零搭建Mac开发环境\ndate: 2020-06-20\ncategories: [操作系统,Mac]\n---\n\n前阵子电脑mac进水，搞了台备机，重新安装了各类软件搭建开发环境，特此记录...以防万一...\n\n###  软件包\n\n1. Chrome\n\n2. 搜狗输入法\n\n3. pycharm（2020.1）\n\n   - 模板：Editor -> File and code Templates  -> Python Script：\n\n     ```python\n      #!/usr/bin/env python\n      # -*- coding: utf-8 -*-\n      # @Author: levylv\n      # @Date  : ${DATE}\n     ```\n\n   - 激活 方法同idea\n\n4. Idea （2020.1）\n\n   - 模板：Editor -> File and code Templates  -> File Header:\n\n     ```java\n     /**\n      * Created by levylv on ${YEAR}/${MONTH}/${DAY}.\n      */\n     ```\n\n   - 激活 2020.1.2破解 https://www.jianshu.com/p/46f00b2ce3ce\n\n   - 插件 leetcode-editor https://github.com/shuzijun/leetcode-question , lombok 官网下载\n\n   - 插件 easycode\n\n5. 钉钉\n\n6. dchat\n\n7. 微信\n\n8. 网易云音乐\n\n9. typora\n\n   - ipic图床\n\n\n\n### 开发环境：\n\n1. Anaconda（4.8.2）\n\n   - 新版conda自己会配置环境变量，以及激活base环境\n\n2. jdk 8\n\n   - 配置java_home：~/.bash_profile。完整的~/.bash_profile配置看后面\n\n3. iterm2\n\n   - 颜色配置：~/.bash_profile\n\n4. homebrew https://zhuanlan.zhihu.com/p/90508170\n\n5. macvim\n\n   - brew install macvim\n\n   - 配置文件~/.vimrc，我的祖传配置：\n\n     ```sh\n     \"Wei Lyu\n     \"levy_lv@hotmail.com\n     \"levylv.github.io\n     \n     \"====================\"\n     \"        通用        \"\n     \"====================\"\n     set nocompatible              \" be iMproved \n     filetype plugin indent on\n     set nobackup \"不备份 \n     set autochdir \"自动切换当前目录\n     \n     \"启动，语法高亮，配色\n     winpos 400 200\n     set lines=100 columns=150\n     set laststatus=2   \"总是显示状态栏\n     set hlsearch  \"搜索高亮\n     set ignorecase \"搜索忽略大小写\n     syntax enable\n     syntax on\n     set t_Co=256\n     set cursorline \"高亮光标行\n     set ruler   \"显示光标位置状态栏\n     set number\n     set guifont=Monaco:h15\n     colorscheme molokai\n     let g:molokai_original = 1\n     let g:rehash256 = 1\n     \n     \n     \"Tab相关\n     set tabstop=4 \"制表符占用空格数\n     set softtabstop=4 \"将连续数量的空格视为一个制表符\n     set shiftwidth=4 \"格式化时制表符占用空格数\n     set expandtab \"制表符扩展为空格\n     set cindent\n     set autoindent\n     \n     \"编码相关\n     set encoding=utf-8\n     set fileencodings=ucs-bom,utf-8,cp936,gb18030,big5,euc-jp,euc-kr,latin1\n     \n     \"使用箭头导航buffer\"\n     \"map <right> :bn<cr>\n     \"map <left> :bp<cr>\n     \"set autowrite \"在切换buffer时自动保存当前的文件\n     \n     \n     \"====================\"\n     \"Vundle Configuration\"\n     \"====================\"\n     filetype off                  \" required\n     \n     \" set the runtime path to include Vundle and initialize\n     set rtp+=~/.vim/bundle/Vundle.vim\n     call vundle#begin()\n     \" alternatively, pass a path where Vundle should install plugins\n     \"call vundle#begin('~/some/path/here')\n     \n     \" let Vundle manage Vundle, required\n     Plugin 'VundleVim/Vundle.vim'\n     \n     \" My Plugin here:\n     \" Plugin 'Valloric/YouCompleteMe'\n     \" Plugin 'majutsushi/tagbar'\n     \" Plugin 'fholgado/minibufexpl.vim'\n     Plugin 'scrooloose/nerdtree'\n     \n     \n     \n     \" All of your Plugins must be added before the following line\n     call vundle#end()            \" required\n     filetype plugin indent on    \" required\n     \n     \n     \"===========================\"\n     \"Vundle Plugin Configuration\"\n     \"===========================\"\n     \n     \"minibufexpl\n     \"let g:miniBufExplMapWindowNavVim = 1 \"可以用<C-h,j,k,l>切换到上下左右的窗口 \n     \"let g:miniBufExplMapCTabSwitchBufs = 1 \"<C-Tab>,<C-S-Tab>切换\n     \"let g:miniBufExplModSelTarget = 1 \n     \n     \"NERDTree\n     nnoremap <Tab> :NERDTreeToggle<CR>\n     \n     ```\n\n   - 主题molokai\n\n   - vundle插件\n\n6. Maven（3.6.3） https://www.runoob.com/maven/maven-setup.html\n\n7. ClashX 翻墙：https://github.com/yichengchen/clashX/releases\n\n8. git\n\n   - ~/.gitconfig配置，祖传alias配置：\n\n     ```shell\n     [user]\n     \tname = lvwei\n     \temail = ***\n     \n     [alias]\n     \ta \t = !git add . && git status\n     \taa       = !git add . && git add -u . && git status\n     \tac       = !git add . && git commit\n     \tacm      = !git add . && git commit -m\n     \talias    = !git config --list | grep 'alias'\n     \tau       = !git add -u . && git status\n     \tc        = commit\n     \tca       = commit --amend\n     \tcm       = commit -m\n     \td        = diff\n     \tl        = log --graph --all --pretty=format:'%C(yellow)%h%C(cyan)%d%Creset %s %C(white)- %an, %ar%Creset'\n     \tlg       = log --color --graph --pretty=format:'%C(bold white)%h%Creset -%C(bold green)%d%Creset %s %C(bold green)(%cr)%Creset %C(bold blue)<%an>%Creset' --abbrev-commit --date=relative\n     \tll       = log --stat --abbrev-commit\n     \tllg      = log --color --graph --pretty=format:'%C(bold white)%H %d%Creset%n%s%n%+b%C(bold blue)%an <%ae>%Creset %C(bold green)%cr (%ci)' --abbrev-commit\n     \tmaster   = checkout master\n     \ts        = status\n     \tspull    = svn rebase\n     \tspush    = svn dcommit\n     \n     [credential]\n     \thelper = store\n     [core]\n     \texcludesfile = /Users/didi/.gitignore_global\n     ```\n\n   - .gitignore_global配置，祖传全局ignore配置：\n\n     ```shell\n     # Compiled source #\n     ###################\n     *.com\n     *.class\n     *.dll\n     *.exe\n     *.o\n     *.so\n      \n     # Packages #\n     ############\n     # it's better to unpack these files and commit the raw source\n     # git has its own built in compression methods\n     *.7z\n     *.dmg\n     *.gz\n     *.iso\n     *.jar\n     *.rar\n     *.tar\n     *.zip\n     # Logs and databases #\n     ######################\n     *.log\n     *.sql\n     *.sqlite\n     # OS generated files #\n     ######################\n     .DS_Store\n     .DS_Store?\n     .idea\n     ._*\n     .Spotlight-V100\n     .Trashes\n     Icon?\n     ehthumbs.db\n     Thumbs.db\n     ```\n\n     \n\n9. ~/.bash_profile配置:\n\n   ```shell\n   # alias\n   alias ll='ls -lF'\n   alias vi='mvim'\n   \n   # iterm2\n   export CLICOLOR=1\n   export LSCOLOR=Gxfxaxdxcxegedabagacad\n   export PS1='\\[\\e[01;33m\\][\\[\\e[01;36m\\]\\u\\[\\e[01;33m\\]@\\[\\e[01;35m\\]\\h\\[\\e[01;33m\\]] \\[\\e[01;36m\\]\\w \\[\\e[01;32m\\]\\$\\[\\033[00m\\] ' #显示全部路径名\n   \n   # JAVAHOME\n   export JAVA_HOME=$(/usr/libexec/java_home)\n   export PATH=$JAVA_HOME/bin:$PATH\n   \n   # Maven\n   export MAVEN_HOME=/usr/local/apache-maven-3.6.3\n   export PATH=$PATH:$MAVEN_HOME/bin\n   \n   # bash shell\n   export BASH_SILENCE_DEPRECATION_WARNING=1\n   \n   # >>> conda initialize >>>\n   # !! Contents within this block are managed by 'conda init' !!\n   __conda_setup=\"$('/opt/anaconda3/bin/conda' 'shell.bash' 'hook' 2> /dev/null)\"\n   if [ $? -eq 0 ]; then\n       eval \"$__conda_setup\"\n   else\n       if [ -f \"/opt/anaconda3/etc/profile.d/conda.sh\" ]; then\n           . \"/opt/anaconda3/etc/profile.d/conda.sh\"\n       else\n           export PATH=\"/opt/anaconda3/bin:$PATH\"\n       fi\n   fi\n   unset __conda_setup\n   # <<< conda initialize <<<\n   export PATH=/opt/anaconda3/bin:$PATH\n   \n   ```\n\n10. tmux配置, ~/.tmux.conf\n\n    ```shell\n    setw -g mode-keys vi\n    new-session -n $HOST\n    set-option -g status-interval 1\n    set-option -g automatic-rename on\n    #set-option -g automatic-rename-format '#(basename \"#{pane_current_path}\")'\n    \n    #select last window\n    bind-key C-l select-window -l\n    \n    #up\n    bind-key k select-pane -U\n    #down\n    bind-key j select-pane -D\n    #left\n    bind-key h select-pane -L\n    #right\n    bind-key l select-pane -R\n    \n    # resize pane\n    bind -r ^k resizep -U 1 # upward (prefix Ctrl+k)\n    bind -r ^j resizep -D 1 # downward (prefix Ctrl+j)\n    bind -r ^h resizep -L 1 # to the left (prefix Ctrl+h)\n    bind -r ^l resizep -R 1 # to the right (prefix Ctrl+l)\n    bind % split-window -h -c \"#{pane_current_path}\"\n    ```\n\n    ","slug":"操作系统/Mac/从零搭建Mac开发环境","published":1,"updated":"2022-09-15T03:46:43.360Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qo006bjqrrkgi0ovka","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>前阵子电脑mac进水，搞了台备机，重新安装了各类软件搭建开发环境，特此记录…以防万一…</p>\n<h3 id=\"软件包\"><a href=\"#软件包\" class=\"headerlink\" title=\"软件包\"></a>软件包</h3><ol>\n<li><p>Chrome</p>\n</li>\n<li><p>搜狗输入法</p>\n</li>\n<li><p>pycharm（2020.1）</p>\n<ul>\n<li><p>模板：Editor -&gt; File and code Templates  -&gt; Python Script：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/env python</span></span><br><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"comment\"># @Author: levylv</span></span><br><span class=\"line\"><span class=\"comment\"># @Date  : $&#123;DATE&#125;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>激活 方法同idea</p>\n</li>\n</ul>\n</li>\n<li><p>Idea （2020.1）</p>\n<ul>\n<li><p>模板：Editor -&gt; File and code Templates  -&gt; File Header:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Created by levylv on $&#123;YEAR&#125;/$&#123;MONTH&#125;/$&#123;DAY&#125;.</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>激活 2020.1.2破解 <a href=\"https://www.jianshu.com/p/46f00b2ce3ce\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/46f00b2ce3ce</a></p>\n</li>\n<li><p>插件 leetcode-editor <a href=\"https://github.com/shuzijun/leetcode-question\" target=\"_blank\" rel=\"noopener\">https://github.com/shuzijun/leetcode-question</a> , lombok 官网下载</p>\n</li>\n<li><p>插件 easycode</p>\n</li>\n</ul>\n</li>\n<li><p>钉钉</p>\n</li>\n<li><p>dchat</p>\n</li>\n<li><p>微信</p>\n</li>\n<li><p>网易云音乐</p>\n</li>\n<li><p>typora</p>\n<ul>\n<li>ipic图床</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"开发环境：\"><a href=\"#开发环境：\" class=\"headerlink\" title=\"开发环境：\"></a>开发环境：</h3><ol>\n<li><p>Anaconda（4.8.2）</p>\n<ul>\n<li>新版conda自己会配置环境变量，以及激活base环境</li>\n</ul>\n</li>\n<li><p>jdk 8</p>\n<ul>\n<li>配置java_home：~/.bash_profile。完整的~/.bash_profile配置看后面</li>\n</ul>\n</li>\n<li><p>iterm2</p>\n<ul>\n<li>颜色配置：~/.bash_profile</li>\n</ul>\n</li>\n<li><p>homebrew <a href=\"https://zhuanlan.zhihu.com/p/90508170\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/90508170</a></p>\n</li>\n<li><p>macvim</p>\n<ul>\n<li><p>brew install macvim</p>\n</li>\n<li><p>配置文件~/.vimrc，我的祖传配置：</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">\"Wei Lyu</span></span><br><span class=\"line\"><span class=\"string\">\"</span>levy_lv@hotmail.com</span><br><span class=\"line\"><span class=\"string\">\"levylv.github.io</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\"</span>====================<span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">\"</span>        通用        <span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">\"</span>====================<span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">set nocompatible              \"</span> be iMproved </span><br><span class=\"line\">filetype plugin indent on</span><br><span class=\"line\"><span class=\"built_in\">set</span> nobackup <span class=\"string\">\"不备份 </span></span><br><span class=\"line\"><span class=\"string\">set autochdir \"</span>自动切换当前目录</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\"启动，语法高亮，配色</span></span><br><span class=\"line\"><span class=\"string\">winpos 400 200</span></span><br><span class=\"line\"><span class=\"string\">set lines=100 columns=150</span></span><br><span class=\"line\"><span class=\"string\">set laststatus=2   \"</span>总是显示状态栏</span><br><span class=\"line\"><span class=\"built_in\">set</span> hlsearch  <span class=\"string\">\"搜索高亮</span></span><br><span class=\"line\"><span class=\"string\">set ignorecase \"</span>搜索忽略大小写</span><br><span class=\"line\">syntax <span class=\"built_in\">enable</span></span><br><span class=\"line\">syntax on</span><br><span class=\"line\"><span class=\"built_in\">set</span> t_Co=256</span><br><span class=\"line\"><span class=\"built_in\">set</span> cursorline <span class=\"string\">\"高亮光标行</span></span><br><span class=\"line\"><span class=\"string\">set ruler   \"</span>显示光标位置状态栏</span><br><span class=\"line\"><span class=\"built_in\">set</span> number</span><br><span class=\"line\"><span class=\"built_in\">set</span> guifont=Monaco:h15</span><br><span class=\"line\">colorscheme molokai</span><br><span class=\"line\"><span class=\"built_in\">let</span> g:molokai_original = 1</span><br><span class=\"line\"><span class=\"built_in\">let</span> g:rehash256 = 1</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\"Tab相关</span></span><br><span class=\"line\"><span class=\"string\">set tabstop=4 \"</span>制表符占用空格数</span><br><span class=\"line\"><span class=\"built_in\">set</span> softtabstop=4 <span class=\"string\">\"将连续数量的空格视为一个制表符</span></span><br><span class=\"line\"><span class=\"string\">set shiftwidth=4 \"</span>格式化时制表符占用空格数</span><br><span class=\"line\"><span class=\"built_in\">set</span> expandtab <span class=\"string\">\"制表符扩展为空格</span></span><br><span class=\"line\"><span class=\"string\">set cindent</span></span><br><span class=\"line\"><span class=\"string\">set autoindent</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\"</span>编码相关</span><br><span class=\"line\"><span class=\"built_in\">set</span> encoding=utf-8</span><br><span class=\"line\"><span class=\"built_in\">set</span> fileencodings=ucs-bom,utf-8,cp936,gb18030,big5,euc-jp,euc-kr,latin1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\"使用箭头导航buffer\"</span></span><br><span class=\"line\"><span class=\"string\">\"map &lt;right&gt; :bn&lt;cr&gt;</span></span><br><span class=\"line\"><span class=\"string\">\"</span>map &lt;left&gt; :bp&lt;cr&gt;</span><br><span class=\"line\"><span class=\"string\">\"set autowrite \"</span>在切换buffer时自动保存当前的文件</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\"====================\"</span></span><br><span class=\"line\"><span class=\"string\">\"Vundle Configuration\"</span></span><br><span class=\"line\"><span class=\"string\">\"====================\"</span></span><br><span class=\"line\">filetype off                  <span class=\"string\">\" required</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\"</span> <span class=\"built_in\">set</span> the runtime path to include Vundle and initialize</span><br><span class=\"line\"><span class=\"built_in\">set</span> rtp+=~/.vim/bundle/Vundle.vim</span><br><span class=\"line\">call vundle<span class=\"comment\">#begin()</span></span><br><span class=\"line\"><span class=\"string\">\" alternatively, pass a path where Vundle should install plugins</span></span><br><span class=\"line\"><span class=\"string\">\"</span>call vundle<span class=\"comment\">#begin('~/some/path/here')</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\" let Vundle manage Vundle, required</span></span><br><span class=\"line\"><span class=\"string\">Plugin 'VundleVim/Vundle.vim'</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\"</span> My Plugin here:</span><br><span class=\"line\"><span class=\"string\">\" Plugin 'Valloric/YouCompleteMe'</span></span><br><span class=\"line\"><span class=\"string\">\"</span> Plugin <span class=\"string\">'majutsushi/tagbar'</span></span><br><span class=\"line\"><span class=\"string\">\" Plugin 'fholgado/minibufexpl.vim'</span></span><br><span class=\"line\"><span class=\"string\">Plugin 'scrooloose/nerdtree'</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\"</span> All of your Plugins must be added before the following line</span><br><span class=\"line\">call vundle<span class=\"comment\">#end()            \" required</span></span><br><span class=\"line\">filetype plugin indent on    <span class=\"string\">\" required</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\"</span>===========================<span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">\"</span>Vundle Plugin Configuration<span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">\"</span>===========================<span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\"</span>minibufexpl</span><br><span class=\"line\"><span class=\"string\">\"let g:miniBufExplMapWindowNavVim = 1 \"</span>可以用&lt;C-h,j,k,l&gt;切换到上下左右的窗口 </span><br><span class=\"line\"><span class=\"string\">\"let g:miniBufExplMapCTabSwitchBufs = 1 \"</span>&lt;C-Tab&gt;,&lt;C-S-Tab&gt;切换</span><br><span class=\"line\"><span class=\"string\">\"let g:miniBufExplModSelTarget = 1 </span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\"</span>NERDTree</span><br><span class=\"line\">nnoremap &lt;Tab&gt; :NERDTreeToggle&lt;CR&gt;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>主题molokai</p>\n</li>\n<li><p>vundle插件</p>\n</li>\n</ul>\n</li>\n<li><p>Maven（3.6.3） <a href=\"https://www.runoob.com/maven/maven-setup.html\" target=\"_blank\" rel=\"noopener\">https://www.runoob.com/maven/maven-setup.html</a></p>\n</li>\n<li><p>ClashX 翻墙：<a href=\"https://github.com/yichengchen/clashX/releases\" target=\"_blank\" rel=\"noopener\">https://github.com/yichengchen/clashX/releases</a></p>\n</li>\n<li><p>git</p>\n<ul>\n<li><p>~/.gitconfig配置，祖传alias配置：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[user]</span><br><span class=\"line\">\tname = lvwei</span><br><span class=\"line\">\temail = ***</span><br><span class=\"line\"></span><br><span class=\"line\">[alias]</span><br><span class=\"line\">\ta \t = !git add . &amp;&amp; git status</span><br><span class=\"line\">\taa       = !git add . &amp;&amp; git add -u . &amp;&amp; git status</span><br><span class=\"line\">\tac       = !git add . &amp;&amp; git commit</span><br><span class=\"line\">\tacm      = !git add . &amp;&amp; git commit -m</span><br><span class=\"line\">\talias    = !git config --list | grep 'alias'</span><br><span class=\"line\">\tau       = !git add -u . &amp;&amp; git status</span><br><span class=\"line\">\tc        = commit</span><br><span class=\"line\">\tca       = commit --amend</span><br><span class=\"line\">\tcm       = commit -m</span><br><span class=\"line\">\td        = diff</span><br><span class=\"line\">\tl        = log --graph --all --pretty=format:'%C(yellow)%h%C(cyan)%d%Creset %s %C(white)- %an, %ar%Creset'</span><br><span class=\"line\">\tlg       = log --color --graph --pretty=format:'%C(bold white)%h%Creset -%C(bold green)%d%Creset %s %C(bold green)(%cr)%Creset %C(bold blue)&lt;%an&gt;%Creset' --abbrev-commit --date=relative</span><br><span class=\"line\">\tll       = log --stat --abbrev-commit</span><br><span class=\"line\">\tllg      = log --color --graph --pretty=format:'%C(bold white)%H %d%Creset%n%s%n%+b%C(bold blue)%an &lt;%ae&gt;%Creset %C(bold green)%cr (%ci)' --abbrev-commit</span><br><span class=\"line\">\tmaster   = checkout master</span><br><span class=\"line\">\ts        = status</span><br><span class=\"line\">\tspull    = svn rebase</span><br><span class=\"line\">\tspush    = svn dcommit</span><br><span class=\"line\"></span><br><span class=\"line\">[credential]</span><br><span class=\"line\">\thelper = store</span><br><span class=\"line\">[core]</span><br><span class=\"line\">\texcludesfile = /Users/didi/.gitignore_global</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>.gitignore_global配置，祖传全局ignore配置：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> Compiled <span class=\"built_in\">source</span> <span class=\"comment\">#</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\">##################</span></span></span><br><span class=\"line\">*.com</span><br><span class=\"line\">*.class</span><br><span class=\"line\">*.dll</span><br><span class=\"line\">*.exe</span><br><span class=\"line\">*.o</span><br><span class=\"line\">*.so</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> Packages <span class=\"comment\">#</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\">###########</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> it<span class=\"string\">'s better to unpack these files and commit the raw source</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> git has its own built <span class=\"keyword\">in</span> compression methods</span></span><br><span class=\"line\">*.7z</span><br><span class=\"line\">*.dmg</span><br><span class=\"line\">*.gz</span><br><span class=\"line\">*.iso</span><br><span class=\"line\">*.jar</span><br><span class=\"line\">*.rar</span><br><span class=\"line\">*.tar</span><br><span class=\"line\">*.zip</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> Logs and databases <span class=\"comment\">#</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\">#####################</span></span></span><br><span class=\"line\">*.log</span><br><span class=\"line\">*.sql</span><br><span class=\"line\">*.sqlite</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> OS generated files <span class=\"comment\">#</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\">#####################</span></span></span><br><span class=\"line\">.DS_Store</span><br><span class=\"line\">.DS_Store?</span><br><span class=\"line\">.idea</span><br><span class=\"line\">._*</span><br><span class=\"line\">.Spotlight-V100</span><br><span class=\"line\">.Trashes</span><br><span class=\"line\">Icon?</span><br><span class=\"line\">ehthumbs.db</span><br><span class=\"line\">Thumbs.db</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p>~/.bash_profile配置:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> <span class=\"built_in\">alias</span></span></span><br><span class=\"line\">alias ll='ls -lF'</span><br><span class=\"line\">alias vi='mvim'</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> iterm2</span></span><br><span class=\"line\">export CLICOLOR=1</span><br><span class=\"line\">export LSCOLOR=Gxfxaxdxcxegedabagacad</span><br><span class=\"line\">export PS1='\\[\\e[01;33m\\][\\[\\e[01;36m\\]\\u\\[\\e[01;33m\\]@\\[\\e[01;35m\\]\\h\\[\\e[01;33m\\]] \\[\\e[01;36m\\]\\w \\[\\e[01;32m\\]\\$\\[\\033[00m\\] ' #显示全部路径名</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> JAVAHOME</span></span><br><span class=\"line\">export JAVA_HOME=$(/usr/libexec/java_home)</span><br><span class=\"line\">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> Maven</span></span><br><span class=\"line\">export MAVEN_HOME=/usr/local/apache-maven-3.6.3</span><br><span class=\"line\">export PATH=$PATH:$MAVEN_HOME/bin</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> bash shell</span></span><br><span class=\"line\">export BASH_SILENCE_DEPRECATION_WARNING=1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> &gt;&gt;&gt; conda initialize &gt;&gt;&gt;</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> !! Contents within this block are managed by <span class=\"string\">'conda init'</span> !!</span></span><br><span class=\"line\">__conda_setup=\"$('/opt/anaconda3/bin/conda' 'shell.bash' 'hook' 2&gt; /dev/null)\"</span><br><span class=\"line\">if [ $? -eq 0 ]; then</span><br><span class=\"line\">    eval \"$__conda_setup\"</span><br><span class=\"line\">else</span><br><span class=\"line\">    if [ -f \"/opt/anaconda3/etc/profile.d/conda.sh\" ]; then</span><br><span class=\"line\">        . \"/opt/anaconda3/etc/profile.d/conda.sh\"</span><br><span class=\"line\">    else</span><br><span class=\"line\">        export PATH=\"/opt/anaconda3/bin:$PATH\"</span><br><span class=\"line\">    fi</span><br><span class=\"line\">fi</span><br><span class=\"line\">unset __conda_setup</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> &lt;&lt;&lt; conda initialize &lt;&lt;&lt;</span></span><br><span class=\"line\">export PATH=/opt/anaconda3/bin:$PATH</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>tmux配置, ~/.tmux.conf</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">setw -g mode-keys vi</span><br><span class=\"line\">new-session -n $HOST</span><br><span class=\"line\">set-option -g status-interval 1</span><br><span class=\"line\">set-option -g automatic-rename on</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"built_in\">set</span>-option -g automatic-rename-format <span class=\"string\">'#(basename \"#&#123;pane_current_path&#125;\")'</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">select last window</span></span><br><span class=\"line\">bind-key C-l select-window -l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">up</span></span><br><span class=\"line\">bind-key k select-pane -U</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">down</span></span><br><span class=\"line\">bind-key j select-pane -D</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">left</span></span><br><span class=\"line\">bind-key h select-pane -L</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">right</span></span><br><span class=\"line\">bind-key l select-pane -R</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> resize pane</span></span><br><span class=\"line\">bind -r ^k resizep -U 1 # upward (prefix Ctrl+k)</span><br><span class=\"line\">bind -r ^j resizep -D 1 # downward (prefix Ctrl+j)</span><br><span class=\"line\">bind -r ^h resizep -L 1 # to the left (prefix Ctrl+h)</span><br><span class=\"line\">bind -r ^l resizep -R 1 # to the right (prefix Ctrl+l)</span><br><span class=\"line\">bind % split-window -h -c \"#&#123;pane_current_path&#125;\"</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>前阵子电脑mac进水，搞了台备机，重新安装了各类软件搭建开发环境，特此记录…以防万一…</p>\n<h3 id=\"软件包\"><a href=\"#软件包\" class=\"headerlink\" title=\"软件包\"></a>软件包</h3><ol>\n<li><p>Chrome</p>\n</li>\n<li><p>搜狗输入法</p>\n</li>\n<li><p>pycharm（2020.1）</p>\n<ul>\n<li><p>模板：Editor -&gt; File and code Templates  -&gt; Python Script：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/env python</span></span><br><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"comment\"># @Author: levylv</span></span><br><span class=\"line\"><span class=\"comment\"># @Date  : $&#123;DATE&#125;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>激活 方法同idea</p>\n</li>\n</ul>\n</li>\n<li><p>Idea （2020.1）</p>\n<ul>\n<li><p>模板：Editor -&gt; File and code Templates  -&gt; File Header:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Created by levylv on $&#123;YEAR&#125;/$&#123;MONTH&#125;/$&#123;DAY&#125;.</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>激活 2020.1.2破解 <a href=\"https://www.jianshu.com/p/46f00b2ce3ce\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/46f00b2ce3ce</a></p>\n</li>\n<li><p>插件 leetcode-editor <a href=\"https://github.com/shuzijun/leetcode-question\" target=\"_blank\" rel=\"noopener\">https://github.com/shuzijun/leetcode-question</a> , lombok 官网下载</p>\n</li>\n<li><p>插件 easycode</p>\n</li>\n</ul>\n</li>\n<li><p>钉钉</p>\n</li>\n<li><p>dchat</p>\n</li>\n<li><p>微信</p>\n</li>\n<li><p>网易云音乐</p>\n</li>\n<li><p>typora</p>\n<ul>\n<li>ipic图床</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"开发环境：\"><a href=\"#开发环境：\" class=\"headerlink\" title=\"开发环境：\"></a>开发环境：</h3><ol>\n<li><p>Anaconda（4.8.2）</p>\n<ul>\n<li>新版conda自己会配置环境变量，以及激活base环境</li>\n</ul>\n</li>\n<li><p>jdk 8</p>\n<ul>\n<li>配置java_home：~/.bash_profile。完整的~/.bash_profile配置看后面</li>\n</ul>\n</li>\n<li><p>iterm2</p>\n<ul>\n<li>颜色配置：~/.bash_profile</li>\n</ul>\n</li>\n<li><p>homebrew <a href=\"https://zhuanlan.zhihu.com/p/90508170\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/90508170</a></p>\n</li>\n<li><p>macvim</p>\n<ul>\n<li><p>brew install macvim</p>\n</li>\n<li><p>配置文件~/.vimrc，我的祖传配置：</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">\"Wei Lyu</span></span><br><span class=\"line\"><span class=\"string\">\"</span>levy_lv@hotmail.com</span><br><span class=\"line\"><span class=\"string\">\"levylv.github.io</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\"</span>====================<span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">\"</span>        通用        <span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">\"</span>====================<span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">set nocompatible              \"</span> be iMproved </span><br><span class=\"line\">filetype plugin indent on</span><br><span class=\"line\"><span class=\"built_in\">set</span> nobackup <span class=\"string\">\"不备份 </span></span><br><span class=\"line\"><span class=\"string\">set autochdir \"</span>自动切换当前目录</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\"启动，语法高亮，配色</span></span><br><span class=\"line\"><span class=\"string\">winpos 400 200</span></span><br><span class=\"line\"><span class=\"string\">set lines=100 columns=150</span></span><br><span class=\"line\"><span class=\"string\">set laststatus=2   \"</span>总是显示状态栏</span><br><span class=\"line\"><span class=\"built_in\">set</span> hlsearch  <span class=\"string\">\"搜索高亮</span></span><br><span class=\"line\"><span class=\"string\">set ignorecase \"</span>搜索忽略大小写</span><br><span class=\"line\">syntax <span class=\"built_in\">enable</span></span><br><span class=\"line\">syntax on</span><br><span class=\"line\"><span class=\"built_in\">set</span> t_Co=256</span><br><span class=\"line\"><span class=\"built_in\">set</span> cursorline <span class=\"string\">\"高亮光标行</span></span><br><span class=\"line\"><span class=\"string\">set ruler   \"</span>显示光标位置状态栏</span><br><span class=\"line\"><span class=\"built_in\">set</span> number</span><br><span class=\"line\"><span class=\"built_in\">set</span> guifont=Monaco:h15</span><br><span class=\"line\">colorscheme molokai</span><br><span class=\"line\"><span class=\"built_in\">let</span> g:molokai_original = 1</span><br><span class=\"line\"><span class=\"built_in\">let</span> g:rehash256 = 1</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\"Tab相关</span></span><br><span class=\"line\"><span class=\"string\">set tabstop=4 \"</span>制表符占用空格数</span><br><span class=\"line\"><span class=\"built_in\">set</span> softtabstop=4 <span class=\"string\">\"将连续数量的空格视为一个制表符</span></span><br><span class=\"line\"><span class=\"string\">set shiftwidth=4 \"</span>格式化时制表符占用空格数</span><br><span class=\"line\"><span class=\"built_in\">set</span> expandtab <span class=\"string\">\"制表符扩展为空格</span></span><br><span class=\"line\"><span class=\"string\">set cindent</span></span><br><span class=\"line\"><span class=\"string\">set autoindent</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\"</span>编码相关</span><br><span class=\"line\"><span class=\"built_in\">set</span> encoding=utf-8</span><br><span class=\"line\"><span class=\"built_in\">set</span> fileencodings=ucs-bom,utf-8,cp936,gb18030,big5,euc-jp,euc-kr,latin1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\"使用箭头导航buffer\"</span></span><br><span class=\"line\"><span class=\"string\">\"map &lt;right&gt; :bn&lt;cr&gt;</span></span><br><span class=\"line\"><span class=\"string\">\"</span>map &lt;left&gt; :bp&lt;cr&gt;</span><br><span class=\"line\"><span class=\"string\">\"set autowrite \"</span>在切换buffer时自动保存当前的文件</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\"====================\"</span></span><br><span class=\"line\"><span class=\"string\">\"Vundle Configuration\"</span></span><br><span class=\"line\"><span class=\"string\">\"====================\"</span></span><br><span class=\"line\">filetype off                  <span class=\"string\">\" required</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\"</span> <span class=\"built_in\">set</span> the runtime path to include Vundle and initialize</span><br><span class=\"line\"><span class=\"built_in\">set</span> rtp+=~/.vim/bundle/Vundle.vim</span><br><span class=\"line\">call vundle<span class=\"comment\">#begin()</span></span><br><span class=\"line\"><span class=\"string\">\" alternatively, pass a path where Vundle should install plugins</span></span><br><span class=\"line\"><span class=\"string\">\"</span>call vundle<span class=\"comment\">#begin('~/some/path/here')</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\" let Vundle manage Vundle, required</span></span><br><span class=\"line\"><span class=\"string\">Plugin 'VundleVim/Vundle.vim'</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\"</span> My Plugin here:</span><br><span class=\"line\"><span class=\"string\">\" Plugin 'Valloric/YouCompleteMe'</span></span><br><span class=\"line\"><span class=\"string\">\"</span> Plugin <span class=\"string\">'majutsushi/tagbar'</span></span><br><span class=\"line\"><span class=\"string\">\" Plugin 'fholgado/minibufexpl.vim'</span></span><br><span class=\"line\"><span class=\"string\">Plugin 'scrooloose/nerdtree'</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\"</span> All of your Plugins must be added before the following line</span><br><span class=\"line\">call vundle<span class=\"comment\">#end()            \" required</span></span><br><span class=\"line\">filetype plugin indent on    <span class=\"string\">\" required</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\"</span>===========================<span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">\"</span>Vundle Plugin Configuration<span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">\"</span>===========================<span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\"</span>minibufexpl</span><br><span class=\"line\"><span class=\"string\">\"let g:miniBufExplMapWindowNavVim = 1 \"</span>可以用&lt;C-h,j,k,l&gt;切换到上下左右的窗口 </span><br><span class=\"line\"><span class=\"string\">\"let g:miniBufExplMapCTabSwitchBufs = 1 \"</span>&lt;C-Tab&gt;,&lt;C-S-Tab&gt;切换</span><br><span class=\"line\"><span class=\"string\">\"let g:miniBufExplModSelTarget = 1 </span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\"</span>NERDTree</span><br><span class=\"line\">nnoremap &lt;Tab&gt; :NERDTreeToggle&lt;CR&gt;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>主题molokai</p>\n</li>\n<li><p>vundle插件</p>\n</li>\n</ul>\n</li>\n<li><p>Maven（3.6.3） <a href=\"https://www.runoob.com/maven/maven-setup.html\" target=\"_blank\" rel=\"noopener\">https://www.runoob.com/maven/maven-setup.html</a></p>\n</li>\n<li><p>ClashX 翻墙：<a href=\"https://github.com/yichengchen/clashX/releases\" target=\"_blank\" rel=\"noopener\">https://github.com/yichengchen/clashX/releases</a></p>\n</li>\n<li><p>git</p>\n<ul>\n<li><p>~/.gitconfig配置，祖传alias配置：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[user]</span><br><span class=\"line\">\tname = lvwei</span><br><span class=\"line\">\temail = ***</span><br><span class=\"line\"></span><br><span class=\"line\">[alias]</span><br><span class=\"line\">\ta \t = !git add . &amp;&amp; git status</span><br><span class=\"line\">\taa       = !git add . &amp;&amp; git add -u . &amp;&amp; git status</span><br><span class=\"line\">\tac       = !git add . &amp;&amp; git commit</span><br><span class=\"line\">\tacm      = !git add . &amp;&amp; git commit -m</span><br><span class=\"line\">\talias    = !git config --list | grep 'alias'</span><br><span class=\"line\">\tau       = !git add -u . &amp;&amp; git status</span><br><span class=\"line\">\tc        = commit</span><br><span class=\"line\">\tca       = commit --amend</span><br><span class=\"line\">\tcm       = commit -m</span><br><span class=\"line\">\td        = diff</span><br><span class=\"line\">\tl        = log --graph --all --pretty=format:'%C(yellow)%h%C(cyan)%d%Creset %s %C(white)- %an, %ar%Creset'</span><br><span class=\"line\">\tlg       = log --color --graph --pretty=format:'%C(bold white)%h%Creset -%C(bold green)%d%Creset %s %C(bold green)(%cr)%Creset %C(bold blue)&lt;%an&gt;%Creset' --abbrev-commit --date=relative</span><br><span class=\"line\">\tll       = log --stat --abbrev-commit</span><br><span class=\"line\">\tllg      = log --color --graph --pretty=format:'%C(bold white)%H %d%Creset%n%s%n%+b%C(bold blue)%an &lt;%ae&gt;%Creset %C(bold green)%cr (%ci)' --abbrev-commit</span><br><span class=\"line\">\tmaster   = checkout master</span><br><span class=\"line\">\ts        = status</span><br><span class=\"line\">\tspull    = svn rebase</span><br><span class=\"line\">\tspush    = svn dcommit</span><br><span class=\"line\"></span><br><span class=\"line\">[credential]</span><br><span class=\"line\">\thelper = store</span><br><span class=\"line\">[core]</span><br><span class=\"line\">\texcludesfile = /Users/didi/.gitignore_global</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>.gitignore_global配置，祖传全局ignore配置：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> Compiled <span class=\"built_in\">source</span> <span class=\"comment\">#</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\">##################</span></span></span><br><span class=\"line\">*.com</span><br><span class=\"line\">*.class</span><br><span class=\"line\">*.dll</span><br><span class=\"line\">*.exe</span><br><span class=\"line\">*.o</span><br><span class=\"line\">*.so</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> Packages <span class=\"comment\">#</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\">###########</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> it<span class=\"string\">'s better to unpack these files and commit the raw source</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> git has its own built <span class=\"keyword\">in</span> compression methods</span></span><br><span class=\"line\">*.7z</span><br><span class=\"line\">*.dmg</span><br><span class=\"line\">*.gz</span><br><span class=\"line\">*.iso</span><br><span class=\"line\">*.jar</span><br><span class=\"line\">*.rar</span><br><span class=\"line\">*.tar</span><br><span class=\"line\">*.zip</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> Logs and databases <span class=\"comment\">#</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\">#####################</span></span></span><br><span class=\"line\">*.log</span><br><span class=\"line\">*.sql</span><br><span class=\"line\">*.sqlite</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> OS generated files <span class=\"comment\">#</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\">#####################</span></span></span><br><span class=\"line\">.DS_Store</span><br><span class=\"line\">.DS_Store?</span><br><span class=\"line\">.idea</span><br><span class=\"line\">._*</span><br><span class=\"line\">.Spotlight-V100</span><br><span class=\"line\">.Trashes</span><br><span class=\"line\">Icon?</span><br><span class=\"line\">ehthumbs.db</span><br><span class=\"line\">Thumbs.db</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p>~/.bash_profile配置:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> <span class=\"built_in\">alias</span></span></span><br><span class=\"line\">alias ll='ls -lF'</span><br><span class=\"line\">alias vi='mvim'</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> iterm2</span></span><br><span class=\"line\">export CLICOLOR=1</span><br><span class=\"line\">export LSCOLOR=Gxfxaxdxcxegedabagacad</span><br><span class=\"line\">export PS1='\\[\\e[01;33m\\][\\[\\e[01;36m\\]\\u\\[\\e[01;33m\\]@\\[\\e[01;35m\\]\\h\\[\\e[01;33m\\]] \\[\\e[01;36m\\]\\w \\[\\e[01;32m\\]\\$\\[\\033[00m\\] ' #显示全部路径名</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> JAVAHOME</span></span><br><span class=\"line\">export JAVA_HOME=$(/usr/libexec/java_home)</span><br><span class=\"line\">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> Maven</span></span><br><span class=\"line\">export MAVEN_HOME=/usr/local/apache-maven-3.6.3</span><br><span class=\"line\">export PATH=$PATH:$MAVEN_HOME/bin</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> bash shell</span></span><br><span class=\"line\">export BASH_SILENCE_DEPRECATION_WARNING=1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> &gt;&gt;&gt; conda initialize &gt;&gt;&gt;</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> !! Contents within this block are managed by <span class=\"string\">'conda init'</span> !!</span></span><br><span class=\"line\">__conda_setup=\"$('/opt/anaconda3/bin/conda' 'shell.bash' 'hook' 2&gt; /dev/null)\"</span><br><span class=\"line\">if [ $? -eq 0 ]; then</span><br><span class=\"line\">    eval \"$__conda_setup\"</span><br><span class=\"line\">else</span><br><span class=\"line\">    if [ -f \"/opt/anaconda3/etc/profile.d/conda.sh\" ]; then</span><br><span class=\"line\">        . \"/opt/anaconda3/etc/profile.d/conda.sh\"</span><br><span class=\"line\">    else</span><br><span class=\"line\">        export PATH=\"/opt/anaconda3/bin:$PATH\"</span><br><span class=\"line\">    fi</span><br><span class=\"line\">fi</span><br><span class=\"line\">unset __conda_setup</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> &lt;&lt;&lt; conda initialize &lt;&lt;&lt;</span></span><br><span class=\"line\">export PATH=/opt/anaconda3/bin:$PATH</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>tmux配置, ~/.tmux.conf</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">setw -g mode-keys vi</span><br><span class=\"line\">new-session -n $HOST</span><br><span class=\"line\">set-option -g status-interval 1</span><br><span class=\"line\">set-option -g automatic-rename on</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"built_in\">set</span>-option -g automatic-rename-format <span class=\"string\">'#(basename \"#&#123;pane_current_path&#125;\")'</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">select last window</span></span><br><span class=\"line\">bind-key C-l select-window -l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">up</span></span><br><span class=\"line\">bind-key k select-pane -U</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">down</span></span><br><span class=\"line\">bind-key j select-pane -D</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">left</span></span><br><span class=\"line\">bind-key h select-pane -L</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">right</span></span><br><span class=\"line\">bind-key l select-pane -R</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> resize pane</span></span><br><span class=\"line\">bind -r ^k resizep -U 1 # upward (prefix Ctrl+k)</span><br><span class=\"line\">bind -r ^j resizep -D 1 # downward (prefix Ctrl+j)</span><br><span class=\"line\">bind -r ^h resizep -L 1 # to the left (prefix Ctrl+h)</span><br><span class=\"line\">bind -r ^l resizep -R 1 # to the right (prefix Ctrl+l)</span><br><span class=\"line\">bind % split-window -h -c \"#&#123;pane_current_path&#125;\"</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n"},{"title":"C++虚函数和Java类比","date":"2021-05-30T16:00:00.000Z","_content":"\n小结：\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gr1pwowrwuj30hk0a8dgv.jpg\" alt=\"image-20210531170324424\" style=\"zoom:50%;\" />\n\n- 在C++中，多态是靠虚函数实现的，因为如果是普通函数，调用的方法是根据当前指针类型来判断的，而不是根据指针所指向对象的类型，JAVA则是根据实际对象分配的，所以JAVA的普通函数就类似C++的虚函数。\n- 所以C++如果一个类是基类，它的析构函数一定是虚函数。\n- C++的纯虚函数就类似JAVA的抽象函数，也就是只有函数定义。\n- C++的抽象类就是JAVA的抽象类，也就是有至少有一个纯虚函数/抽象函数的类。\n- C++的虚基类就是JAVA的接口，也就是全部是纯虚函数/抽象函数的类。\n- C++可以多继承，而JAVA只能单继承，所以JAVA又搞了接口出来。\n\n\n\n参考资料：\n\n[C++ 与 Java 之中的虚函数、抽象函数、抽象类、接口 比较](https://blog.csdn.net/u013630349/article/details/50838558)\n\n[C++虚函数与JAVA中抽象函数比较](https://www.huaweicloud.com/articles/6b9f1996380f9e89335a747ac42322a5.html)\n\n\n\n","source":"_posts/编程开发/C++/C++虚函数和Java类比.md","raw":"---\ntitle: C++虚函数和Java类比\ndate: 2021-05-31 \ncategories: [编程开发,C++]\n---\n\n小结：\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gr1pwowrwuj30hk0a8dgv.jpg\" alt=\"image-20210531170324424\" style=\"zoom:50%;\" />\n\n- 在C++中，多态是靠虚函数实现的，因为如果是普通函数，调用的方法是根据当前指针类型来判断的，而不是根据指针所指向对象的类型，JAVA则是根据实际对象分配的，所以JAVA的普通函数就类似C++的虚函数。\n- 所以C++如果一个类是基类，它的析构函数一定是虚函数。\n- C++的纯虚函数就类似JAVA的抽象函数，也就是只有函数定义。\n- C++的抽象类就是JAVA的抽象类，也就是有至少有一个纯虚函数/抽象函数的类。\n- C++的虚基类就是JAVA的接口，也就是全部是纯虚函数/抽象函数的类。\n- C++可以多继承，而JAVA只能单继承，所以JAVA又搞了接口出来。\n\n\n\n参考资料：\n\n[C++ 与 Java 之中的虚函数、抽象函数、抽象类、接口 比较](https://blog.csdn.net/u013630349/article/details/50838558)\n\n[C++虚函数与JAVA中抽象函数比较](https://www.huaweicloud.com/articles/6b9f1996380f9e89335a747ac42322a5.html)\n\n\n\n","slug":"编程开发/C++/C++虚函数和Java类比","published":1,"updated":"2022-09-15T03:46:43.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qp006ejqrr81m6tagn","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>小结：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gr1pwowrwuj30hk0a8dgv.jpg\" alt=\"image-20210531170324424\" style=\"zoom:50%;\"></p>\n<ul>\n<li>在C++中，多态是靠虚函数实现的，因为如果是普通函数，调用的方法是根据当前指针类型来判断的，而不是根据指针所指向对象的类型，JAVA则是根据实际对象分配的，所以JAVA的普通函数就类似C++的虚函数。</li>\n<li>所以C++如果一个类是基类，它的析构函数一定是虚函数。</li>\n<li>C++的纯虚函数就类似JAVA的抽象函数，也就是只有函数定义。</li>\n<li>C++的抽象类就是JAVA的抽象类，也就是有至少有一个纯虚函数/抽象函数的类。</li>\n<li>C++的虚基类就是JAVA的接口，也就是全部是纯虚函数/抽象函数的类。</li>\n<li>C++可以多继承，而JAVA只能单继承，所以JAVA又搞了接口出来。</li>\n</ul>\n<p>参考资料：</p>\n<p><a href=\"https://blog.csdn.net/u013630349/article/details/50838558\" target=\"_blank\" rel=\"noopener\">C++ 与 Java 之中的虚函数、抽象函数、抽象类、接口 比较</a></p>\n<p><a href=\"https://www.huaweicloud.com/articles/6b9f1996380f9e89335a747ac42322a5.html\" target=\"_blank\" rel=\"noopener\">C++虚函数与JAVA中抽象函数比较</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>小结：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gr1pwowrwuj30hk0a8dgv.jpg\" alt=\"image-20210531170324424\" style=\"zoom:50%;\"></p>\n<ul>\n<li>在C++中，多态是靠虚函数实现的，因为如果是普通函数，调用的方法是根据当前指针类型来判断的，而不是根据指针所指向对象的类型，JAVA则是根据实际对象分配的，所以JAVA的普通函数就类似C++的虚函数。</li>\n<li>所以C++如果一个类是基类，它的析构函数一定是虚函数。</li>\n<li>C++的纯虚函数就类似JAVA的抽象函数，也就是只有函数定义。</li>\n<li>C++的抽象类就是JAVA的抽象类，也就是有至少有一个纯虚函数/抽象函数的类。</li>\n<li>C++的虚基类就是JAVA的接口，也就是全部是纯虚函数/抽象函数的类。</li>\n<li>C++可以多继承，而JAVA只能单继承，所以JAVA又搞了接口出来。</li>\n</ul>\n<p>参考资料：</p>\n<p><a href=\"https://blog.csdn.net/u013630349/article/details/50838558\" target=\"_blank\" rel=\"noopener\">C++ 与 Java 之中的虚函数、抽象函数、抽象类、接口 比较</a></p>\n<p><a href=\"https://www.huaweicloud.com/articles/6b9f1996380f9e89335a747ac42322a5.html\" target=\"_blank\" rel=\"noopener\">C++虚函数与JAVA中抽象函数比较</a></p>\n"},{"title":"关于Include","date":"2020-01-18T16:00:00.000Z","_content":"\n\n\n在C/C++中，include本质上就是将代码代入，约定俗成的方法：\n\n- 头文件.h：声明，引用其他文件的时候只需引入头文件，编译器会基于声明在源代码的编译结果中找到定义。如果在头文件中做了定义，可能会出现重复定义的报错，比如A头文件做了定义，B引用A，C既引用B又引用A，则会出现重复定义。\n- 源代码.cpp：编译阶段所有.cpp文件都会被编译，编译器查找声明，在源代码中找到定义。\n\n\n\n值得注意的是，由于include本质是代码引入，所以其和java的import是不一样的。\n\n举个例子，比如A是一个公共模块，例如日志打印方法(INFO,WARN等)，B引入了A，C既需要引入B，同时也需要日志模块A，在java/python中，同时需要import B和A，而C++只需要import B就相当于引入了A。\n\n","source":"_posts/编程开发/C++/关于Include.md","raw":"---\ntitle: 关于Include\ndate: 2020-01-19\ncategories: [编程开发,C++]\n---\n\n\n\n在C/C++中，include本质上就是将代码代入，约定俗成的方法：\n\n- 头文件.h：声明，引用其他文件的时候只需引入头文件，编译器会基于声明在源代码的编译结果中找到定义。如果在头文件中做了定义，可能会出现重复定义的报错，比如A头文件做了定义，B引用A，C既引用B又引用A，则会出现重复定义。\n- 源代码.cpp：编译阶段所有.cpp文件都会被编译，编译器查找声明，在源代码中找到定义。\n\n\n\n值得注意的是，由于include本质是代码引入，所以其和java的import是不一样的。\n\n举个例子，比如A是一个公共模块，例如日志打印方法(INFO,WARN等)，B引入了A，C既需要引入B，同时也需要日志模块A，在java/python中，同时需要import B和A，而C++只需要import B就相当于引入了A。\n\n","slug":"编程开发/C++/关于Include","published":1,"updated":"2022-09-15T03:46:43.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qp006hjqrrp3hk6vb3","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>在C/C++中，include本质上就是将代码代入，约定俗成的方法：</p>\n<ul>\n<li>头文件.h：声明，引用其他文件的时候只需引入头文件，编译器会基于声明在源代码的编译结果中找到定义。如果在头文件中做了定义，可能会出现重复定义的报错，比如A头文件做了定义，B引用A，C既引用B又引用A，则会出现重复定义。</li>\n<li>源代码.cpp：编译阶段所有.cpp文件都会被编译，编译器查找声明，在源代码中找到定义。</li>\n</ul>\n<p>值得注意的是，由于include本质是代码引入，所以其和java的import是不一样的。</p>\n<p>举个例子，比如A是一个公共模块，例如日志打印方法(INFO,WARN等)，B引入了A，C既需要引入B，同时也需要日志模块A，在java/python中，同时需要import B和A，而C++只需要import B就相当于引入了A。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在C/C++中，include本质上就是将代码代入，约定俗成的方法：</p>\n<ul>\n<li>头文件.h：声明，引用其他文件的时候只需引入头文件，编译器会基于声明在源代码的编译结果中找到定义。如果在头文件中做了定义，可能会出现重复定义的报错，比如A头文件做了定义，B引用A，C既引用B又引用A，则会出现重复定义。</li>\n<li>源代码.cpp：编译阶段所有.cpp文件都会被编译，编译器查找声明，在源代码中找到定义。</li>\n</ul>\n<p>值得注意的是，由于include本质是代码引入，所以其和java的import是不一样的。</p>\n<p>举个例子，比如A是一个公共模块，例如日志打印方法(INFO,WARN等)，B引入了A，C既需要引入B，同时也需要日志模块A，在java/python中，同时需要import B和A，而C++只需要import B就相当于引入了A。</p>\n"},{"title":"Java泛型","date":"2018-11-19T10:13:30.000Z","_content":"\n```java\nList stringArrayList = new ArrayList();\n\nList integerArrayList = new ArrayList();\n\nClass classStringArrayList = stringArrayList.getClass();\n\nClass classIntegerArrayList = integerArrayList.getClass();\n\nif(classStringArrayList.equals(classIntegerArrayList)){ Log.d(\"泛型测试\",\"类型相同\"); }  --相同\n```\n\n \n\n**泛型类型在逻辑上看以看成是多个不同的类型，实际上都是相同的基本类型。**\n\n```java\npublic void showKeyValue1(Generic obj){ Log.d(\"泛型测试\",\"key value is \" + obj.getKey()); }\n\nGeneric gInteger = new Generic(123);\n\nGeneric gNumber = new Generic(456);\n\nshowKeyValue(gNumber);\n\n// showKeyValue这个方法编译器会为我们报错：Generic<java.lang.Integer>\n\n// cannot be applied to Generic<java.lang.Number>\n\n// showKeyValue(gInteger);\n\n```\n\n**同一种泛型可以对应多个版本（因为参数类型是不确定的），不同版本的泛型类实例是不兼容的**。","source":"_posts/编程开发/Java/Java泛型.md","raw":"---\ntitle: Java泛型\ndate: 2018-11-19 18:13:30\ncategories: [编程开发,Java]\n---\n\n```java\nList stringArrayList = new ArrayList();\n\nList integerArrayList = new ArrayList();\n\nClass classStringArrayList = stringArrayList.getClass();\n\nClass classIntegerArrayList = integerArrayList.getClass();\n\nif(classStringArrayList.equals(classIntegerArrayList)){ Log.d(\"泛型测试\",\"类型相同\"); }  --相同\n```\n\n \n\n**泛型类型在逻辑上看以看成是多个不同的类型，实际上都是相同的基本类型。**\n\n```java\npublic void showKeyValue1(Generic obj){ Log.d(\"泛型测试\",\"key value is \" + obj.getKey()); }\n\nGeneric gInteger = new Generic(123);\n\nGeneric gNumber = new Generic(456);\n\nshowKeyValue(gNumber);\n\n// showKeyValue这个方法编译器会为我们报错：Generic<java.lang.Integer>\n\n// cannot be applied to Generic<java.lang.Number>\n\n// showKeyValue(gInteger);\n\n```\n\n**同一种泛型可以对应多个版本（因为参数类型是不确定的），不同版本的泛型类实例是不兼容的**。","slug":"编程开发/Java/Java泛型","published":1,"updated":"2022-09-15T03:46:43.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qq006jjqrr8l4fzcd9","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List stringArrayList = <span class=\"keyword\">new</span> ArrayList();</span><br><span class=\"line\"></span><br><span class=\"line\">List integerArrayList = <span class=\"keyword\">new</span> ArrayList();</span><br><span class=\"line\"></span><br><span class=\"line\">Class classStringArrayList = stringArrayList.getClass();</span><br><span class=\"line\"></span><br><span class=\"line\">Class classIntegerArrayList = integerArrayList.getClass();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span>(classStringArrayList.equals(classIntegerArrayList))&#123; Log.d(<span class=\"string\">\"泛型测试\"</span>,<span class=\"string\">\"类型相同\"</span>); &#125;  --相同</span><br></pre></td></tr></table></figure>\n<p><strong>泛型类型在逻辑上看以看成是多个不同的类型，实际上都是相同的基本类型。</strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">showKeyValue1</span><span class=\"params\">(Generic obj)</span></span>&#123; Log.d(<span class=\"string\">\"泛型测试\"</span>,<span class=\"string\">\"key value is \"</span> + obj.getKey()); &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">Generic gInteger = <span class=\"keyword\">new</span> Generic(<span class=\"number\">123</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">Generic gNumber = <span class=\"keyword\">new</span> Generic(<span class=\"number\">456</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">showKeyValue(gNumber);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// showKeyValue这个方法编译器会为我们报错：Generic&lt;java.lang.Integer&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// cannot be applied to Generic&lt;java.lang.Number&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// showKeyValue(gInteger);</span></span><br></pre></td></tr></table></figure>\n<p><strong>同一种泛型可以对应多个版本（因为参数类型是不确定的），不同版本的泛型类实例是不兼容的</strong>。</p>\n","site":{"data":{}},"excerpt":"","more":"<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List stringArrayList = <span class=\"keyword\">new</span> ArrayList();</span><br><span class=\"line\"></span><br><span class=\"line\">List integerArrayList = <span class=\"keyword\">new</span> ArrayList();</span><br><span class=\"line\"></span><br><span class=\"line\">Class classStringArrayList = stringArrayList.getClass();</span><br><span class=\"line\"></span><br><span class=\"line\">Class classIntegerArrayList = integerArrayList.getClass();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span>(classStringArrayList.equals(classIntegerArrayList))&#123; Log.d(<span class=\"string\">\"泛型测试\"</span>,<span class=\"string\">\"类型相同\"</span>); &#125;  --相同</span><br></pre></td></tr></table></figure>\n<p><strong>泛型类型在逻辑上看以看成是多个不同的类型，实际上都是相同的基本类型。</strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">showKeyValue1</span><span class=\"params\">(Generic obj)</span></span>&#123; Log.d(<span class=\"string\">\"泛型测试\"</span>,<span class=\"string\">\"key value is \"</span> + obj.getKey()); &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">Generic gInteger = <span class=\"keyword\">new</span> Generic(<span class=\"number\">123</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">Generic gNumber = <span class=\"keyword\">new</span> Generic(<span class=\"number\">456</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">showKeyValue(gNumber);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// showKeyValue这个方法编译器会为我们报错：Generic&lt;java.lang.Integer&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// cannot be applied to Generic&lt;java.lang.Number&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// showKeyValue(gInteger);</span></span><br></pre></td></tr></table></figure>\n<p><strong>同一种泛型可以对应多个版本（因为参数类型是不确定的），不同版本的泛型类实例是不兼容的</strong>。</p>\n"},{"title":"理解blade","date":"2021-02-02T16:00:00.000Z","_content":"\n\n\n今天在研究一个大型c++工程如何做单元测试，这个工程是用blade进行构建的，之前不是特别懂blade，看了网上的相关博客以及github的wiki，大致明白了blade原理，确实相比makefile而言，blade构建是更加方便简洁的。\n\n参考相关博客：[blade学习](https://www.bbsmax.com/A/MAzAOWYq59/) , [blade git wiki](https://github.com/chen3feng/blade-build/blob/master/doc/zh_CN/develop.md) ，[blade cc wiki](https://github.com/chen3feng/blade-build/blob/master/doc/zh_CN/build_rules/cc.md)\n\n\n\n具体不解释了，主要记录几个关键点：\n\n- cc_library就是要打包的库，默认打包成静态库，也就是libxxx.a文件，也可以打包成动态库，也就是libxxx.so文件，通过BUILD配置即可。\n  - 静态库直接将库文件打包到最终的可执行文件中。\n  - 动态库只在可执行文件运行时候进行链接，需要建立一个lib文件夹放这些so库。\n- blade的根目录往往是放在项目的上一级，因为项目依赖其他的git项目等，都需要在根目录下生成。blade会基于项目build的target，去其他目录查找所有的依赖target，构建拓扑顺序，最终全部生成target，默认是在bluid_release目录下。\n- 对于一些项目依赖的第三方库，往往都是已经编译好的libxxx.a文件，这种的话需要注意几个点：\n  - 需要有include目录，里面是一些头文件，方便编译找到定义，有点类似接口的感觉。\n  - BUILD里面不需要再构建\n  - 例如下面这个配置\n    - prebuild=True，预先已经生成了libjemalloc.a，不需要再生成\n    - export_incs：这个就是定义编译时候寻找头文件的目录，已经编译好的第三方库会有这个include目录放头文件。正常我们自定义工程是不需要加这个配置的，因为头文件是在整个自定义工程里有的。\n    - build_dynamic：生成动态库\n\n![image-20210203173926774](https://tva1.sinaimg.cn/large/e6c9d24ely1h51rl55p9sj206z03amx4.jpg)","source":"_posts/编程开发/C++/理解blade.md","raw":"---\ntitle: 理解blade\ndate: 2021-02-03\ncategories: [编程开发,C++]\n\n---\n\n\n\n今天在研究一个大型c++工程如何做单元测试，这个工程是用blade进行构建的，之前不是特别懂blade，看了网上的相关博客以及github的wiki，大致明白了blade原理，确实相比makefile而言，blade构建是更加方便简洁的。\n\n参考相关博客：[blade学习](https://www.bbsmax.com/A/MAzAOWYq59/) , [blade git wiki](https://github.com/chen3feng/blade-build/blob/master/doc/zh_CN/develop.md) ，[blade cc wiki](https://github.com/chen3feng/blade-build/blob/master/doc/zh_CN/build_rules/cc.md)\n\n\n\n具体不解释了，主要记录几个关键点：\n\n- cc_library就是要打包的库，默认打包成静态库，也就是libxxx.a文件，也可以打包成动态库，也就是libxxx.so文件，通过BUILD配置即可。\n  - 静态库直接将库文件打包到最终的可执行文件中。\n  - 动态库只在可执行文件运行时候进行链接，需要建立一个lib文件夹放这些so库。\n- blade的根目录往往是放在项目的上一级，因为项目依赖其他的git项目等，都需要在根目录下生成。blade会基于项目build的target，去其他目录查找所有的依赖target，构建拓扑顺序，最终全部生成target，默认是在bluid_release目录下。\n- 对于一些项目依赖的第三方库，往往都是已经编译好的libxxx.a文件，这种的话需要注意几个点：\n  - 需要有include目录，里面是一些头文件，方便编译找到定义，有点类似接口的感觉。\n  - BUILD里面不需要再构建\n  - 例如下面这个配置\n    - prebuild=True，预先已经生成了libjemalloc.a，不需要再生成\n    - export_incs：这个就是定义编译时候寻找头文件的目录，已经编译好的第三方库会有这个include目录放头文件。正常我们自定义工程是不需要加这个配置的，因为头文件是在整个自定义工程里有的。\n    - build_dynamic：生成动态库\n\n![image-20210203173926774](https://tva1.sinaimg.cn/large/e6c9d24ely1h51rl55p9sj206z03amx4.jpg)","slug":"编程开发/C++/理解blade","published":1,"updated":"2022-09-15T03:46:43.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qq006mjqrr2iqcme13","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>今天在研究一个大型c++工程如何做单元测试，这个工程是用blade进行构建的，之前不是特别懂blade，看了网上的相关博客以及github的wiki，大致明白了blade原理，确实相比makefile而言，blade构建是更加方便简洁的。</p>\n<p>参考相关博客：<a href=\"https://www.bbsmax.com/A/MAzAOWYq59/\" target=\"_blank\" rel=\"noopener\">blade学习</a> , <a href=\"https://github.com/chen3feng/blade-build/blob/master/doc/zh_CN/develop.md\" target=\"_blank\" rel=\"noopener\">blade git wiki</a> ，<a href=\"https://github.com/chen3feng/blade-build/blob/master/doc/zh_CN/build_rules/cc.md\" target=\"_blank\" rel=\"noopener\">blade cc wiki</a></p>\n<p>具体不解释了，主要记录几个关键点：</p>\n<ul>\n<li>cc_library就是要打包的库，默认打包成静态库，也就是libxxx.a文件，也可以打包成动态库，也就是libxxx.so文件，通过BUILD配置即可。<ul>\n<li>静态库直接将库文件打包到最终的可执行文件中。</li>\n<li>动态库只在可执行文件运行时候进行链接，需要建立一个lib文件夹放这些so库。</li>\n</ul>\n</li>\n<li>blade的根目录往往是放在项目的上一级，因为项目依赖其他的git项目等，都需要在根目录下生成。blade会基于项目build的target，去其他目录查找所有的依赖target，构建拓扑顺序，最终全部生成target，默认是在bluid_release目录下。</li>\n<li>对于一些项目依赖的第三方库，往往都是已经编译好的libxxx.a文件，这种的话需要注意几个点：<ul>\n<li>需要有include目录，里面是一些头文件，方便编译找到定义，有点类似接口的感觉。</li>\n<li>BUILD里面不需要再构建</li>\n<li>例如下面这个配置<ul>\n<li>prebuild=True，预先已经生成了libjemalloc.a，不需要再生成</li>\n<li>export_incs：这个就是定义编译时候寻找头文件的目录，已经编译好的第三方库会有这个include目录放头文件。正常我们自定义工程是不需要加这个配置的，因为头文件是在整个自定义工程里有的。</li>\n<li>build_dynamic：生成动态库</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rl55p9sj206z03amx4.jpg\" alt=\"image-20210203173926774\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>今天在研究一个大型c++工程如何做单元测试，这个工程是用blade进行构建的，之前不是特别懂blade，看了网上的相关博客以及github的wiki，大致明白了blade原理，确实相比makefile而言，blade构建是更加方便简洁的。</p>\n<p>参考相关博客：<a href=\"https://www.bbsmax.com/A/MAzAOWYq59/\" target=\"_blank\" rel=\"noopener\">blade学习</a> , <a href=\"https://github.com/chen3feng/blade-build/blob/master/doc/zh_CN/develop.md\" target=\"_blank\" rel=\"noopener\">blade git wiki</a> ，<a href=\"https://github.com/chen3feng/blade-build/blob/master/doc/zh_CN/build_rules/cc.md\" target=\"_blank\" rel=\"noopener\">blade cc wiki</a></p>\n<p>具体不解释了，主要记录几个关键点：</p>\n<ul>\n<li>cc_library就是要打包的库，默认打包成静态库，也就是libxxx.a文件，也可以打包成动态库，也就是libxxx.so文件，通过BUILD配置即可。<ul>\n<li>静态库直接将库文件打包到最终的可执行文件中。</li>\n<li>动态库只在可执行文件运行时候进行链接，需要建立一个lib文件夹放这些so库。</li>\n</ul>\n</li>\n<li>blade的根目录往往是放在项目的上一级，因为项目依赖其他的git项目等，都需要在根目录下生成。blade会基于项目build的target，去其他目录查找所有的依赖target，构建拓扑顺序，最终全部生成target，默认是在bluid_release目录下。</li>\n<li>对于一些项目依赖的第三方库，往往都是已经编译好的libxxx.a文件，这种的话需要注意几个点：<ul>\n<li>需要有include目录，里面是一些头文件，方便编译找到定义，有点类似接口的感觉。</li>\n<li>BUILD里面不需要再构建</li>\n<li>例如下面这个配置<ul>\n<li>prebuild=True，预先已经生成了libjemalloc.a，不需要再生成</li>\n<li>export_incs：这个就是定义编译时候寻找头文件的目录，已经编译好的第三方库会有这个include目录放头文件。正常我们自定义工程是不需要加这个配置的，因为头文件是在整个自定义工程里有的。</li>\n<li>build_dynamic：生成动态库</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h51rl55p9sj206z03amx4.jpg\" alt=\"image-20210203173926774\"></p>\n"},{"title":"POJO、JavaBean和SpringBean","date":"2020-05-09T10:13:30.000Z","_content":"\n## POJO\n普通JAVA类，专指只有setter / getter / toString的简单类，包括DO/DTO/BO/VO等。\n\nPOJO是一个简单的、普通Java对象，特点是有private的属性和public的getter、setter，除此之外不具有任何特殊角色，不继承或不实现任何其它Java框架的类或接口。 \n\n## JavaBean\n\n**为了方便开发，约定的一种java类的规范！**，\n- 所有属性为private。\n- 这个类必须具有一个公共的(public)无参构造函数\n- private属性必须提供public的getter和setter来给外部访问，并且方法的命名也必须遵循一定的命名规范。 。\n- 这个类应是可序列化的，要实现serializable接口。\n\n没有其他业务逻辑的javaBean,就是一个POJO\n\n## SpringBean\n\nSpringBean是受Spring管理的对象。所有能受Spring容器管理的对象，都可以成为SpringBean。\n\n\nSpring容器对Bean没有特殊要求，不像JavaBean 一样遵循一些规范（不过对于通过设值方法注入的Bean,一定要提供setter 方法。）\n\n传统的的Javabean，如果我们要创建一个 Bean，我们就要使用关键字 New。\n但是，在 Spring 中，Bean 的创建是由 Spring 容器进行的，也就是说，在 Spring 中使用 Bean 的时候，不是由关键字 New 来创建实例了, 由Spring容器管理其生命周期行为，","source":"_posts/编程开发/Java/POJO、JavaBean和SpringBean.md","raw":"---\ntitle: POJO、JavaBean和SpringBean\ndate: 2020-05-09 18:13:30\ncategories: [编程开发,Java]\n---\n\n## POJO\n普通JAVA类，专指只有setter / getter / toString的简单类，包括DO/DTO/BO/VO等。\n\nPOJO是一个简单的、普通Java对象，特点是有private的属性和public的getter、setter，除此之外不具有任何特殊角色，不继承或不实现任何其它Java框架的类或接口。 \n\n## JavaBean\n\n**为了方便开发，约定的一种java类的规范！**，\n- 所有属性为private。\n- 这个类必须具有一个公共的(public)无参构造函数\n- private属性必须提供public的getter和setter来给外部访问，并且方法的命名也必须遵循一定的命名规范。 。\n- 这个类应是可序列化的，要实现serializable接口。\n\n没有其他业务逻辑的javaBean,就是一个POJO\n\n## SpringBean\n\nSpringBean是受Spring管理的对象。所有能受Spring容器管理的对象，都可以成为SpringBean。\n\n\nSpring容器对Bean没有特殊要求，不像JavaBean 一样遵循一些规范（不过对于通过设值方法注入的Bean,一定要提供setter 方法。）\n\n传统的的Javabean，如果我们要创建一个 Bean，我们就要使用关键字 New。\n但是，在 Spring 中，Bean 的创建是由 Spring 容器进行的，也就是说，在 Spring 中使用 Bean 的时候，不是由关键字 New 来创建实例了, 由Spring容器管理其生命周期行为，","slug":"编程开发/Java/POJO、JavaBean和SpringBean","published":1,"updated":"2022-09-15T03:46:43.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qr006njqrr46ysdxru","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"POJO\"><a href=\"#POJO\" class=\"headerlink\" title=\"POJO\"></a>POJO</h2><p>普通JAVA类，专指只有setter / getter / toString的简单类，包括DO/DTO/BO/VO等。</p>\n<p>POJO是一个简单的、普通Java对象，特点是有private的属性和public的getter、setter，除此之外不具有任何特殊角色，不继承或不实现任何其它Java框架的类或接口。 </p>\n<h2 id=\"JavaBean\"><a href=\"#JavaBean\" class=\"headerlink\" title=\"JavaBean\"></a>JavaBean</h2><p><strong>为了方便开发，约定的一种java类的规范！</strong>，</p>\n<ul>\n<li>所有属性为private。</li>\n<li>这个类必须具有一个公共的(public)无参构造函数</li>\n<li>private属性必须提供public的getter和setter来给外部访问，并且方法的命名也必须遵循一定的命名规范。 。</li>\n<li>这个类应是可序列化的，要实现serializable接口。</li>\n</ul>\n<p>没有其他业务逻辑的javaBean,就是一个POJO</p>\n<h2 id=\"SpringBean\"><a href=\"#SpringBean\" class=\"headerlink\" title=\"SpringBean\"></a>SpringBean</h2><p>SpringBean是受Spring管理的对象。所有能受Spring容器管理的对象，都可以成为SpringBean。</p>\n<p>Spring容器对Bean没有特殊要求，不像JavaBean 一样遵循一些规范（不过对于通过设值方法注入的Bean,一定要提供setter 方法。）</p>\n<p>传统的的Javabean，如果我们要创建一个 Bean，我们就要使用关键字 New。<br>但是，在 Spring 中，Bean 的创建是由 Spring 容器进行的，也就是说，在 Spring 中使用 Bean 的时候，不是由关键字 New 来创建实例了, 由Spring容器管理其生命周期行为，</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"POJO\"><a href=\"#POJO\" class=\"headerlink\" title=\"POJO\"></a>POJO</h2><p>普通JAVA类，专指只有setter / getter / toString的简单类，包括DO/DTO/BO/VO等。</p>\n<p>POJO是一个简单的、普通Java对象，特点是有private的属性和public的getter、setter，除此之外不具有任何特殊角色，不继承或不实现任何其它Java框架的类或接口。 </p>\n<h2 id=\"JavaBean\"><a href=\"#JavaBean\" class=\"headerlink\" title=\"JavaBean\"></a>JavaBean</h2><p><strong>为了方便开发，约定的一种java类的规范！</strong>，</p>\n<ul>\n<li>所有属性为private。</li>\n<li>这个类必须具有一个公共的(public)无参构造函数</li>\n<li>private属性必须提供public的getter和setter来给外部访问，并且方法的命名也必须遵循一定的命名规范。 。</li>\n<li>这个类应是可序列化的，要实现serializable接口。</li>\n</ul>\n<p>没有其他业务逻辑的javaBean,就是一个POJO</p>\n<h2 id=\"SpringBean\"><a href=\"#SpringBean\" class=\"headerlink\" title=\"SpringBean\"></a>SpringBean</h2><p>SpringBean是受Spring管理的对象。所有能受Spring容器管理的对象，都可以成为SpringBean。</p>\n<p>Spring容器对Bean没有特殊要求，不像JavaBean 一样遵循一些规范（不过对于通过设值方法注入的Bean,一定要提供setter 方法。）</p>\n<p>传统的的Javabean，如果我们要创建一个 Bean，我们就要使用关键字 New。<br>但是，在 Spring 中，Bean 的创建是由 Spring 容器进行的，也就是说，在 Spring 中使用 Bean 的时候，不是由关键字 New 来创建实例了, 由Spring容器管理其生命周期行为，</p>\n"},{"title":"hash数据结构原理","date":"2020-03-08T10:13:30.000Z","_content":"\njava hashMap底层实现：数组+链表+红黑树(链表长度大于8的时候)\n\nhashcode 通过hash函数 —> hash值\n\nhash值 通过数组长度取余 —> index\n\n \n\n所以说hash函数要尽量能够均匀数组位置。\n\njava里的hashMap的hash函数是：Hash值=（hashcode）^ (hashcode >>> 16)\n\nhashMap预设数组长度也蛮重要，到load_factor(默认0.75)后，会resize 2倍，index都得重新算了。\n\n \n\npython里dict对string的hash函数就很蛋疼，是64位的整数。\n\n  \n\n虽然hash的查询，插入，删除都很快，因为hash里的数组填不满，所以说hash相对其他数据结构而言，比较耗内存，且resize很慢。有点像空间换时间。","source":"_posts/编程开发/Java/hash数据结构原理.md","raw":"---\ntitle: hash数据结构原理\ndate: 2020-03-08 18:13:30\ncategories: [编程开发,Java]\n---\n\njava hashMap底层实现：数组+链表+红黑树(链表长度大于8的时候)\n\nhashcode 通过hash函数 —> hash值\n\nhash值 通过数组长度取余 —> index\n\n \n\n所以说hash函数要尽量能够均匀数组位置。\n\njava里的hashMap的hash函数是：Hash值=（hashcode）^ (hashcode >>> 16)\n\nhashMap预设数组长度也蛮重要，到load_factor(默认0.75)后，会resize 2倍，index都得重新算了。\n\n \n\npython里dict对string的hash函数就很蛋疼，是64位的整数。\n\n  \n\n虽然hash的查询，插入，删除都很快，因为hash里的数组填不满，所以说hash相对其他数据结构而言，比较耗内存，且resize很慢。有点像空间换时间。","slug":"编程开发/Java/hash数据结构原理","published":1,"updated":"2022-09-15T03:46:43.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qv006qjqrru3hphcwr","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>java hashMap底层实现：数组+链表+红黑树(链表长度大于8的时候)</p>\n<p>hashcode 通过hash函数 —&gt; hash值</p>\n<p>hash值 通过数组长度取余 —&gt; index</p>\n<p>所以说hash函数要尽量能够均匀数组位置。</p>\n<p>java里的hashMap的hash函数是：Hash值=（hashcode）^ (hashcode &gt;&gt;&gt; 16)</p>\n<p>hashMap预设数组长度也蛮重要，到load_factor(默认0.75)后，会resize 2倍，index都得重新算了。</p>\n<p>python里dict对string的hash函数就很蛋疼，是64位的整数。</p>\n<p>虽然hash的查询，插入，删除都很快，因为hash里的数组填不满，所以说hash相对其他数据结构而言，比较耗内存，且resize很慢。有点像空间换时间。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>java hashMap底层实现：数组+链表+红黑树(链表长度大于8的时候)</p>\n<p>hashcode 通过hash函数 —&gt; hash值</p>\n<p>hash值 通过数组长度取余 —&gt; index</p>\n<p>所以说hash函数要尽量能够均匀数组位置。</p>\n<p>java里的hashMap的hash函数是：Hash值=（hashcode）^ (hashcode &gt;&gt;&gt; 16)</p>\n<p>hashMap预设数组长度也蛮重要，到load_factor(默认0.75)后，会resize 2倍，index都得重新算了。</p>\n<p>python里dict对string的hash函数就很蛋疼，是64位的整数。</p>\n<p>虽然hash的查询，插入，删除都很快，因为hash里的数组填不满，所以说hash相对其他数据结构而言，比较耗内存，且resize很慢。有点像空间换时间。</p>\n"},{"title":"java I/O","date":"2019-06-11T10:13:30.000Z","_content":"\n\n\n1. 多线程（同步阻塞）；\n2. IO多路复用（select，poll，epoll）（同步非阻塞，严格地来讲，是把阻塞点改变了位置）；\n3. 直接暴露出异步的IO接口，如kernel-aio和IOCP（异步非阻塞）。\n\n \n\nNIO就是IO多路复用，同步非阻塞，selector用来监听channel(OS内核空间)，另有ByteBuffer可读可写，处理程序数据空间。\n\n![image-20200605165005503](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhifritq9j30pd0elafo.jpg) \n\n字节流操作，无输入输出缓存，所以一般包一个bufferedInputStream，bufferedOutputStream\n\n字符流操作，自带缓存。\n\n \n\nhttps://www.zhihu.com/question/19732473\n\n \n\n \n\n","source":"_posts/编程开发/Java/java IO.md","raw":"---\ntitle: java I/O\ndate: 2019-06-11 18:13:30\ncategories: [编程开发,Java]\n---\n\n\n\n1. 多线程（同步阻塞）；\n2. IO多路复用（select，poll，epoll）（同步非阻塞，严格地来讲，是把阻塞点改变了位置）；\n3. 直接暴露出异步的IO接口，如kernel-aio和IOCP（异步非阻塞）。\n\n \n\nNIO就是IO多路复用，同步非阻塞，selector用来监听channel(OS内核空间)，另有ByteBuffer可读可写，处理程序数据空间。\n\n![image-20200605165005503](https://tva1.sinaimg.cn/large/007S8ZIlly1gfhifritq9j30pd0elafo.jpg) \n\n字节流操作，无输入输出缓存，所以一般包一个bufferedInputStream，bufferedOutputStream\n\n字符流操作，自带缓存。\n\n \n\nhttps://www.zhihu.com/question/19732473\n\n \n\n \n\n","slug":"编程开发/Java/java IO","published":1,"updated":"2022-09-15T03:46:43.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qw006sjqrrbhzyjl22","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><ol>\n<li>多线程（同步阻塞）；</li>\n<li>IO多路复用（select，poll，epoll）（同步非阻塞，严格地来讲，是把阻塞点改变了位置）；</li>\n<li>直接暴露出异步的IO接口，如kernel-aio和IOCP（异步非阻塞）。</li>\n</ol>\n<p>NIO就是IO多路复用，同步非阻塞，selector用来监听channel(OS内核空间)，另有ByteBuffer可读可写，处理程序数据空间。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhifritq9j30pd0elafo.jpg\" alt=\"image-20200605165005503\"> </p>\n<p>字节流操作，无输入输出缓存，所以一般包一个bufferedInputStream，bufferedOutputStream</p>\n<p>字符流操作，自带缓存。</p>\n<p><a href=\"https://www.zhihu.com/question/19732473\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/19732473</a></p>\n","site":{"data":{}},"excerpt":"","more":"<ol>\n<li>多线程（同步阻塞）；</li>\n<li>IO多路复用（select，poll，epoll）（同步非阻塞，严格地来讲，是把阻塞点改变了位置）；</li>\n<li>直接暴露出异步的IO接口，如kernel-aio和IOCP（异步非阻塞）。</li>\n</ol>\n<p>NIO就是IO多路复用，同步非阻塞，selector用来监听channel(OS内核空间)，另有ByteBuffer可读可写，处理程序数据空间。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gfhifritq9j30pd0elafo.jpg\" alt=\"image-20200605165005503\"> </p>\n<p>字节流操作，无输入输出缓存，所以一般包一个bufferedInputStream，bufferedOutputStream</p>\n<p>字符流操作，自带缓存。</p>\n<p><a href=\"https://www.zhihu.com/question/19732473\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/19732473</a></p>\n"},{"title":"系统管理工具Systemd","date":"2021-01-19T16:00:00.000Z","_content":"\n\n\n以前linux用的是initd工具来管理系统，后来渐渐被systemd取代了。具体可看[这篇博客](http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html)，介绍得非常详细。\n\n\n\n注意以下几点：\n\n- systemd是可以直接与系统内核交互的，比如关机，关电源，停止cpu计算等。\n- unit是一个资源的概念，不仅仅包含service，还有很多其他的比如挂载，硬件设备等资源。\n- target是一个unit组的概念，相当于以前的run_level。比如poweroff，reboot, multi_user，graphical等状态，这些状态都对应了一系列unit的启动和关闭，一般我们都用默认状态，对应的是graphical状态。\n- 我们一般都是用户自定义damen，所以要加个后缀--user，这种情况下service的符号链接是注册在~/.config/systemd/user/下的。\n- 用户自定义service的话，unit配置文件只要写【Service】和【Install】就好了。\n\n","source":"_posts/操作系统/Linux/系统管理工具systemd.md","raw":"---\ntitle: 系统管理工具Systemd\ndate: 2021-01-20\ncategories: [操作系统,Linux]\n---\n\n\n\n以前linux用的是initd工具来管理系统，后来渐渐被systemd取代了。具体可看[这篇博客](http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html)，介绍得非常详细。\n\n\n\n注意以下几点：\n\n- systemd是可以直接与系统内核交互的，比如关机，关电源，停止cpu计算等。\n- unit是一个资源的概念，不仅仅包含service，还有很多其他的比如挂载，硬件设备等资源。\n- target是一个unit组的概念，相当于以前的run_level。比如poweroff，reboot, multi_user，graphical等状态，这些状态都对应了一系列unit的启动和关闭，一般我们都用默认状态，对应的是graphical状态。\n- 我们一般都是用户自定义damen，所以要加个后缀--user，这种情况下service的符号链接是注册在~/.config/systemd/user/下的。\n- 用户自定义service的话，unit配置文件只要写【Service】和【Install】就好了。\n\n","slug":"操作系统/Linux/系统管理工具systemd","published":1,"updated":"2022-09-15T03:46:43.360Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qw006vjqrrkmjp3t5b","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>以前linux用的是initd工具来管理系统，后来渐渐被systemd取代了。具体可看<a href=\"http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html\" target=\"_blank\" rel=\"noopener\">这篇博客</a>，介绍得非常详细。</p>\n<p>注意以下几点：</p>\n<ul>\n<li>systemd是可以直接与系统内核交互的，比如关机，关电源，停止cpu计算等。</li>\n<li>unit是一个资源的概念，不仅仅包含service，还有很多其他的比如挂载，硬件设备等资源。</li>\n<li>target是一个unit组的概念，相当于以前的run_level。比如poweroff，reboot, multi_user，graphical等状态，这些状态都对应了一系列unit的启动和关闭，一般我们都用默认状态，对应的是graphical状态。</li>\n<li>我们一般都是用户自定义damen，所以要加个后缀—user，这种情况下service的符号链接是注册在~/.config/systemd/user/下的。</li>\n<li>用户自定义service的话，unit配置文件只要写【Service】和【Install】就好了。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>以前linux用的是initd工具来管理系统，后来渐渐被systemd取代了。具体可看<a href=\"http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html\" target=\"_blank\" rel=\"noopener\">这篇博客</a>，介绍得非常详细。</p>\n<p>注意以下几点：</p>\n<ul>\n<li>systemd是可以直接与系统内核交互的，比如关机，关电源，停止cpu计算等。</li>\n<li>unit是一个资源的概念，不仅仅包含service，还有很多其他的比如挂载，硬件设备等资源。</li>\n<li>target是一个unit组的概念，相当于以前的run_level。比如poweroff，reboot, multi_user，graphical等状态，这些状态都对应了一系列unit的启动和关闭，一般我们都用默认状态，对应的是graphical状态。</li>\n<li>我们一般都是用户自定义damen，所以要加个后缀—user，这种情况下service的符号链接是注册在~/.config/systemd/user/下的。</li>\n<li>用户自定义service的话，unit配置文件只要写【Service】和【Install】就好了。</li>\n</ul>\n"},{"title":"java和python的字符字节数问题","date":"2019-06-10T16:00:00.000Z","_content":"\n#### Java\n\n- Java中的基本类型char的字节数是固定的，2个字节，默认编码是UTF-16\n- Java中的字符串的字节数则是不固定的，对于英文字符，占1个字节，而对于中文字符的话，就会因为编码方式而改变：\n  - 如GBK编码，中文字符2个字节\n  - 如UTF-8编码，中文字符3个字节\n- 查看方式：str1.getBytes(\"utf-8\").length\n\n\n\n#### Python\n\n- Python没有基本类型，就是指字符串，原理和java类型，对于英文字符，占1个字节，而对于中文字符的话，就会因为编码方式而改变。\n- 查看方式：len(str1.encode('gbk'))\n\n\n\n#### 编码转化\n\njava中char的默认编码是UTF-16，2个字节，但实际操作系统中的默认编码一般都是UTF-8，所以在程序中如果没有指定操作系统的编码，一般都会进行UTF-16到UTF-8的编译码转换。当char的字节范围超过2个字节时，java会通过utf-16 pair的形式来解决。\n\n```java\n       String s = \"ｮA\";\n        try {\n            byte[] utf8 = s.getBytes(\"utf-8\");//不指定的话就默认是OS的编码，一般UTF-8\n            System.out.println(utf8.length);\n//            System.out.println(s.getBytes(\"utf-16\")[0]);\n//            System.out.println(s.getBytes(\"utf-16\")[1]);\n//            System.out.println(s.getBytes(\"utf-16\")[2]);\n//            System.out.println(s.getBytes(\"utf-16\")[3]);\n            for (int i = 0; i < utf8.length; i++) {\n                System.out.println(byteToBit(utf8[i]));\n            }\n\n\n            byte[] utf16 = s.getBytes(\"utf-16\");\n            System.out.println(utf16.length);\n//            System.out.println(s.getBytes(\"utf-16\")[0]);\n//            System.out.println(s.getBytes(\"utf-16\")[1]);\n//            System.out.println(s.getBytes(\"utf-16\")[2]);\n//            System.out.println(s.getBytes(\"utf-16\")[3]);\n            for (int i = 0; i < utf16.length; i++) {\n                System.out.println(byteToBit(utf16[i]));\n            }\n\n        }catch (UnsupportedEncodingException e) {\n            e.printStackTrace();\n        }\n```\n\n结果：\n\n```\n4 //UTF-8的话，第一个字符3个字节，第二个字符1个字节(ACSII码)\n11101111\n10111101\n10101110\n01000001\n6 //UTF-16的话，第一个字符4个字节，FEFF,FF6E pair，第二个字符2个字节(空字节+ASCII码)\n11111110\n11111111\n11111111\n01101110\n00000000\n01000001\n```\n\n\n\n对于byte和char：\n\nbyte就是1个字节，8位，int表示-128~127\n\nchar的话就是对应byte的编码表示，指定编码集后就对应char，一般不指定进行转换的话就是OS默认utf-8，char直接赋值的话存储的就是java默认utf-16","source":"_posts/编程开发/Java/java和python的字符字节数问题.md","raw":"---\ntitle: java和python的字符字节数问题\ndate: 2019-06-11 \ncategories: [编程开发,Java]\n---\n\n#### Java\n\n- Java中的基本类型char的字节数是固定的，2个字节，默认编码是UTF-16\n- Java中的字符串的字节数则是不固定的，对于英文字符，占1个字节，而对于中文字符的话，就会因为编码方式而改变：\n  - 如GBK编码，中文字符2个字节\n  - 如UTF-8编码，中文字符3个字节\n- 查看方式：str1.getBytes(\"utf-8\").length\n\n\n\n#### Python\n\n- Python没有基本类型，就是指字符串，原理和java类型，对于英文字符，占1个字节，而对于中文字符的话，就会因为编码方式而改变。\n- 查看方式：len(str1.encode('gbk'))\n\n\n\n#### 编码转化\n\njava中char的默认编码是UTF-16，2个字节，但实际操作系统中的默认编码一般都是UTF-8，所以在程序中如果没有指定操作系统的编码，一般都会进行UTF-16到UTF-8的编译码转换。当char的字节范围超过2个字节时，java会通过utf-16 pair的形式来解决。\n\n```java\n       String s = \"ｮA\";\n        try {\n            byte[] utf8 = s.getBytes(\"utf-8\");//不指定的话就默认是OS的编码，一般UTF-8\n            System.out.println(utf8.length);\n//            System.out.println(s.getBytes(\"utf-16\")[0]);\n//            System.out.println(s.getBytes(\"utf-16\")[1]);\n//            System.out.println(s.getBytes(\"utf-16\")[2]);\n//            System.out.println(s.getBytes(\"utf-16\")[3]);\n            for (int i = 0; i < utf8.length; i++) {\n                System.out.println(byteToBit(utf8[i]));\n            }\n\n\n            byte[] utf16 = s.getBytes(\"utf-16\");\n            System.out.println(utf16.length);\n//            System.out.println(s.getBytes(\"utf-16\")[0]);\n//            System.out.println(s.getBytes(\"utf-16\")[1]);\n//            System.out.println(s.getBytes(\"utf-16\")[2]);\n//            System.out.println(s.getBytes(\"utf-16\")[3]);\n            for (int i = 0; i < utf16.length; i++) {\n                System.out.println(byteToBit(utf16[i]));\n            }\n\n        }catch (UnsupportedEncodingException e) {\n            e.printStackTrace();\n        }\n```\n\n结果：\n\n```\n4 //UTF-8的话，第一个字符3个字节，第二个字符1个字节(ACSII码)\n11101111\n10111101\n10101110\n01000001\n6 //UTF-16的话，第一个字符4个字节，FEFF,FF6E pair，第二个字符2个字节(空字节+ASCII码)\n11111110\n11111111\n11111111\n01101110\n00000000\n01000001\n```\n\n\n\n对于byte和char：\n\nbyte就是1个字节，8位，int表示-128~127\n\nchar的话就是对应byte的编码表示，指定编码集后就对应char，一般不指定进行转换的话就是OS默认utf-8，char直接赋值的话存储的就是java默认utf-16","slug":"编程开发/Java/java和python的字符字节数问题","published":1,"updated":"2022-09-15T03:46:43.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qx006xjqrrvg562gdp","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h4 id=\"Java\"><a href=\"#Java\" class=\"headerlink\" title=\"Java\"></a>Java</h4><ul>\n<li>Java中的基本类型char的字节数是固定的，2个字节，默认编码是UTF-16</li>\n<li>Java中的字符串的字节数则是不固定的，对于英文字符，占1个字节，而对于中文字符的话，就会因为编码方式而改变：<ul>\n<li>如GBK编码，中文字符2个字节</li>\n<li>如UTF-8编码，中文字符3个字节</li>\n</ul>\n</li>\n<li>查看方式：str1.getBytes(“utf-8”).length</li>\n</ul>\n<h4 id=\"Python\"><a href=\"#Python\" class=\"headerlink\" title=\"Python\"></a>Python</h4><ul>\n<li>Python没有基本类型，就是指字符串，原理和java类型，对于英文字符，占1个字节，而对于中文字符的话，就会因为编码方式而改变。</li>\n<li>查看方式：len(str1.encode(‘gbk’))</li>\n</ul>\n<h4 id=\"编码转化\"><a href=\"#编码转化\" class=\"headerlink\" title=\"编码转化\"></a>编码转化</h4><p>java中char的默认编码是UTF-16，2个字节，但实际操作系统中的默认编码一般都是UTF-8，所以在程序中如果没有指定操作系统的编码，一般都会进行UTF-16到UTF-8的编译码转换。当char的字节范围超过2个字节时，java会通过utf-16 pair的形式来解决。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">       String s = <span class=\"string\">\"ｮA\"</span>;</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">byte</span>[] utf8 = s.getBytes(<span class=\"string\">\"utf-8\"</span>);<span class=\"comment\">//不指定的话就默认是OS的编码，一般UTF-8</span></span><br><span class=\"line\">            System.out.println(utf8.length);</span><br><span class=\"line\"><span class=\"comment\">//            System.out.println(s.getBytes(\"utf-16\")[0]);</span></span><br><span class=\"line\"><span class=\"comment\">//            System.out.println(s.getBytes(\"utf-16\")[1]);</span></span><br><span class=\"line\"><span class=\"comment\">//            System.out.println(s.getBytes(\"utf-16\")[2]);</span></span><br><span class=\"line\"><span class=\"comment\">//            System.out.println(s.getBytes(\"utf-16\")[3]);</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; utf8.length; i++) &#123;</span><br><span class=\"line\">                System.out.println(byteToBit(utf8[i]));</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">byte</span>[] utf16 = s.getBytes(<span class=\"string\">\"utf-16\"</span>);</span><br><span class=\"line\">            System.out.println(utf16.length);</span><br><span class=\"line\"><span class=\"comment\">//            System.out.println(s.getBytes(\"utf-16\")[0]);</span></span><br><span class=\"line\"><span class=\"comment\">//            System.out.println(s.getBytes(\"utf-16\")[1]);</span></span><br><span class=\"line\"><span class=\"comment\">//            System.out.println(s.getBytes(\"utf-16\")[2]);</span></span><br><span class=\"line\"><span class=\"comment\">//            System.out.println(s.getBytes(\"utf-16\")[3]);</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; utf16.length; i++) &#123;</span><br><span class=\"line\">                System.out.println(byteToBit(utf16[i]));</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#125;<span class=\"keyword\">catch</span> (UnsupportedEncodingException e) &#123;</span><br><span class=\"line\">            e.printStackTrace();</span><br><span class=\"line\">        &#125;</span><br></pre></td></tr></table></figure>\n<p>结果：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">4 //UTF-8的话，第一个字符3个字节，第二个字符1个字节(ACSII码)</span><br><span class=\"line\">11101111</span><br><span class=\"line\">10111101</span><br><span class=\"line\">10101110</span><br><span class=\"line\">01000001</span><br><span class=\"line\">6 //UTF-16的话，第一个字符4个字节，FEFF,FF6E pair，第二个字符2个字节(空字节+ASCII码)</span><br><span class=\"line\">11111110</span><br><span class=\"line\">11111111</span><br><span class=\"line\">11111111</span><br><span class=\"line\">01101110</span><br><span class=\"line\">00000000</span><br><span class=\"line\">01000001</span><br></pre></td></tr></table></figure>\n<p>对于byte和char：</p>\n<p>byte就是1个字节，8位，int表示-128~127</p>\n<p>char的话就是对应byte的编码表示，指定编码集后就对应char，一般不指定进行转换的话就是OS默认utf-8，char直接赋值的话存储的就是java默认utf-16</p>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"Java\"><a href=\"#Java\" class=\"headerlink\" title=\"Java\"></a>Java</h4><ul>\n<li>Java中的基本类型char的字节数是固定的，2个字节，默认编码是UTF-16</li>\n<li>Java中的字符串的字节数则是不固定的，对于英文字符，占1个字节，而对于中文字符的话，就会因为编码方式而改变：<ul>\n<li>如GBK编码，中文字符2个字节</li>\n<li>如UTF-8编码，中文字符3个字节</li>\n</ul>\n</li>\n<li>查看方式：str1.getBytes(“utf-8”).length</li>\n</ul>\n<h4 id=\"Python\"><a href=\"#Python\" class=\"headerlink\" title=\"Python\"></a>Python</h4><ul>\n<li>Python没有基本类型，就是指字符串，原理和java类型，对于英文字符，占1个字节，而对于中文字符的话，就会因为编码方式而改变。</li>\n<li>查看方式：len(str1.encode(‘gbk’))</li>\n</ul>\n<h4 id=\"编码转化\"><a href=\"#编码转化\" class=\"headerlink\" title=\"编码转化\"></a>编码转化</h4><p>java中char的默认编码是UTF-16，2个字节，但实际操作系统中的默认编码一般都是UTF-8，所以在程序中如果没有指定操作系统的编码，一般都会进行UTF-16到UTF-8的编译码转换。当char的字节范围超过2个字节时，java会通过utf-16 pair的形式来解决。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">       String s = <span class=\"string\">\"ｮA\"</span>;</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">byte</span>[] utf8 = s.getBytes(<span class=\"string\">\"utf-8\"</span>);<span class=\"comment\">//不指定的话就默认是OS的编码，一般UTF-8</span></span><br><span class=\"line\">            System.out.println(utf8.length);</span><br><span class=\"line\"><span class=\"comment\">//            System.out.println(s.getBytes(\"utf-16\")[0]);</span></span><br><span class=\"line\"><span class=\"comment\">//            System.out.println(s.getBytes(\"utf-16\")[1]);</span></span><br><span class=\"line\"><span class=\"comment\">//            System.out.println(s.getBytes(\"utf-16\")[2]);</span></span><br><span class=\"line\"><span class=\"comment\">//            System.out.println(s.getBytes(\"utf-16\")[3]);</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; utf8.length; i++) &#123;</span><br><span class=\"line\">                System.out.println(byteToBit(utf8[i]));</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">byte</span>[] utf16 = s.getBytes(<span class=\"string\">\"utf-16\"</span>);</span><br><span class=\"line\">            System.out.println(utf16.length);</span><br><span class=\"line\"><span class=\"comment\">//            System.out.println(s.getBytes(\"utf-16\")[0]);</span></span><br><span class=\"line\"><span class=\"comment\">//            System.out.println(s.getBytes(\"utf-16\")[1]);</span></span><br><span class=\"line\"><span class=\"comment\">//            System.out.println(s.getBytes(\"utf-16\")[2]);</span></span><br><span class=\"line\"><span class=\"comment\">//            System.out.println(s.getBytes(\"utf-16\")[3]);</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; utf16.length; i++) &#123;</span><br><span class=\"line\">                System.out.println(byteToBit(utf16[i]));</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#125;<span class=\"keyword\">catch</span> (UnsupportedEncodingException e) &#123;</span><br><span class=\"line\">            e.printStackTrace();</span><br><span class=\"line\">        &#125;</span><br></pre></td></tr></table></figure>\n<p>结果：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">4 //UTF-8的话，第一个字符3个字节，第二个字符1个字节(ACSII码)</span><br><span class=\"line\">11101111</span><br><span class=\"line\">10111101</span><br><span class=\"line\">10101110</span><br><span class=\"line\">01000001</span><br><span class=\"line\">6 //UTF-16的话，第一个字符4个字节，FEFF,FF6E pair，第二个字符2个字节(空字节+ASCII码)</span><br><span class=\"line\">11111110</span><br><span class=\"line\">11111111</span><br><span class=\"line\">11111111</span><br><span class=\"line\">01101110</span><br><span class=\"line\">00000000</span><br><span class=\"line\">01000001</span><br></pre></td></tr></table></figure>\n<p>对于byte和char：</p>\n<p>byte就是1个字节，8位，int表示-128~127</p>\n<p>char的话就是对应byte的编码表示，指定编码集后就对应char，一般不指定进行转换的话就是OS默认utf-8，char直接赋值的话存储的就是java默认utf-16</p>\n"},{"title":"C语言中的指针详解","date":"2017-06-28T09:46:54.000Z","_content":"\n最近在创建动态二维数组(数组大小为变量)的时候，遇到了一些关于指针的问题，经过一番试验和研究，将一些比较容易出错的地方进行了归纳整理。\n\n# 数组名和指针\n```c\nint a[4] = {0};\nint *b = new int[4];\ncout << sizeof(a) << endl;  // 4 * sizeof(int)\ncout << sizeof(b) << endl; // sizeof(int*)\n```\n<!-- more -->\n对于一个数组，数组名从值上来讲就等于它第一个元素的地址，但它和指针其实是有区别的:\n\n- 你可以修改指针的内容，但无法修改数组名的指向。\n- 对于sizeof，数组名得到的是整个数组的大小，指针则是指针类型占的内存大小。\n\n# 数组指针和指针数组\n```c\nint a[4] = {0};\nint (* b)[4] = &a;\nint *c[4];\ncout << sizeof(b) << endl; // sizeof(int*)\ncout << sizeof(c) << endl; // sizeof(int*) * 4\n```\n上述b就是一个数组指针，该指针指向一个长度为4的数组，指针移动1则对应移动4个int。c则是指针数组，b和c千万不要搞混，[]的优先级要高于\\*, 所以c是一个数组，但该数组储存的都是指针。注意，尽管b是数组指针，但是其占的内存依然是指针类型占的内存大小。\n\n\n提到数组指针后，就要讲到我的出发点二维数组了。\n```c\nint **a = new int[2][4]; // 错\nint(*a)[4] = new int[2][4]; // 对\n```\n我刚开始就错写成了第一种形式，发现这样会出错。我的想法是对于int[0]，int[1], int[2]里面储存的是int[4]数组的值，这个值应该就是一位维组名，我等价得以为是指向首个元素的地址，也就是``int *``类型，那么a就应该是指向指针的指针。\n\n但事实上，正如之前所说，数组名只是在值上等于指向首个元素的地址，但两者并不等价！只是在参数传递，数组名赋值给指针时两者值相等！仔细去想，如果按照我一开始的这种想法，sizeof(\\*a)就只是一个指针的内存，无法代表一维数组的大小。\n\n因此，int[0]中存储的就只是一维数组名，然后再对该一维数组名取地址，才是正确的指向int[0]的地址，同样的，这个值也是和二维数组名在值上相同，但是并不等价。\n\n```c\nint *a = new int[2];\nint (*a)[3] = new int[2][3];\nint(* a)[3][4] = new int[2][3][4];\n```\n以上才是正确的形式，多维可以类推。\n\n# 总结\n- 数组指针， 不能因为数组名在值上等于指针，而等价为指向指针的指针。\n- 指针数组，在值上等价与指向指针的指针，可以将数组名赋给指向指针的指针。\n- 讲真，涉及到多维数组，既然用了c++,那还是用vector吧，简单方便，并且函数传递时是值传递，也可以用引用传递来实现实参改变，比c方便太多了！\n\n\n","source":"_posts/编程开发/C++/C语言中的指针详解.md","raw":"---\ntitle: C语言中的指针详解\ndate: 2017-06-28 17:46:54\ncategories: [编程开发,C++]\n---\n\n最近在创建动态二维数组(数组大小为变量)的时候，遇到了一些关于指针的问题，经过一番试验和研究，将一些比较容易出错的地方进行了归纳整理。\n\n# 数组名和指针\n```c\nint a[4] = {0};\nint *b = new int[4];\ncout << sizeof(a) << endl;  // 4 * sizeof(int)\ncout << sizeof(b) << endl; // sizeof(int*)\n```\n<!-- more -->\n对于一个数组，数组名从值上来讲就等于它第一个元素的地址，但它和指针其实是有区别的:\n\n- 你可以修改指针的内容，但无法修改数组名的指向。\n- 对于sizeof，数组名得到的是整个数组的大小，指针则是指针类型占的内存大小。\n\n# 数组指针和指针数组\n```c\nint a[4] = {0};\nint (* b)[4] = &a;\nint *c[4];\ncout << sizeof(b) << endl; // sizeof(int*)\ncout << sizeof(c) << endl; // sizeof(int*) * 4\n```\n上述b就是一个数组指针，该指针指向一个长度为4的数组，指针移动1则对应移动4个int。c则是指针数组，b和c千万不要搞混，[]的优先级要高于\\*, 所以c是一个数组，但该数组储存的都是指针。注意，尽管b是数组指针，但是其占的内存依然是指针类型占的内存大小。\n\n\n提到数组指针后，就要讲到我的出发点二维数组了。\n```c\nint **a = new int[2][4]; // 错\nint(*a)[4] = new int[2][4]; // 对\n```\n我刚开始就错写成了第一种形式，发现这样会出错。我的想法是对于int[0]，int[1], int[2]里面储存的是int[4]数组的值，这个值应该就是一位维组名，我等价得以为是指向首个元素的地址，也就是``int *``类型，那么a就应该是指向指针的指针。\n\n但事实上，正如之前所说，数组名只是在值上等于指向首个元素的地址，但两者并不等价！只是在参数传递，数组名赋值给指针时两者值相等！仔细去想，如果按照我一开始的这种想法，sizeof(\\*a)就只是一个指针的内存，无法代表一维数组的大小。\n\n因此，int[0]中存储的就只是一维数组名，然后再对该一维数组名取地址，才是正确的指向int[0]的地址，同样的，这个值也是和二维数组名在值上相同，但是并不等价。\n\n```c\nint *a = new int[2];\nint (*a)[3] = new int[2][3];\nint(* a)[3][4] = new int[2][3][4];\n```\n以上才是正确的形式，多维可以类推。\n\n# 总结\n- 数组指针， 不能因为数组名在值上等于指针，而等价为指向指针的指针。\n- 指针数组，在值上等价与指向指针的指针，可以将数组名赋给指向指针的指针。\n- 讲真，涉及到多维数组，既然用了c++,那还是用vector吧，简单方便，并且函数传递时是值传递，也可以用引用传递来实现实参改变，比c方便太多了！\n\n\n","slug":"编程开发/C++/C语言中的指针详解","published":1,"updated":"2022-09-15T03:46:43.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qx0070jqrro7fg7ewj","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>最近在创建动态二维数组(数组大小为变量)的时候，遇到了一些关于指针的问题，经过一番试验和研究，将一些比较容易出错的地方进行了归纳整理。</p>\n<h1 id=\"数组名和指针\"><a href=\"#数组名和指针\" class=\"headerlink\" title=\"数组名和指针\"></a>数组名和指针</h1><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> a[<span class=\"number\">4</span>] = &#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *b = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[<span class=\"number\">4</span>];</span><br><span class=\"line\"><span class=\"built_in\">cout</span> &lt;&lt; <span class=\"keyword\">sizeof</span>(a) &lt;&lt; <span class=\"built_in\">endl</span>;  <span class=\"comment\">// 4 * sizeof(int)</span></span><br><span class=\"line\"><span class=\"built_in\">cout</span> &lt;&lt; <span class=\"keyword\">sizeof</span>(b) &lt;&lt; <span class=\"built_in\">endl</span>; <span class=\"comment\">// sizeof(int*)</span></span><br></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<p>对于一个数组，数组名从值上来讲就等于它第一个元素的地址，但它和指针其实是有区别的:</p>\n<ul>\n<li>你可以修改指针的内容，但无法修改数组名的指向。</li>\n<li>对于sizeof，数组名得到的是整个数组的大小，指针则是指针类型占的内存大小。</li>\n</ul>\n<h1 id=\"数组指针和指针数组\"><a href=\"#数组指针和指针数组\" class=\"headerlink\" title=\"数组指针和指针数组\"></a>数组指针和指针数组</h1><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> a[<span class=\"number\">4</span>] = &#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\"><span class=\"keyword\">int</span> (* b)[<span class=\"number\">4</span>] = &amp;a;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *c[<span class=\"number\">4</span>];</span><br><span class=\"line\"><span class=\"built_in\">cout</span> &lt;&lt; <span class=\"keyword\">sizeof</span>(b) &lt;&lt; <span class=\"built_in\">endl</span>; <span class=\"comment\">// sizeof(int*)</span></span><br><span class=\"line\"><span class=\"built_in\">cout</span> &lt;&lt; <span class=\"keyword\">sizeof</span>(c) &lt;&lt; <span class=\"built_in\">endl</span>; <span class=\"comment\">// sizeof(int*) * 4</span></span><br></pre></td></tr></table></figure>\n<p>上述b就是一个数组指针，该指针指向一个长度为4的数组，指针移动1则对应移动4个int。c则是指针数组，b和c千万不要搞混，[]的优先级要高于*, 所以c是一个数组，但该数组储存的都是指针。注意，尽管b是数组指针，但是其占的内存依然是指针类型占的内存大小。</p>\n<p>提到数组指针后，就要讲到我的出发点二维数组了。<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> **a = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[<span class=\"number\">2</span>][<span class=\"number\">4</span>]; <span class=\"comment\">// 错</span></span><br><span class=\"line\"><span class=\"keyword\">int</span>(*a)[<span class=\"number\">4</span>] = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[<span class=\"number\">2</span>][<span class=\"number\">4</span>]; <span class=\"comment\">// 对</span></span><br></pre></td></tr></table></figure></p>\n<p>我刚开始就错写成了第一种形式，发现这样会出错。我的想法是对于int[0]，int[1], int[2]里面储存的是int[4]数组的值，这个值应该就是一位维组名，我等价得以为是指向首个元素的地址，也就是<code>int *</code>类型，那么a就应该是指向指针的指针。</p>\n<p>但事实上，正如之前所说，数组名只是在值上等于指向首个元素的地址，但两者并不等价！只是在参数传递，数组名赋值给指针时两者值相等！仔细去想，如果按照我一开始的这种想法，sizeof(*a)就只是一个指针的内存，无法代表一维数组的大小。</p>\n<p>因此，int[0]中存储的就只是一维数组名，然后再对该一维数组名取地址，才是正确的指向int[0]的地址，同样的，这个值也是和二维数组名在值上相同，但是并不等价。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> *a = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[<span class=\"number\">2</span>];</span><br><span class=\"line\"><span class=\"keyword\">int</span> (*a)[<span class=\"number\">3</span>] = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[<span class=\"number\">2</span>][<span class=\"number\">3</span>];</span><br><span class=\"line\"><span class=\"keyword\">int</span>(* a)[<span class=\"number\">3</span>][<span class=\"number\">4</span>] = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[<span class=\"number\">2</span>][<span class=\"number\">3</span>][<span class=\"number\">4</span>];</span><br></pre></td></tr></table></figure>\n<p>以上才是正确的形式，多维可以类推。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><ul>\n<li>数组指针， 不能因为数组名在值上等于指针，而等价为指向指针的指针。</li>\n<li>指针数组，在值上等价与指向指针的指针，可以将数组名赋给指向指针的指针。</li>\n<li>讲真，涉及到多维数组，既然用了c++,那还是用vector吧，简单方便，并且函数传递时是值传递，也可以用引用传递来实现实参改变，比c方便太多了！</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>最近在创建动态二维数组(数组大小为变量)的时候，遇到了一些关于指针的问题，经过一番试验和研究，将一些比较容易出错的地方进行了归纳整理。</p>\n<h1 id=\"数组名和指针\"><a href=\"#数组名和指针\" class=\"headerlink\" title=\"数组名和指针\"></a>数组名和指针</h1><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> a[<span class=\"number\">4</span>] = &#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *b = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[<span class=\"number\">4</span>];</span><br><span class=\"line\"><span class=\"built_in\">cout</span> &lt;&lt; <span class=\"keyword\">sizeof</span>(a) &lt;&lt; <span class=\"built_in\">endl</span>;  <span class=\"comment\">// 4 * sizeof(int)</span></span><br><span class=\"line\"><span class=\"built_in\">cout</span> &lt;&lt; <span class=\"keyword\">sizeof</span>(b) &lt;&lt; <span class=\"built_in\">endl</span>; <span class=\"comment\">// sizeof(int*)</span></span><br></pre></td></tr></table></figure>","more":"<p>对于一个数组，数组名从值上来讲就等于它第一个元素的地址，但它和指针其实是有区别的:</p>\n<ul>\n<li>你可以修改指针的内容，但无法修改数组名的指向。</li>\n<li>对于sizeof，数组名得到的是整个数组的大小，指针则是指针类型占的内存大小。</li>\n</ul>\n<h1 id=\"数组指针和指针数组\"><a href=\"#数组指针和指针数组\" class=\"headerlink\" title=\"数组指针和指针数组\"></a>数组指针和指针数组</h1><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> a[<span class=\"number\">4</span>] = &#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\"><span class=\"keyword\">int</span> (* b)[<span class=\"number\">4</span>] = &amp;a;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *c[<span class=\"number\">4</span>];</span><br><span class=\"line\"><span class=\"built_in\">cout</span> &lt;&lt; <span class=\"keyword\">sizeof</span>(b) &lt;&lt; <span class=\"built_in\">endl</span>; <span class=\"comment\">// sizeof(int*)</span></span><br><span class=\"line\"><span class=\"built_in\">cout</span> &lt;&lt; <span class=\"keyword\">sizeof</span>(c) &lt;&lt; <span class=\"built_in\">endl</span>; <span class=\"comment\">// sizeof(int*) * 4</span></span><br></pre></td></tr></table></figure>\n<p>上述b就是一个数组指针，该指针指向一个长度为4的数组，指针移动1则对应移动4个int。c则是指针数组，b和c千万不要搞混，[]的优先级要高于*, 所以c是一个数组，但该数组储存的都是指针。注意，尽管b是数组指针，但是其占的内存依然是指针类型占的内存大小。</p>\n<p>提到数组指针后，就要讲到我的出发点二维数组了。<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> **a = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[<span class=\"number\">2</span>][<span class=\"number\">4</span>]; <span class=\"comment\">// 错</span></span><br><span class=\"line\"><span class=\"keyword\">int</span>(*a)[<span class=\"number\">4</span>] = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[<span class=\"number\">2</span>][<span class=\"number\">4</span>]; <span class=\"comment\">// 对</span></span><br></pre></td></tr></table></figure></p>\n<p>我刚开始就错写成了第一种形式，发现这样会出错。我的想法是对于int[0]，int[1], int[2]里面储存的是int[4]数组的值，这个值应该就是一位维组名，我等价得以为是指向首个元素的地址，也就是<code>int *</code>类型，那么a就应该是指向指针的指针。</p>\n<p>但事实上，正如之前所说，数组名只是在值上等于指向首个元素的地址，但两者并不等价！只是在参数传递，数组名赋值给指针时两者值相等！仔细去想，如果按照我一开始的这种想法，sizeof(*a)就只是一个指针的内存，无法代表一维数组的大小。</p>\n<p>因此，int[0]中存储的就只是一维数组名，然后再对该一维数组名取地址，才是正确的指向int[0]的地址，同样的，这个值也是和二维数组名在值上相同，但是并不等价。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> *a = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[<span class=\"number\">2</span>];</span><br><span class=\"line\"><span class=\"keyword\">int</span> (*a)[<span class=\"number\">3</span>] = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[<span class=\"number\">2</span>][<span class=\"number\">3</span>];</span><br><span class=\"line\"><span class=\"keyword\">int</span>(* a)[<span class=\"number\">3</span>][<span class=\"number\">4</span>] = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[<span class=\"number\">2</span>][<span class=\"number\">3</span>][<span class=\"number\">4</span>];</span><br></pre></td></tr></table></figure>\n<p>以上才是正确的形式，多维可以类推。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><ul>\n<li>数组指针， 不能因为数组名在值上等于指针，而等价为指向指针的指针。</li>\n<li>指针数组，在值上等价与指向指针的指针，可以将数组名赋给指向指针的指针。</li>\n<li>讲真，涉及到多维数组，既然用了c++,那还是用vector吧，简单方便，并且函数传递时是值传递，也可以用引用传递来实现实参改变，比c方便太多了！</li>\n</ul>"},{"title":"关于JAVA的==和equals","date":"2020-05-09T10:13:30.000Z","_content":"\n在大部分的封装类中，都重写了Object类的这个方法，所以两者还是会有区别的。\n\n\n\n- 总的来说，==是一个关系运算符，如果比较的两端都为基本类型，则判断两者的值是否相等,（判断过程中还有不同基本类型的转化，这里不做讨论），如果比较的两端都为引用类型的话，则比较两者所指向对象的地址是否相同；\n\n- 对于equals方法，首先，能调用这个方法肯定是一个对象，然后，如果这个对象所在的类重写了equals方法，则按照重写的方法进行比较，如果没有，则比较两者所指向对象的地址是否相同。 ","source":"_posts/编程开发/Java/关于==和equals.md","raw":"---\ntitle: 关于JAVA的==和equals\ndate: 2020-05-09 18:13:30\ncategories: [编程开发,Java]\n---\n\n在大部分的封装类中，都重写了Object类的这个方法，所以两者还是会有区别的。\n\n\n\n- 总的来说，==是一个关系运算符，如果比较的两端都为基本类型，则判断两者的值是否相等,（判断过程中还有不同基本类型的转化，这里不做讨论），如果比较的两端都为引用类型的话，则比较两者所指向对象的地址是否相同；\n\n- 对于equals方法，首先，能调用这个方法肯定是一个对象，然后，如果这个对象所在的类重写了equals方法，则按照重写的方法进行比较，如果没有，则比较两者所指向对象的地址是否相同。 ","slug":"编程开发/Java/关于==和equals","published":1,"updated":"2022-09-15T03:46:43.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qy0072jqrr60zqd407","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>在大部分的封装类中，都重写了Object类的这个方法，所以两者还是会有区别的。</p>\n<ul>\n<li><p>总的来说，==是一个关系运算符，如果比较的两端都为基本类型，则判断两者的值是否相等,（判断过程中还有不同基本类型的转化，这里不做讨论），如果比较的两端都为引用类型的话，则比较两者所指向对象的地址是否相同；</p>\n</li>\n<li><p>对于equals方法，首先，能调用这个方法肯定是一个对象，然后，如果这个对象所在的类重写了equals方法，则按照重写的方法进行比较，如果没有，则比较两者所指向对象的地址是否相同。 </p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>在大部分的封装类中，都重写了Object类的这个方法，所以两者还是会有区别的。</p>\n<ul>\n<li><p>总的来说，==是一个关系运算符，如果比较的两端都为基本类型，则判断两者的值是否相等,（判断过程中还有不同基本类型的转化，这里不做讨论），如果比较的两端都为引用类型的话，则比较两者所指向对象的地址是否相同；</p>\n</li>\n<li><p>对于equals方法，首先，能调用这个方法肯定是一个对象，然后，如果这个对象所在的类重写了equals方法，则按照重写的方法进行比较，如果没有，则比较两者所指向对象的地址是否相同。 </p>\n</li>\n</ul>\n"},{"title":"关于阻塞非阻塞，同步异步的最好解释","date":"2019-10-17T10:13:30.000Z","_content":"\n\n\n还是不同层次的问题……\n一个网络包从应用程序A发到另一台电脑上的应用程序B，需要经历：\n\n1. 从A的业务代码到A的软件框架\n2. 从A的软件框架到计算机的操作系统内核\n3. 从A所在计算机的内核到网卡\n4. 从网卡经过网线发到交换机等设备，层层转发，到达B所在计算机的网卡\n5. 从B所在计算机的网卡到B所在计算机的内核\n6. 从B所在计算机的内核到B的程序的用户空间\n7. 从B的软件框架到B的业务代码\n\n这个层级关系就像是过程调用一样，前一级调用后一级的功能，后一级返回一个结果给前一级（比如：成功，或者失败）。只有在单独一级的调用上，可以说同步还是异步的问题。所谓同步，是指调用协议中结果在调用完成时返回，这样调用的过程中参与双方都处于一个状态同步的过程。而异步，是指调用方发出请求就立即返回，请求甚至可能还没到达接收方，比如说放到了某个缓冲区中，等待对方取走或者第三方转交；而结果，则通过接收方主动推送，或调用方轮询来得到。\n\n从这个定义中，我们看：\n\n- 首先1和7：这取决于软件框架的设计，如果软件框架可以beginXXX，然后立即返回，这就是一种异步调用，再比如javascript当中的异步HTTP调用，传入参数时提供一个回调函数，回调函数在完成时调用，再比如协程模型，调用接口后马上切换到其他协程继续执行，在完成时由框架切换回到协程中，这都是典型的异步接口设计。\n\n- 2和6：其他答主已经说得很好了，其实都需要调用方自己把数据在内核和用户空间里搬来搬去，其实都是同步接口，除非是IOCP这样的专门的异步传输接口，所以这一级其实是同步的，阻塞与非阻塞的区别其实是影响调用接口的结果（在特定条件下是否提前返回结果），而不是调用方式。\n\n- 3和5：内核一般通过缓冲区，使用DMI来传输数据，所以这一步又是异步的。\n\n- 4：以太网是个同步时序逻辑，随信号传输时钟，必须两边设备同时就绪了才能开始传输数据，这又是同步的。\n\n\n\n总结来说，讨论究竟是异步还是同步，一定要严格说明说的是哪一部分。其他答主说非阻塞是同步而不是异步，这毫无疑问是正确的，然而说某个框架是异步IO的框架，这也是正确的，因为说的其实是框架提供给业务代码的接口是异步的，不管是回调还是协程，比如说我们可以说某个库是异步的HTTPClient，并没有什么问题，因为说的是给业务代码的接口。由于通常异步的框架都需要在2中使用非阻塞的接口，的确会有很多人把非阻塞和异步混为一谈。\n\n \n\n编程的时候我们写业务代码，基本就是把IO多路复用（事件注册）认为是异步非阻塞的，虽然在linux接口层次还是同步阻塞的。\n\n\n\n\n\n参考文章：https://www.zhihu.com/question/19732473/answer/117012135","source":"_posts/编程开发/Java/关于阻塞非阻塞，同步异步的最好解释.md","raw":"---\ntitle: 关于阻塞非阻塞，同步异步的最好解释\ndate: 2019-10-17 18:13:30\ntags: 并发\ncategories: [编程开发,Java]\n---\n\n\n\n还是不同层次的问题……\n一个网络包从应用程序A发到另一台电脑上的应用程序B，需要经历：\n\n1. 从A的业务代码到A的软件框架\n2. 从A的软件框架到计算机的操作系统内核\n3. 从A所在计算机的内核到网卡\n4. 从网卡经过网线发到交换机等设备，层层转发，到达B所在计算机的网卡\n5. 从B所在计算机的网卡到B所在计算机的内核\n6. 从B所在计算机的内核到B的程序的用户空间\n7. 从B的软件框架到B的业务代码\n\n这个层级关系就像是过程调用一样，前一级调用后一级的功能，后一级返回一个结果给前一级（比如：成功，或者失败）。只有在单独一级的调用上，可以说同步还是异步的问题。所谓同步，是指调用协议中结果在调用完成时返回，这样调用的过程中参与双方都处于一个状态同步的过程。而异步，是指调用方发出请求就立即返回，请求甚至可能还没到达接收方，比如说放到了某个缓冲区中，等待对方取走或者第三方转交；而结果，则通过接收方主动推送，或调用方轮询来得到。\n\n从这个定义中，我们看：\n\n- 首先1和7：这取决于软件框架的设计，如果软件框架可以beginXXX，然后立即返回，这就是一种异步调用，再比如javascript当中的异步HTTP调用，传入参数时提供一个回调函数，回调函数在完成时调用，再比如协程模型，调用接口后马上切换到其他协程继续执行，在完成时由框架切换回到协程中，这都是典型的异步接口设计。\n\n- 2和6：其他答主已经说得很好了，其实都需要调用方自己把数据在内核和用户空间里搬来搬去，其实都是同步接口，除非是IOCP这样的专门的异步传输接口，所以这一级其实是同步的，阻塞与非阻塞的区别其实是影响调用接口的结果（在特定条件下是否提前返回结果），而不是调用方式。\n\n- 3和5：内核一般通过缓冲区，使用DMI来传输数据，所以这一步又是异步的。\n\n- 4：以太网是个同步时序逻辑，随信号传输时钟，必须两边设备同时就绪了才能开始传输数据，这又是同步的。\n\n\n\n总结来说，讨论究竟是异步还是同步，一定要严格说明说的是哪一部分。其他答主说非阻塞是同步而不是异步，这毫无疑问是正确的，然而说某个框架是异步IO的框架，这也是正确的，因为说的其实是框架提供给业务代码的接口是异步的，不管是回调还是协程，比如说我们可以说某个库是异步的HTTPClient，并没有什么问题，因为说的是给业务代码的接口。由于通常异步的框架都需要在2中使用非阻塞的接口，的确会有很多人把非阻塞和异步混为一谈。\n\n \n\n编程的时候我们写业务代码，基本就是把IO多路复用（事件注册）认为是异步非阻塞的，虽然在linux接口层次还是同步阻塞的。\n\n\n\n\n\n参考文章：https://www.zhihu.com/question/19732473/answer/117012135","slug":"编程开发/Java/关于阻塞非阻塞，同步异步的最好解释","published":1,"updated":"2022-09-15T03:46:43.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qy0075jqrr9g9ywftv","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>还是不同层次的问题……<br>一个网络包从应用程序A发到另一台电脑上的应用程序B，需要经历：</p>\n<ol>\n<li>从A的业务代码到A的软件框架</li>\n<li>从A的软件框架到计算机的操作系统内核</li>\n<li>从A所在计算机的内核到网卡</li>\n<li>从网卡经过网线发到交换机等设备，层层转发，到达B所在计算机的网卡</li>\n<li>从B所在计算机的网卡到B所在计算机的内核</li>\n<li>从B所在计算机的内核到B的程序的用户空间</li>\n<li>从B的软件框架到B的业务代码</li>\n</ol>\n<p>这个层级关系就像是过程调用一样，前一级调用后一级的功能，后一级返回一个结果给前一级（比如：成功，或者失败）。只有在单独一级的调用上，可以说同步还是异步的问题。所谓同步，是指调用协议中结果在调用完成时返回，这样调用的过程中参与双方都处于一个状态同步的过程。而异步，是指调用方发出请求就立即返回，请求甚至可能还没到达接收方，比如说放到了某个缓冲区中，等待对方取走或者第三方转交；而结果，则通过接收方主动推送，或调用方轮询来得到。</p>\n<p>从这个定义中，我们看：</p>\n<ul>\n<li><p>首先1和7：这取决于软件框架的设计，如果软件框架可以beginXXX，然后立即返回，这就是一种异步调用，再比如javascript当中的异步HTTP调用，传入参数时提供一个回调函数，回调函数在完成时调用，再比如协程模型，调用接口后马上切换到其他协程继续执行，在完成时由框架切换回到协程中，这都是典型的异步接口设计。</p>\n</li>\n<li><p>2和6：其他答主已经说得很好了，其实都需要调用方自己把数据在内核和用户空间里搬来搬去，其实都是同步接口，除非是IOCP这样的专门的异步传输接口，所以这一级其实是同步的，阻塞与非阻塞的区别其实是影响调用接口的结果（在特定条件下是否提前返回结果），而不是调用方式。</p>\n</li>\n<li><p>3和5：内核一般通过缓冲区，使用DMI来传输数据，所以这一步又是异步的。</p>\n</li>\n<li><p>4：以太网是个同步时序逻辑，随信号传输时钟，必须两边设备同时就绪了才能开始传输数据，这又是同步的。</p>\n</li>\n</ul>\n<p>总结来说，讨论究竟是异步还是同步，一定要严格说明说的是哪一部分。其他答主说非阻塞是同步而不是异步，这毫无疑问是正确的，然而说某个框架是异步IO的框架，这也是正确的，因为说的其实是框架提供给业务代码的接口是异步的，不管是回调还是协程，比如说我们可以说某个库是异步的HTTPClient，并没有什么问题，因为说的是给业务代码的接口。由于通常异步的框架都需要在2中使用非阻塞的接口，的确会有很多人把非阻塞和异步混为一谈。</p>\n<p>编程的时候我们写业务代码，基本就是把IO多路复用（事件注册）认为是异步非阻塞的，虽然在linux接口层次还是同步阻塞的。</p>\n<p>参考文章：<a href=\"https://www.zhihu.com/question/19732473/answer/117012135\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/19732473/answer/117012135</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>还是不同层次的问题……<br>一个网络包从应用程序A发到另一台电脑上的应用程序B，需要经历：</p>\n<ol>\n<li>从A的业务代码到A的软件框架</li>\n<li>从A的软件框架到计算机的操作系统内核</li>\n<li>从A所在计算机的内核到网卡</li>\n<li>从网卡经过网线发到交换机等设备，层层转发，到达B所在计算机的网卡</li>\n<li>从B所在计算机的网卡到B所在计算机的内核</li>\n<li>从B所在计算机的内核到B的程序的用户空间</li>\n<li>从B的软件框架到B的业务代码</li>\n</ol>\n<p>这个层级关系就像是过程调用一样，前一级调用后一级的功能，后一级返回一个结果给前一级（比如：成功，或者失败）。只有在单独一级的调用上，可以说同步还是异步的问题。所谓同步，是指调用协议中结果在调用完成时返回，这样调用的过程中参与双方都处于一个状态同步的过程。而异步，是指调用方发出请求就立即返回，请求甚至可能还没到达接收方，比如说放到了某个缓冲区中，等待对方取走或者第三方转交；而结果，则通过接收方主动推送，或调用方轮询来得到。</p>\n<p>从这个定义中，我们看：</p>\n<ul>\n<li><p>首先1和7：这取决于软件框架的设计，如果软件框架可以beginXXX，然后立即返回，这就是一种异步调用，再比如javascript当中的异步HTTP调用，传入参数时提供一个回调函数，回调函数在完成时调用，再比如协程模型，调用接口后马上切换到其他协程继续执行，在完成时由框架切换回到协程中，这都是典型的异步接口设计。</p>\n</li>\n<li><p>2和6：其他答主已经说得很好了，其实都需要调用方自己把数据在内核和用户空间里搬来搬去，其实都是同步接口，除非是IOCP这样的专门的异步传输接口，所以这一级其实是同步的，阻塞与非阻塞的区别其实是影响调用接口的结果（在特定条件下是否提前返回结果），而不是调用方式。</p>\n</li>\n<li><p>3和5：内核一般通过缓冲区，使用DMI来传输数据，所以这一步又是异步的。</p>\n</li>\n<li><p>4：以太网是个同步时序逻辑，随信号传输时钟，必须两边设备同时就绪了才能开始传输数据，这又是同步的。</p>\n</li>\n</ul>\n<p>总结来说，讨论究竟是异步还是同步，一定要严格说明说的是哪一部分。其他答主说非阻塞是同步而不是异步，这毫无疑问是正确的，然而说某个框架是异步IO的框架，这也是正确的，因为说的其实是框架提供给业务代码的接口是异步的，不管是回调还是协程，比如说我们可以说某个库是异步的HTTPClient，并没有什么问题，因为说的是给业务代码的接口。由于通常异步的框架都需要在2中使用非阻塞的接口，的确会有很多人把非阻塞和异步混为一谈。</p>\n<p>编程的时候我们写业务代码，基本就是把IO多路复用（事件注册）认为是异步非阻塞的，虽然在linux接口层次还是同步阻塞的。</p>\n<p>参考文章：<a href=\"https://www.zhihu.com/question/19732473/answer/117012135\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/19732473/answer/117012135</a></p>\n"},{"title":"JAVA堆和栈内存","date":"2020-01-07T10:13:30.000Z","_content":"\n\n\nJava把内存分成两种，一种叫做栈内存，一种叫做堆内存：\n\n- 在函数中定义的**一些基本类型的变量和对象的引用变量都是在函数的栈内存中分配**\n\n- 堆内存用于存放由new创建的对象和数组\n\n \n\n**栈中的变量指向堆内存中的变量，这就是 Java 中的指针!**\n\n","source":"_posts/编程开发/Java/堆和栈内存.md","raw":"---\ntitle: JAVA堆和栈内存\ndate: 2020-01-07 18:13:30\ncategories: [编程开发,Java]\n---\n\n\n\nJava把内存分成两种，一种叫做栈内存，一种叫做堆内存：\n\n- 在函数中定义的**一些基本类型的变量和对象的引用变量都是在函数的栈内存中分配**\n\n- 堆内存用于存放由new创建的对象和数组\n\n \n\n**栈中的变量指向堆内存中的变量，这就是 Java 中的指针!**\n\n","slug":"编程开发/Java/堆和栈内存","published":1,"updated":"2022-09-15T03:46:43.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551qz0077jqrrrtwm1fsw","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>Java把内存分成两种，一种叫做栈内存，一种叫做堆内存：</p>\n<ul>\n<li><p>在函数中定义的<strong>一些基本类型的变量和对象的引用变量都是在函数的栈内存中分配</strong></p>\n</li>\n<li><p>堆内存用于存放由new创建的对象和数组</p>\n</li>\n</ul>\n<p><strong>栈中的变量指向堆内存中的变量，这就是 Java 中的指针!</strong></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Java把内存分成两种，一种叫做栈内存，一种叫做堆内存：</p>\n<ul>\n<li><p>在函数中定义的<strong>一些基本类型的变量和对象的引用变量都是在函数的栈内存中分配</strong></p>\n</li>\n<li><p>堆内存用于存放由new创建的对象和数组</p>\n</li>\n</ul>\n<p><strong>栈中的变量指向堆内存中的变量，这就是 Java 中的指针!</strong></p>\n"},{"title":"序列化与反序列化","date":"2020-03-07T10:13:30.000Z","_content":"\n## 基本概率\n\n为了磁盘or网络传输，序列/反序列化对象的状态(成员变量)，反序列化的其实是一个新的对象。\n\n## java序列化与反序列化\n\n支持序列化和反序列化的基本类型有：String，Array，Enum和Serializable\n\n1. 当父类继承Serializable接口，所有子类都可以被序列化\n2. 子类实现了Serializable接口，父类没有，父类中的属性不能序列化（不报错，数据会丢失），但是子类中属性人能正确序列化\n3. 如果序列化的属性是对象，这个对象也必须实现Serializable接口，否则会报错\n4. 在反序列化时，如果对象的属性有修改或删减，修改的部分属性会丢失，但不会报错\n5. 在反序列化时，如果serialVersionUID被修改，那么反序列化时会失败\n6. List或者Map容器中包含的泛型类型也必须实现Serializable接口，否则也会报java.io.NotSerializableException\n\n参考： \nhttps://blog.csdn.net/moudaen/article/details/19122233 \nhttps://blog.csdn.net/qq_16628781/article/details/70049623\n\n## 序列化/反序列化协议\n\njava序列化为二进制码，python的pickle也是序列化模块，为了能够支持**不同平台、不同语言(前后端)之间**的对象传输，必须有相关的通用协议规范。\n\n相关协议有：protobuf、json、xml、thrift等。现在主流是json、protobuf用的比较多，thrift其实是一个rpc框架，也包括了序列化/反序列化协议。\n\n目前网络传输主流框架：\n\n- Restful框架：用http协议，get/post/put/delte/head，把任何操作都定义成增删改查。序列化/反序列化协议一般是json。主流对公网站一般都是该框架。\n- RPC框架：只给接口，操作更符合我们日常的编程方法or函数，传输吞吐更快，一般对内网站都用该框架。如dubbo,thrift等。","source":"_posts/编程开发/Java/序列化与反序列化.md","raw":"---\ntitle: 序列化与反序列化\ndate: 2020-03-07 18:13:30\ncategories: [编程开发,Java]\n---\n\n## 基本概率\n\n为了磁盘or网络传输，序列/反序列化对象的状态(成员变量)，反序列化的其实是一个新的对象。\n\n## java序列化与反序列化\n\n支持序列化和反序列化的基本类型有：String，Array，Enum和Serializable\n\n1. 当父类继承Serializable接口，所有子类都可以被序列化\n2. 子类实现了Serializable接口，父类没有，父类中的属性不能序列化（不报错，数据会丢失），但是子类中属性人能正确序列化\n3. 如果序列化的属性是对象，这个对象也必须实现Serializable接口，否则会报错\n4. 在反序列化时，如果对象的属性有修改或删减，修改的部分属性会丢失，但不会报错\n5. 在反序列化时，如果serialVersionUID被修改，那么反序列化时会失败\n6. List或者Map容器中包含的泛型类型也必须实现Serializable接口，否则也会报java.io.NotSerializableException\n\n参考： \nhttps://blog.csdn.net/moudaen/article/details/19122233 \nhttps://blog.csdn.net/qq_16628781/article/details/70049623\n\n## 序列化/反序列化协议\n\njava序列化为二进制码，python的pickle也是序列化模块，为了能够支持**不同平台、不同语言(前后端)之间**的对象传输，必须有相关的通用协议规范。\n\n相关协议有：protobuf、json、xml、thrift等。现在主流是json、protobuf用的比较多，thrift其实是一个rpc框架，也包括了序列化/反序列化协议。\n\n目前网络传输主流框架：\n\n- Restful框架：用http协议，get/post/put/delte/head，把任何操作都定义成增删改查。序列化/反序列化协议一般是json。主流对公网站一般都是该框架。\n- RPC框架：只给接口，操作更符合我们日常的编程方法or函数，传输吞吐更快，一般对内网站都用该框架。如dubbo,thrift等。","slug":"编程开发/Java/序列化与反序列化","published":1,"updated":"2022-09-15T03:46:43.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551r0007bjqrrt48j34fy","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"基本概率\"><a href=\"#基本概率\" class=\"headerlink\" title=\"基本概率\"></a>基本概率</h2><p>为了磁盘or网络传输，序列/反序列化对象的状态(成员变量)，反序列化的其实是一个新的对象。</p>\n<h2 id=\"java序列化与反序列化\"><a href=\"#java序列化与反序列化\" class=\"headerlink\" title=\"java序列化与反序列化\"></a>java序列化与反序列化</h2><p>支持序列化和反序列化的基本类型有：String，Array，Enum和Serializable</p>\n<ol>\n<li>当父类继承Serializable接口，所有子类都可以被序列化</li>\n<li>子类实现了Serializable接口，父类没有，父类中的属性不能序列化（不报错，数据会丢失），但是子类中属性人能正确序列化</li>\n<li>如果序列化的属性是对象，这个对象也必须实现Serializable接口，否则会报错</li>\n<li>在反序列化时，如果对象的属性有修改或删减，修改的部分属性会丢失，但不会报错</li>\n<li>在反序列化时，如果serialVersionUID被修改，那么反序列化时会失败</li>\n<li>List或者Map容器中包含的泛型类型也必须实现Serializable接口，否则也会报java.io.NotSerializableException</li>\n</ol>\n<p>参考：<br><a href=\"https://blog.csdn.net/moudaen/article/details/19122233\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/moudaen/article/details/19122233</a><br><a href=\"https://blog.csdn.net/qq_16628781/article/details/70049623\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_16628781/article/details/70049623</a></p>\n<h2 id=\"序列化-反序列化协议\"><a href=\"#序列化-反序列化协议\" class=\"headerlink\" title=\"序列化/反序列化协议\"></a>序列化/反序列化协议</h2><p>java序列化为二进制码，python的pickle也是序列化模块，为了能够支持<strong>不同平台、不同语言(前后端)之间</strong>的对象传输，必须有相关的通用协议规范。</p>\n<p>相关协议有：protobuf、json、xml、thrift等。现在主流是json、protobuf用的比较多，thrift其实是一个rpc框架，也包括了序列化/反序列化协议。</p>\n<p>目前网络传输主流框架：</p>\n<ul>\n<li>Restful框架：用http协议，get/post/put/delte/head，把任何操作都定义成增删改查。序列化/反序列化协议一般是json。主流对公网站一般都是该框架。</li>\n<li>RPC框架：只给接口，操作更符合我们日常的编程方法or函数，传输吞吐更快，一般对内网站都用该框架。如dubbo,thrift等。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"基本概率\"><a href=\"#基本概率\" class=\"headerlink\" title=\"基本概率\"></a>基本概率</h2><p>为了磁盘or网络传输，序列/反序列化对象的状态(成员变量)，反序列化的其实是一个新的对象。</p>\n<h2 id=\"java序列化与反序列化\"><a href=\"#java序列化与反序列化\" class=\"headerlink\" title=\"java序列化与反序列化\"></a>java序列化与反序列化</h2><p>支持序列化和反序列化的基本类型有：String，Array，Enum和Serializable</p>\n<ol>\n<li>当父类继承Serializable接口，所有子类都可以被序列化</li>\n<li>子类实现了Serializable接口，父类没有，父类中的属性不能序列化（不报错，数据会丢失），但是子类中属性人能正确序列化</li>\n<li>如果序列化的属性是对象，这个对象也必须实现Serializable接口，否则会报错</li>\n<li>在反序列化时，如果对象的属性有修改或删减，修改的部分属性会丢失，但不会报错</li>\n<li>在反序列化时，如果serialVersionUID被修改，那么反序列化时会失败</li>\n<li>List或者Map容器中包含的泛型类型也必须实现Serializable接口，否则也会报java.io.NotSerializableException</li>\n</ol>\n<p>参考：<br><a href=\"https://blog.csdn.net/moudaen/article/details/19122233\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/moudaen/article/details/19122233</a><br><a href=\"https://blog.csdn.net/qq_16628781/article/details/70049623\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_16628781/article/details/70049623</a></p>\n<h2 id=\"序列化-反序列化协议\"><a href=\"#序列化-反序列化协议\" class=\"headerlink\" title=\"序列化/反序列化协议\"></a>序列化/反序列化协议</h2><p>java序列化为二进制码，python的pickle也是序列化模块，为了能够支持<strong>不同平台、不同语言(前后端)之间</strong>的对象传输，必须有相关的通用协议规范。</p>\n<p>相关协议有：protobuf、json、xml、thrift等。现在主流是json、protobuf用的比较多，thrift其实是一个rpc框架，也包括了序列化/反序列化协议。</p>\n<p>目前网络传输主流框架：</p>\n<ul>\n<li>Restful框架：用http协议，get/post/put/delte/head，把任何操作都定义成增删改查。序列化/反序列化协议一般是json。主流对公网站一般都是该框架。</li>\n<li>RPC框架：只给接口，操作更符合我们日常的编程方法or函数，传输吞吐更快，一般对内网站都用该框架。如dubbo,thrift等。</li>\n</ul>\n"},{"title":"JAVA异常处理","date":"2020-05-08T10:13:30.000Z","_content":"\n## 两种异常类型\n- 受检异常：例如IOException，编译器会进行检测，必须捕获或者duck处理，一般是外部因素造成的\n\n- 非受检异常：RuntimeException及其子类，不要求捕获或者抛出处理，编译器不检测，一般是程序员逻辑漏洞造成的。这个也是我们平时写代码时要注意的异常处理。声明/不声明都无所谓，运行的时候如果出错，异常就会出现。\n\n\n单线程main这种，如果异常抛出，程序中断。\n\n像web容器这种，出现runtime异常，该线程中断，容器会重新启一个线程，所以其实不影响。","source":"_posts/编程开发/Java/异常处理.md","raw":"---\ntitle: JAVA异常处理\ndate: 2020-05-08 18:13:30\ncategories: [编程开发,Java]\n---\n\n## 两种异常类型\n- 受检异常：例如IOException，编译器会进行检测，必须捕获或者duck处理，一般是外部因素造成的\n\n- 非受检异常：RuntimeException及其子类，不要求捕获或者抛出处理，编译器不检测，一般是程序员逻辑漏洞造成的。这个也是我们平时写代码时要注意的异常处理。声明/不声明都无所谓，运行的时候如果出错，异常就会出现。\n\n\n单线程main这种，如果异常抛出，程序中断。\n\n像web容器这种，出现runtime异常，该线程中断，容器会重新启一个线程，所以其实不影响。","slug":"编程开发/Java/异常处理","published":1,"updated":"2022-09-15T03:46:43.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551r0007djqrrweorslnj","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"两种异常类型\"><a href=\"#两种异常类型\" class=\"headerlink\" title=\"两种异常类型\"></a>两种异常类型</h2><ul>\n<li><p>受检异常：例如IOException，编译器会进行检测，必须捕获或者duck处理，一般是外部因素造成的</p>\n</li>\n<li><p>非受检异常：RuntimeException及其子类，不要求捕获或者抛出处理，编译器不检测，一般是程序员逻辑漏洞造成的。这个也是我们平时写代码时要注意的异常处理。声明/不声明都无所谓，运行的时候如果出错，异常就会出现。</p>\n</li>\n</ul>\n<p>单线程main这种，如果异常抛出，程序中断。</p>\n<p>像web容器这种，出现runtime异常，该线程中断，容器会重新启一个线程，所以其实不影响。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"两种异常类型\"><a href=\"#两种异常类型\" class=\"headerlink\" title=\"两种异常类型\"></a>两种异常类型</h2><ul>\n<li><p>受检异常：例如IOException，编译器会进行检测，必须捕获或者duck处理，一般是外部因素造成的</p>\n</li>\n<li><p>非受检异常：RuntimeException及其子类，不要求捕获或者抛出处理，编译器不检测，一般是程序员逻辑漏洞造成的。这个也是我们平时写代码时要注意的异常处理。声明/不声明都无所谓，运行的时候如果出错，异常就会出现。</p>\n</li>\n</ul>\n<p>单线程main这种，如果异常抛出，程序中断。</p>\n<p>像web容器这种，出现runtime异常，该线程中断，容器会重新启一个线程，所以其实不影响。</p>\n"},{"title":"输入输出流相关类","date":"2020-03-14T10:13:30.000Z","_content":"\n## 字节流-byte\n\n基类：InputStream/OutputStream\n\n以输入为例： \n-System.in: read(), 一个一个字节从控制台读取，因为只有一个字节，所以中文字符读取不了(UTF-16是2个字节)。 \n\\- FileInputStream：read(), 一个一个字节从磁盘读取 \n\\- BufferedInputStream:read(), 虽然也是一个一个字节读取，但是是从缓存里读，减少了IO次数，效率更高，所以一般都用这个类包一层 \n\\- DataInputStream:readInt(), readDouble()等，直接写入各种数据类型，底层也是通过字节传输。要与DataOutputStream配合使用。 \n\\- ObjectInputStream: readObject(),直接写入对象，同理。\n\n## 字符流-char\n\n基类：Reader/Writer\n\n以输入为例： \n\\- InputStreamReader: read(),一个一个字符读取 \n\\- FileReader：read(), 一个一个字符从磁盘读取 \n\\- BufferedReader:readLine(), 直接读取一行字符，从缓存里读减少了IO次数，效率更高，所以一般都用这个类包一层 \n\\- 没有DataInputStreamReader，因为数据本身就是若干个字符了 \n\\- 没有ObjectInputStreamReader，同理\n\n## 常用场景\n\n- 网络一般要靠字节传输，但是数据往往通过字符承载。所以要将字节流转成字符流。\n\n```\nBufferedReader(new InputStreamReader(new InputStream(...)))\n```\n\n- 直接传数据： \n  `DataInputStream(new BufferedInputStream(new InputStream(...)))`\n- 直接传对象： \n  `ObjectInputStream(new BufferedInputStream(new InputStream(...)))`","source":"_posts/编程开发/Java/输入输出流相关类.md","raw":"---\ntitle: 输入输出流相关类\ndate: 2020-03-14 18:13:30\ncategories: [编程开发,Java]\n---\n\n## 字节流-byte\n\n基类：InputStream/OutputStream\n\n以输入为例： \n-System.in: read(), 一个一个字节从控制台读取，因为只有一个字节，所以中文字符读取不了(UTF-16是2个字节)。 \n\\- FileInputStream：read(), 一个一个字节从磁盘读取 \n\\- BufferedInputStream:read(), 虽然也是一个一个字节读取，但是是从缓存里读，减少了IO次数，效率更高，所以一般都用这个类包一层 \n\\- DataInputStream:readInt(), readDouble()等，直接写入各种数据类型，底层也是通过字节传输。要与DataOutputStream配合使用。 \n\\- ObjectInputStream: readObject(),直接写入对象，同理。\n\n## 字符流-char\n\n基类：Reader/Writer\n\n以输入为例： \n\\- InputStreamReader: read(),一个一个字符读取 \n\\- FileReader：read(), 一个一个字符从磁盘读取 \n\\- BufferedReader:readLine(), 直接读取一行字符，从缓存里读减少了IO次数，效率更高，所以一般都用这个类包一层 \n\\- 没有DataInputStreamReader，因为数据本身就是若干个字符了 \n\\- 没有ObjectInputStreamReader，同理\n\n## 常用场景\n\n- 网络一般要靠字节传输，但是数据往往通过字符承载。所以要将字节流转成字符流。\n\n```\nBufferedReader(new InputStreamReader(new InputStream(...)))\n```\n\n- 直接传数据： \n  `DataInputStream(new BufferedInputStream(new InputStream(...)))`\n- 直接传对象： \n  `ObjectInputStream(new BufferedInputStream(new InputStream(...)))`","slug":"编程开发/Java/输入输出流相关类","published":1,"updated":"2022-09-15T03:46:43.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551r1007gjqrrxpgibgue","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"字节流-byte\"><a href=\"#字节流-byte\" class=\"headerlink\" title=\"字节流-byte\"></a>字节流-byte</h2><p>基类：InputStream/OutputStream</p>\n<p>以输入为例：<br>-System.in: read(), 一个一个字节从控制台读取，因为只有一个字节，所以中文字符读取不了(UTF-16是2个字节)。<br>- FileInputStream：read(), 一个一个字节从磁盘读取<br>- BufferedInputStream:read(), 虽然也是一个一个字节读取，但是是从缓存里读，减少了IO次数，效率更高，所以一般都用这个类包一层<br>- DataInputStream:readInt(), readDouble()等，直接写入各种数据类型，底层也是通过字节传输。要与DataOutputStream配合使用。<br>- ObjectInputStream: readObject(),直接写入对象，同理。</p>\n<h2 id=\"字符流-char\"><a href=\"#字符流-char\" class=\"headerlink\" title=\"字符流-char\"></a>字符流-char</h2><p>基类：Reader/Writer</p>\n<p>以输入为例：<br>- InputStreamReader: read(),一个一个字符读取<br>- FileReader：read(), 一个一个字符从磁盘读取<br>- BufferedReader:readLine(), 直接读取一行字符，从缓存里读减少了IO次数，效率更高，所以一般都用这个类包一层<br>- 没有DataInputStreamReader，因为数据本身就是若干个字符了<br>- 没有ObjectInputStreamReader，同理</p>\n<h2 id=\"常用场景\"><a href=\"#常用场景\" class=\"headerlink\" title=\"常用场景\"></a>常用场景</h2><ul>\n<li>网络一般要靠字节传输，但是数据往往通过字符承载。所以要将字节流转成字符流。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BufferedReader(new InputStreamReader(new InputStream(...)))</span><br></pre></td></tr></table></figure>\n<ul>\n<li>直接传数据：<br><code>DataInputStream(new BufferedInputStream(new InputStream(...)))</code></li>\n<li>直接传对象：<br><code>ObjectInputStream(new BufferedInputStream(new InputStream(...)))</code></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"字节流-byte\"><a href=\"#字节流-byte\" class=\"headerlink\" title=\"字节流-byte\"></a>字节流-byte</h2><p>基类：InputStream/OutputStream</p>\n<p>以输入为例：<br>-System.in: read(), 一个一个字节从控制台读取，因为只有一个字节，所以中文字符读取不了(UTF-16是2个字节)。<br>- FileInputStream：read(), 一个一个字节从磁盘读取<br>- BufferedInputStream:read(), 虽然也是一个一个字节读取，但是是从缓存里读，减少了IO次数，效率更高，所以一般都用这个类包一层<br>- DataInputStream:readInt(), readDouble()等，直接写入各种数据类型，底层也是通过字节传输。要与DataOutputStream配合使用。<br>- ObjectInputStream: readObject(),直接写入对象，同理。</p>\n<h2 id=\"字符流-char\"><a href=\"#字符流-char\" class=\"headerlink\" title=\"字符流-char\"></a>字符流-char</h2><p>基类：Reader/Writer</p>\n<p>以输入为例：<br>- InputStreamReader: read(),一个一个字符读取<br>- FileReader：read(), 一个一个字符从磁盘读取<br>- BufferedReader:readLine(), 直接读取一行字符，从缓存里读减少了IO次数，效率更高，所以一般都用这个类包一层<br>- 没有DataInputStreamReader，因为数据本身就是若干个字符了<br>- 没有ObjectInputStreamReader，同理</p>\n<h2 id=\"常用场景\"><a href=\"#常用场景\" class=\"headerlink\" title=\"常用场景\"></a>常用场景</h2><ul>\n<li>网络一般要靠字节传输，但是数据往往通过字符承载。所以要将字节流转成字符流。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BufferedReader(new InputStreamReader(new InputStream(...)))</span><br></pre></td></tr></table></figure>\n<ul>\n<li>直接传数据：<br><code>DataInputStream(new BufferedInputStream(new InputStream(...)))</code></li>\n<li>直接传对象：<br><code>ObjectInputStream(new BufferedInputStream(new InputStream(...)))</code></li>\n</ul>\n"},{"title":"Texlive和Ctex的中文兼容问题","date":"2017-07-07T08:43:27.000Z","_content":"\n因为用的Ubuntu，所以用的是texlive编译环境来写latex,当然我也用过ctex套装。总体来讲，感觉编译速度texlive要更胜一筹，用起来更加舒服。\n\n今早师妹找我要beamer的模板，因为师妹用的是windows系统下的ctex，所以就发现了一个以前没弄清楚的问题，关于ctex和texlive的兼容问题。\n\n\n# 概念区别\n说兼容问题之前，关于ctex和texlive有一些基本概念要搞清楚（我之前也弄混了。。）\n<!-- more -->\n- Texlive是一个latex语言的编译环境， Ctex只是一个中文版套装！\n- Latex的编译环境主要有以下几个：\n    - Texlive(主要用于Linux)\n    - MikTex(主要用于Windows)\n    - MaxTex(主要用于Mac)\n- Ctex是专门针对中文的国人整理的一个套装，用的是MikTex的编译环境，还包含了WinEdt编辑器，GsView等软件。\n- Ctex package又是另一个概念！在我们需要写中文latex文档时，就需要用到ctex这个宏包，所以此ctex又非彼ctex。。\n\n# 英文兼容\nTexlive和ctex在英文上面，没有任何的兼容问题。我以前在这两种环境下切换时，都是写的英文文档，这就是为什么我之前一直觉得没有兼容问题，天真地以为两者虽然环境不同，但latex,pdflatex,xelatex等等命令功能都是一样的。。但事实上，之所以英文没有兼容问题，是因为无论那种编码方式，英文都是以一个字节的ASCII码形式编码，因此在任何编码中，英文都是兼容的。\n\n# 中文兼容\n中文兼容就是一个很大的问题了，因为在ctex的winedt编辑器中，默认的编码方式是GBK，而在linux环境下，默认的编码方式是utf-8，这就是为什么很多时候，linux下的文件放到windows下中文就会乱码。\n\n对于编辑器而言，我们可以设置不同的编码打开方式，让文件正常显示，但是尽管如此，文件本身的编码方式依然是不会改变的！所以最好的方法，就是在哪种环境下，就转换为哪种环境下的编码方式，以防止后面莫名奇妙地出错。注意，这里就要提到一个叫做inputenc的包了, 这个包可以让我们选择打开文件的编码方式，但是我对于gbk编码的文件选择utf-8打开，最终还是会出现问题。。所以我觉得这个包应该也是没有编码转换的功能，还是之前那个方法，最好先将文件编码转换好！\n\n既然文件编码已经转换好，接下来说一说，ctex和texlive对中文支持的区别\n\n## Texlive中文支持\nTexlive下要支持中文，最简单的方法就是满足下面三个条件\n- UTF-8编码的tex文件\n- `\\usepackage{ctex}`\n- Xelatex编译文件\n\n简单明了，这也是一个通用的方法，在任何编译环境下，都可以使用此方法支持中文。注意，有的时候在用这个方法编译从ctex那边移植过来的文件时，可能会遇到中文字体问题，大概率是因为模板里用了windows下的字体，而linux下没有这些字体，需要安装。\n\n## Ctex中文支持\n除了上面所述的方法，ctex有自己独特的中文支持方法（毕竟国人开发）：\n- GBK编码的tex文件\n- `\\usepackage{ctex}`\n- latex-dvi-ps-pdf或者pdflatex编译文件\n\n这个方法也挺简单的，但是只能针对于ctex,我觉得其中的原理应该是ctex对于pdflatex和latex命令做了一些调整，使其能够支持中文，我觉得他们本身应该是不能支持中文的。\n\n**切记，这两种方式最好不要随意搭配，搭配后可能会成功，但大概率是要出问题的。。我觉得最好的办法就是采用xelatex编辑utf-8文件！**\n\n\n\n# 总结\n以上这些是我经过查阅资料以及在windows和ubuntu下试验总体得到的，具体一些理解可能会有偏差，但以上几个方法是肯定正确的。\n\n最后加一个小tips：\n如果要改变beamer模板中的itemsize符号，需要加`\\setbeamertemplate{items}[符号]`;若是article环境，需加`\\renewcommand{\\labelitemi}{符号}`。\n","source":"_posts/编程开发/Latex/some-questions-about-ctex-and-texlive.md","raw":"---\ntitle: Texlive和Ctex的中文兼容问题\ndate: 2017-07-07 16:43:27\ncategories: [编程开发,Latex]\n---\n\n因为用的Ubuntu，所以用的是texlive编译环境来写latex,当然我也用过ctex套装。总体来讲，感觉编译速度texlive要更胜一筹，用起来更加舒服。\n\n今早师妹找我要beamer的模板，因为师妹用的是windows系统下的ctex，所以就发现了一个以前没弄清楚的问题，关于ctex和texlive的兼容问题。\n\n\n# 概念区别\n说兼容问题之前，关于ctex和texlive有一些基本概念要搞清楚（我之前也弄混了。。）\n<!-- more -->\n- Texlive是一个latex语言的编译环境， Ctex只是一个中文版套装！\n- Latex的编译环境主要有以下几个：\n    - Texlive(主要用于Linux)\n    - MikTex(主要用于Windows)\n    - MaxTex(主要用于Mac)\n- Ctex是专门针对中文的国人整理的一个套装，用的是MikTex的编译环境，还包含了WinEdt编辑器，GsView等软件。\n- Ctex package又是另一个概念！在我们需要写中文latex文档时，就需要用到ctex这个宏包，所以此ctex又非彼ctex。。\n\n# 英文兼容\nTexlive和ctex在英文上面，没有任何的兼容问题。我以前在这两种环境下切换时，都是写的英文文档，这就是为什么我之前一直觉得没有兼容问题，天真地以为两者虽然环境不同，但latex,pdflatex,xelatex等等命令功能都是一样的。。但事实上，之所以英文没有兼容问题，是因为无论那种编码方式，英文都是以一个字节的ASCII码形式编码，因此在任何编码中，英文都是兼容的。\n\n# 中文兼容\n中文兼容就是一个很大的问题了，因为在ctex的winedt编辑器中，默认的编码方式是GBK，而在linux环境下，默认的编码方式是utf-8，这就是为什么很多时候，linux下的文件放到windows下中文就会乱码。\n\n对于编辑器而言，我们可以设置不同的编码打开方式，让文件正常显示，但是尽管如此，文件本身的编码方式依然是不会改变的！所以最好的方法，就是在哪种环境下，就转换为哪种环境下的编码方式，以防止后面莫名奇妙地出错。注意，这里就要提到一个叫做inputenc的包了, 这个包可以让我们选择打开文件的编码方式，但是我对于gbk编码的文件选择utf-8打开，最终还是会出现问题。。所以我觉得这个包应该也是没有编码转换的功能，还是之前那个方法，最好先将文件编码转换好！\n\n既然文件编码已经转换好，接下来说一说，ctex和texlive对中文支持的区别\n\n## Texlive中文支持\nTexlive下要支持中文，最简单的方法就是满足下面三个条件\n- UTF-8编码的tex文件\n- `\\usepackage{ctex}`\n- Xelatex编译文件\n\n简单明了，这也是一个通用的方法，在任何编译环境下，都可以使用此方法支持中文。注意，有的时候在用这个方法编译从ctex那边移植过来的文件时，可能会遇到中文字体问题，大概率是因为模板里用了windows下的字体，而linux下没有这些字体，需要安装。\n\n## Ctex中文支持\n除了上面所述的方法，ctex有自己独特的中文支持方法（毕竟国人开发）：\n- GBK编码的tex文件\n- `\\usepackage{ctex}`\n- latex-dvi-ps-pdf或者pdflatex编译文件\n\n这个方法也挺简单的，但是只能针对于ctex,我觉得其中的原理应该是ctex对于pdflatex和latex命令做了一些调整，使其能够支持中文，我觉得他们本身应该是不能支持中文的。\n\n**切记，这两种方式最好不要随意搭配，搭配后可能会成功，但大概率是要出问题的。。我觉得最好的办法就是采用xelatex编辑utf-8文件！**\n\n\n\n# 总结\n以上这些是我经过查阅资料以及在windows和ubuntu下试验总体得到的，具体一些理解可能会有偏差，但以上几个方法是肯定正确的。\n\n最后加一个小tips：\n如果要改变beamer模板中的itemsize符号，需要加`\\setbeamertemplate{items}[符号]`;若是article环境，需加`\\renewcommand{\\labelitemi}{符号}`。\n","slug":"编程开发/Latex/some-questions-about-ctex-and-texlive","published":1,"updated":"2022-09-15T03:46:43.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551r3007ijqrr3og07txs","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>因为用的Ubuntu，所以用的是texlive编译环境来写latex,当然我也用过ctex套装。总体来讲，感觉编译速度texlive要更胜一筹，用起来更加舒服。</p>\n<p>今早师妹找我要beamer的模板，因为师妹用的是windows系统下的ctex，所以就发现了一个以前没弄清楚的问题，关于ctex和texlive的兼容问题。</p>\n<h1 id=\"概念区别\"><a href=\"#概念区别\" class=\"headerlink\" title=\"概念区别\"></a>概念区别</h1><p>说兼容问题之前，关于ctex和texlive有一些基本概念要搞清楚（我之前也弄混了。。）<br><a id=\"more\"></a></p>\n<ul>\n<li>Texlive是一个latex语言的编译环境， Ctex只是一个中文版套装！</li>\n<li>Latex的编译环境主要有以下几个：<ul>\n<li>Texlive(主要用于Linux)</li>\n<li>MikTex(主要用于Windows)</li>\n<li>MaxTex(主要用于Mac)</li>\n</ul>\n</li>\n<li>Ctex是专门针对中文的国人整理的一个套装，用的是MikTex的编译环境，还包含了WinEdt编辑器，GsView等软件。</li>\n<li>Ctex package又是另一个概念！在我们需要写中文latex文档时，就需要用到ctex这个宏包，所以此ctex又非彼ctex。。</li>\n</ul>\n<h1 id=\"英文兼容\"><a href=\"#英文兼容\" class=\"headerlink\" title=\"英文兼容\"></a>英文兼容</h1><p>Texlive和ctex在英文上面，没有任何的兼容问题。我以前在这两种环境下切换时，都是写的英文文档，这就是为什么我之前一直觉得没有兼容问题，天真地以为两者虽然环境不同，但latex,pdflatex,xelatex等等命令功能都是一样的。。但事实上，之所以英文没有兼容问题，是因为无论那种编码方式，英文都是以一个字节的ASCII码形式编码，因此在任何编码中，英文都是兼容的。</p>\n<h1 id=\"中文兼容\"><a href=\"#中文兼容\" class=\"headerlink\" title=\"中文兼容\"></a>中文兼容</h1><p>中文兼容就是一个很大的问题了，因为在ctex的winedt编辑器中，默认的编码方式是GBK，而在linux环境下，默认的编码方式是utf-8，这就是为什么很多时候，linux下的文件放到windows下中文就会乱码。</p>\n<p>对于编辑器而言，我们可以设置不同的编码打开方式，让文件正常显示，但是尽管如此，文件本身的编码方式依然是不会改变的！所以最好的方法，就是在哪种环境下，就转换为哪种环境下的编码方式，以防止后面莫名奇妙地出错。注意，这里就要提到一个叫做inputenc的包了, 这个包可以让我们选择打开文件的编码方式，但是我对于gbk编码的文件选择utf-8打开，最终还是会出现问题。。所以我觉得这个包应该也是没有编码转换的功能，还是之前那个方法，最好先将文件编码转换好！</p>\n<p>既然文件编码已经转换好，接下来说一说，ctex和texlive对中文支持的区别</p>\n<h2 id=\"Texlive中文支持\"><a href=\"#Texlive中文支持\" class=\"headerlink\" title=\"Texlive中文支持\"></a>Texlive中文支持</h2><p>Texlive下要支持中文，最简单的方法就是满足下面三个条件</p>\n<ul>\n<li>UTF-8编码的tex文件</li>\n<li><code>\\usepackage{ctex}</code></li>\n<li>Xelatex编译文件</li>\n</ul>\n<p>简单明了，这也是一个通用的方法，在任何编译环境下，都可以使用此方法支持中文。注意，有的时候在用这个方法编译从ctex那边移植过来的文件时，可能会遇到中文字体问题，大概率是因为模板里用了windows下的字体，而linux下没有这些字体，需要安装。</p>\n<h2 id=\"Ctex中文支持\"><a href=\"#Ctex中文支持\" class=\"headerlink\" title=\"Ctex中文支持\"></a>Ctex中文支持</h2><p>除了上面所述的方法，ctex有自己独特的中文支持方法（毕竟国人开发）：</p>\n<ul>\n<li>GBK编码的tex文件</li>\n<li><code>\\usepackage{ctex}</code></li>\n<li>latex-dvi-ps-pdf或者pdflatex编译文件</li>\n</ul>\n<p>这个方法也挺简单的，但是只能针对于ctex,我觉得其中的原理应该是ctex对于pdflatex和latex命令做了一些调整，使其能够支持中文，我觉得他们本身应该是不能支持中文的。</p>\n<p><strong>切记，这两种方式最好不要随意搭配，搭配后可能会成功，但大概率是要出问题的。。我觉得最好的办法就是采用xelatex编辑utf-8文件！</strong></p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>以上这些是我经过查阅资料以及在windows和ubuntu下试验总体得到的，具体一些理解可能会有偏差，但以上几个方法是肯定正确的。</p>\n<p>最后加一个小tips：<br>如果要改变beamer模板中的itemsize符号，需要加<code>\\setbeamertemplate{items}[符号]</code>;若是article环境，需加<code>\\renewcommand{\\labelitemi}{符号}</code>。</p>\n","site":{"data":{}},"excerpt":"<p>因为用的Ubuntu，所以用的是texlive编译环境来写latex,当然我也用过ctex套装。总体来讲，感觉编译速度texlive要更胜一筹，用起来更加舒服。</p>\n<p>今早师妹找我要beamer的模板，因为师妹用的是windows系统下的ctex，所以就发现了一个以前没弄清楚的问题，关于ctex和texlive的兼容问题。</p>\n<h1 id=\"概念区别\"><a href=\"#概念区别\" class=\"headerlink\" title=\"概念区别\"></a>概念区别</h1><p>说兼容问题之前，关于ctex和texlive有一些基本概念要搞清楚（我之前也弄混了。。）<br>","more":"</p>\n<ul>\n<li>Texlive是一个latex语言的编译环境， Ctex只是一个中文版套装！</li>\n<li>Latex的编译环境主要有以下几个：<ul>\n<li>Texlive(主要用于Linux)</li>\n<li>MikTex(主要用于Windows)</li>\n<li>MaxTex(主要用于Mac)</li>\n</ul>\n</li>\n<li>Ctex是专门针对中文的国人整理的一个套装，用的是MikTex的编译环境，还包含了WinEdt编辑器，GsView等软件。</li>\n<li>Ctex package又是另一个概念！在我们需要写中文latex文档时，就需要用到ctex这个宏包，所以此ctex又非彼ctex。。</li>\n</ul>\n<h1 id=\"英文兼容\"><a href=\"#英文兼容\" class=\"headerlink\" title=\"英文兼容\"></a>英文兼容</h1><p>Texlive和ctex在英文上面，没有任何的兼容问题。我以前在这两种环境下切换时，都是写的英文文档，这就是为什么我之前一直觉得没有兼容问题，天真地以为两者虽然环境不同，但latex,pdflatex,xelatex等等命令功能都是一样的。。但事实上，之所以英文没有兼容问题，是因为无论那种编码方式，英文都是以一个字节的ASCII码形式编码，因此在任何编码中，英文都是兼容的。</p>\n<h1 id=\"中文兼容\"><a href=\"#中文兼容\" class=\"headerlink\" title=\"中文兼容\"></a>中文兼容</h1><p>中文兼容就是一个很大的问题了，因为在ctex的winedt编辑器中，默认的编码方式是GBK，而在linux环境下，默认的编码方式是utf-8，这就是为什么很多时候，linux下的文件放到windows下中文就会乱码。</p>\n<p>对于编辑器而言，我们可以设置不同的编码打开方式，让文件正常显示，但是尽管如此，文件本身的编码方式依然是不会改变的！所以最好的方法，就是在哪种环境下，就转换为哪种环境下的编码方式，以防止后面莫名奇妙地出错。注意，这里就要提到一个叫做inputenc的包了, 这个包可以让我们选择打开文件的编码方式，但是我对于gbk编码的文件选择utf-8打开，最终还是会出现问题。。所以我觉得这个包应该也是没有编码转换的功能，还是之前那个方法，最好先将文件编码转换好！</p>\n<p>既然文件编码已经转换好，接下来说一说，ctex和texlive对中文支持的区别</p>\n<h2 id=\"Texlive中文支持\"><a href=\"#Texlive中文支持\" class=\"headerlink\" title=\"Texlive中文支持\"></a>Texlive中文支持</h2><p>Texlive下要支持中文，最简单的方法就是满足下面三个条件</p>\n<ul>\n<li>UTF-8编码的tex文件</li>\n<li><code>\\usepackage{ctex}</code></li>\n<li>Xelatex编译文件</li>\n</ul>\n<p>简单明了，这也是一个通用的方法，在任何编译环境下，都可以使用此方法支持中文。注意，有的时候在用这个方法编译从ctex那边移植过来的文件时，可能会遇到中文字体问题，大概率是因为模板里用了windows下的字体，而linux下没有这些字体，需要安装。</p>\n<h2 id=\"Ctex中文支持\"><a href=\"#Ctex中文支持\" class=\"headerlink\" title=\"Ctex中文支持\"></a>Ctex中文支持</h2><p>除了上面所述的方法，ctex有自己独特的中文支持方法（毕竟国人开发）：</p>\n<ul>\n<li>GBK编码的tex文件</li>\n<li><code>\\usepackage{ctex}</code></li>\n<li>latex-dvi-ps-pdf或者pdflatex编译文件</li>\n</ul>\n<p>这个方法也挺简单的，但是只能针对于ctex,我觉得其中的原理应该是ctex对于pdflatex和latex命令做了一些调整，使其能够支持中文，我觉得他们本身应该是不能支持中文的。</p>\n<p><strong>切记，这两种方式最好不要随意搭配，搭配后可能会成功，但大概率是要出问题的。。我觉得最好的办法就是采用xelatex编辑utf-8文件！</strong></p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>以上这些是我经过查阅资料以及在windows和ubuntu下试验总体得到的，具体一些理解可能会有偏差，但以上几个方法是肯定正确的。</p>\n<p>最后加一个小tips：<br>如果要改变beamer模板中的itemsize符号，需要加<code>\\setbeamertemplate{items}[符号]</code>;若是article环境，需加<code>\\renewcommand{\\labelitemi}{符号}</code>。</p>"},{"title":"import及__init__.py","date":"2019-03-07T14:06:02.000Z","_content":"\n\n\n## import注意事项:\n\n```python\nfrom package1 import module1\nfrom package1.module2 import function1\nfrom package2 import class1\nfrom package2.subpackage1.module5 import function2\n```\n\n注意，module.function这种形式是不行的，用.前面只能是package\n\n\n\n\n\n## __init__.py注意事项:\n\n- 放在package目录下\n\n- 可以没有，这种情况下一定要手动 from package import module\n\n- 如果有，import package的时候，会自动加载该文件的内容，其中用法有包括:\n\n  ```python\n  __all__ = ['foofactories', 'tallFoos', 'shortfoos', 'medumfoos',\n             'santaslittlehelperfoo', 'superawsomefoo', 'anotherfoo']\n  # deprecated to keep older scripts who import this from breaking\n  from foo.foofactories import fooFactory\n  from foo.tallfoos import tallFoo\n  from foo.shortfoos import shortFoo\n  ```\n\n  从而达到 from package import function的目的\n\n","source":"_posts/编程开发/Python/import及__init__.py.md","raw":"---\ntitle: import及__init__.py\ndate: 2019-03-07 22:06:02\ncategories: [编程开发,Python]\n---\n\n\n\n## import注意事项:\n\n```python\nfrom package1 import module1\nfrom package1.module2 import function1\nfrom package2 import class1\nfrom package2.subpackage1.module5 import function2\n```\n\n注意，module.function这种形式是不行的，用.前面只能是package\n\n\n\n\n\n## __init__.py注意事项:\n\n- 放在package目录下\n\n- 可以没有，这种情况下一定要手动 from package import module\n\n- 如果有，import package的时候，会自动加载该文件的内容，其中用法有包括:\n\n  ```python\n  __all__ = ['foofactories', 'tallFoos', 'shortfoos', 'medumfoos',\n             'santaslittlehelperfoo', 'superawsomefoo', 'anotherfoo']\n  # deprecated to keep older scripts who import this from breaking\n  from foo.foofactories import fooFactory\n  from foo.tallfoos import tallFoo\n  from foo.shortfoos import shortFoo\n  ```\n\n  从而达到 from package import function的目的\n\n","slug":"编程开发/Python/import及__init__.py","published":1,"updated":"2022-09-15T03:46:43.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551r5007ljqrr34t4xrp8","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"import注意事项\"><a href=\"#import注意事项\" class=\"headerlink\" title=\"import注意事项:\"></a>import注意事项:</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> package1 <span class=\"keyword\">import</span> module1</span><br><span class=\"line\"><span class=\"keyword\">from</span> package1.module2 <span class=\"keyword\">import</span> function1</span><br><span class=\"line\"><span class=\"keyword\">from</span> package2 <span class=\"keyword\">import</span> class1</span><br><span class=\"line\"><span class=\"keyword\">from</span> package2.subpackage1.module5 <span class=\"keyword\">import</span> function2</span><br></pre></td></tr></table></figure>\n<p>注意，module.function这种形式是不行的，用.前面只能是package</p>\n<h2 id=\"init-py注意事项\"><a href=\"#init-py注意事项\" class=\"headerlink\" title=\"init.py注意事项:\"></a><strong>init</strong>.py注意事项:</h2><ul>\n<li><p>放在package目录下</p>\n</li>\n<li><p>可以没有，这种情况下一定要手动 from package import module</p>\n</li>\n<li><p>如果有，import package的时候，会自动加载该文件的内容，其中用法有包括:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">__all__ = [<span class=\"string\">'foofactories'</span>, <span class=\"string\">'tallFoos'</span>, <span class=\"string\">'shortfoos'</span>, <span class=\"string\">'medumfoos'</span>,</span><br><span class=\"line\">           <span class=\"string\">'santaslittlehelperfoo'</span>, <span class=\"string\">'superawsomefoo'</span>, <span class=\"string\">'anotherfoo'</span>]</span><br><span class=\"line\"><span class=\"comment\"># deprecated to keep older scripts who import this from breaking</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> foo.foofactories <span class=\"keyword\">import</span> fooFactory</span><br><span class=\"line\"><span class=\"keyword\">from</span> foo.tallfoos <span class=\"keyword\">import</span> tallFoo</span><br><span class=\"line\"><span class=\"keyword\">from</span> foo.shortfoos <span class=\"keyword\">import</span> shortFoo</span><br></pre></td></tr></table></figure>\n<p>从而达到 from package import function的目的</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"import注意事项\"><a href=\"#import注意事项\" class=\"headerlink\" title=\"import注意事项:\"></a>import注意事项:</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> package1 <span class=\"keyword\">import</span> module1</span><br><span class=\"line\"><span class=\"keyword\">from</span> package1.module2 <span class=\"keyword\">import</span> function1</span><br><span class=\"line\"><span class=\"keyword\">from</span> package2 <span class=\"keyword\">import</span> class1</span><br><span class=\"line\"><span class=\"keyword\">from</span> package2.subpackage1.module5 <span class=\"keyword\">import</span> function2</span><br></pre></td></tr></table></figure>\n<p>注意，module.function这种形式是不行的，用.前面只能是package</p>\n<h2 id=\"init-py注意事项\"><a href=\"#init-py注意事项\" class=\"headerlink\" title=\"init.py注意事项:\"></a><strong>init</strong>.py注意事项:</h2><ul>\n<li><p>放在package目录下</p>\n</li>\n<li><p>可以没有，这种情况下一定要手动 from package import module</p>\n</li>\n<li><p>如果有，import package的时候，会自动加载该文件的内容，其中用法有包括:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">__all__ = [<span class=\"string\">'foofactories'</span>, <span class=\"string\">'tallFoos'</span>, <span class=\"string\">'shortfoos'</span>, <span class=\"string\">'medumfoos'</span>,</span><br><span class=\"line\">           <span class=\"string\">'santaslittlehelperfoo'</span>, <span class=\"string\">'superawsomefoo'</span>, <span class=\"string\">'anotherfoo'</span>]</span><br><span class=\"line\"><span class=\"comment\"># deprecated to keep older scripts who import this from breaking</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> foo.foofactories <span class=\"keyword\">import</span> fooFactory</span><br><span class=\"line\"><span class=\"keyword\">from</span> foo.tallfoos <span class=\"keyword\">import</span> tallFoo</span><br><span class=\"line\"><span class=\"keyword\">from</span> foo.shortfoos <span class=\"keyword\">import</span> shortFoo</span><br></pre></td></tr></table></figure>\n<p>从而达到 from package import function的目的</p>\n</li>\n</ul>\n"},{"title":"python2和3切换注意事项","date":"2019-02-02T14:06:02.000Z","_content":"\n\n\n- 除法问题。\n\n  ```python\n  # python2\n  >>> 3/2\n  1\n  >>> 3/2.0\n  1.5\n  # python3\n  >>> 3/2\n  1.5\n  >>> 3//2\n  1.5\n  ```\n\n  \n\n  **解决方法**：from __future__ import division\n\n- 字符串编码不同：\n\n  - python2字符串分为str类型和unicode类型\n\n    - str：非unicode形式，以各种编码方式用字节存储(gbk, ascii, utf-8, utf-16等)\n    - Unicode：unicode形式\n\n    默认就是str类型，除非指定u\"字符串\"，才是unicode类型。相对来说不合理，在代码中涉及到中文的时候(用str类型)就会遇到编码和解码问题，中间有各种隐式的转换，程序可能报错，因为python2的默认编码为ascii，sys.getdefaultencoding()\n\n  - pyhont3字符串分为str类型和bytes类型\n\n    - str：unicode形式\n    - bytes：非unicode形式，以各种编码方式用字节存储(gbk, ascii, utf-8, utf-16等)\n\n    这样更加合理一点，我们平时用到的就是str类型，用最通用的Unicode来表示，只在底层存储时候转成相应编码方式。\n\n  **解决方法**：文件头部指定编码utf-8，sys.setdefaultencoding为utf-8。\n\n- map,filter等。python2返回结果是list，python3返回一个可迭代对象，需要list()才行\n\n- python3没有xrange\n\n- python2的raw_input() 等同于 python3的input()， python2的input()只接受数字输入\n\n- print。 python2中的print是语句，python3是函数\n\n  ```python\n  # py2\n  >>> print(\"hello\", \"world\")\n  ('hello', 'world')\n  ```\n\n  **解决方法**: from __future__ import print_function\n\n- 还有个我自己发现的列表解析式的问题！ \n\n  ```python\n  for i in range(6):\n      y = [j for j in range(10)]\n      print(j)\n  ```\n\n  这个代码，python2下 j = 9，但python3下j不存在！说明j的作用域只在列表解析式里。\n\n","source":"_posts/编程开发/Python/python2和3切换注意事项.md","raw":"---\ntitle: python2和3切换注意事项\ndate: 2019-02-02 22:06:02\ncategories: [编程开发,Python]\n---\n\n\n\n- 除法问题。\n\n  ```python\n  # python2\n  >>> 3/2\n  1\n  >>> 3/2.0\n  1.5\n  # python3\n  >>> 3/2\n  1.5\n  >>> 3//2\n  1.5\n  ```\n\n  \n\n  **解决方法**：from __future__ import division\n\n- 字符串编码不同：\n\n  - python2字符串分为str类型和unicode类型\n\n    - str：非unicode形式，以各种编码方式用字节存储(gbk, ascii, utf-8, utf-16等)\n    - Unicode：unicode形式\n\n    默认就是str类型，除非指定u\"字符串\"，才是unicode类型。相对来说不合理，在代码中涉及到中文的时候(用str类型)就会遇到编码和解码问题，中间有各种隐式的转换，程序可能报错，因为python2的默认编码为ascii，sys.getdefaultencoding()\n\n  - pyhont3字符串分为str类型和bytes类型\n\n    - str：unicode形式\n    - bytes：非unicode形式，以各种编码方式用字节存储(gbk, ascii, utf-8, utf-16等)\n\n    这样更加合理一点，我们平时用到的就是str类型，用最通用的Unicode来表示，只在底层存储时候转成相应编码方式。\n\n  **解决方法**：文件头部指定编码utf-8，sys.setdefaultencoding为utf-8。\n\n- map,filter等。python2返回结果是list，python3返回一个可迭代对象，需要list()才行\n\n- python3没有xrange\n\n- python2的raw_input() 等同于 python3的input()， python2的input()只接受数字输入\n\n- print。 python2中的print是语句，python3是函数\n\n  ```python\n  # py2\n  >>> print(\"hello\", \"world\")\n  ('hello', 'world')\n  ```\n\n  **解决方法**: from __future__ import print_function\n\n- 还有个我自己发现的列表解析式的问题！ \n\n  ```python\n  for i in range(6):\n      y = [j for j in range(10)]\n      print(j)\n  ```\n\n  这个代码，python2下 j = 9，但python3下j不存在！说明j的作用域只在列表解析式里。\n\n","slug":"编程开发/Python/python2和3切换注意事项","published":1,"updated":"2022-09-15T03:46:43.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551r6007njqrrvwa9dkm2","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><ul>\n<li><p>除法问题。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># python2</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"number\">3</span>/<span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"number\">3</span>/<span class=\"number\">2.0</span></span><br><span class=\"line\"><span class=\"number\">1.5</span></span><br><span class=\"line\"><span class=\"comment\"># python3</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"number\">3</span>/<span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">1.5</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"number\">3</span>//<span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">1.5</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>  <strong>解决方法</strong>：from <strong>future</strong> import division</p>\n<ul>\n<li><p>字符串编码不同：</p>\n<ul>\n<li><p>python2字符串分为str类型和unicode类型</p>\n<ul>\n<li>str：非unicode形式，以各种编码方式用字节存储(gbk, ascii, utf-8, utf-16等)</li>\n<li>Unicode：unicode形式</li>\n</ul>\n<p>默认就是str类型，除非指定u”字符串”，才是unicode类型。相对来说不合理，在代码中涉及到中文的时候(用str类型)就会遇到编码和解码问题，中间有各种隐式的转换，程序可能报错，因为python2的默认编码为ascii，sys.getdefaultencoding()</p>\n</li>\n<li><p>pyhont3字符串分为str类型和bytes类型</p>\n<ul>\n<li>str：unicode形式</li>\n<li>bytes：非unicode形式，以各种编码方式用字节存储(gbk, ascii, utf-8, utf-16等)</li>\n</ul>\n<p>这样更加合理一点，我们平时用到的就是str类型，用最通用的Unicode来表示，只在底层存储时候转成相应编码方式。</p>\n</li>\n</ul>\n<p><strong>解决方法</strong>：文件头部指定编码utf-8，sys.setdefaultencoding为utf-8。</p>\n</li>\n<li><p>map,filter等。python2返回结果是list，python3返回一个可迭代对象，需要list()才行</p>\n</li>\n<li><p>python3没有xrange</p>\n</li>\n<li><p>python2的raw_input() 等同于 python3的input()， python2的input()只接受数字输入</p>\n</li>\n<li><p>print。 python2中的print是语句，python3是函数</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># py2</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>print(<span class=\"string\">\"hello\"</span>, <span class=\"string\">\"world\"</span>)</span><br><span class=\"line\">(<span class=\"string\">'hello'</span>, <span class=\"string\">'world'</span>)</span><br></pre></td></tr></table></figure>\n<p><strong>解决方法</strong>: from <strong>future</strong> import print_function</p>\n</li>\n<li><p>还有个我自己发现的列表解析式的问题！ </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">6</span>):</span><br><span class=\"line\">    y = [j <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">10</span>)]</span><br><span class=\"line\">    print(j)</span><br></pre></td></tr></table></figure>\n<p>这个代码，python2下 j = 9，但python3下j不存在！说明j的作用域只在列表解析式里。</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li><p>除法问题。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># python2</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"number\">3</span>/<span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"number\">3</span>/<span class=\"number\">2.0</span></span><br><span class=\"line\"><span class=\"number\">1.5</span></span><br><span class=\"line\"><span class=\"comment\"># python3</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"number\">3</span>/<span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">1.5</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"number\">3</span>//<span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">1.5</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>  <strong>解决方法</strong>：from <strong>future</strong> import division</p>\n<ul>\n<li><p>字符串编码不同：</p>\n<ul>\n<li><p>python2字符串分为str类型和unicode类型</p>\n<ul>\n<li>str：非unicode形式，以各种编码方式用字节存储(gbk, ascii, utf-8, utf-16等)</li>\n<li>Unicode：unicode形式</li>\n</ul>\n<p>默认就是str类型，除非指定u”字符串”，才是unicode类型。相对来说不合理，在代码中涉及到中文的时候(用str类型)就会遇到编码和解码问题，中间有各种隐式的转换，程序可能报错，因为python2的默认编码为ascii，sys.getdefaultencoding()</p>\n</li>\n<li><p>pyhont3字符串分为str类型和bytes类型</p>\n<ul>\n<li>str：unicode形式</li>\n<li>bytes：非unicode形式，以各种编码方式用字节存储(gbk, ascii, utf-8, utf-16等)</li>\n</ul>\n<p>这样更加合理一点，我们平时用到的就是str类型，用最通用的Unicode来表示，只在底层存储时候转成相应编码方式。</p>\n</li>\n</ul>\n<p><strong>解决方法</strong>：文件头部指定编码utf-8，sys.setdefaultencoding为utf-8。</p>\n</li>\n<li><p>map,filter等。python2返回结果是list，python3返回一个可迭代对象，需要list()才行</p>\n</li>\n<li><p>python3没有xrange</p>\n</li>\n<li><p>python2的raw_input() 等同于 python3的input()， python2的input()只接受数字输入</p>\n</li>\n<li><p>print。 python2中的print是语句，python3是函数</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># py2</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>print(<span class=\"string\">\"hello\"</span>, <span class=\"string\">\"world\"</span>)</span><br><span class=\"line\">(<span class=\"string\">'hello'</span>, <span class=\"string\">'world'</span>)</span><br></pre></td></tr></table></figure>\n<p><strong>解决方法</strong>: from <strong>future</strong> import print_function</p>\n</li>\n<li><p>还有个我自己发现的列表解析式的问题！ </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">6</span>):</span><br><span class=\"line\">    y = [j <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">10</span>)]</span><br><span class=\"line\">    print(j)</span><br></pre></td></tr></table></figure>\n<p>这个代码，python2下 j = 9，但python3下j不存在！说明j的作用域只在列表解析式里。</p>\n</li>\n</ul>\n"},{"title":"下划线用法","date":"2020-10-08T16:00:00.000Z","_content":"\n\n![image-20201009175708340](https://tva1.sinaimg.cn/large/007S8ZIlly1gjj8geqjr5j31700mo7gr.jpg)","source":"_posts/编程开发/Python/下划线用法.md","raw":"---\ntitle: 下划线用法\ndate: 2020-10-09\ncategories: [编程开发,Python]\n---\n\n\n![image-20201009175708340](https://tva1.sinaimg.cn/large/007S8ZIlly1gjj8geqjr5j31700mo7gr.jpg)","slug":"编程开发/Python/下划线用法","published":1,"updated":"2022-09-15T03:46:43.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551r7007qjqrrg3na7ov9","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gjj8geqjr5j31700mo7gr.jpg\" alt=\"image-20201009175708340\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p><img src=\"https://tva1.sinaimg.cn/large/007S8ZIlly1gjj8geqjr5j31700mo7gr.jpg\" alt=\"image-20201009175708340\"></p>\n"},{"title":"关于python2的编码问题","date":"2020-10-21T16:00:00.000Z","_content":"\n\n\n## 基本知识\n\n首先我们要弄明白Unicode这个概念，我以前一直理解有问题，以为是类似于ascii、utf-8的一种编码方式而已，然而我错了，可以看这篇文章：[字符编码笔记：ASCII，Unicode 和 UTF-8](http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html)，总结一下就是：\n\n- Unicode不是一种编码方式，而是定义了统一的字符集，包含了世界上的所有字符。它相当于维护了一个映射code point，一个二进制表示对应一个字符。虽然从这个理解上，也有点像是编码，毕竟也要用一个大概四个字节的二进制表示来表示一个字符，但还是要认为他只是一个字符集，而不是编码方式。\n- UTF-8则是Unicode具体的一种编码实现方式，采用变长的字节来存储每个字符。\n- 任何字符都可以用unicode表示，然后用某种编码方式，例如utf-8、ascii、gbk等方式，存储为字节形式。\n\n\n\n## Python中的编码问题\n\n- 在python2里面，str类型是以某种编码方式存好的字节，unicode类型才是以无编码方式存储的。\n\n```python\n>>> demo = '人'\n>>> demo\n>>> '\\xe4\\xba\\xba'  # 3个字节\n>>> demo = u'人'\n>>> demo\n>>> u'\\u4eba' # 1个中文字符, 2个字节\n```\n\n- 为了避免一系列蛋疼的编码问题，我们可以采用这种方式：\n\n  - 文件头部指定默认编码方式，这样str类型默认是按照utf-8来编码\n\n    ```python\n    # -*- coding:utf-8 -*-\n    ```\n\n  - 指定python解释器的默认编码方式，这样中间有一些隐式的编解码转换，就不会出现蛋疼的问题了\n\n    ```python\n    import sys\n    reload(sys)\n    sys.setdefaultencoding('utf-8')\n    ```\n\n\n\n\n很好的几个资料：[Byte(字节) 与 Bytearray(二进制数组)](https://www.cnblogs.com/zh605929205/articles/7268840.html), [编码：字符串和二进制](https://hexilee.me/2018/09/21/coding/)\n\n","source":"_posts/编程开发/Python/关于python2的编码问题.md","raw":"---\ntitle: 关于python2的编码问题\ndate: 2020-10-22\ncategories: [编程开发,Python]\n---\n\n\n\n## 基本知识\n\n首先我们要弄明白Unicode这个概念，我以前一直理解有问题，以为是类似于ascii、utf-8的一种编码方式而已，然而我错了，可以看这篇文章：[字符编码笔记：ASCII，Unicode 和 UTF-8](http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html)，总结一下就是：\n\n- Unicode不是一种编码方式，而是定义了统一的字符集，包含了世界上的所有字符。它相当于维护了一个映射code point，一个二进制表示对应一个字符。虽然从这个理解上，也有点像是编码，毕竟也要用一个大概四个字节的二进制表示来表示一个字符，但还是要认为他只是一个字符集，而不是编码方式。\n- UTF-8则是Unicode具体的一种编码实现方式，采用变长的字节来存储每个字符。\n- 任何字符都可以用unicode表示，然后用某种编码方式，例如utf-8、ascii、gbk等方式，存储为字节形式。\n\n\n\n## Python中的编码问题\n\n- 在python2里面，str类型是以某种编码方式存好的字节，unicode类型才是以无编码方式存储的。\n\n```python\n>>> demo = '人'\n>>> demo\n>>> '\\xe4\\xba\\xba'  # 3个字节\n>>> demo = u'人'\n>>> demo\n>>> u'\\u4eba' # 1个中文字符, 2个字节\n```\n\n- 为了避免一系列蛋疼的编码问题，我们可以采用这种方式：\n\n  - 文件头部指定默认编码方式，这样str类型默认是按照utf-8来编码\n\n    ```python\n    # -*- coding:utf-8 -*-\n    ```\n\n  - 指定python解释器的默认编码方式，这样中间有一些隐式的编解码转换，就不会出现蛋疼的问题了\n\n    ```python\n    import sys\n    reload(sys)\n    sys.setdefaultencoding('utf-8')\n    ```\n\n\n\n\n很好的几个资料：[Byte(字节) 与 Bytearray(二进制数组)](https://www.cnblogs.com/zh605929205/articles/7268840.html), [编码：字符串和二进制](https://hexilee.me/2018/09/21/coding/)\n\n","slug":"编程开发/Python/关于python2的编码问题","published":1,"updated":"2022-09-15T03:46:43.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551r7007sjqrr3663daba","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"基本知识\"><a href=\"#基本知识\" class=\"headerlink\" title=\"基本知识\"></a>基本知识</h2><p>首先我们要弄明白Unicode这个概念，我以前一直理解有问题，以为是类似于ascii、utf-8的一种编码方式而已，然而我错了，可以看这篇文章：<a href=\"http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html\" target=\"_blank\" rel=\"noopener\">字符编码笔记：ASCII，Unicode 和 UTF-8</a>，总结一下就是：</p>\n<ul>\n<li>Unicode不是一种编码方式，而是定义了统一的字符集，包含了世界上的所有字符。它相当于维护了一个映射code point，一个二进制表示对应一个字符。虽然从这个理解上，也有点像是编码，毕竟也要用一个大概四个字节的二进制表示来表示一个字符，但还是要认为他只是一个字符集，而不是编码方式。</li>\n<li>UTF-8则是Unicode具体的一种编码实现方式，采用变长的字节来存储每个字符。</li>\n<li>任何字符都可以用unicode表示，然后用某种编码方式，例如utf-8、ascii、gbk等方式，存储为字节形式。</li>\n</ul>\n<h2 id=\"Python中的编码问题\"><a href=\"#Python中的编码问题\" class=\"headerlink\" title=\"Python中的编码问题\"></a>Python中的编码问题</h2><ul>\n<li>在python2里面，str类型是以某种编码方式存好的字节，unicode类型才是以无编码方式存储的。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>demo = <span class=\"string\">'人'</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>demo</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"string\">'\\xe4\\xba\\xba'</span>  <span class=\"comment\"># 3个字节</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>demo = <span class=\"string\">u'人'</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>demo</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"string\">u'\\u4eba'</span> <span class=\"comment\"># 1个中文字符, 2个字节</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>为了避免一系列蛋疼的编码问题，我们可以采用这种方式：</p>\n<ul>\n<li><p>文件头部指定默认编码方式，这样str类型默认是按照utf-8来编码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding:utf-8 -*-</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>指定python解释器的默认编码方式，这样中间有一些隐式的编解码转换，就不会出现蛋疼的问题了</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\">reload(sys)</span><br><span class=\"line\">sys.setdefaultencoding(<span class=\"string\">'utf-8'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<p>很好的几个资料：<a href=\"https://www.cnblogs.com/zh605929205/articles/7268840.html\" target=\"_blank\" rel=\"noopener\">Byte(字节) 与 Bytearray(二进制数组)</a>, <a href=\"https://hexilee.me/2018/09/21/coding/\" target=\"_blank\" rel=\"noopener\">编码：字符串和二进制</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"基本知识\"><a href=\"#基本知识\" class=\"headerlink\" title=\"基本知识\"></a>基本知识</h2><p>首先我们要弄明白Unicode这个概念，我以前一直理解有问题，以为是类似于ascii、utf-8的一种编码方式而已，然而我错了，可以看这篇文章：<a href=\"http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html\" target=\"_blank\" rel=\"noopener\">字符编码笔记：ASCII，Unicode 和 UTF-8</a>，总结一下就是：</p>\n<ul>\n<li>Unicode不是一种编码方式，而是定义了统一的字符集，包含了世界上的所有字符。它相当于维护了一个映射code point，一个二进制表示对应一个字符。虽然从这个理解上，也有点像是编码，毕竟也要用一个大概四个字节的二进制表示来表示一个字符，但还是要认为他只是一个字符集，而不是编码方式。</li>\n<li>UTF-8则是Unicode具体的一种编码实现方式，采用变长的字节来存储每个字符。</li>\n<li>任何字符都可以用unicode表示，然后用某种编码方式，例如utf-8、ascii、gbk等方式，存储为字节形式。</li>\n</ul>\n<h2 id=\"Python中的编码问题\"><a href=\"#Python中的编码问题\" class=\"headerlink\" title=\"Python中的编码问题\"></a>Python中的编码问题</h2><ul>\n<li>在python2里面，str类型是以某种编码方式存好的字节，unicode类型才是以无编码方式存储的。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>demo = <span class=\"string\">'人'</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>demo</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"string\">'\\xe4\\xba\\xba'</span>  <span class=\"comment\"># 3个字节</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>demo = <span class=\"string\">u'人'</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>demo</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"string\">u'\\u4eba'</span> <span class=\"comment\"># 1个中文字符, 2个字节</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>为了避免一系列蛋疼的编码问题，我们可以采用这种方式：</p>\n<ul>\n<li><p>文件头部指定默认编码方式，这样str类型默认是按照utf-8来编码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding:utf-8 -*-</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>指定python解释器的默认编码方式，这样中间有一些隐式的编解码转换，就不会出现蛋疼的问题了</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\">reload(sys)</span><br><span class=\"line\">sys.setdefaultencoding(<span class=\"string\">'utf-8'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<p>很好的几个资料：<a href=\"https://www.cnblogs.com/zh605929205/articles/7268840.html\" target=\"_blank\" rel=\"noopener\">Byte(字节) 与 Bytearray(二进制数组)</a>, <a href=\"https://hexilee.me/2018/09/21/coding/\" target=\"_blank\" rel=\"noopener\">编码：字符串和二进制</a></p>\n"},{"title":"切片操作","date":"2018-06-03T14:06:02.000Z","_content":"\n## python切片\n\n切片复制属于较深拷贝，意思是如果拷贝的元素是可变对象，那么指的是同一段内存。如a = [1,2,3, [1,2,3]]中的a[3]，跟copy()方法一样，深拷贝是deepcopy()。\n\n \n\n## go切片\n\n切片属于一段引用，即深拷贝，切片有长度和容量之分。切片中[:]尾数默认是长度，但是容量是指原来数组的长度,如果切片长度超出，容量还在的话，可以正常访问。","source":"_posts/编程开发/Python/切片操作.md","raw":"---\ntitle: 切片操作\ndate: 2018-06-03 22:06:02\ncategories: [编程开发,Python]\n---\n\n## python切片\n\n切片复制属于较深拷贝，意思是如果拷贝的元素是可变对象，那么指的是同一段内存。如a = [1,2,3, [1,2,3]]中的a[3]，跟copy()方法一样，深拷贝是deepcopy()。\n\n \n\n## go切片\n\n切片属于一段引用，即深拷贝，切片有长度和容量之分。切片中[:]尾数默认是长度，但是容量是指原来数组的长度,如果切片长度超出，容量还在的话，可以正常访问。","slug":"编程开发/Python/切片操作","published":1,"updated":"2022-09-15T03:46:43.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551r8007ujqrrnzdpljet","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"python切片\"><a href=\"#python切片\" class=\"headerlink\" title=\"python切片\"></a>python切片</h2><p>切片复制属于较深拷贝，意思是如果拷贝的元素是可变对象，那么指的是同一段内存。如a = [1,2,3, [1,2,3]]中的a[3]，跟copy()方法一样，深拷贝是deepcopy()。</p>\n<h2 id=\"go切片\"><a href=\"#go切片\" class=\"headerlink\" title=\"go切片\"></a>go切片</h2><p>切片属于一段引用，即深拷贝，切片有长度和容量之分。切片中[:]尾数默认是长度，但是容量是指原来数组的长度,如果切片长度超出，容量还在的话，可以正常访问。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"python切片\"><a href=\"#python切片\" class=\"headerlink\" title=\"python切片\"></a>python切片</h2><p>切片复制属于较深拷贝，意思是如果拷贝的元素是可变对象，那么指的是同一段内存。如a = [1,2,3, [1,2,3]]中的a[3]，跟copy()方法一样，深拷贝是deepcopy()。</p>\n<h2 id=\"go切片\"><a href=\"#go切片\" class=\"headerlink\" title=\"go切片\"></a>go切片</h2><p>切片属于一段引用，即深拷贝，切片有长度和容量之分。切片中[:]尾数默认是长度，但是容量是指原来数组的长度,如果切片长度超出，容量还在的话，可以正常访问。</p>\n"},{"title":"引用，浅拷贝和深拷贝","date":"2019-05-06T14:06:02.000Z","_content":"\n\n\n## 引用\n\n变量名是别名，没有开辟新的内存，指向同一块内存\n\n \n\n### 浅拷贝：\n\n一般出现在array-like对象中，如list等。\n\n虽然开辟了一块新的内存，但是对象中的每一个元素都是指向原对象的每个元素的地址。例如：\n\na = [1,2,[1,2,3]]\n\nb =copy.copy(a)\n\nid(a[2]) == id(b[2])\n\n对于元素为不可变对象时，倒无所谓，如果元素为可变对象，那么a变b也变。\n\n切片就是浅拷贝！！\n\n \n\n### 深拷贝：\n\n既开辟了新的内存，对象中的每个元素又都是数值的拷贝，而非地址。\n\n使用方式：copy.deepcopy()\n\n \n\n \n\n## 神奇的pandas: \n\n﻿经过对pandas的一番探索，引用，切片，花式索引。。结论是：pandas的内存机制实在是有点复杂，真是摸不透。\n\n例如：a是一个dataframe, b = a.loc[:]，这个操作后a.loc[1]的地址都会变..太恐怖了\n\n所以还是总结一下，平时用的比较多的操作：\n\n对于切片处理，如b = a.loc[:]，如果修改b.loc[*,*]的值，a也会变，如果b经过一些其他的操作，如sort_values等之后，b又变成了一个单独的内存空间。\n\n对于花式索引，如b = a[a['*'] > *]，修改b.loc[*,*]的值，a不会变。\n\n ","source":"_posts/编程开发/Python/引用, 浅拷贝和深拷贝.md","raw":"---\ntitle: 引用，浅拷贝和深拷贝\ndate: 2019-05-06 22:06:02\ncategories: [编程开发,Python]\n---\n\n\n\n## 引用\n\n变量名是别名，没有开辟新的内存，指向同一块内存\n\n \n\n### 浅拷贝：\n\n一般出现在array-like对象中，如list等。\n\n虽然开辟了一块新的内存，但是对象中的每一个元素都是指向原对象的每个元素的地址。例如：\n\na = [1,2,[1,2,3]]\n\nb =copy.copy(a)\n\nid(a[2]) == id(b[2])\n\n对于元素为不可变对象时，倒无所谓，如果元素为可变对象，那么a变b也变。\n\n切片就是浅拷贝！！\n\n \n\n### 深拷贝：\n\n既开辟了新的内存，对象中的每个元素又都是数值的拷贝，而非地址。\n\n使用方式：copy.deepcopy()\n\n \n\n \n\n## 神奇的pandas: \n\n﻿经过对pandas的一番探索，引用，切片，花式索引。。结论是：pandas的内存机制实在是有点复杂，真是摸不透。\n\n例如：a是一个dataframe, b = a.loc[:]，这个操作后a.loc[1]的地址都会变..太恐怖了\n\n所以还是总结一下，平时用的比较多的操作：\n\n对于切片处理，如b = a.loc[:]，如果修改b.loc[*,*]的值，a也会变，如果b经过一些其他的操作，如sort_values等之后，b又变成了一个单独的内存空间。\n\n对于花式索引，如b = a[a['*'] > *]，修改b.loc[*,*]的值，a不会变。\n\n ","slug":"编程开发/Python/引用, 浅拷贝和深拷贝","published":1,"updated":"2022-09-15T03:46:43.364Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551rb007vjqrrwhvw9ljx","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"引用\"><a href=\"#引用\" class=\"headerlink\" title=\"引用\"></a>引用</h2><p>变量名是别名，没有开辟新的内存，指向同一块内存</p>\n<h3 id=\"浅拷贝：\"><a href=\"#浅拷贝：\" class=\"headerlink\" title=\"浅拷贝：\"></a>浅拷贝：</h3><p>一般出现在array-like对象中，如list等。</p>\n<p>虽然开辟了一块新的内存，但是对象中的每一个元素都是指向原对象的每个元素的地址。例如：</p>\n<p>a = [1,2,[1,2,3]]</p>\n<p>b =copy.copy(a)</p>\n<p>id(a[2]) == id(b[2])</p>\n<p>对于元素为不可变对象时，倒无所谓，如果元素为可变对象，那么a变b也变。</p>\n<p>切片就是浅拷贝！！</p>\n<h3 id=\"深拷贝：\"><a href=\"#深拷贝：\" class=\"headerlink\" title=\"深拷贝：\"></a>深拷贝：</h3><p>既开辟了新的内存，对象中的每个元素又都是数值的拷贝，而非地址。</p>\n<p>使用方式：copy.deepcopy()</p>\n<h2 id=\"神奇的pandas\"><a href=\"#神奇的pandas\" class=\"headerlink\" title=\"神奇的pandas:\"></a>神奇的pandas:</h2><p>﻿经过对pandas的一番探索，引用，切片，花式索引。。结论是：pandas的内存机制实在是有点复杂，真是摸不透。</p>\n<p>例如：a是一个dataframe, b = a.loc[:]，这个操作后a.loc[1]的地址都会变..太恐怖了</p>\n<p>所以还是总结一下，平时用的比较多的操作：</p>\n<p>对于切片处理，如b = a.loc[:]，如果修改b.loc[<em>,</em>]的值，a也会变，如果b经过一些其他的操作，如sort_values等之后，b又变成了一个单独的内存空间。</p>\n<p>对于花式索引，如b = a[a[‘<em>‘] &gt; </em>]，修改b.loc[<em>,</em>]的值，a不会变。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"引用\"><a href=\"#引用\" class=\"headerlink\" title=\"引用\"></a>引用</h2><p>变量名是别名，没有开辟新的内存，指向同一块内存</p>\n<h3 id=\"浅拷贝：\"><a href=\"#浅拷贝：\" class=\"headerlink\" title=\"浅拷贝：\"></a>浅拷贝：</h3><p>一般出现在array-like对象中，如list等。</p>\n<p>虽然开辟了一块新的内存，但是对象中的每一个元素都是指向原对象的每个元素的地址。例如：</p>\n<p>a = [1,2,[1,2,3]]</p>\n<p>b =copy.copy(a)</p>\n<p>id(a[2]) == id(b[2])</p>\n<p>对于元素为不可变对象时，倒无所谓，如果元素为可变对象，那么a变b也变。</p>\n<p>切片就是浅拷贝！！</p>\n<h3 id=\"深拷贝：\"><a href=\"#深拷贝：\" class=\"headerlink\" title=\"深拷贝：\"></a>深拷贝：</h3><p>既开辟了新的内存，对象中的每个元素又都是数值的拷贝，而非地址。</p>\n<p>使用方式：copy.deepcopy()</p>\n<h2 id=\"神奇的pandas\"><a href=\"#神奇的pandas\" class=\"headerlink\" title=\"神奇的pandas:\"></a>神奇的pandas:</h2><p>﻿经过对pandas的一番探索，引用，切片，花式索引。。结论是：pandas的内存机制实在是有点复杂，真是摸不透。</p>\n<p>例如：a是一个dataframe, b = a.loc[:]，这个操作后a.loc[1]的地址都会变..太恐怖了</p>\n<p>所以还是总结一下，平时用的比较多的操作：</p>\n<p>对于切片处理，如b = a.loc[:]，如果修改b.loc[<em>,</em>]的值，a也会变，如果b经过一些其他的操作，如sort_values等之后，b又变成了一个单独的内存空间。</p>\n<p>对于花式索引，如b = a[a[‘<em>‘] &gt; </em>]，修改b.loc[<em>,</em>]的值，a不会变。</p>\n"},{"title":"类变量和实例变量","date":"2021-06-24T16:00:00.000Z","_content":"\n\n\n类和实例都可以访问 类变量，但是实例只能访问，无法修改，一旦修改了，则会生成一个同名的实例变量，而非本身的类变量。\n\n\n\n```\nclass A(object):\n    a = 1\n    b = 2\n    def __init__(self):\n        print self.a  # 1\n        self.a = 3\n\nt = A()\nprint t.a  # 3\nprint A.a  # 1\n\nt.a = 4\nprint t.a  # 4 \nprint A.a  # 1\n```\n\n\n\n\n","source":"_posts/编程开发/Python/类变量和实例变量.md","raw":"---\ntitle: 类变量和实例变量\ndate: 2021-06-25\ncategories: [编程开发,Python]\n---\n\n\n\n类和实例都可以访问 类变量，但是实例只能访问，无法修改，一旦修改了，则会生成一个同名的实例变量，而非本身的类变量。\n\n\n\n```\nclass A(object):\n    a = 1\n    b = 2\n    def __init__(self):\n        print self.a  # 1\n        self.a = 3\n\nt = A()\nprint t.a  # 3\nprint A.a  # 1\n\nt.a = 4\nprint t.a  # 4 \nprint A.a  # 1\n```\n\n\n\n\n","slug":"编程开发/Python/类变量和实例变量","published":1,"updated":"2022-09-15T03:46:43.364Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551rd007xjqrry43cn6z9","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>类和实例都可以访问 类变量，但是实例只能访问，无法修改，一旦修改了，则会生成一个同名的实例变量，而非本身的类变量。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class A(object):</span><br><span class=\"line\">    a = 1</span><br><span class=\"line\">    b = 2</span><br><span class=\"line\">    def __init__(self):</span><br><span class=\"line\">        print self.a  # 1</span><br><span class=\"line\">        self.a = 3</span><br><span class=\"line\"></span><br><span class=\"line\">t = A()</span><br><span class=\"line\">print t.a  # 3</span><br><span class=\"line\">print A.a  # 1</span><br><span class=\"line\"></span><br><span class=\"line\">t.a = 4</span><br><span class=\"line\">print t.a  # 4 </span><br><span class=\"line\">print A.a  # 1</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>类和实例都可以访问 类变量，但是实例只能访问，无法修改，一旦修改了，则会生成一个同名的实例变量，而非本身的类变量。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class A(object):</span><br><span class=\"line\">    a = 1</span><br><span class=\"line\">    b = 2</span><br><span class=\"line\">    def __init__(self):</span><br><span class=\"line\">        print self.a  # 1</span><br><span class=\"line\">        self.a = 3</span><br><span class=\"line\"></span><br><span class=\"line\">t = A()</span><br><span class=\"line\">print t.a  # 3</span><br><span class=\"line\">print A.a  # 1</span><br><span class=\"line\"></span><br><span class=\"line\">t.a = 4</span><br><span class=\"line\">print t.a  # 4 </span><br><span class=\"line\">print A.a  # 1</span><br></pre></td></tr></table></figure>\n"},{"title":"Linux Shell多进程并发以及并发数控制","date":"2018-11-05T10:13:30.000Z","_content":"\n利用命名管道：和文件描述符绑定，利用FIFO，数据滞留的特性，控制并发数。\n\nhttps://blog.csdn.net/yeweiouyang/article/details/52512522\n\n","source":"_posts/编程开发/Shell/Shell多进程并发以及并发数控制.md","raw":"---\ntitle: Linux Shell多进程并发以及并发数控制\ndate: 2018-11-05 18:13:30\ncategories: [编程开发,Shell]\n---\n\n利用命名管道：和文件描述符绑定，利用FIFO，数据滞留的特性，控制并发数。\n\nhttps://blog.csdn.net/yeweiouyang/article/details/52512522\n\n","slug":"编程开发/Shell/Shell多进程并发以及并发数控制","published":1,"updated":"2022-09-15T03:46:43.364Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551rf007yjqrreg8w68nb","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>利用命名管道：和文件描述符绑定，利用FIFO，数据滞留的特性，控制并发数。</p>\n<p><a href=\"https://blog.csdn.net/yeweiouyang/article/details/52512522\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/yeweiouyang/article/details/52512522</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>利用命名管道：和文件描述符绑定，利用FIFO，数据滞留的特性，控制并发数。</p>\n<p><a href=\"https://blog.csdn.net/yeweiouyang/article/details/52512522\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/yeweiouyang/article/details/52512522</a></p>\n"},{"title":"shell中的$1,$#等","date":"2018-11-11T10:13:30.000Z","_content":"\n### $$\nShell本身的PID（ProcessID）\n### $!\nShell最后运行的后台Process的PID\n### $?\n最后运行的命令的结束代码（返回值）\n### $-\n使用Set命令设定的Flag一览\n### $*\n所有参数列表。如\"$*\"用「\"」括起来的情况、以\"$1 $2 … $n\"的形式输出所有参数。\n### $@\n所有参数列表。如\"$@\"用「\"」括起来的情况、以\"$1\" \"$2\" … \"$n\" 的形式输出所有参数。\n### $#\n添加到Shell的参数个数\n### $0\nShell本身的文件名\n### \\$1～\\$n\n添加到Shell的各参数值。$1是第1参数、$2是第2参数…。","source":"_posts/编程开发/Shell/shell $1,$#等.md","raw":"---\ntitle: shell中的$1,$#等\ndate: 2018-11-11 18:13:30\ncategories: [编程开发,Shell]\n---\n\n### $$\nShell本身的PID（ProcessID）\n### $!\nShell最后运行的后台Process的PID\n### $?\n最后运行的命令的结束代码（返回值）\n### $-\n使用Set命令设定的Flag一览\n### $*\n所有参数列表。如\"$*\"用「\"」括起来的情况、以\"$1 $2 … $n\"的形式输出所有参数。\n### $@\n所有参数列表。如\"$@\"用「\"」括起来的情况、以\"$1\" \"$2\" … \"$n\" 的形式输出所有参数。\n### $#\n添加到Shell的参数个数\n### $0\nShell本身的文件名\n### \\$1～\\$n\n添加到Shell的各参数值。$1是第1参数、$2是第2参数…。","slug":"编程开发/Shell/shell $1,$#等","published":1,"updated":"2022-09-15T03:46:43.364Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551rj0080jqrrhrr1x4is","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id><a href=\"#\" class=\"headerlink\" title=\"$$\"></a>$$</h3><p>Shell本身的PID（ProcessID）</p>\n<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"$!\"></a>$!</h3><p>Shell最后运行的后台Process的PID</p>\n<h3 id=\"-2\"><a href=\"#-2\" class=\"headerlink\" title=\"$?\"></a>$?</h3><p>最后运行的命令的结束代码（返回值）</p>\n<h3 id=\"-3\"><a href=\"#-3\" class=\"headerlink\" title=\"$-\"></a>$-</h3><p>使用Set命令设定的Flag一览</p>\n<h3 id=\"-4\"><a href=\"#-4\" class=\"headerlink\" title=\"$*\"></a>$*</h3><p>所有参数列表。如”$*”用「”」括起来的情况、以”$1 $2 … $n”的形式输出所有参数。</p>\n<h3 id=\"-5\"><a href=\"#-5\" class=\"headerlink\" title=\"$@\"></a>$@</h3><p>所有参数列表。如”$@”用「”」括起来的情况、以”$1” “$2” … “$n” 的形式输出所有参数。</p>\n<h3 id=\"-6\"><a href=\"#-6\" class=\"headerlink\" title=\"$\"></a>$</h3><p>添加到Shell的参数个数</p>\n<h3 id=\"0\"><a href=\"#0\" class=\"headerlink\" title=\"$0\"></a>$0</h3><p>Shell本身的文件名</p>\n<h3 id=\"1～-n\"><a href=\"#1～-n\" class=\"headerlink\" title=\"$1～$n\"></a>$1～$n</h3><p>添加到Shell的各参数值。$1是第1参数、$2是第2参数…。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id><a href=\"#\" class=\"headerlink\" title=\"$$\"></a>$$</h3><p>Shell本身的PID（ProcessID）</p>\n<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"$!\"></a>$!</h3><p>Shell最后运行的后台Process的PID</p>\n<h3 id=\"-2\"><a href=\"#-2\" class=\"headerlink\" title=\"$?\"></a>$?</h3><p>最后运行的命令的结束代码（返回值）</p>\n<h3 id=\"-3\"><a href=\"#-3\" class=\"headerlink\" title=\"$-\"></a>$-</h3><p>使用Set命令设定的Flag一览</p>\n<h3 id=\"-4\"><a href=\"#-4\" class=\"headerlink\" title=\"$*\"></a>$*</h3><p>所有参数列表。如”$*”用「”」括起来的情况、以”$1 $2 … $n”的形式输出所有参数。</p>\n<h3 id=\"-5\"><a href=\"#-5\" class=\"headerlink\" title=\"$@\"></a>$@</h3><p>所有参数列表。如”$@”用「”」括起来的情况、以”$1” “$2” … “$n” 的形式输出所有参数。</p>\n<h3 id=\"-6\"><a href=\"#-6\" class=\"headerlink\" title=\"$\"></a>$</h3><p>添加到Shell的参数个数</p>\n<h3 id=\"0\"><a href=\"#0\" class=\"headerlink\" title=\"$0\"></a>$0</h3><p>Shell本身的文件名</p>\n<h3 id=\"1～-n\"><a href=\"#1～-n\" class=\"headerlink\" title=\"$1～$n\"></a>$1～$n</h3><p>添加到Shell的各参数值。$1是第1参数、$2是第2参数…。</p>\n"},{"title":"shell交互式及登录式","date":"2019-02-15T10:13:30.000Z","_content":"\n登录式和非登录式区别：\n\n \n\n“登陆shell”通常指的是：（/etc/profile,~/.bash_profile, ~/.bashrc,/etc/bashrc）\n\n-  用户通过输入用户名/密码（或证书认证）后启动的shell；\n\n- 通过带有-l|--login参数的bash命令启动的shell。\n\n例如，系统启动、远程登录、使用su -切换用户、通过bash --login命令或 -i 启动bash等。\n\n \n\n而其他情况启动的shell基本上就都是“非登陆shell”了。(~/.bashrc, /etc/bashrc)\n\n例如，从图形界面启动终端、使用su切换用户、通过bash命令启动bash等。 \n\n \n\n“登录shell”和“非登陆shell”的区别在于**启动shell时所执行的startup文件不同**。\n\n \n\n交互式和非交互式区别：\n\n非交互式：有-c选项或者执行一个shell脚本\n\n交互式： 命令行交互形式\n\n\n\n注意：非交互式shell应用基本都是原shell环境下创建一个非交互式子shell执行程序，用户不变，环境变量不变，不会重新加载startup文件。\n\n \n\n总结：\n\n日常用到的就这三类：\n\n交互式登录shell\n\n交互式非登录shell\n\n非交互式shell\n\n ","source":"_posts/编程开发/Shell/shell交互式及登录式.md","raw":"---\ntitle: shell交互式及登录式\ndate: 2019-02-15 18:13:30\ncategories: [编程开发,Shell]\n---\n\n登录式和非登录式区别：\n\n \n\n“登陆shell”通常指的是：（/etc/profile,~/.bash_profile, ~/.bashrc,/etc/bashrc）\n\n-  用户通过输入用户名/密码（或证书认证）后启动的shell；\n\n- 通过带有-l|--login参数的bash命令启动的shell。\n\n例如，系统启动、远程登录、使用su -切换用户、通过bash --login命令或 -i 启动bash等。\n\n \n\n而其他情况启动的shell基本上就都是“非登陆shell”了。(~/.bashrc, /etc/bashrc)\n\n例如，从图形界面启动终端、使用su切换用户、通过bash命令启动bash等。 \n\n \n\n“登录shell”和“非登陆shell”的区别在于**启动shell时所执行的startup文件不同**。\n\n \n\n交互式和非交互式区别：\n\n非交互式：有-c选项或者执行一个shell脚本\n\n交互式： 命令行交互形式\n\n\n\n注意：非交互式shell应用基本都是原shell环境下创建一个非交互式子shell执行程序，用户不变，环境变量不变，不会重新加载startup文件。\n\n \n\n总结：\n\n日常用到的就这三类：\n\n交互式登录shell\n\n交互式非登录shell\n\n非交互式shell\n\n ","slug":"编程开发/Shell/shell交互式及登录式","published":1,"updated":"2022-09-15T03:46:43.364Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551rk0081jqrr58f2xb5f","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>登录式和非登录式区别：</p>\n<p>“登陆shell”通常指的是：（/etc/profile,~/.bash_profile, ~/.bashrc,/etc/bashrc）</p>\n<ul>\n<li><p>用户通过输入用户名/密码（或证书认证）后启动的shell；</p>\n</li>\n<li><p>通过带有-l|—login参数的bash命令启动的shell。</p>\n</li>\n</ul>\n<p>例如，系统启动、远程登录、使用su -切换用户、通过bash —login命令或 -i 启动bash等。</p>\n<p>而其他情况启动的shell基本上就都是“非登陆shell”了。(~/.bashrc, /etc/bashrc)</p>\n<p>例如，从图形界面启动终端、使用su切换用户、通过bash命令启动bash等。 </p>\n<p>“登录shell”和“非登陆shell”的区别在于<strong>启动shell时所执行的startup文件不同</strong>。</p>\n<p>交互式和非交互式区别：</p>\n<p>非交互式：有-c选项或者执行一个shell脚本</p>\n<p>交互式： 命令行交互形式</p>\n<p>注意：非交互式shell应用基本都是原shell环境下创建一个非交互式子shell执行程序，用户不变，环境变量不变，不会重新加载startup文件。</p>\n<p>总结：</p>\n<p>日常用到的就这三类：</p>\n<p>交互式登录shell</p>\n<p>交互式非登录shell</p>\n<p>非交互式shell</p>\n","site":{"data":{}},"excerpt":"","more":"<p>登录式和非登录式区别：</p>\n<p>“登陆shell”通常指的是：（/etc/profile,~/.bash_profile, ~/.bashrc,/etc/bashrc）</p>\n<ul>\n<li><p>用户通过输入用户名/密码（或证书认证）后启动的shell；</p>\n</li>\n<li><p>通过带有-l|—login参数的bash命令启动的shell。</p>\n</li>\n</ul>\n<p>例如，系统启动、远程登录、使用su -切换用户、通过bash —login命令或 -i 启动bash等。</p>\n<p>而其他情况启动的shell基本上就都是“非登陆shell”了。(~/.bashrc, /etc/bashrc)</p>\n<p>例如，从图形界面启动终端、使用su切换用户、通过bash命令启动bash等。 </p>\n<p>“登录shell”和“非登陆shell”的区别在于<strong>启动shell时所执行的startup文件不同</strong>。</p>\n<p>交互式和非交互式区别：</p>\n<p>非交互式：有-c选项或者执行一个shell脚本</p>\n<p>交互式： 命令行交互形式</p>\n<p>注意：非交互式shell应用基本都是原shell环境下创建一个非交互式子shell执行程序，用户不变，环境变量不变，不会重新加载startup文件。</p>\n<p>总结：</p>\n<p>日常用到的就这三类：</p>\n<p>交互式登录shell</p>\n<p>交互式非登录shell</p>\n<p>非交互式shell</p>\n"},{"title":"shell变量中的反斜杠","date":"2018-05-22T10:13:30.000Z","_content":"\n- 变量最好用双引号引起来，可以解析里面的变量和命令\n\n- 用单引号引起来的变量是硬转义\n- echo -E “” 无转义，echo -e \"\"有转义\n- 对于\\，在命令行本身就代表了换行继续的意思，多以无论-E 还 -e，\\本身就自带转义。\n\n因此，对于多个\\先要默认对多个\\转义，并且转义时按照两两消除的方式，然后再按命令参数执行命令。\n\n例如，\n\n\"\\\\\\...\\\\\"，假设为x个\\，若x为偶数，则解析为x/2个\\，若x为奇数，则最后一个\\生效，另起换行。\n\n此时，如果再执行echo -e，也就是再次转义，那么就是在之前的基础上，再次两两消除转义。\n\n \n\n举例：\n\necho -e \"\\\\\\\\\\\"  : 换行继续\n\necho  -E \"\\\\\\\\n\" : \\\\n\n\necho -e \"\\\\\\\\n\"  : \\n\n\necho -e \"\\\\\\\\\\n\" : \\ 换行\n\n ","source":"_posts/编程开发/Shell/shell变量中的反斜杠.md","raw":"---\ntitle: shell变量中的反斜杠\ndate: 2018-05-22 18:13:30\ncategories: [编程开发,Shell]\n---\n\n- 变量最好用双引号引起来，可以解析里面的变量和命令\n\n- 用单引号引起来的变量是硬转义\n- echo -E “” 无转义，echo -e \"\"有转义\n- 对于\\，在命令行本身就代表了换行继续的意思，多以无论-E 还 -e，\\本身就自带转义。\n\n因此，对于多个\\先要默认对多个\\转义，并且转义时按照两两消除的方式，然后再按命令参数执行命令。\n\n例如，\n\n\"\\\\\\...\\\\\"，假设为x个\\，若x为偶数，则解析为x/2个\\，若x为奇数，则最后一个\\生效，另起换行。\n\n此时，如果再执行echo -e，也就是再次转义，那么就是在之前的基础上，再次两两消除转义。\n\n \n\n举例：\n\necho -e \"\\\\\\\\\\\"  : 换行继续\n\necho  -E \"\\\\\\\\n\" : \\\\n\n\necho -e \"\\\\\\\\n\"  : \\n\n\necho -e \"\\\\\\\\\\n\" : \\ 换行\n\n ","slug":"编程开发/Shell/shell变量中的反斜杠","published":1,"updated":"2022-09-15T03:46:43.364Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551rp0083jqrryvq38avw","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><ul>\n<li><p>变量最好用双引号引起来，可以解析里面的变量和命令</p>\n</li>\n<li><p>用单引号引起来的变量是硬转义</p>\n</li>\n<li>echo -E “” 无转义，echo -e “”有转义</li>\n<li>对于\\，在命令行本身就代表了换行继续的意思，多以无论-E 还 -e，\\本身就自带转义。</li>\n</ul>\n<p>因此，对于多个\\先要默认对多个\\转义，并且转义时按照两两消除的方式，然后再按命令参数执行命令。</p>\n<p>例如，</p>\n<p>“\\...\\“，假设为x个\\，若x为偶数，则解析为x/2个\\，若x为奇数，则最后一个\\生效，另起换行。</p>\n<p>此时，如果再执行echo -e，也就是再次转义，那么就是在之前的基础上，再次两两消除转义。</p>\n<p>举例：</p>\n<p>echo -e “\\\\\\”  : 换行继续</p>\n<p>echo  -E “\\\\n” : \\n</p>\n<p>echo -e “\\\\n”  : \\n</p>\n<p>echo -e “\\\\\\n” : \\ 换行</p>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li><p>变量最好用双引号引起来，可以解析里面的变量和命令</p>\n</li>\n<li><p>用单引号引起来的变量是硬转义</p>\n</li>\n<li>echo -E “” 无转义，echo -e “”有转义</li>\n<li>对于\\，在命令行本身就代表了换行继续的意思，多以无论-E 还 -e，\\本身就自带转义。</li>\n</ul>\n<p>因此，对于多个\\先要默认对多个\\转义，并且转义时按照两两消除的方式，然后再按命令参数执行命令。</p>\n<p>例如，</p>\n<p>“\\...\\“，假设为x个\\，若x为偶数，则解析为x/2个\\，若x为奇数，则最后一个\\生效，另起换行。</p>\n<p>此时，如果再执行echo -e，也就是再次转义，那么就是在之前的基础上，再次两两消除转义。</p>\n<p>举例：</p>\n<p>echo -e “\\\\\\”  : 换行继续</p>\n<p>echo  -E “\\\\n” : \\n</p>\n<p>echo -e “\\\\n”  : \\n</p>\n<p>echo -e “\\\\\\n” : \\ 换行</p>\n"},{"title":"shell的变量","date":"2019-07-02T10:13:30.000Z","_content":"\n### 局部变量\n\n只在函数内定义的变量，如果不加local关键词，其实还是一个全局变量(函数外能够访问)\n\n \n\n### 全局变量\n\n在当前shell内定义的变量，其他shell不能访问\n\n \n\n### 环境变量\n\n用export定义，在当前shell的子shell中可以传递，传子不传父。\n\n","source":"_posts/编程开发/Shell/shell的变量.md","raw":"---\ntitle: shell的变量\ndate: 2019-07-02 18:13:30\ncategories: [编程开发,Shell]\n---\n\n### 局部变量\n\n只在函数内定义的变量，如果不加local关键词，其实还是一个全局变量(函数外能够访问)\n\n \n\n### 全局变量\n\n在当前shell内定义的变量，其他shell不能访问\n\n \n\n### 环境变量\n\n用export定义，在当前shell的子shell中可以传递，传子不传父。\n\n","slug":"编程开发/Shell/shell的变量","published":1,"updated":"2022-09-15T03:46:43.364Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551rp0084jqrryd6y34hu","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"局部变量\"><a href=\"#局部变量\" class=\"headerlink\" title=\"局部变量\"></a>局部变量</h3><p>只在函数内定义的变量，如果不加local关键词，其实还是一个全局变量(函数外能够访问)</p>\n<h3 id=\"全局变量\"><a href=\"#全局变量\" class=\"headerlink\" title=\"全局变量\"></a>全局变量</h3><p>在当前shell内定义的变量，其他shell不能访问</p>\n<h3 id=\"环境变量\"><a href=\"#环境变量\" class=\"headerlink\" title=\"环境变量\"></a>环境变量</h3><p>用export定义，在当前shell的子shell中可以传递，传子不传父。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"局部变量\"><a href=\"#局部变量\" class=\"headerlink\" title=\"局部变量\"></a>局部变量</h3><p>只在函数内定义的变量，如果不加local关键词，其实还是一个全局变量(函数外能够访问)</p>\n<h3 id=\"全局变量\"><a href=\"#全局变量\" class=\"headerlink\" title=\"全局变量\"></a>全局变量</h3><p>在当前shell内定义的变量，其他shell不能访问</p>\n<h3 id=\"环境变量\"><a href=\"#环境变量\" class=\"headerlink\" title=\"环境变量\"></a>环境变量</h3><p>用export定义，在当前shell的子shell中可以传递，传子不传父。</p>\n"},{"title":"sudo与su","date":"2019-02-15T10:13:30.000Z","_content":"\n\n\nsudo -u user单纯以某用户身份运行命令，并不切换环境，需要输入当前用户密码，。sudo的各类权限在/etc/sudoers配置\n\n \n\nsu 则切换到某用户的环境下，需要输入某用户的密码。这里注意一定要加 su -  ，只有这样才会生成login shell加载/etc/profile和~/.bash_profile，如果不加的话，启动non-login shell，不加载上述文件，环境变量部分是原用户的。\n\n","source":"_posts/编程开发/Shell/sudo与su.md","raw":"---\ntitle: sudo与su\ndate: 2019-02-15 18:13:30\ncategories: [编程开发,Shell]\n---\n\n\n\nsudo -u user单纯以某用户身份运行命令，并不切换环境，需要输入当前用户密码，。sudo的各类权限在/etc/sudoers配置\n\n \n\nsu 则切换到某用户的环境下，需要输入某用户的密码。这里注意一定要加 su -  ，只有这样才会生成login shell加载/etc/profile和~/.bash_profile，如果不加的话，启动non-login shell，不加载上述文件，环境变量部分是原用户的。\n\n","slug":"编程开发/Shell/sudo与su","published":1,"updated":"2022-09-15T03:46:43.364Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551rq0087jqrridgc85yr","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>sudo -u user单纯以某用户身份运行命令，并不切换环境，需要输入当前用户密码，。sudo的各类权限在/etc/sudoers配置</p>\n<p>su 则切换到某用户的环境下，需要输入某用户的密码。这里注意一定要加 su -  ，只有这样才会生成login shell加载/etc/profile和~/.bash_profile，如果不加的话，启动non-login shell，不加载上述文件，环境变量部分是原用户的。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>sudo -u user单纯以某用户身份运行命令，并不切换环境，需要输入当前用户密码，。sudo的各类权限在/etc/sudoers配置</p>\n<p>su 则切换到某用户的环境下，需要输入某用户的密码。这里注意一定要加 su -  ，只有这样才会生成login shell加载/etc/profile和~/.bash_profile，如果不加的话，启动non-login shell，不加载上述文件，环境变量部分是原用户的。</p>\n"},{"title":"关于nuhup与&","date":"2018-11-02T10:13:30.000Z","_content":"\nhttps://www.jianshu.com/p/747e0d5021a2\n\n \n\n- 如果后台&开了多个子进程，关闭父进程，子进程变成孤儿进程，继续运行。\n\n- 如果后台&开了多个子进程，关闭终端，进程全部结束。\n\n- 如果后台&开了多个字进程，但是用了nohup，关闭终端，子进程继续运行。\n\n- 如果后台&开了多个子进程，先关闭父进程，再关闭终端，子进程继续运行，子进程变成孤儿进程，父进程变了。\n\n","source":"_posts/编程开发/Shell/关于nuhup与&.md","raw":"---\ntitle: 关于nuhup与&\ndate: 2018-11-02 18:13:30\ncategories: [编程开发,Shell]\n---\n\nhttps://www.jianshu.com/p/747e0d5021a2\n\n \n\n- 如果后台&开了多个子进程，关闭父进程，子进程变成孤儿进程，继续运行。\n\n- 如果后台&开了多个子进程，关闭终端，进程全部结束。\n\n- 如果后台&开了多个字进程，但是用了nohup，关闭终端，子进程继续运行。\n\n- 如果后台&开了多个子进程，先关闭父进程，再关闭终端，子进程继续运行，子进程变成孤儿进程，父进程变了。\n\n","slug":"编程开发/Shell/关于nuhup与&","published":1,"updated":"2022-09-15T03:46:43.364Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551rq0089jqrr5wbsif8f","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p><a href=\"https://www.jianshu.com/p/747e0d5021a2\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/747e0d5021a2</a></p>\n<ul>\n<li><p>如果后台&amp;开了多个子进程，关闭父进程，子进程变成孤儿进程，继续运行。</p>\n</li>\n<li><p>如果后台&amp;开了多个子进程，关闭终端，进程全部结束。</p>\n</li>\n<li><p>如果后台&amp;开了多个字进程，但是用了nohup，关闭终端，子进程继续运行。</p>\n</li>\n<li><p>如果后台&amp;开了多个子进程，先关闭父进程，再关闭终端，子进程继续运行，子进程变成孤儿进程，父进程变了。</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.jianshu.com/p/747e0d5021a2\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/747e0d5021a2</a></p>\n<ul>\n<li><p>如果后台&amp;开了多个子进程，关闭父进程，子进程变成孤儿进程，继续运行。</p>\n</li>\n<li><p>如果后台&amp;开了多个子进程，关闭终端，进程全部结束。</p>\n</li>\n<li><p>如果后台&amp;开了多个字进程，但是用了nohup，关闭终端，子进程继续运行。</p>\n</li>\n<li><p>如果后台&amp;开了多个子进程，先关闭父进程，再关闭终端，子进程继续运行，子进程变成孤儿进程，父进程变了。</p>\n</li>\n</ul>\n"},{"title":"关于sh,source,exec","date":"2018-11-02T10:13:30.000Z","_content":"\n\n\nsource相当于把文件中的命令按顺序在当前shell执行一次\n\nsh则会另起一个子shell，export的环境变量不能返回到父shell\n\nhttps://www.jianshu.com/p/dd7956aec097\n\n","source":"_posts/编程开发/Shell/关于sh,source,exec.md","raw":"---\ntitle: 关于sh,source,exec\ndate: 2018-11-02 18:13:30\ncategories: [编程开发,Shell]\n---\n\n\n\nsource相当于把文件中的命令按顺序在当前shell执行一次\n\nsh则会另起一个子shell，export的环境变量不能返回到父shell\n\nhttps://www.jianshu.com/p/dd7956aec097\n\n","slug":"编程开发/Shell/关于sh,source,exec","published":1,"updated":"2022-09-15T03:46:43.364Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551rq008bjqrrx9sevq5y","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>source相当于把文件中的命令按顺序在当前shell执行一次</p>\n<p>sh则会另起一个子shell，export的环境变量不能返回到父shell</p>\n<p><a href=\"https://www.jianshu.com/p/dd7956aec097\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/dd7956aec097</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>source相当于把文件中的命令按顺序在当前shell执行一次</p>\n<p>sh则会另起一个子shell，export的环境变量不能返回到父shell</p>\n<p><a href=\"https://www.jianshu.com/p/dd7956aec097\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/dd7956aec097</a></p>\n"},{"title":"父子shell和父子进程","date":"2019-02-15T10:13:30.000Z","_content":"\n首先，shell也是一个进程！\n\n \n\n举个例子：\n\n在某个shell下(该shell也是一个进程，id为1)，执行一个脚本文件，同时便会生成一个非交互子shell（进程id为2），然后该脚本文件的每一行可执行程序，又会生成新的子进程id如3，4，5，6等等\n\n \n\n \n\n父子shell中的变量问题：\n\n- 普通自定义变量不会共享，只在当前shell生效\n\n- 环境变量：\n\n   如果没有切换用户，子shell（非交互式）共享父shell的环境变量\n\n   如果切换了用户:\n\n  - 假设是su，那会创建子non-login shell（交互式），环境变量部分新用户，部分原用户，部分消失(只加载~/.bashrc)\n\n  - 假设是su -，那会创建login shell（交互式），环境变量全部为新用户(加载/etc/profile,~/.bash_profile)\n\n \n\n ","source":"_posts/编程开发/Shell/父子shell和父子进程.md","raw":"---\ntitle: 父子shell和父子进程\ndate: 2019-02-15 18:13:30\ncategories: [编程开发,Shell]\n---\n\n首先，shell也是一个进程！\n\n \n\n举个例子：\n\n在某个shell下(该shell也是一个进程，id为1)，执行一个脚本文件，同时便会生成一个非交互子shell（进程id为2），然后该脚本文件的每一行可执行程序，又会生成新的子进程id如3，4，5，6等等\n\n \n\n \n\n父子shell中的变量问题：\n\n- 普通自定义变量不会共享，只在当前shell生效\n\n- 环境变量：\n\n   如果没有切换用户，子shell（非交互式）共享父shell的环境变量\n\n   如果切换了用户:\n\n  - 假设是su，那会创建子non-login shell（交互式），环境变量部分新用户，部分原用户，部分消失(只加载~/.bashrc)\n\n  - 假设是su -，那会创建login shell（交互式），环境变量全部为新用户(加载/etc/profile,~/.bash_profile)\n\n \n\n ","slug":"编程开发/Shell/父子shell和父子进程","published":1,"updated":"2022-09-15T03:46:43.364Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551rr008ejqrrgqbkth5t","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>首先，shell也是一个进程！</p>\n<p>举个例子：</p>\n<p>在某个shell下(该shell也是一个进程，id为1)，执行一个脚本文件，同时便会生成一个非交互子shell（进程id为2），然后该脚本文件的每一行可执行程序，又会生成新的子进程id如3，4，5，6等等</p>\n<p>父子shell中的变量问题：</p>\n<ul>\n<li><p>普通自定义变量不会共享，只在当前shell生效</p>\n</li>\n<li><p>环境变量：</p>\n<p> 如果没有切换用户，子shell（非交互式）共享父shell的环境变量</p>\n<p> 如果切换了用户:</p>\n<ul>\n<li><p>假设是su，那会创建子non-login shell（交互式），环境变量部分新用户，部分原用户，部分消失(只加载~/.bashrc)</p>\n</li>\n<li><p>假设是su -，那会创建login shell（交互式），环境变量全部为新用户(加载/etc/profile,~/.bash_profile)</p>\n</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>首先，shell也是一个进程！</p>\n<p>举个例子：</p>\n<p>在某个shell下(该shell也是一个进程，id为1)，执行一个脚本文件，同时便会生成一个非交互子shell（进程id为2），然后该脚本文件的每一行可执行程序，又会生成新的子进程id如3，4，5，6等等</p>\n<p>父子shell中的变量问题：</p>\n<ul>\n<li><p>普通自定义变量不会共享，只在当前shell生效</p>\n</li>\n<li><p>环境变量：</p>\n<p> 如果没有切换用户，子shell（非交互式）共享父shell的环境变量</p>\n<p> 如果切换了用户:</p>\n<ul>\n<li><p>假设是su，那会创建子non-login shell（交互式），环境变量部分新用户，部分原用户，部分消失(只加载~/.bashrc)</p>\n</li>\n<li><p>假设是su -，那会创建login shell（交互式），环境变量全部为新用户(加载/etc/profile,~/.bash_profile)</p>\n</li>\n</ul>\n</li>\n</ul>\n"},{"title":"Vim自动补全神器-YouCompleteMe","date":"2017-06-12T10:13:30.000Z","_content":"\n# Vim\nUbuntu自带的vim是vim.tiny版本，很多功能都不全，所以我们需要装一个完整版的，并且我习惯装一个gvim,`sudo apt-get install vim-gtk`。 有意思的是，我发现`apt-get`下面有一个叫`vim+youcompleteme`的版本，我就好奇得装了一下，结果打开vim发现并没有补全功能，但是却装了`ruby，nodejs,ycmd`等几个软件，`ycmd`应该就是补全软件，然而不知道该怎么在vim里使用...所以最终我还是按照github上的说明手动装了`youcompleteme`,这部分留到后文说。\n\n<!-- more -->\n\n## 插件Vundle\nVundle是一个很实用的vim插件，通过它可以方便得管理其他插件，安装很简单。\n```git\n$ git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim\n```\n\n装完之后，需要在`.vimrc`里进行配置，\n```\nset nocompatible              \" be iMproved, required\nfiletype off                  \" required\n\n\" set the runtime path to include Vundle and initialize\nset rtp+=~/.vim/bundle/Vundle.vim\ncall vundle#begin()\n\" alternatively, pass a path where Vundle should install plugins\n\"call vundle#begin('~/some/path/here')\n\n\" let Vundle manage Vundle, required\nPlugin 'VundleVim/Vundle.vim'\n\n\" The following are examples of different formats supported.\n\" Keep Plugin commands between vundle#begin/end.\n\" plugin on GitHub repo\nPlugin 'tpope/vim-fugitive'\n\" plugin from http://vim-scripts.org/vim/scripts.html\n\" Plugin 'L9'\n\" Git plugin not hosted on GitHub\nPlugin 'git://git.wincent.com/command-t.git'\n\" git repos on your local machine (i.e. when working on your own plugin)\nPlugin 'file:///home/gmarik/path/to/plugin'\n\" The sparkup vim script is in a subdirectory of this repo called vim.\n\" Pass the path to set the runtimepath properly.\nPlugin 'rstacruz/sparkup', {'rtp': 'vim/'}\n\" Install L9 and avoid a Naming conflict if you've already installed a\n\" different version somewhere else.\n\" Plugin 'ascenator/L9', {'name': 'newL9'}\n\n\" All of your Plugins must be added before the following line\ncall vundle#end()            \" required\nfiletype plugin indent on    \" required\n\" To ignore plugin indent changes, instead use:\n\"filetype plugin on\n\"\n\" Brief help\n\" :PluginList       - lists configured plugins\n\" :PluginInstall    - installs plugins; append `!` to update or just :PluginUpdate\n\" :PluginSearch foo - searches for foo; append `!` to refresh local cache\n\" :PluginClean      - confirms removal of unused plugins; append `!` to auto-approve removal\n\"\n\" see :h vundle for more details or wiki for FAQ\n\" Put your non-Plugin stuff after this line\n```\n\n最终打开vim，输入`：PluginInstall`来安装你在配置文件里写的插件。\n\n我安装了下面几个我常用的插件。\n```\n\" My Plugin here:\n\n\" plugin on GitHub repo\nPlugin 'Valloric/YouCompleteMe'\nPlugin 'luochen1990/rainbow'\nPlugin 'fholgado/minibufexpl.vim'\nPlugin 'scrooloose/nerdtree'\n```\n\n# YouCompleteMe\n在我的插件里可以看到我装了YouCompleteMe这个插件，但是光vundle装好还是不够的，我们需要再编译一个能用的引擎。\n\n## 安装必备的编译环境和python环境\n```\nsudo apt-get install build-essential cmake\nsudo apt-get install python-dev python3-dev\n```\n## 检查vim版本\n我们需要检查vim版本以及vim支持的python版本，保证vim版本高于7.4.1578,支持python2或者Python3。我们可以输入命令：`vim --version`来查看，以下是我的输出截图：\n![image.png](http://upload-images.jianshu.io/upload_images/825093-cc5dac3d1fd71ef2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/550)\n可以看到版本是7.4.1689，不支持python2,但支持python3（貌似Ubuntu16.04开始移除python2的支持了）。\n\n## 编译支持C家族语义补全的YCM\n```\ncd ~/.vim/bundle/YouCompleteMe\nPython3 ./install.py --clang-completer //由于我的vim只支持Python3,所以在前面加python3命令\n```\n命令执行之后，系统会去下载libclang,因为YCM语义支持是靠clang编译器的，这里需要经过漫长得等待。。如果一切顺利的话，YCM就安装完毕了。\n\n##YCM配置\n我的YCM配置如下：\n```\n\"YouCompleteMe\n\"let g:ycm_path_to_python_interpreter = '/usr/bin/python'\nset runtimepath+=~/.vim/bundle/YouCompleteMe\nlet g:ycm_collect_identifiers_from_tags_files = 1           \" 开启 YCM 基于标签引擎\nlet g:ycm_collect_identifiers_from_comments_and_strings = 1 \" 注释与字符串中的内容也用于补全\nlet g:syntastic_ignore_files=[\".*\\.py$\"]\nlet g:ycm_seed_identifiers_with_syntax = 1                  \" 语法关键字补全\nlet g:ycm_complete_in_comments = 1\nlet g:ycm_confirm_extra_conf = 0\n\"let g:ycm_key_list_select_completion = ['<c-n>', '<Down>']  \" 映射按键, 没有这个会拦截掉tab, 导致其他插件的tab不能用.\n\"let g:ycm_key_list_previous_completion = ['<c-p>', '<Up>']\nlet g:ycm_complete_in_comments = 1                          \" 在注释输入中也能补全\nlet g:ycm_complete_in_strings = 1                           \" 在字符串输入中也能补全\nlet g:ycm_collect_identifiers_from_comments_and_strings = 1 \" 注释和字符串中的文字也会被收入补全\nlet g:ycm_global_ycm_extra_conf='~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py'\n\"let g:ycm_show_diagnostics_ui = 0                           \" 禁用语法检查\ninoremap <expr> <CR> pumvisible() ? \"\\<C-y>\" : \"\\<CR>\" |            \" 回车即选中当前项\nnnoremap <F5> :YcmCompleter GoToDefinitionElseDeclaration<CR>\n\"let g:ycm_min_num_of_chars_for_completion=2                 \" 从第2个键入字符就开始罗列匹配项\nlet g:ycm_autoclose_preview_window_after_completion = 1  \" 补全后自动关闭preview\n```\n一个能够进行语法检查，自动补全，并且GoToDefinition的YCM就可以使用了，但是还有一点瑕疵：＃include <iostream>, #include <stdio> vector, 什么的都不能补全，这是因为这些头文件的路径没有被找到，下面的工作就是要让YouCompleteMe找到这些头文件，而且，以后有什么库文件，比如OpenCV，OPenGL什么的，都可以按照这个方法添加。\n\n打开并编辑~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py，这就是我们设定vim默认调用的YCM配置文件，然后可以在flags[*]数组的后面添加你想要的路径，例如: stdio.h等Ｃ语言的头文件包含在/usr/include中，那么您需要添加这样一条\n> \n'-isystem',\n‘/usr/include’,\n\n如果需要C++的补全，就需要添加：\n> \n'-isystem',\n‘/usr/include/c++/5’,\n\n需要什么，就添加什么，现在编辑c/c++文件你就发现支持头文件补全了！\n\n# 我的vim配置\n根据个人习惯，我的vimrc配置如下：\n```\n\"Wei Lyu\n\"levy_lv@hotmail.com\n\"levylv.github.io\n\n\"====================\"\n\"        通用        \"\n\"====================\"\nset nocompatible              \" be iMproved, required\nfiletype plugin indent on\nset nobackup \"不备份 \nset autochdir \"自动切换当前目录\nset mouse=a\n\n\"启动，语法高亮，配色\nwinpos 500 200   \"窗口位置\nset lines=30 columns=85  \"窗口大小\nset guioptions-=T  \"不要菜单栏\nset laststatus=2   \"总是显示状态栏\nset hlsearch  \"搜索高亮\nset ignorecase \"搜索忽略大小写\nsyntax enable\nsyntax on\nset t_Co=256\nset cursorline \"高亮光标行\nset ruler   \"显示光标位置状态栏\nset number\nset guifont=Ubuntu\\ Mono\\ 13\ncolorscheme molokai\nset clipboard=unnamed \"可以用系统剪贴板\n\n\"Tab相关\nset expandtab \"制表符扩展为空格\nset tabstop=4 \"制表符占用空格数\nset softtabstop=4 \"将连续数量的空格视为一个制表符\nset shiftwidth=4 \"格式化时制表符占用空格数\nset cindent\nset autoindent\n\n\"编码相关\nset encoding=utf-8\nset langmenu=zh_CN.UTF-8\nlanguage message zh_CN.UTF-8\nset fileencodings=ucs-bom,utf-8,cp936,gb18030,big5,euc-jp,euc-kr,latin1\n\n\"使用CTRL+[hjkl]在窗口间导航\"\nmap <C-c> <C-W>c\nmap <C-j> <C-W>j\nmap <C-k> <C-W>k\nmap <C-h> <C-W>h\nmap <C-l> <C-W>l\n\n\"使用箭头导航buffer\"\nmap <right> :bn<cr>\nmap <left> :bp<cr>\nset autowrite \"在切换buffer时自动保存当前的文件\n\n\"\"使用ALT+[jk]来移动行内容\nnmap <M-j> mz:m+<cr>`z\nnmap <M-k> mz:m-2<cr>`z\nvmap <M-j> :m'>+<cr>`<my`>mzgv`yo`z\nvmap <M-k> :m'<-2<cr>`>my`<mzgv`yo`z\n\n\"根据文件类型做不同处理\nfunction HeaderPython()  \"python加头注释\n    call setline(1, \"#!/usr/bin/env python3\")\n    call append(1,  \"# -*- coding: utf-8 -*-\")\n    call append(2,  \"# mail:levy_lv@hotmail.com\")\n    call append(3,  \"# Lyu Wei @ \" . strftime('%Y-%m-%d', localtime()))\n    normal G\n    normal o\n    normal o\nendf\nautocmd bufnewfile *.py call HeaderPython()\n\nfunction HeaderBash()  \"shell脚本加注释\n    call setline(1, \"#!/bin/bash\")\n    call append(1,  \"# -*- coding: utf-8 -*-\")\n    call append(2,  \"# mail:levy_lv@hotmail.com\")\n    call append(3,  \"# Lyu Wei @ \" . strftime('%Y-%m-%d', localtime()))\n    normal G\n    normal o\n    normal o\nendf\nautocmd bufnewfile *.sh call HeaderBash()\n\nfunction HeaderCpp() \"C++文件加头文件\n    call setline(1, \"#include <iostream>\")\n    call append(1, \"using namespace std;\")\n    normal G\n    normal o\n    normal o\nendf\nautocmd bufnewfile *.cpp,*.cc call HeaderCpp()\n\n\"C,C++单个文件调试\nmap <F8> :call Rungdb()<CR>\nfunc! Rungdb()\n    exec \"w\"\n    exec \"!g++ % -g -o %<\"\n    exec \"!gdb ./%<\"\nendfunc\n\n\"====================\"\n\"Vundle Configuration\"\n\"====================\"\nfiletype off                  \" required\n\n\" set the runtime path to include Vundle and initialize\nset rtp+=~/.vim/bundle/Vundle.vim\ncall vundle#begin()\n\" alternatively, pass a path where Vundle should install plugins\n\"call vundle#begin('~/some/path/here')\n\n\" let Vundle manage Vundle, required\nPlugin 'VundleVim/Vundle.vim'\n\n\" My Plugin here:\n\n\" plugin on GitHub repo\nPlugin 'Valloric/YouCompleteMe'\nPlugin 'luochen1990/rainbow'\n\"Plugin 'majutsushi/tagbar'\nPlugin 'fholgado/minibufexpl.vim'\nPlugin 'scrooloose/nerdtree'\n\n\n\n\" All of your Plugins must be added before the following line\ncall vundle#end()            \" required\nfiletype plugin indent on    \" required\n\n\n\"===========================\"\n\"Vundle Plugin Configuration\"\n\"===========================\"\n\n\"Rainbow\nlet g:rainbow_active = 1 \" 0 if you want to enable it later via: RainbowTogglw\n\n\"Tagbar\n\"nmap <F8> :TagbarToggle<CR>\n\n\"YouCompleteMe\n\"let g:ycm_path_to_python_interpreter = '/usr/bin/python'\nset runtimepath+=~/.vim/bundle/YouCompleteMe\nlet g:ycm_collect_identifiers_from_tags_files = 1           \" 开启 YCM 基于标签引擎\nlet g:ycm_collect_identifiers_from_comments_and_strings = 1 \" 注释与字符串中的内容也用于补全\nlet g:syntastic_ignore_files=[\".*\\.py$\"]\nlet g:ycm_seed_identifiers_with_syntax = 1                  \" 语法关键字补全\nlet g:ycm_complete_in_comments = 1\nlet g:ycm_confirm_extra_conf = 0\n\"let g:ycm_key_list_select_completion = ['<c-n>', '<Down>']  \" 映射按键, 没有这个会拦截掉tab, 导致其他插件的tab不能用.\n\"let g:ycm_key_list_previous_completion = ['<c-p>', '<Up>']\nlet g:ycm_complete_in_comments = 1                          \" 在注释输入中也能补全\nlet g:ycm_complete_in_strings = 1                           \" 在字符串输入中也能补全\nlet g:ycm_collect_identifiers_from_comments_and_strings = 1 \" 注释和字符串中的文字也会被收入补全\nlet g:ycm_global_ycm_extra_conf='~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py'\n\"let g:ycm_show_diagnostics_ui = 0                           \" 禁用语法检查\ninoremap <expr> <CR> pumvisible() ? \"\\<C-y>\" : \"\\<CR>\" |            \" 回车即选中当前项\nnnoremap <F5> :YcmCompleter GoToDefinitionElseDeclaration<CR>\n\"let g:ycm_min_num_of_chars_for_completion=2                 \" 从第2个键入字符就开始罗列匹配项\nlet g:ycm_autoclose_preview_window_after_completion = 1  \" 补全后自动关闭preview\n\n\"minibufexpl\nlet g:miniBufExplMapWindowNavVim = 1 \"可以用<C-h,j,k,l>切换到上下左右的窗口 \nlet g:miniBufExplMapCTabSwitchBufs = 1 \"<C-Tab>,<C-S-Tab>切换\nlet g:miniBufExplModSelTarget = 1 \n\n\"NERDTree\nnnoremap <F4> :NERDTreeToggle<CR>\n\n\n```\n","source":"_posts/编程开发/Vim/Vim自动补全神器.md","raw":"---\ntitle: Vim自动补全神器-YouCompleteMe\ndate: 2017-06-12 18:13:30\ncategories: [编程开发,Vim]\n---\n\n# Vim\nUbuntu自带的vim是vim.tiny版本，很多功能都不全，所以我们需要装一个完整版的，并且我习惯装一个gvim,`sudo apt-get install vim-gtk`。 有意思的是，我发现`apt-get`下面有一个叫`vim+youcompleteme`的版本，我就好奇得装了一下，结果打开vim发现并没有补全功能，但是却装了`ruby，nodejs,ycmd`等几个软件，`ycmd`应该就是补全软件，然而不知道该怎么在vim里使用...所以最终我还是按照github上的说明手动装了`youcompleteme`,这部分留到后文说。\n\n<!-- more -->\n\n## 插件Vundle\nVundle是一个很实用的vim插件，通过它可以方便得管理其他插件，安装很简单。\n```git\n$ git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim\n```\n\n装完之后，需要在`.vimrc`里进行配置，\n```\nset nocompatible              \" be iMproved, required\nfiletype off                  \" required\n\n\" set the runtime path to include Vundle and initialize\nset rtp+=~/.vim/bundle/Vundle.vim\ncall vundle#begin()\n\" alternatively, pass a path where Vundle should install plugins\n\"call vundle#begin('~/some/path/here')\n\n\" let Vundle manage Vundle, required\nPlugin 'VundleVim/Vundle.vim'\n\n\" The following are examples of different formats supported.\n\" Keep Plugin commands between vundle#begin/end.\n\" plugin on GitHub repo\nPlugin 'tpope/vim-fugitive'\n\" plugin from http://vim-scripts.org/vim/scripts.html\n\" Plugin 'L9'\n\" Git plugin not hosted on GitHub\nPlugin 'git://git.wincent.com/command-t.git'\n\" git repos on your local machine (i.e. when working on your own plugin)\nPlugin 'file:///home/gmarik/path/to/plugin'\n\" The sparkup vim script is in a subdirectory of this repo called vim.\n\" Pass the path to set the runtimepath properly.\nPlugin 'rstacruz/sparkup', {'rtp': 'vim/'}\n\" Install L9 and avoid a Naming conflict if you've already installed a\n\" different version somewhere else.\n\" Plugin 'ascenator/L9', {'name': 'newL9'}\n\n\" All of your Plugins must be added before the following line\ncall vundle#end()            \" required\nfiletype plugin indent on    \" required\n\" To ignore plugin indent changes, instead use:\n\"filetype plugin on\n\"\n\" Brief help\n\" :PluginList       - lists configured plugins\n\" :PluginInstall    - installs plugins; append `!` to update or just :PluginUpdate\n\" :PluginSearch foo - searches for foo; append `!` to refresh local cache\n\" :PluginClean      - confirms removal of unused plugins; append `!` to auto-approve removal\n\"\n\" see :h vundle for more details or wiki for FAQ\n\" Put your non-Plugin stuff after this line\n```\n\n最终打开vim，输入`：PluginInstall`来安装你在配置文件里写的插件。\n\n我安装了下面几个我常用的插件。\n```\n\" My Plugin here:\n\n\" plugin on GitHub repo\nPlugin 'Valloric/YouCompleteMe'\nPlugin 'luochen1990/rainbow'\nPlugin 'fholgado/minibufexpl.vim'\nPlugin 'scrooloose/nerdtree'\n```\n\n# YouCompleteMe\n在我的插件里可以看到我装了YouCompleteMe这个插件，但是光vundle装好还是不够的，我们需要再编译一个能用的引擎。\n\n## 安装必备的编译环境和python环境\n```\nsudo apt-get install build-essential cmake\nsudo apt-get install python-dev python3-dev\n```\n## 检查vim版本\n我们需要检查vim版本以及vim支持的python版本，保证vim版本高于7.4.1578,支持python2或者Python3。我们可以输入命令：`vim --version`来查看，以下是我的输出截图：\n![image.png](http://upload-images.jianshu.io/upload_images/825093-cc5dac3d1fd71ef2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/550)\n可以看到版本是7.4.1689，不支持python2,但支持python3（貌似Ubuntu16.04开始移除python2的支持了）。\n\n## 编译支持C家族语义补全的YCM\n```\ncd ~/.vim/bundle/YouCompleteMe\nPython3 ./install.py --clang-completer //由于我的vim只支持Python3,所以在前面加python3命令\n```\n命令执行之后，系统会去下载libclang,因为YCM语义支持是靠clang编译器的，这里需要经过漫长得等待。。如果一切顺利的话，YCM就安装完毕了。\n\n##YCM配置\n我的YCM配置如下：\n```\n\"YouCompleteMe\n\"let g:ycm_path_to_python_interpreter = '/usr/bin/python'\nset runtimepath+=~/.vim/bundle/YouCompleteMe\nlet g:ycm_collect_identifiers_from_tags_files = 1           \" 开启 YCM 基于标签引擎\nlet g:ycm_collect_identifiers_from_comments_and_strings = 1 \" 注释与字符串中的内容也用于补全\nlet g:syntastic_ignore_files=[\".*\\.py$\"]\nlet g:ycm_seed_identifiers_with_syntax = 1                  \" 语法关键字补全\nlet g:ycm_complete_in_comments = 1\nlet g:ycm_confirm_extra_conf = 0\n\"let g:ycm_key_list_select_completion = ['<c-n>', '<Down>']  \" 映射按键, 没有这个会拦截掉tab, 导致其他插件的tab不能用.\n\"let g:ycm_key_list_previous_completion = ['<c-p>', '<Up>']\nlet g:ycm_complete_in_comments = 1                          \" 在注释输入中也能补全\nlet g:ycm_complete_in_strings = 1                           \" 在字符串输入中也能补全\nlet g:ycm_collect_identifiers_from_comments_and_strings = 1 \" 注释和字符串中的文字也会被收入补全\nlet g:ycm_global_ycm_extra_conf='~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py'\n\"let g:ycm_show_diagnostics_ui = 0                           \" 禁用语法检查\ninoremap <expr> <CR> pumvisible() ? \"\\<C-y>\" : \"\\<CR>\" |            \" 回车即选中当前项\nnnoremap <F5> :YcmCompleter GoToDefinitionElseDeclaration<CR>\n\"let g:ycm_min_num_of_chars_for_completion=2                 \" 从第2个键入字符就开始罗列匹配项\nlet g:ycm_autoclose_preview_window_after_completion = 1  \" 补全后自动关闭preview\n```\n一个能够进行语法检查，自动补全，并且GoToDefinition的YCM就可以使用了，但是还有一点瑕疵：＃include <iostream>, #include <stdio> vector, 什么的都不能补全，这是因为这些头文件的路径没有被找到，下面的工作就是要让YouCompleteMe找到这些头文件，而且，以后有什么库文件，比如OpenCV，OPenGL什么的，都可以按照这个方法添加。\n\n打开并编辑~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py，这就是我们设定vim默认调用的YCM配置文件，然后可以在flags[*]数组的后面添加你想要的路径，例如: stdio.h等Ｃ语言的头文件包含在/usr/include中，那么您需要添加这样一条\n> \n'-isystem',\n‘/usr/include’,\n\n如果需要C++的补全，就需要添加：\n> \n'-isystem',\n‘/usr/include/c++/5’,\n\n需要什么，就添加什么，现在编辑c/c++文件你就发现支持头文件补全了！\n\n# 我的vim配置\n根据个人习惯，我的vimrc配置如下：\n```\n\"Wei Lyu\n\"levy_lv@hotmail.com\n\"levylv.github.io\n\n\"====================\"\n\"        通用        \"\n\"====================\"\nset nocompatible              \" be iMproved, required\nfiletype plugin indent on\nset nobackup \"不备份 \nset autochdir \"自动切换当前目录\nset mouse=a\n\n\"启动，语法高亮，配色\nwinpos 500 200   \"窗口位置\nset lines=30 columns=85  \"窗口大小\nset guioptions-=T  \"不要菜单栏\nset laststatus=2   \"总是显示状态栏\nset hlsearch  \"搜索高亮\nset ignorecase \"搜索忽略大小写\nsyntax enable\nsyntax on\nset t_Co=256\nset cursorline \"高亮光标行\nset ruler   \"显示光标位置状态栏\nset number\nset guifont=Ubuntu\\ Mono\\ 13\ncolorscheme molokai\nset clipboard=unnamed \"可以用系统剪贴板\n\n\"Tab相关\nset expandtab \"制表符扩展为空格\nset tabstop=4 \"制表符占用空格数\nset softtabstop=4 \"将连续数量的空格视为一个制表符\nset shiftwidth=4 \"格式化时制表符占用空格数\nset cindent\nset autoindent\n\n\"编码相关\nset encoding=utf-8\nset langmenu=zh_CN.UTF-8\nlanguage message zh_CN.UTF-8\nset fileencodings=ucs-bom,utf-8,cp936,gb18030,big5,euc-jp,euc-kr,latin1\n\n\"使用CTRL+[hjkl]在窗口间导航\"\nmap <C-c> <C-W>c\nmap <C-j> <C-W>j\nmap <C-k> <C-W>k\nmap <C-h> <C-W>h\nmap <C-l> <C-W>l\n\n\"使用箭头导航buffer\"\nmap <right> :bn<cr>\nmap <left> :bp<cr>\nset autowrite \"在切换buffer时自动保存当前的文件\n\n\"\"使用ALT+[jk]来移动行内容\nnmap <M-j> mz:m+<cr>`z\nnmap <M-k> mz:m-2<cr>`z\nvmap <M-j> :m'>+<cr>`<my`>mzgv`yo`z\nvmap <M-k> :m'<-2<cr>`>my`<mzgv`yo`z\n\n\"根据文件类型做不同处理\nfunction HeaderPython()  \"python加头注释\n    call setline(1, \"#!/usr/bin/env python3\")\n    call append(1,  \"# -*- coding: utf-8 -*-\")\n    call append(2,  \"# mail:levy_lv@hotmail.com\")\n    call append(3,  \"# Lyu Wei @ \" . strftime('%Y-%m-%d', localtime()))\n    normal G\n    normal o\n    normal o\nendf\nautocmd bufnewfile *.py call HeaderPython()\n\nfunction HeaderBash()  \"shell脚本加注释\n    call setline(1, \"#!/bin/bash\")\n    call append(1,  \"# -*- coding: utf-8 -*-\")\n    call append(2,  \"# mail:levy_lv@hotmail.com\")\n    call append(3,  \"# Lyu Wei @ \" . strftime('%Y-%m-%d', localtime()))\n    normal G\n    normal o\n    normal o\nendf\nautocmd bufnewfile *.sh call HeaderBash()\n\nfunction HeaderCpp() \"C++文件加头文件\n    call setline(1, \"#include <iostream>\")\n    call append(1, \"using namespace std;\")\n    normal G\n    normal o\n    normal o\nendf\nautocmd bufnewfile *.cpp,*.cc call HeaderCpp()\n\n\"C,C++单个文件调试\nmap <F8> :call Rungdb()<CR>\nfunc! Rungdb()\n    exec \"w\"\n    exec \"!g++ % -g -o %<\"\n    exec \"!gdb ./%<\"\nendfunc\n\n\"====================\"\n\"Vundle Configuration\"\n\"====================\"\nfiletype off                  \" required\n\n\" set the runtime path to include Vundle and initialize\nset rtp+=~/.vim/bundle/Vundle.vim\ncall vundle#begin()\n\" alternatively, pass a path where Vundle should install plugins\n\"call vundle#begin('~/some/path/here')\n\n\" let Vundle manage Vundle, required\nPlugin 'VundleVim/Vundle.vim'\n\n\" My Plugin here:\n\n\" plugin on GitHub repo\nPlugin 'Valloric/YouCompleteMe'\nPlugin 'luochen1990/rainbow'\n\"Plugin 'majutsushi/tagbar'\nPlugin 'fholgado/minibufexpl.vim'\nPlugin 'scrooloose/nerdtree'\n\n\n\n\" All of your Plugins must be added before the following line\ncall vundle#end()            \" required\nfiletype plugin indent on    \" required\n\n\n\"===========================\"\n\"Vundle Plugin Configuration\"\n\"===========================\"\n\n\"Rainbow\nlet g:rainbow_active = 1 \" 0 if you want to enable it later via: RainbowTogglw\n\n\"Tagbar\n\"nmap <F8> :TagbarToggle<CR>\n\n\"YouCompleteMe\n\"let g:ycm_path_to_python_interpreter = '/usr/bin/python'\nset runtimepath+=~/.vim/bundle/YouCompleteMe\nlet g:ycm_collect_identifiers_from_tags_files = 1           \" 开启 YCM 基于标签引擎\nlet g:ycm_collect_identifiers_from_comments_and_strings = 1 \" 注释与字符串中的内容也用于补全\nlet g:syntastic_ignore_files=[\".*\\.py$\"]\nlet g:ycm_seed_identifiers_with_syntax = 1                  \" 语法关键字补全\nlet g:ycm_complete_in_comments = 1\nlet g:ycm_confirm_extra_conf = 0\n\"let g:ycm_key_list_select_completion = ['<c-n>', '<Down>']  \" 映射按键, 没有这个会拦截掉tab, 导致其他插件的tab不能用.\n\"let g:ycm_key_list_previous_completion = ['<c-p>', '<Up>']\nlet g:ycm_complete_in_comments = 1                          \" 在注释输入中也能补全\nlet g:ycm_complete_in_strings = 1                           \" 在字符串输入中也能补全\nlet g:ycm_collect_identifiers_from_comments_and_strings = 1 \" 注释和字符串中的文字也会被收入补全\nlet g:ycm_global_ycm_extra_conf='~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py'\n\"let g:ycm_show_diagnostics_ui = 0                           \" 禁用语法检查\ninoremap <expr> <CR> pumvisible() ? \"\\<C-y>\" : \"\\<CR>\" |            \" 回车即选中当前项\nnnoremap <F5> :YcmCompleter GoToDefinitionElseDeclaration<CR>\n\"let g:ycm_min_num_of_chars_for_completion=2                 \" 从第2个键入字符就开始罗列匹配项\nlet g:ycm_autoclose_preview_window_after_completion = 1  \" 补全后自动关闭preview\n\n\"minibufexpl\nlet g:miniBufExplMapWindowNavVim = 1 \"可以用<C-h,j,k,l>切换到上下左右的窗口 \nlet g:miniBufExplMapCTabSwitchBufs = 1 \"<C-Tab>,<C-S-Tab>切换\nlet g:miniBufExplModSelTarget = 1 \n\n\"NERDTree\nnnoremap <F4> :NERDTreeToggle<CR>\n\n\n```\n","slug":"编程开发/Vim/Vim自动补全神器","published":1,"updated":"2022-09-15T03:46:43.364Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl9o551rv008fjqrro2kuchlr","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"Vim\"><a href=\"#Vim\" class=\"headerlink\" title=\"Vim\"></a>Vim</h1><p>Ubuntu自带的vim是vim.tiny版本，很多功能都不全，所以我们需要装一个完整版的，并且我习惯装一个gvim,<code>sudo apt-get install vim-gtk</code>。 有意思的是，我发现<code>apt-get</code>下面有一个叫<code>vim+youcompleteme</code>的版本，我就好奇得装了一下，结果打开vim发现并没有补全功能，但是却装了<code>ruby，nodejs,ycmd</code>等几个软件，<code>ycmd</code>应该就是补全软件，然而不知道该怎么在vim里使用…所以最终我还是按照github上的说明手动装了<code>youcompleteme</code>,这部分留到后文说。</p>\n<a id=\"more\"></a>\n<h2 id=\"插件Vundle\"><a href=\"#插件Vundle\" class=\"headerlink\" title=\"插件Vundle\"></a>插件Vundle</h2><p>Vundle是一个很实用的vim插件，通过它可以方便得管理其他插件，安装很简单。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim</span><br></pre></td></tr></table></figure></p>\n<p>装完之后，需要在<code>.vimrc</code>里进行配置，<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set nocompatible              &quot; be iMproved, required</span><br><span class=\"line\">filetype off                  &quot; required</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; set the runtime path to include Vundle and initialize</span><br><span class=\"line\">set rtp+=~/.vim/bundle/Vundle.vim</span><br><span class=\"line\">call vundle#begin()</span><br><span class=\"line\">&quot; alternatively, pass a path where Vundle should install plugins</span><br><span class=\"line\">&quot;call vundle#begin(&apos;~/some/path/here&apos;)</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; let Vundle manage Vundle, required</span><br><span class=\"line\">Plugin &apos;VundleVim/Vundle.vim&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; The following are examples of different formats supported.</span><br><span class=\"line\">&quot; Keep Plugin commands between vundle#begin/end.</span><br><span class=\"line\">&quot; plugin on GitHub repo</span><br><span class=\"line\">Plugin &apos;tpope/vim-fugitive&apos;</span><br><span class=\"line\">&quot; plugin from http://vim-scripts.org/vim/scripts.html</span><br><span class=\"line\">&quot; Plugin &apos;L9&apos;</span><br><span class=\"line\">&quot; Git plugin not hosted on GitHub</span><br><span class=\"line\">Plugin &apos;git://git.wincent.com/command-t.git&apos;</span><br><span class=\"line\">&quot; git repos on your local machine (i.e. when working on your own plugin)</span><br><span class=\"line\">Plugin &apos;file:///home/gmarik/path/to/plugin&apos;</span><br><span class=\"line\">&quot; The sparkup vim script is in a subdirectory of this repo called vim.</span><br><span class=\"line\">&quot; Pass the path to set the runtimepath properly.</span><br><span class=\"line\">Plugin &apos;rstacruz/sparkup&apos;, &#123;&apos;rtp&apos;: &apos;vim/&apos;&#125;</span><br><span class=\"line\">&quot; Install L9 and avoid a Naming conflict if you&apos;ve already installed a</span><br><span class=\"line\">&quot; different version somewhere else.</span><br><span class=\"line\">&quot; Plugin &apos;ascenator/L9&apos;, &#123;&apos;name&apos;: &apos;newL9&apos;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; All of your Plugins must be added before the following line</span><br><span class=\"line\">call vundle#end()            &quot; required</span><br><span class=\"line\">filetype plugin indent on    &quot; required</span><br><span class=\"line\">&quot; To ignore plugin indent changes, instead use:</span><br><span class=\"line\">&quot;filetype plugin on</span><br><span class=\"line\">&quot;</span><br><span class=\"line\">&quot; Brief help</span><br><span class=\"line\">&quot; :PluginList       - lists configured plugins</span><br><span class=\"line\">&quot; :PluginInstall    - installs plugins; append `!` to update or just :PluginUpdate</span><br><span class=\"line\">&quot; :PluginSearch foo - searches for foo; append `!` to refresh local cache</span><br><span class=\"line\">&quot; :PluginClean      - confirms removal of unused plugins; append `!` to auto-approve removal</span><br><span class=\"line\">&quot;</span><br><span class=\"line\">&quot; see :h vundle for more details or wiki for FAQ</span><br><span class=\"line\">&quot; Put your non-Plugin stuff after this line</span><br></pre></td></tr></table></figure></p>\n<p>最终打开vim，输入<code>：PluginInstall</code>来安装你在配置文件里写的插件。</p>\n<p>我安装了下面几个我常用的插件。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot; My Plugin here:</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; plugin on GitHub repo</span><br><span class=\"line\">Plugin &apos;Valloric/YouCompleteMe&apos;</span><br><span class=\"line\">Plugin &apos;luochen1990/rainbow&apos;</span><br><span class=\"line\">Plugin &apos;fholgado/minibufexpl.vim&apos;</span><br><span class=\"line\">Plugin &apos;scrooloose/nerdtree&apos;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"YouCompleteMe\"><a href=\"#YouCompleteMe\" class=\"headerlink\" title=\"YouCompleteMe\"></a>YouCompleteMe</h1><p>在我的插件里可以看到我装了YouCompleteMe这个插件，但是光vundle装好还是不够的，我们需要再编译一个能用的引擎。</p>\n<h2 id=\"安装必备的编译环境和python环境\"><a href=\"#安装必备的编译环境和python环境\" class=\"headerlink\" title=\"安装必备的编译环境和python环境\"></a>安装必备的编译环境和python环境</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install build-essential cmake</span><br><span class=\"line\">sudo apt-get install python-dev python3-dev</span><br></pre></td></tr></table></figure>\n<h2 id=\"检查vim版本\"><a href=\"#检查vim版本\" class=\"headerlink\" title=\"检查vim版本\"></a>检查vim版本</h2><p>我们需要检查vim版本以及vim支持的python版本，保证vim版本高于7.4.1578,支持python2或者Python3。我们可以输入命令：<code>vim --version</code>来查看，以下是我的输出截图：<br><img src=\"http://upload-images.jianshu.io/upload_images/825093-cc5dac3d1fd71ef2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/550\" alt=\"image.png\"><br>可以看到版本是7.4.1689，不支持python2,但支持python3（貌似Ubuntu16.04开始移除python2的支持了）。</p>\n<h2 id=\"编译支持C家族语义补全的YCM\"><a href=\"#编译支持C家族语义补全的YCM\" class=\"headerlink\" title=\"编译支持C家族语义补全的YCM\"></a>编译支持C家族语义补全的YCM</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd ~/.vim/bundle/YouCompleteMe</span><br><span class=\"line\">Python3 ./install.py --clang-completer //由于我的vim只支持Python3,所以在前面加python3命令</span><br></pre></td></tr></table></figure>\n<p>命令执行之后，系统会去下载libclang,因为YCM语义支持是靠clang编译器的，这里需要经过漫长得等待。。如果一切顺利的话，YCM就安装完毕了。</p>\n<h2 id=\"YCM配置\"><a href=\"#YCM配置\" class=\"headerlink\" title=\"YCM配置\"></a>YCM配置</h2><p>我的YCM配置如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;YouCompleteMe</span><br><span class=\"line\">&quot;let g:ycm_path_to_python_interpreter = &apos;/usr/bin/python&apos;</span><br><span class=\"line\">set runtimepath+=~/.vim/bundle/YouCompleteMe</span><br><span class=\"line\">let g:ycm_collect_identifiers_from_tags_files = 1           &quot; 开启 YCM 基于标签引擎</span><br><span class=\"line\">let g:ycm_collect_identifiers_from_comments_and_strings = 1 &quot; 注释与字符串中的内容也用于补全</span><br><span class=\"line\">let g:syntastic_ignore_files=[&quot;.*\\.py$&quot;]</span><br><span class=\"line\">let g:ycm_seed_identifiers_with_syntax = 1                  &quot; 语法关键字补全</span><br><span class=\"line\">let g:ycm_complete_in_comments = 1</span><br><span class=\"line\">let g:ycm_confirm_extra_conf = 0</span><br><span class=\"line\">&quot;let g:ycm_key_list_select_completion = [&apos;&lt;c-n&gt;&apos;, &apos;&lt;Down&gt;&apos;]  &quot; 映射按键, 没有这个会拦截掉tab, 导致其他插件的tab不能用.</span><br><span class=\"line\">&quot;let g:ycm_key_list_previous_completion = [&apos;&lt;c-p&gt;&apos;, &apos;&lt;Up&gt;&apos;]</span><br><span class=\"line\">let g:ycm_complete_in_comments = 1                          &quot; 在注释输入中也能补全</span><br><span class=\"line\">let g:ycm_complete_in_strings = 1                           &quot; 在字符串输入中也能补全</span><br><span class=\"line\">let g:ycm_collect_identifiers_from_comments_and_strings = 1 &quot; 注释和字符串中的文字也会被收入补全</span><br><span class=\"line\">let g:ycm_global_ycm_extra_conf=&apos;~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py&apos;</span><br><span class=\"line\">&quot;let g:ycm_show_diagnostics_ui = 0                           &quot; 禁用语法检查</span><br><span class=\"line\">inoremap &lt;expr&gt; &lt;CR&gt; pumvisible() ? &quot;\\&lt;C-y&gt;&quot; : &quot;\\&lt;CR&gt;&quot; |            &quot; 回车即选中当前项</span><br><span class=\"line\">nnoremap &lt;F5&gt; :YcmCompleter GoToDefinitionElseDeclaration&lt;CR&gt;</span><br><span class=\"line\">&quot;let g:ycm_min_num_of_chars_for_completion=2                 &quot; 从第2个键入字符就开始罗列匹配项</span><br><span class=\"line\">let g:ycm_autoclose_preview_window_after_completion = 1  &quot; 补全后自动关闭preview</span><br></pre></td></tr></table></figure></p>\n<p>一个能够进行语法检查，自动补全，并且GoToDefinition的YCM就可以使用了，但是还有一点瑕疵：＃include <iostream>, #include <stdio> vector, 什么的都不能补全，这是因为这些头文件的路径没有被找到，下面的工作就是要让YouCompleteMe找到这些头文件，而且，以后有什么库文件，比如OpenCV，OPenGL什么的，都可以按照这个方法添加。</stdio></iostream></p>\n<p>打开并编辑~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py，这就是我们设定vim默认调用的YCM配置文件，然后可以在flags[*]数组的后面添加你想要的路径，例如: stdio.h等Ｃ语言的头文件包含在/usr/include中，那么您需要添加这样一条</p>\n<blockquote>\n<p>‘-isystem’,<br>‘/usr/include’,</p>\n</blockquote>\n<p>如果需要C++的补全，就需要添加：</p>\n<blockquote>\n<p>‘-isystem’,<br>‘/usr/include/c++/5’,</p>\n</blockquote>\n<p>需要什么，就添加什么，现在编辑c/c++文件你就发现支持头文件补全了！</p>\n<h1 id=\"我的vim配置\"><a href=\"#我的vim配置\" class=\"headerlink\" title=\"我的vim配置\"></a>我的vim配置</h1><p>根据个人习惯，我的vimrc配置如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;Wei Lyu</span><br><span class=\"line\">&quot;levy_lv@hotmail.com</span><br><span class=\"line\">&quot;levylv.github.io</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;====================&quot;</span><br><span class=\"line\">&quot;        通用        &quot;</span><br><span class=\"line\">&quot;====================&quot;</span><br><span class=\"line\">set nocompatible              &quot; be iMproved, required</span><br><span class=\"line\">filetype plugin indent on</span><br><span class=\"line\">set nobackup &quot;不备份 </span><br><span class=\"line\">set autochdir &quot;自动切换当前目录</span><br><span class=\"line\">set mouse=a</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;启动，语法高亮，配色</span><br><span class=\"line\">winpos 500 200   &quot;窗口位置</span><br><span class=\"line\">set lines=30 columns=85  &quot;窗口大小</span><br><span class=\"line\">set guioptions-=T  &quot;不要菜单栏</span><br><span class=\"line\">set laststatus=2   &quot;总是显示状态栏</span><br><span class=\"line\">set hlsearch  &quot;搜索高亮</span><br><span class=\"line\">set ignorecase &quot;搜索忽略大小写</span><br><span class=\"line\">syntax enable</span><br><span class=\"line\">syntax on</span><br><span class=\"line\">set t_Co=256</span><br><span class=\"line\">set cursorline &quot;高亮光标行</span><br><span class=\"line\">set ruler   &quot;显示光标位置状态栏</span><br><span class=\"line\">set number</span><br><span class=\"line\">set guifont=Ubuntu\\ Mono\\ 13</span><br><span class=\"line\">colorscheme molokai</span><br><span class=\"line\">set clipboard=unnamed &quot;可以用系统剪贴板</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;Tab相关</span><br><span class=\"line\">set expandtab &quot;制表符扩展为空格</span><br><span class=\"line\">set tabstop=4 &quot;制表符占用空格数</span><br><span class=\"line\">set softtabstop=4 &quot;将连续数量的空格视为一个制表符</span><br><span class=\"line\">set shiftwidth=4 &quot;格式化时制表符占用空格数</span><br><span class=\"line\">set cindent</span><br><span class=\"line\">set autoindent</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;编码相关</span><br><span class=\"line\">set encoding=utf-8</span><br><span class=\"line\">set langmenu=zh_CN.UTF-8</span><br><span class=\"line\">language message zh_CN.UTF-8</span><br><span class=\"line\">set fileencodings=ucs-bom,utf-8,cp936,gb18030,big5,euc-jp,euc-kr,latin1</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;使用CTRL+[hjkl]在窗口间导航&quot;</span><br><span class=\"line\">map &lt;C-c&gt; &lt;C-W&gt;c</span><br><span class=\"line\">map &lt;C-j&gt; &lt;C-W&gt;j</span><br><span class=\"line\">map &lt;C-k&gt; &lt;C-W&gt;k</span><br><span class=\"line\">map &lt;C-h&gt; &lt;C-W&gt;h</span><br><span class=\"line\">map &lt;C-l&gt; &lt;C-W&gt;l</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;使用箭头导航buffer&quot;</span><br><span class=\"line\">map &lt;right&gt; :bn&lt;cr&gt;</span><br><span class=\"line\">map &lt;left&gt; :bp&lt;cr&gt;</span><br><span class=\"line\">set autowrite &quot;在切换buffer时自动保存当前的文件</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;&quot;使用ALT+[jk]来移动行内容</span><br><span class=\"line\">nmap &lt;M-j&gt; mz:m+&lt;cr&gt;`z</span><br><span class=\"line\">nmap &lt;M-k&gt; mz:m-2&lt;cr&gt;`z</span><br><span class=\"line\">vmap &lt;M-j&gt; :m&apos;&gt;+&lt;cr&gt;`&lt;my`&gt;mzgv`yo`z</span><br><span class=\"line\">vmap &lt;M-k&gt; :m&apos;&lt;-2&lt;cr&gt;`&gt;my`&lt;mzgv`yo`z</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;根据文件类型做不同处理</span><br><span class=\"line\">function HeaderPython()  &quot;python加头注释</span><br><span class=\"line\">    call setline(1, &quot;#!/usr/bin/env python3&quot;)</span><br><span class=\"line\">    call append(1,  &quot;# -*- coding: utf-8 -*-&quot;)</span><br><span class=\"line\">    call append(2,  &quot;# mail:levy_lv@hotmail.com&quot;)</span><br><span class=\"line\">    call append(3,  &quot;# Lyu Wei @ &quot; . strftime(&apos;%Y-%m-%d&apos;, localtime()))</span><br><span class=\"line\">    normal G</span><br><span class=\"line\">    normal o</span><br><span class=\"line\">    normal o</span><br><span class=\"line\">endf</span><br><span class=\"line\">autocmd bufnewfile *.py call HeaderPython()</span><br><span class=\"line\"></span><br><span class=\"line\">function HeaderBash()  &quot;shell脚本加注释</span><br><span class=\"line\">    call setline(1, &quot;#!/bin/bash&quot;)</span><br><span class=\"line\">    call append(1,  &quot;# -*- coding: utf-8 -*-&quot;)</span><br><span class=\"line\">    call append(2,  &quot;# mail:levy_lv@hotmail.com&quot;)</span><br><span class=\"line\">    call append(3,  &quot;# Lyu Wei @ &quot; . strftime(&apos;%Y-%m-%d&apos;, localtime()))</span><br><span class=\"line\">    normal G</span><br><span class=\"line\">    normal o</span><br><span class=\"line\">    normal o</span><br><span class=\"line\">endf</span><br><span class=\"line\">autocmd bufnewfile *.sh call HeaderBash()</span><br><span class=\"line\"></span><br><span class=\"line\">function HeaderCpp() &quot;C++文件加头文件</span><br><span class=\"line\">    call setline(1, &quot;#include &lt;iostream&gt;&quot;)</span><br><span class=\"line\">    call append(1, &quot;using namespace std;&quot;)</span><br><span class=\"line\">    normal G</span><br><span class=\"line\">    normal o</span><br><span class=\"line\">    normal o</span><br><span class=\"line\">endf</span><br><span class=\"line\">autocmd bufnewfile *.cpp,*.cc call HeaderCpp()</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;C,C++单个文件调试</span><br><span class=\"line\">map &lt;F8&gt; :call Rungdb()&lt;CR&gt;</span><br><span class=\"line\">func! Rungdb()</span><br><span class=\"line\">    exec &quot;w&quot;</span><br><span class=\"line\">    exec &quot;!g++ % -g -o %&lt;&quot;</span><br><span class=\"line\">    exec &quot;!gdb ./%&lt;&quot;</span><br><span class=\"line\">endfunc</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;====================&quot;</span><br><span class=\"line\">&quot;Vundle Configuration&quot;</span><br><span class=\"line\">&quot;====================&quot;</span><br><span class=\"line\">filetype off                  &quot; required</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; set the runtime path to include Vundle and initialize</span><br><span class=\"line\">set rtp+=~/.vim/bundle/Vundle.vim</span><br><span class=\"line\">call vundle#begin()</span><br><span class=\"line\">&quot; alternatively, pass a path where Vundle should install plugins</span><br><span class=\"line\">&quot;call vundle#begin(&apos;~/some/path/here&apos;)</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; let Vundle manage Vundle, required</span><br><span class=\"line\">Plugin &apos;VundleVim/Vundle.vim&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; My Plugin here:</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; plugin on GitHub repo</span><br><span class=\"line\">Plugin &apos;Valloric/YouCompleteMe&apos;</span><br><span class=\"line\">Plugin &apos;luochen1990/rainbow&apos;</span><br><span class=\"line\">&quot;Plugin &apos;majutsushi/tagbar&apos;</span><br><span class=\"line\">Plugin &apos;fholgado/minibufexpl.vim&apos;</span><br><span class=\"line\">Plugin &apos;scrooloose/nerdtree&apos;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&quot; All of your Plugins must be added before the following line</span><br><span class=\"line\">call vundle#end()            &quot; required</span><br><span class=\"line\">filetype plugin indent on    &quot; required</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&quot;===========================&quot;</span><br><span class=\"line\">&quot;Vundle Plugin Configuration&quot;</span><br><span class=\"line\">&quot;===========================&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;Rainbow</span><br><span class=\"line\">let g:rainbow_active = 1 &quot; 0 if you want to enable it later via: RainbowTogglw</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;Tagbar</span><br><span class=\"line\">&quot;nmap &lt;F8&gt; :TagbarToggle&lt;CR&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;YouCompleteMe</span><br><span class=\"line\">&quot;let g:ycm_path_to_python_interpreter = &apos;/usr/bin/python&apos;</span><br><span class=\"line\">set runtimepath+=~/.vim/bundle/YouCompleteMe</span><br><span class=\"line\">let g:ycm_collect_identifiers_from_tags_files = 1           &quot; 开启 YCM 基于标签引擎</span><br><span class=\"line\">let g:ycm_collect_identifiers_from_comments_and_strings = 1 &quot; 注释与字符串中的内容也用于补全</span><br><span class=\"line\">let g:syntastic_ignore_files=[&quot;.*\\.py$&quot;]</span><br><span class=\"line\">let g:ycm_seed_identifiers_with_syntax = 1                  &quot; 语法关键字补全</span><br><span class=\"line\">let g:ycm_complete_in_comments = 1</span><br><span class=\"line\">let g:ycm_confirm_extra_conf = 0</span><br><span class=\"line\">&quot;let g:ycm_key_list_select_completion = [&apos;&lt;c-n&gt;&apos;, &apos;&lt;Down&gt;&apos;]  &quot; 映射按键, 没有这个会拦截掉tab, 导致其他插件的tab不能用.</span><br><span class=\"line\">&quot;let g:ycm_key_list_previous_completion = [&apos;&lt;c-p&gt;&apos;, &apos;&lt;Up&gt;&apos;]</span><br><span class=\"line\">let g:ycm_complete_in_comments = 1                          &quot; 在注释输入中也能补全</span><br><span class=\"line\">let g:ycm_complete_in_strings = 1                           &quot; 在字符串输入中也能补全</span><br><span class=\"line\">let g:ycm_collect_identifiers_from_comments_and_strings = 1 &quot; 注释和字符串中的文字也会被收入补全</span><br><span class=\"line\">let g:ycm_global_ycm_extra_conf=&apos;~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py&apos;</span><br><span class=\"line\">&quot;let g:ycm_show_diagnostics_ui = 0                           &quot; 禁用语法检查</span><br><span class=\"line\">inoremap &lt;expr&gt; &lt;CR&gt; pumvisible() ? &quot;\\&lt;C-y&gt;&quot; : &quot;\\&lt;CR&gt;&quot; |            &quot; 回车即选中当前项</span><br><span class=\"line\">nnoremap &lt;F5&gt; :YcmCompleter GoToDefinitionElseDeclaration&lt;CR&gt;</span><br><span class=\"line\">&quot;let g:ycm_min_num_of_chars_for_completion=2                 &quot; 从第2个键入字符就开始罗列匹配项</span><br><span class=\"line\">let g:ycm_autoclose_preview_window_after_completion = 1  &quot; 补全后自动关闭preview</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;minibufexpl</span><br><span class=\"line\">let g:miniBufExplMapWindowNavVim = 1 &quot;可以用&lt;C-h,j,k,l&gt;切换到上下左右的窗口 </span><br><span class=\"line\">let g:miniBufExplMapCTabSwitchBufs = 1 &quot;&lt;C-Tab&gt;,&lt;C-S-Tab&gt;切换</span><br><span class=\"line\">let g:miniBufExplModSelTarget = 1 </span><br><span class=\"line\"></span><br><span class=\"line\">&quot;NERDTree</span><br><span class=\"line\">nnoremap &lt;F4&gt; :NERDTreeToggle&lt;CR&gt;</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"Vim\"><a href=\"#Vim\" class=\"headerlink\" title=\"Vim\"></a>Vim</h1><p>Ubuntu自带的vim是vim.tiny版本，很多功能都不全，所以我们需要装一个完整版的，并且我习惯装一个gvim,<code>sudo apt-get install vim-gtk</code>。 有意思的是，我发现<code>apt-get</code>下面有一个叫<code>vim+youcompleteme</code>的版本，我就好奇得装了一下，结果打开vim发现并没有补全功能，但是却装了<code>ruby，nodejs,ycmd</code>等几个软件，<code>ycmd</code>应该就是补全软件，然而不知道该怎么在vim里使用…所以最终我还是按照github上的说明手动装了<code>youcompleteme</code>,这部分留到后文说。</p>","more":"<h2 id=\"插件Vundle\"><a href=\"#插件Vundle\" class=\"headerlink\" title=\"插件Vundle\"></a>插件Vundle</h2><p>Vundle是一个很实用的vim插件，通过它可以方便得管理其他插件，安装很简单。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim</span><br></pre></td></tr></table></figure></p>\n<p>装完之后，需要在<code>.vimrc</code>里进行配置，<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set nocompatible              &quot; be iMproved, required</span><br><span class=\"line\">filetype off                  &quot; required</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; set the runtime path to include Vundle and initialize</span><br><span class=\"line\">set rtp+=~/.vim/bundle/Vundle.vim</span><br><span class=\"line\">call vundle#begin()</span><br><span class=\"line\">&quot; alternatively, pass a path where Vundle should install plugins</span><br><span class=\"line\">&quot;call vundle#begin(&apos;~/some/path/here&apos;)</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; let Vundle manage Vundle, required</span><br><span class=\"line\">Plugin &apos;VundleVim/Vundle.vim&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; The following are examples of different formats supported.</span><br><span class=\"line\">&quot; Keep Plugin commands between vundle#begin/end.</span><br><span class=\"line\">&quot; plugin on GitHub repo</span><br><span class=\"line\">Plugin &apos;tpope/vim-fugitive&apos;</span><br><span class=\"line\">&quot; plugin from http://vim-scripts.org/vim/scripts.html</span><br><span class=\"line\">&quot; Plugin &apos;L9&apos;</span><br><span class=\"line\">&quot; Git plugin not hosted on GitHub</span><br><span class=\"line\">Plugin &apos;git://git.wincent.com/command-t.git&apos;</span><br><span class=\"line\">&quot; git repos on your local machine (i.e. when working on your own plugin)</span><br><span class=\"line\">Plugin &apos;file:///home/gmarik/path/to/plugin&apos;</span><br><span class=\"line\">&quot; The sparkup vim script is in a subdirectory of this repo called vim.</span><br><span class=\"line\">&quot; Pass the path to set the runtimepath properly.</span><br><span class=\"line\">Plugin &apos;rstacruz/sparkup&apos;, &#123;&apos;rtp&apos;: &apos;vim/&apos;&#125;</span><br><span class=\"line\">&quot; Install L9 and avoid a Naming conflict if you&apos;ve already installed a</span><br><span class=\"line\">&quot; different version somewhere else.</span><br><span class=\"line\">&quot; Plugin &apos;ascenator/L9&apos;, &#123;&apos;name&apos;: &apos;newL9&apos;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; All of your Plugins must be added before the following line</span><br><span class=\"line\">call vundle#end()            &quot; required</span><br><span class=\"line\">filetype plugin indent on    &quot; required</span><br><span class=\"line\">&quot; To ignore plugin indent changes, instead use:</span><br><span class=\"line\">&quot;filetype plugin on</span><br><span class=\"line\">&quot;</span><br><span class=\"line\">&quot; Brief help</span><br><span class=\"line\">&quot; :PluginList       - lists configured plugins</span><br><span class=\"line\">&quot; :PluginInstall    - installs plugins; append `!` to update or just :PluginUpdate</span><br><span class=\"line\">&quot; :PluginSearch foo - searches for foo; append `!` to refresh local cache</span><br><span class=\"line\">&quot; :PluginClean      - confirms removal of unused plugins; append `!` to auto-approve removal</span><br><span class=\"line\">&quot;</span><br><span class=\"line\">&quot; see :h vundle for more details or wiki for FAQ</span><br><span class=\"line\">&quot; Put your non-Plugin stuff after this line</span><br></pre></td></tr></table></figure></p>\n<p>最终打开vim，输入<code>：PluginInstall</code>来安装你在配置文件里写的插件。</p>\n<p>我安装了下面几个我常用的插件。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot; My Plugin here:</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; plugin on GitHub repo</span><br><span class=\"line\">Plugin &apos;Valloric/YouCompleteMe&apos;</span><br><span class=\"line\">Plugin &apos;luochen1990/rainbow&apos;</span><br><span class=\"line\">Plugin &apos;fholgado/minibufexpl.vim&apos;</span><br><span class=\"line\">Plugin &apos;scrooloose/nerdtree&apos;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"YouCompleteMe\"><a href=\"#YouCompleteMe\" class=\"headerlink\" title=\"YouCompleteMe\"></a>YouCompleteMe</h1><p>在我的插件里可以看到我装了YouCompleteMe这个插件，但是光vundle装好还是不够的，我们需要再编译一个能用的引擎。</p>\n<h2 id=\"安装必备的编译环境和python环境\"><a href=\"#安装必备的编译环境和python环境\" class=\"headerlink\" title=\"安装必备的编译环境和python环境\"></a>安装必备的编译环境和python环境</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install build-essential cmake</span><br><span class=\"line\">sudo apt-get install python-dev python3-dev</span><br></pre></td></tr></table></figure>\n<h2 id=\"检查vim版本\"><a href=\"#检查vim版本\" class=\"headerlink\" title=\"检查vim版本\"></a>检查vim版本</h2><p>我们需要检查vim版本以及vim支持的python版本，保证vim版本高于7.4.1578,支持python2或者Python3。我们可以输入命令：<code>vim --version</code>来查看，以下是我的输出截图：<br><img src=\"http://upload-images.jianshu.io/upload_images/825093-cc5dac3d1fd71ef2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/550\" alt=\"image.png\"><br>可以看到版本是7.4.1689，不支持python2,但支持python3（貌似Ubuntu16.04开始移除python2的支持了）。</p>\n<h2 id=\"编译支持C家族语义补全的YCM\"><a href=\"#编译支持C家族语义补全的YCM\" class=\"headerlink\" title=\"编译支持C家族语义补全的YCM\"></a>编译支持C家族语义补全的YCM</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd ~/.vim/bundle/YouCompleteMe</span><br><span class=\"line\">Python3 ./install.py --clang-completer //由于我的vim只支持Python3,所以在前面加python3命令</span><br></pre></td></tr></table></figure>\n<p>命令执行之后，系统会去下载libclang,因为YCM语义支持是靠clang编译器的，这里需要经过漫长得等待。。如果一切顺利的话，YCM就安装完毕了。</p>\n<h2 id=\"YCM配置\"><a href=\"#YCM配置\" class=\"headerlink\" title=\"YCM配置\"></a>YCM配置</h2><p>我的YCM配置如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;YouCompleteMe</span><br><span class=\"line\">&quot;let g:ycm_path_to_python_interpreter = &apos;/usr/bin/python&apos;</span><br><span class=\"line\">set runtimepath+=~/.vim/bundle/YouCompleteMe</span><br><span class=\"line\">let g:ycm_collect_identifiers_from_tags_files = 1           &quot; 开启 YCM 基于标签引擎</span><br><span class=\"line\">let g:ycm_collect_identifiers_from_comments_and_strings = 1 &quot; 注释与字符串中的内容也用于补全</span><br><span class=\"line\">let g:syntastic_ignore_files=[&quot;.*\\.py$&quot;]</span><br><span class=\"line\">let g:ycm_seed_identifiers_with_syntax = 1                  &quot; 语法关键字补全</span><br><span class=\"line\">let g:ycm_complete_in_comments = 1</span><br><span class=\"line\">let g:ycm_confirm_extra_conf = 0</span><br><span class=\"line\">&quot;let g:ycm_key_list_select_completion = [&apos;&lt;c-n&gt;&apos;, &apos;&lt;Down&gt;&apos;]  &quot; 映射按键, 没有这个会拦截掉tab, 导致其他插件的tab不能用.</span><br><span class=\"line\">&quot;let g:ycm_key_list_previous_completion = [&apos;&lt;c-p&gt;&apos;, &apos;&lt;Up&gt;&apos;]</span><br><span class=\"line\">let g:ycm_complete_in_comments = 1                          &quot; 在注释输入中也能补全</span><br><span class=\"line\">let g:ycm_complete_in_strings = 1                           &quot; 在字符串输入中也能补全</span><br><span class=\"line\">let g:ycm_collect_identifiers_from_comments_and_strings = 1 &quot; 注释和字符串中的文字也会被收入补全</span><br><span class=\"line\">let g:ycm_global_ycm_extra_conf=&apos;~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py&apos;</span><br><span class=\"line\">&quot;let g:ycm_show_diagnostics_ui = 0                           &quot; 禁用语法检查</span><br><span class=\"line\">inoremap &lt;expr&gt; &lt;CR&gt; pumvisible() ? &quot;\\&lt;C-y&gt;&quot; : &quot;\\&lt;CR&gt;&quot; |            &quot; 回车即选中当前项</span><br><span class=\"line\">nnoremap &lt;F5&gt; :YcmCompleter GoToDefinitionElseDeclaration&lt;CR&gt;</span><br><span class=\"line\">&quot;let g:ycm_min_num_of_chars_for_completion=2                 &quot; 从第2个键入字符就开始罗列匹配项</span><br><span class=\"line\">let g:ycm_autoclose_preview_window_after_completion = 1  &quot; 补全后自动关闭preview</span><br></pre></td></tr></table></figure></p>\n<p>一个能够进行语法检查，自动补全，并且GoToDefinition的YCM就可以使用了，但是还有一点瑕疵：＃include <iostream>, #include <stdio> vector, 什么的都不能补全，这是因为这些头文件的路径没有被找到，下面的工作就是要让YouCompleteMe找到这些头文件，而且，以后有什么库文件，比如OpenCV，OPenGL什么的，都可以按照这个方法添加。</stdio></iostream></p>\n<p>打开并编辑~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py，这就是我们设定vim默认调用的YCM配置文件，然后可以在flags[*]数组的后面添加你想要的路径，例如: stdio.h等Ｃ语言的头文件包含在/usr/include中，那么您需要添加这样一条</p>\n<blockquote>\n<p>‘-isystem’,<br>‘/usr/include’,</p>\n</blockquote>\n<p>如果需要C++的补全，就需要添加：</p>\n<blockquote>\n<p>‘-isystem’,<br>‘/usr/include/c++/5’,</p>\n</blockquote>\n<p>需要什么，就添加什么，现在编辑c/c++文件你就发现支持头文件补全了！</p>\n<h1 id=\"我的vim配置\"><a href=\"#我的vim配置\" class=\"headerlink\" title=\"我的vim配置\"></a>我的vim配置</h1><p>根据个人习惯，我的vimrc配置如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;Wei Lyu</span><br><span class=\"line\">&quot;levy_lv@hotmail.com</span><br><span class=\"line\">&quot;levylv.github.io</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;====================&quot;</span><br><span class=\"line\">&quot;        通用        &quot;</span><br><span class=\"line\">&quot;====================&quot;</span><br><span class=\"line\">set nocompatible              &quot; be iMproved, required</span><br><span class=\"line\">filetype plugin indent on</span><br><span class=\"line\">set nobackup &quot;不备份 </span><br><span class=\"line\">set autochdir &quot;自动切换当前目录</span><br><span class=\"line\">set mouse=a</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;启动，语法高亮，配色</span><br><span class=\"line\">winpos 500 200   &quot;窗口位置</span><br><span class=\"line\">set lines=30 columns=85  &quot;窗口大小</span><br><span class=\"line\">set guioptions-=T  &quot;不要菜单栏</span><br><span class=\"line\">set laststatus=2   &quot;总是显示状态栏</span><br><span class=\"line\">set hlsearch  &quot;搜索高亮</span><br><span class=\"line\">set ignorecase &quot;搜索忽略大小写</span><br><span class=\"line\">syntax enable</span><br><span class=\"line\">syntax on</span><br><span class=\"line\">set t_Co=256</span><br><span class=\"line\">set cursorline &quot;高亮光标行</span><br><span class=\"line\">set ruler   &quot;显示光标位置状态栏</span><br><span class=\"line\">set number</span><br><span class=\"line\">set guifont=Ubuntu\\ Mono\\ 13</span><br><span class=\"line\">colorscheme molokai</span><br><span class=\"line\">set clipboard=unnamed &quot;可以用系统剪贴板</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;Tab相关</span><br><span class=\"line\">set expandtab &quot;制表符扩展为空格</span><br><span class=\"line\">set tabstop=4 &quot;制表符占用空格数</span><br><span class=\"line\">set softtabstop=4 &quot;将连续数量的空格视为一个制表符</span><br><span class=\"line\">set shiftwidth=4 &quot;格式化时制表符占用空格数</span><br><span class=\"line\">set cindent</span><br><span class=\"line\">set autoindent</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;编码相关</span><br><span class=\"line\">set encoding=utf-8</span><br><span class=\"line\">set langmenu=zh_CN.UTF-8</span><br><span class=\"line\">language message zh_CN.UTF-8</span><br><span class=\"line\">set fileencodings=ucs-bom,utf-8,cp936,gb18030,big5,euc-jp,euc-kr,latin1</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;使用CTRL+[hjkl]在窗口间导航&quot;</span><br><span class=\"line\">map &lt;C-c&gt; &lt;C-W&gt;c</span><br><span class=\"line\">map &lt;C-j&gt; &lt;C-W&gt;j</span><br><span class=\"line\">map &lt;C-k&gt; &lt;C-W&gt;k</span><br><span class=\"line\">map &lt;C-h&gt; &lt;C-W&gt;h</span><br><span class=\"line\">map &lt;C-l&gt; &lt;C-W&gt;l</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;使用箭头导航buffer&quot;</span><br><span class=\"line\">map &lt;right&gt; :bn&lt;cr&gt;</span><br><span class=\"line\">map &lt;left&gt; :bp&lt;cr&gt;</span><br><span class=\"line\">set autowrite &quot;在切换buffer时自动保存当前的文件</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;&quot;使用ALT+[jk]来移动行内容</span><br><span class=\"line\">nmap &lt;M-j&gt; mz:m+&lt;cr&gt;`z</span><br><span class=\"line\">nmap &lt;M-k&gt; mz:m-2&lt;cr&gt;`z</span><br><span class=\"line\">vmap &lt;M-j&gt; :m&apos;&gt;+&lt;cr&gt;`&lt;my`&gt;mzgv`yo`z</span><br><span class=\"line\">vmap &lt;M-k&gt; :m&apos;&lt;-2&lt;cr&gt;`&gt;my`&lt;mzgv`yo`z</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;根据文件类型做不同处理</span><br><span class=\"line\">function HeaderPython()  &quot;python加头注释</span><br><span class=\"line\">    call setline(1, &quot;#!/usr/bin/env python3&quot;)</span><br><span class=\"line\">    call append(1,  &quot;# -*- coding: utf-8 -*-&quot;)</span><br><span class=\"line\">    call append(2,  &quot;# mail:levy_lv@hotmail.com&quot;)</span><br><span class=\"line\">    call append(3,  &quot;# Lyu Wei @ &quot; . strftime(&apos;%Y-%m-%d&apos;, localtime()))</span><br><span class=\"line\">    normal G</span><br><span class=\"line\">    normal o</span><br><span class=\"line\">    normal o</span><br><span class=\"line\">endf</span><br><span class=\"line\">autocmd bufnewfile *.py call HeaderPython()</span><br><span class=\"line\"></span><br><span class=\"line\">function HeaderBash()  &quot;shell脚本加注释</span><br><span class=\"line\">    call setline(1, &quot;#!/bin/bash&quot;)</span><br><span class=\"line\">    call append(1,  &quot;# -*- coding: utf-8 -*-&quot;)</span><br><span class=\"line\">    call append(2,  &quot;# mail:levy_lv@hotmail.com&quot;)</span><br><span class=\"line\">    call append(3,  &quot;# Lyu Wei @ &quot; . strftime(&apos;%Y-%m-%d&apos;, localtime()))</span><br><span class=\"line\">    normal G</span><br><span class=\"line\">    normal o</span><br><span class=\"line\">    normal o</span><br><span class=\"line\">endf</span><br><span class=\"line\">autocmd bufnewfile *.sh call HeaderBash()</span><br><span class=\"line\"></span><br><span class=\"line\">function HeaderCpp() &quot;C++文件加头文件</span><br><span class=\"line\">    call setline(1, &quot;#include &lt;iostream&gt;&quot;)</span><br><span class=\"line\">    call append(1, &quot;using namespace std;&quot;)</span><br><span class=\"line\">    normal G</span><br><span class=\"line\">    normal o</span><br><span class=\"line\">    normal o</span><br><span class=\"line\">endf</span><br><span class=\"line\">autocmd bufnewfile *.cpp,*.cc call HeaderCpp()</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;C,C++单个文件调试</span><br><span class=\"line\">map &lt;F8&gt; :call Rungdb()&lt;CR&gt;</span><br><span class=\"line\">func! Rungdb()</span><br><span class=\"line\">    exec &quot;w&quot;</span><br><span class=\"line\">    exec &quot;!g++ % -g -o %&lt;&quot;</span><br><span class=\"line\">    exec &quot;!gdb ./%&lt;&quot;</span><br><span class=\"line\">endfunc</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;====================&quot;</span><br><span class=\"line\">&quot;Vundle Configuration&quot;</span><br><span class=\"line\">&quot;====================&quot;</span><br><span class=\"line\">filetype off                  &quot; required</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; set the runtime path to include Vundle and initialize</span><br><span class=\"line\">set rtp+=~/.vim/bundle/Vundle.vim</span><br><span class=\"line\">call vundle#begin()</span><br><span class=\"line\">&quot; alternatively, pass a path where Vundle should install plugins</span><br><span class=\"line\">&quot;call vundle#begin(&apos;~/some/path/here&apos;)</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; let Vundle manage Vundle, required</span><br><span class=\"line\">Plugin &apos;VundleVim/Vundle.vim&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; My Plugin here:</span><br><span class=\"line\"></span><br><span class=\"line\">&quot; plugin on GitHub repo</span><br><span class=\"line\">Plugin &apos;Valloric/YouCompleteMe&apos;</span><br><span class=\"line\">Plugin &apos;luochen1990/rainbow&apos;</span><br><span class=\"line\">&quot;Plugin &apos;majutsushi/tagbar&apos;</span><br><span class=\"line\">Plugin &apos;fholgado/minibufexpl.vim&apos;</span><br><span class=\"line\">Plugin &apos;scrooloose/nerdtree&apos;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&quot; All of your Plugins must be added before the following line</span><br><span class=\"line\">call vundle#end()            &quot; required</span><br><span class=\"line\">filetype plugin indent on    &quot; required</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&quot;===========================&quot;</span><br><span class=\"line\">&quot;Vundle Plugin Configuration&quot;</span><br><span class=\"line\">&quot;===========================&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;Rainbow</span><br><span class=\"line\">let g:rainbow_active = 1 &quot; 0 if you want to enable it later via: RainbowTogglw</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;Tagbar</span><br><span class=\"line\">&quot;nmap &lt;F8&gt; :TagbarToggle&lt;CR&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;YouCompleteMe</span><br><span class=\"line\">&quot;let g:ycm_path_to_python_interpreter = &apos;/usr/bin/python&apos;</span><br><span class=\"line\">set runtimepath+=~/.vim/bundle/YouCompleteMe</span><br><span class=\"line\">let g:ycm_collect_identifiers_from_tags_files = 1           &quot; 开启 YCM 基于标签引擎</span><br><span class=\"line\">let g:ycm_collect_identifiers_from_comments_and_strings = 1 &quot; 注释与字符串中的内容也用于补全</span><br><span class=\"line\">let g:syntastic_ignore_files=[&quot;.*\\.py$&quot;]</span><br><span class=\"line\">let g:ycm_seed_identifiers_with_syntax = 1                  &quot; 语法关键字补全</span><br><span class=\"line\">let g:ycm_complete_in_comments = 1</span><br><span class=\"line\">let g:ycm_confirm_extra_conf = 0</span><br><span class=\"line\">&quot;let g:ycm_key_list_select_completion = [&apos;&lt;c-n&gt;&apos;, &apos;&lt;Down&gt;&apos;]  &quot; 映射按键, 没有这个会拦截掉tab, 导致其他插件的tab不能用.</span><br><span class=\"line\">&quot;let g:ycm_key_list_previous_completion = [&apos;&lt;c-p&gt;&apos;, &apos;&lt;Up&gt;&apos;]</span><br><span class=\"line\">let g:ycm_complete_in_comments = 1                          &quot; 在注释输入中也能补全</span><br><span class=\"line\">let g:ycm_complete_in_strings = 1                           &quot; 在字符串输入中也能补全</span><br><span class=\"line\">let g:ycm_collect_identifiers_from_comments_and_strings = 1 &quot; 注释和字符串中的文字也会被收入补全</span><br><span class=\"line\">let g:ycm_global_ycm_extra_conf=&apos;~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py&apos;</span><br><span class=\"line\">&quot;let g:ycm_show_diagnostics_ui = 0                           &quot; 禁用语法检查</span><br><span class=\"line\">inoremap &lt;expr&gt; &lt;CR&gt; pumvisible() ? &quot;\\&lt;C-y&gt;&quot; : &quot;\\&lt;CR&gt;&quot; |            &quot; 回车即选中当前项</span><br><span class=\"line\">nnoremap &lt;F5&gt; :YcmCompleter GoToDefinitionElseDeclaration&lt;CR&gt;</span><br><span class=\"line\">&quot;let g:ycm_min_num_of_chars_for_completion=2                 &quot; 从第2个键入字符就开始罗列匹配项</span><br><span class=\"line\">let g:ycm_autoclose_preview_window_after_completion = 1  &quot; 补全后自动关闭preview</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;minibufexpl</span><br><span class=\"line\">let g:miniBufExplMapWindowNavVim = 1 &quot;可以用&lt;C-h,j,k,l&gt;切换到上下左右的窗口 </span><br><span class=\"line\">let g:miniBufExplMapCTabSwitchBufs = 1 &quot;&lt;C-Tab&gt;,&lt;C-S-Tab&gt;切换</span><br><span class=\"line\">let g:miniBufExplModSelTarget = 1 </span><br><span class=\"line\"></span><br><span class=\"line\">&quot;NERDTree</span><br><span class=\"line\">nnoremap &lt;F4&gt; :NERDTreeToggle&lt;CR&gt;</span><br></pre></td></tr></table></figure></p>"}],"PostAsset":[],"PostCategory":[{"post_id":"cl9o551nz0008jqrrdgiulxo3","category_id":"cl9o551nx0005jqrrvmm6b0y6","_id":"cl9o551o6000gjqrrkk2marmq"},{"post_id":"cl9o551ns0003jqrrsy54fx4t","category_id":"cl9o551nx0005jqrrvmm6b0y6","_id":"cl9o551o7000ljqrr2pwunyo1"},{"post_id":"cl9o551o00009jqrr09luyjkz","category_id":"cl9o551nx0005jqrrvmm6b0y6","_id":"cl9o551o8000ojqrr9ryqb1xr"},{"post_id":"cl9o551o4000djqrriljwauk8","category_id":"cl9o551nx0005jqrrvmm6b0y6","_id":"cl9o551o8000tjqrrwhorfj7y"},{"post_id":"cl9o551nv0004jqrrm844gqrs","category_id":"cl9o551nx0005jqrrvmm6b0y6","_id":"cl9o551o9000vjqrrlmx7snq6"},{"post_id":"cl9o551ny0007jqrri69yfdh8","category_id":"cl9o551nx0005jqrrvmm6b0y6","_id":"cl9o551oa000zjqrr0s86leuc"},{"post_id":"cl9o551o6000fjqrr8r6ix55h","category_id":"cl9o551o8000pjqrr7o73lh1d","_id":"cl9o551oa0013jqrrqenra9ba"},{"post_id":"cl9o551o7000kjqrr49g1eo8e","category_id":"cl9o551o9000wjqrrkcbssxp6","_id":"cl9o551ob001ajqrrke8s01g5"},{"post_id":"cl9o551o7000njqrrk6e4vfg2","category_id":"cl9o551o8000pjqrr7o73lh1d","_id":"cl9o551oc001fjqrrram5t1sj"},{"post_id":"cl9o551o8000sjqrrda6qs3n8","category_id":"cl9o551ob0019jqrrys7svt6v","_id":"cl9o551oe001mjqrr8x440wb8"},{"post_id":"cl9o551o9000ujqrr1x3e1y6p","category_id":"cl9o551ob0019jqrrys7svt6v","_id":"cl9o551of001rjqrrznx2r0hz"},{"post_id":"cl9o551od001kjqrr601f2cnb","category_id":"cl9o551ob0019jqrrys7svt6v","_id":"cl9o551og001tjqrr5kx2ufbo"},{"post_id":"cl9o551o9000yjqrriysoff9j","category_id":"cl9o551ob0019jqrrys7svt6v","_id":"cl9o551oh001wjqrrs2vavfed"},{"post_id":"cl9o551oa0011jqrr4mh5sjah","category_id":"cl9o551ob0019jqrrys7svt6v","_id":"cl9o551oj0021jqrr5x676576"},{"post_id":"cl9o551oa0016jqrrhzie1mbm","category_id":"cl9o551ob0019jqrrys7svt6v","_id":"cl9o551ok0026jqrr2lfe5nta"},{"post_id":"cl9o551ob0018jqrr9b5eb9vx","category_id":"cl9o551oj0020jqrriemy1k6g","_id":"cl9o551om002ejqrr18gz4j19"},{"post_id":"cl9o551oc001cjqrroh79fjhl","category_id":"cl9o551oj0020jqrriemy1k6g","_id":"cl9o551op002jjqrrrgzzqsd3"},{"post_id":"cl9o551oc001ejqrrgjo6gx06","category_id":"cl9o551oj0020jqrriemy1k6g","_id":"cl9o551or002pjqrr162sdjz4"},{"post_id":"cl9o551od001ijqrr9zummokm","category_id":"cl9o551oj0020jqrriemy1k6g","_id":"cl9o551os002vjqrr4val9ou1"},{"post_id":"cl9o551oe001njqrrvw7gu8s8","category_id":"cl9o551oj0020jqrriemy1k6g","_id":"cl9o551ov0032jqrrtlcpq5op"},{"post_id":"cl9o551oe001pjqrr58mmv7nd","category_id":"cl9o551oj0020jqrriemy1k6g","_id":"cl9o551ox0039jqrr6zkczs7p"},{"post_id":"cl9o551og001sjqrrh4bi3hnm","category_id":"cl9o551oj0020jqrriemy1k6g","_id":"cl9o551oz003ejqrrwqtr51q9"},{"post_id":"cl9o551og001ujqrrzi9rqj6k","category_id":"cl9o551ox0038jqrrs9fght1t","_id":"cl9o551p0003ljqrrbtfpenlm"},{"post_id":"cl9o551oh001xjqrr5kgple8s","category_id":"cl9o551ox0038jqrrs9fght1t","_id":"cl9o551p2003qjqrrwtdht7te"},{"post_id":"cl9o551oh001zjqrrus0alk49","category_id":"cl9o551oj0020jqrriemy1k6g","_id":"cl9o551p4003vjqrrqd1k2p6r"},{"post_id":"cl9o551oj0022jqrr45mc7xxd","category_id":"cl9o551ox0038jqrrs9fght1t","_id":"cl9o551p70040jqrr5rniyigw"},{"post_id":"cl9o551ok0023jqrrtof4eir3","category_id":"cl9o551ox0038jqrrs9fght1t","_id":"cl9o551p70043jqrrbt9ueqq6"},{"post_id":"cl9o551ok0027jqrri2c1ns9f","category_id":"cl9o551ox0038jqrrs9fght1t","_id":"cl9o551p80047jqrrdkfe9j9e"},{"post_id":"cl9o551ol0029jqrrvaytn3k9","category_id":"cl9o551ox0038jqrrs9fght1t","_id":"cl9o551p8004ajqrris4su8hz"},{"post_id":"cl9o551om002bjqrrgs1jv5nv","category_id":"cl9o551ox0038jqrrs9fght1t","_id":"cl9o551p9004djqrrjmzh368n"},{"post_id":"cl9o551om002fjqrrlyxp15pu","category_id":"cl9o551ox0038jqrrs9fght1t","_id":"cl9o551p9004fjqrri4265j08"},{"post_id":"cl9o551on002hjqrrss8ropzp","category_id":"cl9o551ox0038jqrrs9fght1t","_id":"cl9o551p9004hjqrrv654fn2n"},{"post_id":"cl9o551op002ljqrrq7npbk4m","category_id":"cl9o551ox0038jqrrs9fght1t","_id":"cl9o551p9004jjqrrmwqxd8rl"},{"post_id":"cl9o551oq002njqrrmmbb3alb","category_id":"cl9o551ox0038jqrrs9fght1t","_id":"cl9o551p9004ljqrr6tza022p"},{"post_id":"cl9o551or002rjqrr1rjecr5f","category_id":"cl9o551ox0038jqrrs9fght1t","_id":"cl9o551pa004njqrrlkt4kpqj"},{"post_id":"cl9o551or002tjqrr31k973aa","category_id":"cl9o551ox0038jqrrs9fght1t","_id":"cl9o551pa004pjqrrgn5qwyaa"},{"post_id":"cl9o551os002xjqrrmon6agv1","category_id":"cl9o551ox0038jqrrs9fght1t","_id":"cl9o551pa004qjqrr8gelilua"},{"post_id":"cl9o551ou0030jqrresgqmqim","category_id":"cl9o551pa004ojqrrpso5l46z","_id":"cl9o551pa004tjqrrbivrpzeo"},{"post_id":"cl9o551ov0034jqrrpj3w6872","category_id":"cl9o551pa004ojqrrpso5l46z","_id":"cl9o551pb004vjqrruhng16rt"},{"post_id":"cl9o551ow0037jqrrtowvws4s","category_id":"cl9o551pa004ojqrrpso5l46z","_id":"cl9o551pb004xjqrrjblbtemr"},{"post_id":"cl9o551ox003bjqrrc5jvcdmr","category_id":"cl9o551pa004ojqrrpso5l46z","_id":"cl9o551pb004zjqrr7xg28sl9"},{"post_id":"cl9o551p0003ijqrr8fh0ou6g","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551pb0053jqrribkfum4n"},{"post_id":"cl9o551p1003mjqrrwyezymh8","category_id":"cl9o551pa004ojqrrpso5l46z","_id":"cl9o551pc0055jqrrvgwzn7h6"},{"post_id":"cl9o551p1003ojqrrdm9cv33m","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551pc0057jqrrfau2yzbe"},{"post_id":"cl9o551p2003rjqrrzokhxqxv","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551pc0058jqrrrwol6sir"},{"post_id":"cl9o551p3003tjqrr43qd30th","category_id":"cl9o551pc0056jqrr37o0dh24","_id":"cl9o551pc005bjqrrhncaccr7"},{"post_id":"cl9o551p5003wjqrrjki0haa0","category_id":"cl9o551pc0056jqrr37o0dh24","_id":"cl9o551pd005djqrree2avnvi"},{"post_id":"cl9o551p5003yjqrrdecgl277","category_id":"cl9o551pc0056jqrr37o0dh24","_id":"cl9o551pd005ejqrr4wc5mcut"},{"post_id":"cl9o551ox003cjqrrcrt5xhdg","category_id":"cl9o551pa004ojqrrpso5l46z","_id":"cl9o551pd005gjqrrlm0gwbj5"},{"post_id":"cl9o551ox003cjqrrcrt5xhdg","category_id":"cl9o551pc005cjqrrhjx4rjtm","_id":"cl9o551pd005hjqrrpnszpwj6"},{"post_id":"cl9o551oz003hjqrrkmyigdj1","category_id":"cl9o551pa004ojqrrpso5l46z","_id":"cl9o551pd005ijqrrgc7oierb"},{"post_id":"cl9o551oz003hjqrrkmyigdj1","category_id":"cl9o551pd005fjqrrv2s8wu0z","_id":"cl9o551pd005jjqrrj8jzqz08"},{"post_id":"cl9o551qe005ojqrrhnsd7ttm","category_id":"cl9o551qd005mjqrrmi7z3orm","_id":"cl9o551qj0065jqrrbjec9w3j"},{"post_id":"cl9o551qe005ojqrrhnsd7ttm","category_id":"cl9o551qh005xjqrr2mwcjraj","_id":"cl9o551qo0069jqrr3s2ujfg9"},{"post_id":"cl9o551qa005kjqrrvbomas32","category_id":"cl9o551qd005mjqrrmi7z3orm","_id":"cl9o551qp006cjqrrv9ehnx4t"},{"post_id":"cl9o551qa005kjqrrvbomas32","category_id":"cl9o551qi0061jqrrmz3xr6zb","_id":"cl9o551qp006fjqrrkrhoeucn"},{"post_id":"cl9o551qf005pjqrrja9fecpt","category_id":"cl9o551qd005mjqrrmi7z3orm","_id":"cl9o551qq006ijqrrd7j0eorh"},{"post_id":"cl9o551qf005pjqrrja9fecpt","category_id":"cl9o551qk0066jqrr8otwtl7f","_id":"cl9o551qq006ljqrrylpwycgl"},{"post_id":"cl9o551qf005rjqrrhcvt63fm","category_id":"cl9o551qd005mjqrrmi7z3orm","_id":"cl9o551qs006ojqrr4hblusw9"},{"post_id":"cl9o551qf005rjqrrhcvt63fm","category_id":"cl9o551qp006djqrrulq178d6","_id":"cl9o551qw006rjqrrbymgla46"},{"post_id":"cl9o551qb005ljqrrj3otbs91","category_id":"cl9o551qd005mjqrrmi7z3orm","_id":"cl9o551qw006ujqrrw2f967k4"},{"post_id":"cl9o551qb005ljqrrj3otbs91","category_id":"cl9o551qq006kjqrrq4qcwhx7","_id":"cl9o551qx006wjqrr0z3h498g"},{"post_id":"cl9o551qg005sjqrr47jkkz1s","category_id":"cl9o551qd005mjqrrmi7z3orm","_id":"cl9o551qx006zjqrrufl1n47b"},{"post_id":"cl9o551qg005sjqrr47jkkz1s","category_id":"cl9o551qp006djqrrulq178d6","_id":"cl9o551qy0071jqrrv368gi7e"},{"post_id":"cl9o551qh005vjqrrpiup3ldm","category_id":"cl9o551qd005mjqrrmi7z3orm","_id":"cl9o551qy0074jqrrs4svlghc"},{"post_id":"cl9o551qh005vjqrrpiup3ldm","category_id":"cl9o551qp006djqrrulq178d6","_id":"cl9o551qz0076jqrrkwghrh0r"},{"post_id":"cl9o551qd005njqrrdlbkjz7u","category_id":"cl9o551qd005mjqrrmi7z3orm","_id":"cl9o551qz0079jqrr22xokvzp"},{"post_id":"cl9o551qd005njqrrdlbkjz7u","category_id":"cl9o551qq006kjqrrq4qcwhx7","_id":"cl9o551r0007cjqrrncgbr1q7"},{"post_id":"cl9o551qh005wjqrrztfpybeb","category_id":"cl9o551qd005mjqrrmi7z3orm","_id":"cl9o551r1007fjqrrvlec19ll"},{"post_id":"cl9o551qh005wjqrrztfpybeb","category_id":"cl9o551qp006djqrrulq178d6","_id":"cl9o551r2007hjqrr1wibimpg"},{"post_id":"cl9o551qh005yjqrr2ayicpci","category_id":"cl9o551qd005mjqrrmi7z3orm","_id":"cl9o551r5007kjqrr14gj1fq4"},{"post_id":"cl9o551qh005yjqrr2ayicpci","category_id":"cl9o551qp006djqrrulq178d6","_id":"cl9o551r6007mjqrrouxk3qi5"},{"post_id":"cl9o551qi0060jqrrk1dk1mq0","category_id":"cl9o551qd005mjqrrmi7z3orm","_id":"cl9o551r6007ojqrryww5z4j3"},{"post_id":"cl9o551qi0060jqrrk1dk1mq0","category_id":"cl9o551qp006djqrrulq178d6","_id":"cl9o551r7007rjqrrssv1riaf"},{"post_id":"cl9o551qp006ejqrr81m6tagn","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551rq0086jqrr76cl8d7r"},{"post_id":"cl9o551qp006ejqrr81m6tagn","category_id":"cl9o551rf007zjqrr480trm4s","_id":"cl9o551rq0088jqrrpald4seh"},{"post_id":"cl9o551qp006hjqrrp3hk6vb3","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551rq008ajqrrxhjbjzqd"},{"post_id":"cl9o551qp006hjqrrp3hk6vb3","category_id":"cl9o551rf007zjqrr480trm4s","_id":"cl9o551rr008djqrr99s20gs9"},{"post_id":"cl9o551qq006jjqrr8l4fzcd9","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551rw008hjqrr9p8wqv7p"},{"post_id":"cl9o551qq006jjqrr8l4fzcd9","category_id":"cl9o551rp0085jqrr7jh70lq3","_id":"cl9o551rw008ijqrry5b3v7yn"},{"post_id":"cl9o551qq006mjqrr2iqcme13","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551rw008kjqrradbkv05p"},{"post_id":"cl9o551qq006mjqrr2iqcme13","category_id":"cl9o551rf007zjqrr480trm4s","_id":"cl9o551rw008ljqrrxaupt16a"},{"post_id":"cl9o551qr006njqrr46ysdxru","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551rx008njqrrom315bt3"},{"post_id":"cl9o551qr006njqrr46ysdxru","category_id":"cl9o551rp0085jqrr7jh70lq3","_id":"cl9o551rx008ojqrr6mb1isqy"},{"post_id":"cl9o551qv006qjqrru3hphcwr","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551rx008qjqrrza8xiw4e"},{"post_id":"cl9o551qv006qjqrru3hphcwr","category_id":"cl9o551rp0085jqrr7jh70lq3","_id":"cl9o551rx008rjqrrcfmp6iov"},{"post_id":"cl9o551qw006sjqrrbhzyjl22","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551rx008tjqrrlcf2rl3z"},{"post_id":"cl9o551qw006sjqrrbhzyjl22","category_id":"cl9o551rp0085jqrr7jh70lq3","_id":"cl9o551rx008ujqrr18un7wq3"},{"post_id":"cl9o551qx006xjqrrvg562gdp","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551ry008xjqrrzxnzm1ba"},{"post_id":"cl9o551qx006xjqrrvg562gdp","category_id":"cl9o551rp0085jqrr7jh70lq3","_id":"cl9o551ry008yjqrreww23ki6"},{"post_id":"cl9o551qx0070jqrro7fg7ewj","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551ry0090jqrrsh82kenm"},{"post_id":"cl9o551qx0070jqrro7fg7ewj","category_id":"cl9o551rf007zjqrr480trm4s","_id":"cl9o551rz0091jqrr1lmlozzf"},{"post_id":"cl9o551qy0072jqrr60zqd407","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551rz0093jqrrsdk9qp0k"},{"post_id":"cl9o551qy0072jqrr60zqd407","category_id":"cl9o551rp0085jqrr7jh70lq3","_id":"cl9o551rz0094jqrr74w7wtls"},{"post_id":"cl9o551qy0075jqrr9g9ywftv","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551rz0096jqrr6bzruhqj"},{"post_id":"cl9o551qy0075jqrr9g9ywftv","category_id":"cl9o551rp0085jqrr7jh70lq3","_id":"cl9o551rz0097jqrrhqi87oev"},{"post_id":"cl9o551qz0077jqrrrtwm1fsw","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s00099jqrrxtm73pur"},{"post_id":"cl9o551qz0077jqrrrtwm1fsw","category_id":"cl9o551rp0085jqrr7jh70lq3","_id":"cl9o551s0009ajqrrupa9nv8q"},{"post_id":"cl9o551r0007bjqrrt48j34fy","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s0009cjqrr57lqtbde"},{"post_id":"cl9o551r0007bjqrrt48j34fy","category_id":"cl9o551rp0085jqrr7jh70lq3","_id":"cl9o551s0009djqrry5ljtbaa"},{"post_id":"cl9o551r0007djqrrweorslnj","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s0009fjqrrx8ev4r6i"},{"post_id":"cl9o551r0007djqrrweorslnj","category_id":"cl9o551rp0085jqrr7jh70lq3","_id":"cl9o551s0009gjqrr0qm3tcaa"},{"post_id":"cl9o551r1007gjqrrxpgibgue","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s0009hjqrr47rbbgje"},{"post_id":"cl9o551r1007gjqrrxpgibgue","category_id":"cl9o551rp0085jqrr7jh70lq3","_id":"cl9o551s0009jjqrrubj4r3df"},{"post_id":"cl9o551r3007ijqrr3og07txs","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s1009kjqrrbickss7l"},{"post_id":"cl9o551r3007ijqrr3og07txs","category_id":"cl9o551s0009ejqrr8ps7o9qo","_id":"cl9o551s1009mjqrrpqgy0xlm"},{"post_id":"cl9o551r5007ljqrr34t4xrp8","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s1009njqrr58yji87d"},{"post_id":"cl9o551r5007ljqrr34t4xrp8","category_id":"cl9o551s0009ijqrr7dh6lcdo","_id":"cl9o551s1009pjqrrnf6ate18"},{"post_id":"cl9o551qj0063jqrrw5ekwuym","category_id":"cl9o551r5007jjqrru6ypn7l8","_id":"cl9o551s1009rjqrrns1ms08x"},{"post_id":"cl9o551qj0063jqrrw5ekwuym","category_id":"cl9o551s1009ljqrrp4nbnhtd","_id":"cl9o551s1009sjqrr92ezic7q"},{"post_id":"cl9o551r6007njqrrvwa9dkm2","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s1009ujqrrvoz5p2vl"},{"post_id":"cl9o551r6007njqrrvwa9dkm2","category_id":"cl9o551s0009ijqrr7dh6lcdo","_id":"cl9o551s1009vjqrrsjmi92c1"},{"post_id":"cl9o551r7007qjqrrg3na7ov9","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s2009xjqrr725tv8s5"},{"post_id":"cl9o551r7007qjqrrg3na7ov9","category_id":"cl9o551s0009ijqrr7dh6lcdo","_id":"cl9o551s2009yjqrr0aew2vhd"},{"post_id":"cl9o551qj0064jqrrch26x58k","category_id":"cl9o551r5007jjqrru6ypn7l8","_id":"cl9o551s200a0jqrron3zyev1"},{"post_id":"cl9o551qj0064jqrrch26x58k","category_id":"cl9o551s1009ljqrrp4nbnhtd","_id":"cl9o551s200a1jqrr9xs61ujv"},{"post_id":"cl9o551r7007sjqrr3663daba","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s200a3jqrrqngimijo"},{"post_id":"cl9o551r7007sjqrr3663daba","category_id":"cl9o551s0009ijqrr7dh6lcdo","_id":"cl9o551s200a4jqrrlxuewv5k"},{"post_id":"cl9o551r8007ujqrrnzdpljet","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s200a6jqrr23v2hgc9"},{"post_id":"cl9o551r8007ujqrrnzdpljet","category_id":"cl9o551s0009ijqrr7dh6lcdo","_id":"cl9o551s300a7jqrrh1zp8olz"},{"post_id":"cl9o551ql0067jqrrga2902zq","category_id":"cl9o551r5007jjqrru6ypn7l8","_id":"cl9o551s300a9jqrrnspa9d02"},{"post_id":"cl9o551ql0067jqrrga2902zq","category_id":"cl9o551s1009ljqrrp4nbnhtd","_id":"cl9o551s300aajqrr6dzgfjyw"},{"post_id":"cl9o551rb007vjqrrwhvw9ljx","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s300acjqrrwu0x7bqv"},{"post_id":"cl9o551rb007vjqrrwhvw9ljx","category_id":"cl9o551s0009ijqrr7dh6lcdo","_id":"cl9o551s300adjqrrdobgimp7"},{"post_id":"cl9o551rd007xjqrry43cn6z9","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s300aejqrrqbacli6s"},{"post_id":"cl9o551rd007xjqrry43cn6z9","category_id":"cl9o551s0009ijqrr7dh6lcdo","_id":"cl9o551s300agjqrr0152mcnn"},{"post_id":"cl9o551qo006bjqrrkgi0ovka","category_id":"cl9o551r5007jjqrru6ypn7l8","_id":"cl9o551s300ahjqrrnn9hlanl"},{"post_id":"cl9o551qo006bjqrrkgi0ovka","category_id":"cl9o551s300abjqrr4j3p1dmh","_id":"cl9o551s300ajjqrrqu8qrk3j"},{"post_id":"cl9o551rf007yjqrreg8w68nb","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s400aljqrr2bkah8l6"},{"post_id":"cl9o551rf007yjqrreg8w68nb","category_id":"cl9o551s300afjqrrbsk9dkb3","_id":"cl9o551s400amjqrrx3l14hl7"},{"post_id":"cl9o551rj0080jqrrhrr1x4is","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s400aojqrr3tdcr5mx"},{"post_id":"cl9o551rj0080jqrrhrr1x4is","category_id":"cl9o551s300afjqrrbsk9dkb3","_id":"cl9o551s400apjqrrzmikgire"},{"post_id":"cl9o551rk0081jqrr58f2xb5f","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s400arjqrrvb2ei9gq"},{"post_id":"cl9o551rk0081jqrr58f2xb5f","category_id":"cl9o551s300afjqrrbsk9dkb3","_id":"cl9o551s400asjqrrt5qc6ztb"},{"post_id":"cl9o551rp0083jqrryvq38avw","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s400aujqrr0m7nww0l"},{"post_id":"cl9o551rp0083jqrryvq38avw","category_id":"cl9o551s300afjqrrbsk9dkb3","_id":"cl9o551s500avjqrr0w1694kj"},{"post_id":"cl9o551rp0084jqrryd6y34hu","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s500axjqrrxtbizkrd"},{"post_id":"cl9o551rp0084jqrryd6y34hu","category_id":"cl9o551s300afjqrrbsk9dkb3","_id":"cl9o551s500ayjqrrljfq4bfz"},{"post_id":"cl9o551rq0087jqrridgc85yr","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s500b0jqrrt2e5kxb7"},{"post_id":"cl9o551rq0087jqrridgc85yr","category_id":"cl9o551s300afjqrrbsk9dkb3","_id":"cl9o551s500b1jqrrs0wbqgvb"},{"post_id":"cl9o551rq0089jqrr5wbsif8f","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s500b3jqrrvbonk39v"},{"post_id":"cl9o551rq0089jqrr5wbsif8f","category_id":"cl9o551s300afjqrrbsk9dkb3","_id":"cl9o551s500b4jqrrnvhbvd9w"},{"post_id":"cl9o551rq008bjqrrx9sevq5y","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s600b6jqrrmfp9mbww"},{"post_id":"cl9o551rq008bjqrrx9sevq5y","category_id":"cl9o551s300afjqrrbsk9dkb3","_id":"cl9o551s600b7jqrres0ol6hh"},{"post_id":"cl9o551rr008ejqrrgqbkth5t","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s600b8jqrrgd2ihctr"},{"post_id":"cl9o551rr008ejqrrgqbkth5t","category_id":"cl9o551s300afjqrrbsk9dkb3","_id":"cl9o551s600bajqrrx8qtrdam"},{"post_id":"cl9o551rv008fjqrro2kuchlr","category_id":"cl9o551pb0050jqrr3sx3to5c","_id":"cl9o551s600bbjqrralne9ukk"},{"post_id":"cl9o551rv008fjqrro2kuchlr","category_id":"cl9o551s500b5jqrrdx55s50t","_id":"cl9o551s600bcjqrr2t2xpvyo"},{"post_id":"cl9o551qw006vjqrrkmjp3t5b","category_id":"cl9o551r5007jjqrru6ypn7l8","_id":"cl9o551s600bdjqrr301bw9io"},{"post_id":"cl9o551qw006vjqrrkmjp3t5b","category_id":"cl9o551s1009ljqrrp4nbnhtd","_id":"cl9o551s600bejqrryrbc6yj6"}],"PostTag":[{"post_id":"cl9o551nz0008jqrrdgiulxo3","tag_id":"cl9o551ny0006jqrrruhxe1si","_id":"cl9o551o4000cjqrrhj3yftyv"},{"post_id":"cl9o551o00009jqrr09luyjkz","tag_id":"cl9o551ny0006jqrrruhxe1si","_id":"cl9o551o6000ejqrr2pt97yfe"},{"post_id":"cl9o551o4000djqrriljwauk8","tag_id":"cl9o551ny0006jqrrruhxe1si","_id":"cl9o551o7000jjqrrmn4nufea"},{"post_id":"cl9o551ns0003jqrrsy54fx4t","tag_id":"cl9o551ny0006jqrrruhxe1si","_id":"cl9o551o7000mjqrrf0zp7nxy"},{"post_id":"cl9o551ns0003jqrrsy54fx4t","tag_id":"cl9o551o2000bjqrrl2fuyv36","_id":"cl9o551o8000rjqrrbi2v9enh"},{"post_id":"cl9o551nv0004jqrrm844gqrs","tag_id":"cl9o551ny0006jqrrruhxe1si","_id":"cl9o551oa0010jqrr722tla2z"},{"post_id":"cl9o551nv0004jqrrm844gqrs","tag_id":"cl9o551o2000bjqrrl2fuyv36","_id":"cl9o551oa0012jqrr214ibxqp"},{"post_id":"cl9o551ny0007jqrri69yfdh8","tag_id":"cl9o551ny0006jqrrruhxe1si","_id":"cl9o551ob0017jqrr6xmm9bo5"},{"post_id":"cl9o551o6000fjqrr8r6ix55h","tag_id":"cl9o551oa0014jqrrk2xch20a","_id":"cl9o551oc001djqrrxo4nj2ji"},{"post_id":"cl9o551o7000njqrrk6e4vfg2","tag_id":"cl9o551oa0014jqrrk2xch20a","_id":"cl9o551od001jjqrrc7g8x854"},{"post_id":"cl9o551o9000ujqrr1x3e1y6p","tag_id":"cl9o551oc001gjqrrmcc18do0","_id":"cl9o551oe001ojqrryoburaf4"},{"post_id":"cl9o551og001ujqrrzi9rqj6k","tag_id":"cl9o551oh001yjqrrkxkhm1y2","_id":"cl9o551ok0025jqrr4uzinv85"},{"post_id":"cl9o551oh001xjqrr5kgple8s","tag_id":"cl9o551ok0024jqrr3rylq1jx","_id":"cl9o551om002cjqrreycaamfs"},{"post_id":"cl9o551oh001zjqrrus0alk49","tag_id":"cl9o551ol002ajqrr1mf4pdui","_id":"cl9o551op002kjqrrmm7ni489"},{"post_id":"cl9o551oj0022jqrr45mc7xxd","tag_id":"cl9o551ok0024jqrr3rylq1jx","_id":"cl9o551or002qjqrrysxx5m54"},{"post_id":"cl9o551ol0029jqrrvaytn3k9","tag_id":"cl9o551oq002mjqrrvghx1eah","_id":"cl9o551os002wjqrr1j9l2wtf"},{"post_id":"cl9o551or002tjqrr31k973aa","tag_id":"cl9o551oq002mjqrrvghx1eah","_id":"cl9o551ou002yjqrrmqz7giup"},{"post_id":"cl9o551om002bjqrrgs1jv5nv","tag_id":"cl9o551oq002mjqrrvghx1eah","_id":"cl9o551ov0033jqrrc80wukgy"},{"post_id":"cl9o551os002xjqrrmon6agv1","tag_id":"cl9o551oq002mjqrrvghx1eah","_id":"cl9o551ow0035jqrrvhej6zfx"},{"post_id":"cl9o551om002fjqrrlyxp15pu","tag_id":"cl9o551oq002mjqrrvghx1eah","_id":"cl9o551ox003ajqrrh2feegi3"},{"post_id":"cl9o551op002ljqrrq7npbk4m","tag_id":"cl9o551ow0036jqrrso4vdlny","_id":"cl9o551oz003gjqrry0qu7jz3"},{"post_id":"cl9o551ov0034jqrrpj3w6872","tag_id":"cl9o551oz003djqrryoh2xuwi","_id":"cl9o551p1003njqrrjgb1gk2r"},{"post_id":"cl9o551ow0037jqrrtowvws4s","tag_id":"cl9o551oz003djqrryoh2xuwi","_id":"cl9o551p2003sjqrrl6xnbjhz"},{"post_id":"cl9o551p3003tjqrr43qd30th","tag_id":"cl9o551p5003xjqrrki7vetct","_id":"cl9o551p70044jqrrrdklo18m"},{"post_id":"cl9o551p5003wjqrrjki0haa0","tag_id":"cl9o551p70041jqrrdtzdcncj","_id":"cl9o551p80048jqrrjxld5yws"},{"post_id":"cl9o551p5003yjqrrdecgl277","tag_id":"cl9o551p5003xjqrrki7vetct","_id":"cl9o551p8004bjqrr5llc53sy"},{"post_id":"cl9o551qf005rjqrrhcvt63fm","tag_id":"cl9o551qg005ujqrr7co1m4hj","_id":"cl9o551qi005zjqrr6bfg9to8"},{"post_id":"cl9o551qh005yjqrr2ayicpci","tag_id":"cl9o551qi0062jqrr5o7tuf54","_id":"cl9o551qo006ajqrr8ciovk6i"},{"post_id":"cl9o551qi0060jqrrk1dk1mq0","tag_id":"cl9o551qi0062jqrr5o7tuf54","_id":"cl9o551qp006gjqrrgyio4g3b"},{"post_id":"cl9o551qy0075jqrr9g9ywftv","tag_id":"cl9o551qi0062jqrr5o7tuf54","_id":"cl9o551qz007ajqrr7sh2b6vj"}],"Tag":[{"name":"Tensorflow","_id":"cl9o551ny0006jqrrruhxe1si"},{"name":"Pytorch","_id":"cl9o551o2000bjqrrl2fuyv36"},{"name":"前端","_id":"cl9o551oa0014jqrrk2xch20a"},{"name":"《推荐系统实战》","_id":"cl9o551oc001gjqrrmcc18do0"},{"name":"CART","_id":"cl9o551oh001yjqrrkxkhm1y2"},{"name":"XGBoost","_id":"cl9o551ok0024jqrr3rylq1jx"},{"name":"时间序列","_id":"cl9o551ol002ajqrr1mf4pdui"},{"name":"特征工程","_id":"cl9o551oq002mjqrrvghx1eah"},{"name":"SVM","_id":"cl9o551ow0036jqrrso4vdlny"},{"name":"李宏毅-ML2020","_id":"cl9o551oz003djqrryoh2xuwi"},{"name":"word2vec","_id":"cl9o551p5003xjqrrki7vetct"},{"name":"《自然语言处理入门》","_id":"cl9o551p70041jqrrdtzdcncj"},{"name":"模型上线","_id":"cl9o551qg005ujqrr7co1m4hj"},{"name":"并发","_id":"cl9o551qi0062jqrr5o7tuf54"}]}}