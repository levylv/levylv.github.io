---
title: CART与普通决策树的区别
date: 2019-04-29 19:28:44 
tags: CART
categories: 机器学习
---



CART可以说是最常用的数，gbdt,xgboost等等...

归纳一下其与普通决策树（ID3，C4.5）的区别：

- 既可以分类，也可以回归。在分类时使用基尼系数，在回归时使用平方误差。
- 只划分左右子树，也就是生成一个二叉树。普通决策树生成多个子树
- 特征在被选择后，在接下来的树中还能被继续使用。普通决策树只使用特征一次。
- 连续特征，n个值，从n-1个中间值中选择；离散特征，n个值，有$2^{(n-1)} - 1$个选择可能(通常是one hot编码)。

