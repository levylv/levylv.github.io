---
title: Dead ReLu问题
date: 2019-05-16 19:28:44 
categories: 深度学习
---



原因很简单，是因为函数的负数区间值为0，导数为0，导致权重不更新。

 

但实际上，真要出现永久dead还是很严苛的：

- 所用训练样本x在该神经元的输入值都是 < 0
-  一般都是网络第一层，前面没有隐藏层。因为如果有隐藏层，隐藏层不死的话，隐藏层输出值还是会变，同样的x, 输入到该层还是有可能被激活。

 

BP经典公式：

该神经元某条链路w导数 = 前面的导数累计 * 该神经元导数值 * 该链路输入值x

